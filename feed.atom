<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>Planète PostgreSQL</title>
  <id>https://planete.postgresql.fr/</id>
  <updated>2025-03-18T16:43:31Z</updated>
  <subtitle>L&#39;actualité de PostgreSQL de français</subtitle>
  <link href="https://planete.postgresql.fr/"></link>
  <author>
    <name>PostgreSQL.fr</name>
    <email>contact@postgresql.fr</email>
  </author>
  <entry>
    <title>PostgreSQL Extension Day 2025</title>
    <updated>2025-03-17T08:30:00Z</updated>
    <id>tag:www.loxodata.com,2025-03-17:/post/pgext-day-2025/</id>
    <link href="http://www.loxodata.com/post/pgext-day-2025/" rel="alternate"></link>
    <summary type="html">&lt;h2 id=&#34;postgresql-extension-day-2025&#34;&gt;PostgreSQL Extension Day 2025&lt;/h2&gt;&#xA;&lt;p&gt;Le 12 mai 2025 se tiendra l&amp;rsquo;événement gratuit &lt;a href=&#34;https://pgext.day/&#34;&gt;PostgreSQL Extension Day&lt;/a&gt; à Montréal, soit la veille de la conférence PostgreSQL &lt;a href=&#34;https://2025.pgconf.dev/&#34;&gt;PGConf.dev&lt;/a&gt; qui se tiendra pour sa part du 13 au 15 mai. Cette conférence n&amp;rsquo;est toutefois pas affiliée à la &lt;a href=&#34;https://2025.pgconf.dev/&#34;&gt;PGConf.dev&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Ce rassemblement a pour but de réunir tous les acteurs qui contribuent et utilisent les extensions de PostgreSQL constituant un écosystème de plusieurs centaines de projets : près de 400 actuellement. Le &lt;a href=&#34;https://pgext.day/&#34;&gt;PostgreSQL Extension Day&lt;/a&gt; est organisé par le groupe &lt;a href=&#34;https://github.com/pgedc&#34;&gt;Postgres Extension Developers Coalition&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Le &lt;a href=&#34;https://sessionize.com/pgextday2025mtl&#34;&gt;CFP&lt;/a&gt; est ouvert jusqu&amp;rsquo;au 1er avril 2025, et les inscriptions sont ouvertes par &lt;a href=&#34;https://pgextday2025mtl.eventbrite.ca/&#34;&gt;ici&lt;/a&gt;.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>L&#39;extension pg_trgm</title>
    <updated>2025-03-07T08:20:00Z</updated>
    <id>tag:www.loxodata.com,2025-03-07:/post/pg_trgm/</id>
    <link href="http://www.loxodata.com/post/pg_trgm/" rel="alternate"></link>
    <summary type="html">&lt;h1 id=&#34;lextension-pg_trgm&#34;&gt;L&amp;rsquo;extension pg_trgm&lt;/h1&gt;&#xA;&lt;h2 id=&#34;présentation&#34;&gt;Présentation&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;rsquo;extension &lt;code&gt;pg_trgm&lt;/code&gt; (trigrammes) est fournie dans la distribution standard de PostgreSQL. Elle est présente dans &lt;code&gt;/contrib&lt;/code&gt; et s&amp;rsquo;installe simplement dans une base de données :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# CREATE EXTENSION IF NOT EXISTS pg_trgm;&#xA;CREATE EXTENSION&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cette extension permet de décomposer une chaîne de caractères en succession de sous-chaînes de 3 caractères (trigrammes), afin de permettre des recherches sur une sous-chaîne, ou bien des recherches de similarité entre chaînes de caractères.&lt;/p&gt;&#xA;&lt;h2 id=&#34;fonctionnement&#34;&gt;Fonctionnement&lt;/h2&gt;&#xA;&lt;h3 id=&#34;jeu-dessai&#34;&gt;Jeu d&amp;rsquo;essai&lt;/h3&gt;&#xA;&lt;p&gt;Dans le cadre de cette présentation, je me suis constitué une table d&amp;rsquo;un million de lignes, laquelle contient un champ &lt;code&gt;family&lt;/code&gt; contenant un nom de famille parmi les 1000 plus fréquent en France, et dont la fréquence dans la table est semblable à celle de la population française :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# \dS my_datas&#xA;                              Table &amp;#34;public.my_datas&amp;#34;&#xA;   Column    |  Type  | Collation | Nullable |               Default&#xA;-------------+--------+-----------+----------+--------------------------------------&#xA; id          | bigint |           | not null | nextval(&amp;#39;my_datas_id_seq&amp;#39;::regclass)&#xA; random_text | text   |           |          |&#xA; family      | text   |           |          |&#xA;Indexes:&#xA;    &amp;#34;idx_test_id&amp;#34; btree (id)&#xA;&#xA;loxodata_text=# SELECT count(1) FROM my_datas;&#xA;  count&#xA;---------&#xA; 1000204&#xA;(1 row)&#xA;&#xA;loxodata_text=# SELECT * FROM my_datas LIMIT 5;&#xA;   id   |             random_text              | family&#xA;--------+--------------------------------------+---------&#xA; 211685 | 94376bb6-3655-4a65-b61a-8dbec927c5e5 | GRANGER&#xA; 211686 | 7f9f8a34-13f2-4459-bd2c-e4b90a7eca9b | LE ROUX&#xA; 211687 | 526549b3-13fe-4aae-87c1-4a5480cf6898 | FUCHS&#xA; 211688 | 1acbdde8-b4cd-4bf8-957c-84adf1c6cf1c | BRUNET&#xA; 211689 | 77cd8645-bfe8-471c-a118-3dbe507d8e8f | LAMBERT&#xA;(5 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;décomposition&#34;&gt;Décomposition&lt;/h3&gt;&#xA;&lt;p&gt;On peut visualiser la décomposition en trigrammes avec la fonction &lt;code&gt;show_trgm()&lt;/code&gt; :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# SELECT show_trgm(&amp;#39;GRANGER&amp;#39;);&#xA;                show_trgm&#xA;-----------------------------------------&#xA; {&amp;#34;  g&amp;#34;,&amp;#34; gr&amp;#34;,ang,&amp;#34;er &amp;#34;,ger,gra,nge,ran}&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;similarité&#34;&gt;Similarité&lt;/h3&gt;&#xA;&lt;p&gt;La fonction &lt;code&gt;similarity()&lt;/code&gt; permet de tester la similarité entre deux chaînes de caractères. Le résultat est un score entre 0 et 1. Zéro indique qu&amp;rsquo;il n&amp;rsquo;y a aucun trigramme en commun entre les deux chaînes, tandis que 1 indique que les deux chaînes sont identiques. On peut ainsi tester la similarité entre deux noms de famille :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# select similarity(&amp;#39;GRANGER&amp;#39;,&amp;#39;BRUNET&amp;#39;);&#xA; similarity&#xA;------------&#xA;          0&#xA;(1 row)&#xA;&#xA;loxodata_text=# select similarity(&amp;#39;GRANGER&amp;#39;,&amp;#39;GRANGE&amp;#39;);&#xA; similarity&#xA;------------&#xA;  0.6666667&#xA;(1 row)&#xA;&#xA;loxodata_text=# select similarity(&amp;#39;GRANGER&amp;#39;,&amp;#39;GRANIER&amp;#39;);&#xA; similarity&#xA;------------&#xA; 0.45454547&#xA;(1 row)&#xA;&#xA;loxodata_text=# select similarity(&amp;#39;GRANGER&amp;#39;,&amp;#39;LEGRAND&amp;#39;);&#xA; similarity&#xA;------------&#xA; 0.14285715&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;L&amp;rsquo;opérateur booléen de similarité entre deux chaînes est &lt;code&gt;%&lt;/code&gt; :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# select &amp;#39;GRANGER&amp;#39; % &amp;#39;GRANIER&amp;#39;;&#xA; ?column?&#xA;----------&#xA; t&#xA;(1 row)&#xA;&#xA;loxodata_text=# select &amp;#39;GRANGER&amp;#39; % &amp;#39;LEGRAND&amp;#39;;&#xA; ?column?&#xA;----------&#xA; f&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;L&amp;rsquo;opérateur booléen retourne &lt;code&gt;True&lt;/code&gt; si le score de similarité excède une limite fixée par défaut à &lt;code&gt;0.3&lt;/code&gt;. La limite courante peut être consultée avec la fonction &lt;code&gt;show_limit()&lt;/code&gt; :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# select show_limit();&#xA; show_limit&#xA;------------&#xA;        0.3&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Et cette limite peut être modifiée au niveau de la session avec la fonction &lt;code&gt;set_limit()&lt;/code&gt;. Ainsi, si on passe le seuil à &lt;code&gt;0.1&lt;/code&gt;, &amp;lsquo;GRANGER&amp;rsquo; et &amp;lsquo;LEGRAND&amp;rsquo; sont désormais considérés comme similaires :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# select set_limit(0.1);&#xA; set_limit&#xA;-----------&#xA;       0.1&#xA;(1 row)&#xA;&#xA;loxodata_text=# select &amp;#39;GRANGER&amp;#39; % &amp;#39;LEGRAND&amp;#39;;&#xA; ?column?&#xA;----------&#xA; t&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cette limite peut être configurée au niveau du cluster avec le paramètre &lt;code&gt;pg_trgm.similarity_threshold&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;indexation-et-performances&#34;&gt;Indexation et performances&lt;/h2&gt;&#xA;&lt;h3 id=&#34;lindexation-btree-classique&#34;&gt;L&amp;rsquo;indexation BTREE classique&lt;/h3&gt;&#xA;&lt;p&gt;Les champs TEXT peuvent être indexés classiquement avec un index BTREE :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# CREATE INDEX idx_test ON my_datas(family text_pattern_ops);&#xA;CREATE INDEX&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cela permet de trouver rapidement des chaînes de caractères ou des débuts de chaînes de caractères :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT id FROM my_datas WHERE family = &amp;#39;GRANGER&amp;#39;;&#xA;                                                     QUERY PLAN&#xA;---------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=10.09..2289.04 rows=731 width=8) (actual time=0.101..0.584 rows=658 loops=1)&#xA;   Recheck Cond: (family = &amp;#39;GRANGER&amp;#39;::text)&#xA;   Heap Blocks: exact=637&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test  (cost=0.00..9.91 rows=731 width=0) (actual time=0.047..0.047 rows=658 loops=1)&#xA;         Index Cond: (family = &amp;#39;GRANGER&amp;#39;::text)&#xA; Planning Time: 0.120 ms&#xA; Execution Time: 0.612 ms&#xA;(7 rows)&#xA;&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT id FROM my_datas WHERE family like  &amp;#39;GRAN%&amp;#39;;&#xA;                                                      QUERY PLAN&#xA;-----------------------------------------------------------------------------------------------------------------------&#xA; Index Scan using idx_test on my_datas  (cost=0.42..8.45 rows=66 width=8) (actual time=0.024..2.121 rows=3692 loops=1)&#xA;   Index Cond: ((family ~&amp;gt;=~ &amp;#39;GRAN&amp;#39;::text) AND (family ~&amp;lt;~ &amp;#39;GRAO&amp;#39;::text))&#xA;   Filter: (family ~~ &amp;#39;GRAN%&amp;#39;::text)&#xA; Planning Time: 0.137 ms&#xA; Execution Time: 2.234 ms&#xA;(5 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cependant un tel index se révèle inutile lorsqu&amp;rsquo;on ne connaît pas le début de la chaîne recherchée. Dans ce cas on bascule sur un Seq Scan malgré la présence de l&amp;rsquo;index :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT id FROM my_datas WHERE family like  &amp;#39;%ANGER&amp;#39;;&#xA;                                                        QUERY PLAN&#xA;---------------------------------------------------------------------------------------------------------------------------&#xA; Gather  (cost=1000.00..17185.70 rows=6643 width=8) (actual time=0.196..36.796 rows=2585 loops=1)&#xA;   Workers Planned: 2&#xA;   Workers Launched: 2&#xA;   -&amp;gt;  Parallel Seq Scan on my_datas  (cost=0.00..15521.40 rows=2768 width=8) (actual time=0.027..33.117 rows=862 loops=3)&#xA;         Filter: (family ~~ &amp;#39;%ANGER&amp;#39;::text)&#xA;         Rows Removed by Filter: 332540&#xA; Planning Time: 0.071 ms&#xA; Execution Time: 36.894 ms&#xA;(8 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;indexation-des-trigrammes&#34;&gt;Indexation des trigrammes&lt;/h3&gt;&#xA;&lt;p&gt;Il est possible d&amp;rsquo;indexer les vecteurs de trigrammes avec un index GIN :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# CREATE INDEX idx_test_trgm ON my_datas USING GIN(family gin_trgm_ops);&#xA;CREATE INDEX&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;La recherche sur la fin de chaîne de caractères se fait maintenant en utilisant l&amp;rsquo;index nouvellement créé :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT id FROM my_datas WHERE family like  &amp;#39;%ANGER&amp;#39;;&#xA;                                                         QUERY PLAN&#xA;-----------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=94.35..9754.04 rows=6643 width=8) (actual time=1.422..3.197 rows=2585 loops=1)&#xA;   Recheck Cond: (family ~~ &amp;#39;%ANGER&amp;#39;::text)&#xA;   Heap Blocks: exact=2292&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..92.69 rows=6643 width=0) (actual time=1.193..1.194 rows=2585 loops=1)&#xA;         Index Cond: (family ~~ &amp;#39;%ANGER&amp;#39;::text)&#xA; Planning Time: 0.085 ms&#xA; Execution Time: 3.282 ms&#xA;(7 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nous pouvons maintenant effectuer une recherche de similarité :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT DISTINCT family FROM my_datas WHERE family %  &amp;#39;GRANGER&amp;#39;;&#xA;                                                               QUERY PLAN&#xA;----------------------------------------------------------------------------------------------------------------------------------------&#xA; Unique  (cost=370.28..370.61 rows=64 width=7) (actual time=19.476..19.867 rows=6 loops=1)&#xA;   -&amp;gt;  Sort  (cost=370.28..370.45 rows=66 width=7) (actual time=19.474..19.632 rows=4284 loops=1)&#xA;         Sort Key: family&#xA;         Sort Method: quicksort  Memory: 264kB&#xA;         -&amp;gt;  Bitmap Heap Scan on my_datas  (cost=119.31..368.29 rows=66 width=7) (actual time=7.737..18.771 rows=4284 loops=1)&#xA;               Recheck Cond: (family % &amp;#39;GRANGER&amp;#39;::text)&#xA;               Rows Removed by Index Recheck: 3468&#xA;               Heap Blocks: exact=5458&#xA;               -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..119.29 rows=66 width=0) (actual time=7.173..7.173 rows=7752 loops=1)&#xA;                     Index Cond: (family % &amp;#39;GRANGER&amp;#39;::text)&#xA; Planning Time: 0.297 ms&#xA; Execution Time: 19.887 ms&#xA;(12 rows)&#xA;&#xA;loxodata_text=# SELECT DISTINCT family FROM my_datas WHERE family %  &amp;#39;GRANGER&amp;#39;;&#xA;  family&#xA;----------&#xA; GRAND&#xA; GRANGE&#xA; GRANGER&#xA; GRANIER&#xA; GRAS&#xA; LAGRANGE&#xA;(6 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cette recherche par similarité peut être utile, votre serviteur en sait quelque chose avec son patronyme qui comporte un &amp;lsquo;B&amp;rsquo; muet et qui entraîne souvent moultes confusions lorsque je dois épeler mon nom, et qui est donc écrit souvent approximativement :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# SELECT DISTINCT family FROM my_datas WHERE family % &amp;#39;LEFEBVRE&amp;#39;;&#xA;  family&#xA;----------&#xA; LEFEBVRE&#xA; LEFEVRE&#xA; LEFEUVRE&#xA;(3 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;performances&#34;&gt;Performances&lt;/h3&gt;&#xA;&lt;p&gt;On peut voir que sur une recherche d&amp;rsquo;égalité, ou bien sur une recherche de début de chaîne, c&amp;rsquo;est l&amp;rsquo;index B-Tree qui est préféré par le planner :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family =  &amp;#39;LEFEBVRE&amp;#39;;&#xA;                                                           QUERY PLAN&#xA;---------------------------------------------------------------------------------------------------------------------------------&#xA; Index Only Scan using idx_test on my_datas  (cost=0.42..1370.94 rows=3801 width=7) (actual time=0.018..0.488 rows=4312 loops=1)&#xA;   Index Cond: (family = &amp;#39;LEFEBVRE&amp;#39;::text)&#xA;   Heap Fetches: 399&#xA; Planning Time: 0.340 ms&#xA; Execution Time: 0.615 ms&#xA;(5 rows)&#xA;&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family like  &amp;#39;LEFEBVRE%&amp;#39;;&#xA;                                                           QUERY PLAN&#xA;---------------------------------------------------------------------------------------------------------------------------------&#xA; Index Only Scan using idx_test on my_datas  (cost=0.42..1389.95 rows=3867 width=7) (actual time=0.010..0.729 rows=4312 loops=1)&#xA;   Index Cond: ((family ~&amp;gt;=~ &amp;#39;LEFEBVRE&amp;#39;::text) AND (family ~&amp;lt;~ &amp;#39;LEFEBVRF&amp;#39;::text))&#xA;   Filter: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA;   Heap Fetches: 399&#xA; Planning Time: 0.165 ms&#xA; Execution Time: 0.877 ms&#xA;(6 rows)&#xA;&#xA;loxodata_text=# drop index idx_test;&#xA;DROP INDEX&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Il est cependant important de noter que si l&amp;rsquo;index B-Tree est préféré sur la recherche en début de chaîne ( &lt;code&gt;LIKE &#39;xxxx%&#39;&lt;/code&gt; ) c&amp;rsquo;est parce que la classe d&amp;rsquo;opérateurs &lt;code&gt;text_pattern_ops&lt;/code&gt; a été utilisée lors de la création de l&amp;rsquo;index. Si nous créons un index B-Tree sans cette classe d&amp;rsquo;opérateurs, il sera préféré pour une recherche d&amp;rsquo;égalité, mais pas pour une recherche de début de chaîne du fait des problèmes complexes liés aux &lt;code&gt;LOCALES&lt;/code&gt; des différentes langues :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# CREATE INDEX idx_test ON my_datas(family);&#xA;CREATE INDEX&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family like  &amp;#39;LEFEBVRE%&amp;#39;;&#xA;                                                          QUERY PLAN&#xA;------------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=139.26..7724.28 rows=3867 width=7) (actual time=2.370..5.048 rows=4312 loops=1)&#xA;   Recheck Cond: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA;   Heap Blocks: exact=3544&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..138.29 rows=3867 width=0) (actual time=2.000..2.000 rows=4312 loops=1)&#xA;         Index Cond: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA; Planning Time: 0.162 ms&#xA; Execution Time: 5.179 ms&#xA;(7 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Si nous supprimons définitivement l&amp;rsquo;index B-Tree, on voit que l&amp;rsquo;index sur les trigrammes est utilisé efficacement pour une recherche d&amp;rsquo;égalité (seulement après PG v13) mais pas aussi efficacement qu&amp;rsquo;avec l&amp;rsquo;index B-Tree (coût estimé 7666 vs 1370). Cependant ce coût est remarquablement constant que la recherche se fasse sur une égalité, un début de chaîne (&lt;code&gt;LIKE &#39;xxx%&#39;&lt;/code&gt;) ou une recherche sur une sous-chaîne (&lt;code&gt;LIKE &#39;%xxx%&#39;&lt;/code&gt;).&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family =  &amp;#39;LEFEBVRE&amp;#39;;&#xA;                                                          QUERY PLAN&#xA;------------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=151.72..7666.35 rows=3801 width=7) (actual time=3.331..6.085 rows=4312 loops=1)&#xA;   Recheck Cond: (family = &amp;#39;LEFEBVRE&amp;#39;::text)&#xA;   Heap Blocks: exact=3544&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..150.77 rows=3801 width=0) (actual time=2.961..2.962 rows=4312 loops=1)&#xA;         Index Cond: (family = &amp;#39;LEFEBVRE&amp;#39;::text)&#xA; Planning Time: 0.095 ms&#xA; Execution Time: 6.298 ms&#xA;(7 rows)&#xA;&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family like  &amp;#39;LEFEBVRE%&amp;#39;;&#xA;                                                          QUERY PLAN&#xA;------------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=139.26..7724.28 rows=3867 width=7) (actual time=2.632..5.366 rows=4312 loops=1)&#xA;   Recheck Cond: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA;   Heap Blocks: exact=3544&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..138.29 rows=3867 width=0) (actual time=2.263..2.263 rows=4312 loops=1)&#xA;         Index Cond: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA; Planning Time: 0.075 ms&#xA; Execution Time: 5.584 ms&#xA;(7 rows)&#xA;&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family like  &amp;#39;%LEFEBVRE%&amp;#39;;&#xA;                                                          QUERY PLAN&#xA;------------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=109.52..7694.54 rows=3867 width=7) (actual time=1.628..4.402 rows=4312 loops=1)&#xA;   Recheck Cond: (family ~~ &amp;#39;%LEFEBVRE%&amp;#39;::text)&#xA;   Heap Blocks: exact=3544&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..108.55 rows=3867 width=0) (actual time=1.260..1.260 rows=4312 loops=1)&#xA;         Index Cond: (family ~~ &amp;#39;%LEFEBVRE%&amp;#39;::text)&#xA; Planning Time: 0.078 ms&#xA; Execution Time: 4.603 ms&#xA;(7 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Si un champ texte fait l&amp;rsquo;objet d&amp;rsquo;une recherche d&amp;rsquo;égalité dans une clause &lt;code&gt;WHERE&lt;/code&gt;, un index B-Tree est parfaitement adéquat.&lt;/li&gt;&#xA;&lt;li&gt;Si un champ texte fait l&amp;rsquo;objet d&amp;rsquo;une recherche sur un début de chaîne de type &lt;code&gt;WHERE champ LIKE &#39;ABC%&#39;&lt;/code&gt; , un index B-Tree est là encore adéquat, à condition de lui spécifier la classe d&amp;rsquo;opérateurs &lt;code&gt;text_pattern_ops&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Si un champ texte fait l&amp;rsquo;objet d&amp;rsquo;une recherche sur une sous-chaîne de type &lt;code&gt;WHERE champ LIKE &#39;%ABC%&#39;&lt;/code&gt; , seul un index GIN ou GiST sur les trigrammes sera utile.&lt;/li&gt;&#xA;&lt;li&gt;Lorsqu&amp;rsquo;un index sur les trigrammes a été créé, dans la plupart des cas l&amp;rsquo;index B-Tree peut être supprimé. Cependant, du fait de la meilleure efficacité du B-Tree, il peut être pertinent dans de rares occasions de conserver également l&amp;rsquo;index B-Tree.&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>Retour sur la PG Conf Europe 2024</title>
    <updated>2025-02-24T14:10:00Z</updated>
    <id>tag:www.loxodata.com,2025-02-24:/post/pgconf-eu-2024-report/</id>
    <link href="http://www.loxodata.com/post/pgconf-eu-2024-report/" rel="alternate"></link>
    <summary type="html">&lt;h2 id=&#34;retour-sur-la-pg-conf-europe-2024&#34;&gt;Retour sur la PG Conf Europe 2024&lt;/h2&gt;&#xA;&lt;p&gt;Cette année, la PostgreSQL Conference Europe 2024 s&amp;rsquo;est déroulée à&#xA;Athènes, en Grèce, à quelques hectomètres de l&amp;rsquo;acropole. À nouveau, un&#xA;record d&amp;rsquo;affluence est battu cette année avec 779 participants, ce qui&#xA;en fait l&amp;rsquo;évènement PostgreSQL le plus important au monde.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://www.loxodata.com/images/post/pgconf-eu-2024/athena-noctua.jpg&#34; alt=&#34;La chouette d&amp;rsquo;Athéna&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;La liste des conférences est disponible sur le site de&#xA;l&amp;rsquo;évènement : &lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/&#34;&gt;https://2024.pgconf.eu/&lt;/a&gt;.&#xA;Les supports de présentations, ainsi que les enregistrements vidéos sont&#xA;également mis à disposition.&lt;/p&gt;&#xA;&lt;p&gt;La &lt;a href=&#34;https://buff.ly/4b483Ff&#34;&gt;conférence d&amp;rsquo;ouverture&lt;/a&gt; est donnée par Stacey Haysler. Le sujet&#xA;abordé est celui du coût de la licence PostgreSQL. Cette dernière&#xA;étant gratuite, elle demande une implication des différents acteurs&#xA;pour que le projet puisse fonctionner et demeurer robuste et pérenne.&lt;/p&gt;&#xA;&lt;p&gt;Les conférences sont ensuite réparties dans différentes salles, avec 4&#xA;conférences simultanées, dont une réservée aux sponsors. Nous résumons&#xA;ici nos notes à propos des présentations auxquelles nous avons&#xA;assisté.&lt;/p&gt;&#xA;&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://anarazel.de/talks/2024-10-23-pgconf-eu-numa-vs-postgresql/numa-vs-postgresql.pdf&#34;&gt;NUMA vs PostgreSQL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Andres Freund nous explique les particularités de NUMA, qui est une&#xA;architecture d&amp;rsquo;accès à la mémoire, ce qui a des conséquences pour les&#xA;processeurs, et donc les logiciels qui s&amp;rsquo;en servent. Quels sont les&#xA;problèmes rencontrés dans le contexte de l&amp;rsquo;utilisation de PostgreSQL ?&#xA;Cette présentation est complexe, mais détaillée et permet à l&amp;rsquo;auditoire&#xA;de mieux comprendre le comportement global des systèmes, tout en&#xA;ouvrant vers des optimisations possibles de PostgreSQL.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5720/slides/608/Streaming%20I_O.pdf&#34;&gt;Streaming I/O and vectored I/O&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Les orateurs Thomas Munro &amp;amp; Nazir Bilal Yavuz détaillent un point&#xA;important concernant les performances des lectures et écritures de&#xA;données (I/O) : après un historique des solutions, ils expliquent ce&#xA;que sont les solutions modernes telles que les Streaming I/O et que peut&#xA;apporter le patch AIO qui est en cours de développement.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/5689-debugging-active-queries-with-mid-flight-instrumented-explain-plans/&#34;&gt;Debugging active queries with mid-flight instrumented explain plans&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Rafael Thofehrn Castro nous présente des extensions et patchs pour&#xA;suivre les plans d&amp;rsquo;exécutions à la volée dans une instance&#xA;PostgreSQL. C&amp;rsquo;est bluffant, malheureusement rien n&amp;rsquo;est disponible&#xA;publiquement.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5747/slides/559/postgres_statistics_presentation.pdf&#34;&gt;A Deep Dive into Postgres Statistics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Louise Leinweber détaille de façon claire et précise ce que sont les&#xA;statistiques sur les données dans PostgreSQL, comment elles sont&#xA;utilisées dans PostgreSQL et quels leviers nous avons pour agir.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/6035-porting-on-prem-performance-troubleshooting-skills-to-the-cloud/&#34;&gt;Porting on-prem performance troubleshooting skills to the cloud&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Denzil Ribeiro évoque l&amp;rsquo;outillage nécessaire à la supervision d&amp;rsquo;une&#xA;instance PostgreSQL dans le cloud, en particulier tout ce qui est&#xA;spécifique aux environnements clouds, très utile lorsqu&amp;rsquo;on vient&#xA;d&amp;rsquo;environnements dits &amp;ldquo;on-premise&amp;rdquo;.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5870/slides/572/PostgreSQL%20Observed%E2%80%94%20and%20Explained.pdf&#34;&gt;PostgreSQL Observed—and Explained&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Stacey Haysler et Karen Jex utilisent quelques points emblématiques&#xA;des problèmes souvent rencontrés par les utilisateurs de PostgreSQL&#xA;pour évoquer les bonnes ou mauvaises pratiques et certains&#xA;anti-patterns connus.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/5812-vacuuming-large-tables-how-recent-postgres-changes-further-enable-mission-critical-workloads/&#34;&gt;Vacuuming Large Tables: How Recent Postgres Changes Further Enable Mission Critical Workloads&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Robert Treat évoque avec humour ses mésaventures avec les vacuums et&#xA;les ID de transactions, et les améliorations apportées depuis dans&#xA;PostgreSQL 17.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5768/slides/619/Postgres%20Partitioning%20-%20Slicing%20and%20Dicing.pdf&#34;&gt;Mastering PostgreSQL Partitioning: Supercharge Performance and Simplify Maintenance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Ryan Booz évoque un outil très utile en ce qui concerne la gestion de&#xA;la performance : le partitionnement des tables, ses différentes&#xA;possibilités et cas d&amp;rsquo;usage, jusqu&amp;rsquo;aux extensions que sont TimescaleDB&#xA;et Citus.&lt;/p&gt;&#xA;&lt;h2 id=&#34;high-availibility&#34;&gt;High availibility&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5916/slides/578/bmejias_Sparta_Dual_Kings_PG_Active_Active.pdf&#34;&gt;Sparta&amp;rsquo;s Dual Kingship and PostgreSQL Active-Active&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Boriss Mejías détaille le fonctionnement d&amp;rsquo;une réplication&#xA;active-active, avec toutes les notions, plus ou moins complexes, qui&#xA;permettent de bien comprendre les contraintes qu&amp;rsquo;imposent ce type de&#xA;réplication.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5892/slides/544/patroni-deployment-patterns.pdf&#34;&gt;Patroni Deployment Patterns&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Michael Banck expose de façon pratique et claire le fonctionnement de&#xA;Patroni, avec quelques éléments pertinents à retenir, correspondant à son&#xA;expérience.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5846/slides/547/comparing_poolers.pdf&#34;&gt;Comparing Connection Poolers for PostgreSQL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Julian Markwort compare les différents gestionnaires de connexions&#xA;entre eux. Quelles sont les différentes questions qui se posent pour&#xA;adopter un tel outil, et pourquoi faut-il choisir pgBouncer ?&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5853/slides/567/Speeding%20up%20logical%20replication%20setup.pdf&#34;&gt;Speeding up logical replication setup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Euler Taveira présente le développement qu&amp;rsquo;il a mené dans PostgreSQL&#xA;pour intégré l&amp;rsquo;outil &lt;code&gt;pg_createsubscriber&lt;/code&gt; qui permet de convertir une&#xA;réplication physique en réplication logique, accélérant ainsi la&#xA;création d&amp;rsquo;un réplica logique.&lt;/p&gt;&#xA;&lt;h3 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/6038/slides/552/CPK%20Your%20Virtual%20DBA.pdf&#34;&gt;Crunchy Postgres for Kubernetes: Your virtual DBA&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Karen Jex explique le fonctionnement de Kubernetes et l&amp;rsquo;utilisation de&#xA;l&amp;rsquo;opérateur Crunchy Postgres, et comment son fonctionnement s&amp;rsquo;articule&#xA;avec le rôle et les responsabilités d&amp;rsquo;un administrateur de bases de&#xA;données.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5584/slides/576/PGConf.EU%20-%20Demystifying%20Kubernetes%20for%20Postgres%20DBAs.pdf&#34;&gt;Demystifying Kubernetes for Postgres DBAs: A Guide to Operators&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Adam Wright évoque le lien entre Kubernetes et PostgreSQL : les&#xA;opérateurs ! Différents opérateurs pour PostgreSQL existent et ne sont&#xA;pas strictement équivalents, ce qui nécessite une compréhension de&#xA;chacun d&amp;rsquo;entre eux de la part de l&amp;rsquo;administrateur de bases de données&#xA;pour les adopter : sécurité, réseau, sauvegarde, stockage, extension.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5829/slides/554/202410-pgconf-From%20VMs%20to%20Cloud-Native%20PostgreSQL%20in%20Kubernetes.pdf&#34;&gt;From VMs to Cloud-Native PostgreSQL in Kubernetes: A Case Study of Migrating a Medium-Sized Application&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;David Pech fait le retour d&amp;rsquo;expérience d&amp;rsquo;une migration d&amp;rsquo;instance&#xA;PostgreSQL depuis des machines virtuelles vers un cluster&#xA;Kubernetes. Le choix de l&amp;rsquo;opérateur Kubernetes est un point important&#xA;de la démarche. Après avoir fait tomber quelques mythes autour de&#xA;Kubernetes, l&amp;rsquo;orateur détaille de plan de travail pour adopter la&#xA;solution.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/5654-fun-with-postgres-high-availability-poker/&#34;&gt;Fun with Postgres High Availability Poker&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Dave Pitts et Derk Van Veen introduisent les concepts de haute&#xA;disponibilité de PostgreSQL par le jeu, ce qui est toujours une bonne&#xA;manière d&amp;rsquo;apprendre.&lt;/p&gt;&#xA;&lt;h2 id=&#34;intelligence-artificielle&#34;&gt;Intelligence artificielle&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5830/slides/609/pgconfeu-2024-vectors-internal.pdf&#34;&gt;Dissimilarity search: implementing in-memory vector search algorithms to PostgreSQL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Jonathan Katz parle de l&amp;rsquo;extension pgvector, qui est une possibilité&#xA;offerte aux utilisateurs de PostgreSQL de vectoriser des données et de&#xA;faire des recherches par approximation.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5579/slides/575/AIfortheDBA_pgconfeu.pdf&#34;&gt;Leveraging AI as a PostgreSQL DBA, Grant Fritchey&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Grant Fritchey se demande si les prompts d&amp;rsquo;IA sont de bons outils pour&#xA;les DBA ? Quelles sont les différentes tâches du DBA qui pourraient&#xA;bénéficier de l&amp;rsquo;aide d&amp;rsquo;un assistant conversationnel ?&lt;/p&gt;&#xA;&lt;h2 id=&#34;sécurité&#34;&gt;Sécurité&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://l_avrot.gitlab.io/slides/permissions_20241023.html#/&#34;&gt;Untangling the Web of PostgreSQL Permissions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Lætitia Avrot évoque l&amp;rsquo;ensemble des fonctionnalités liées aux&#xA;permissions dans PostgreSQL : rôle, groupe, privilèges, Row Level&#xA;Security, privilèges par défaut.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5554/slides/555/PostgreSQL_Security_PgConf2024_Export.pdf&#34;&gt;PostgreSQL security: defending against external Attacks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Taras Kloba détaille un sujet très important, quoique parfois trop&#xA;négligé : comment protéger PostgreSQL contre les attaques. Des mises à&#xA;jour de sécurité à la gestion de l&amp;rsquo;authentification en passant par la&#xA;protection des données, cette présentation fait la liste des points à&#xA;retenir en termes de sécurité.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/5645-column-encryption-solutions-and-ideas/&#34;&gt;Column encryption (solutions and ideas)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Peter Eisentraut fait le tour des besoins et solutions de chiffrement&#xA;de données disponibles avec PostgreSQL.&lt;/p&gt;&#xA;&lt;h2 id=&#34;autres&#34;&gt;Autres&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5710/slides/549/csn-snapshots.pdf&#34;&gt;High-concurrency distributed snapshots, Ants Aasma&lt;/a&gt; :&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Le modèle actuel de snapshot, qui autorise la visibilité des&#xA;enregistrements, est maintenant vieux de plus de vingt ans : quel&#xA;modèle peut-il le remplacer, en prenant en compte la croissance de la&#xA;concurrence d&amp;rsquo;accès. L&amp;rsquo;orateur évoque alors les notions de Commit&#xA;Sequence Number ou d&amp;rsquo;un modèle hybride.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5630/slides/562/undelete_from_table.pdf&#34;&gt;UNDELETE data FROM table;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Christoph Berg explique en détail le fonctionnement de PostgreSQL&#xA;lorsqu&amp;rsquo;on lui demande de supprimer un enregistrement, et ce qu&amp;rsquo;il est&#xA;possible de faire pour retrouver cet enregistrement avec l&amp;rsquo;extension&#xA;&lt;code&gt;pg_dirtyread&lt;/code&gt; ou la commande &lt;code&gt;pg_waldump&lt;/code&gt;. Dans tous les cas, faites&#xA;des sauvegardes !&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5748/slides/588/PGConf.EU.2024_pg_ivm.pdf&#34;&gt;pg_ivm : extension for rapid incremental view&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Yugo Nagata présente l&amp;rsquo;extension &lt;code&gt;pg_ivm&lt;/code&gt; qui permet de créer des vues&#xA;matérialisées incrémentales, qui sont donc mises à jour rapidement,&#xA;contrairement aux vues matérialisées existantes dans PostgreSQL qui&#xA;nécessitent une régénération entière.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 17.4 et autres correctifs</title>
    <updated>2025-02-20T14:30:00Z</updated>
    <id>tag:www.loxodata.com,2025-02-20:/post/postgresql-17-4/</id>
    <link href="http://www.loxodata.com/post/postgresql-17-4/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le PGDG (PostgreSQL Global Development Group) a publié une mise à jour&#xA;de toutes les versions supportées de PostgreSQL, incluant 17.4, 16.8, 15.12,&#xA;14.17 et 13.20.&lt;/p&gt;&#xA;&lt;p&gt;Pour la liste complète des changements, se référer à la &lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;note de publication de versions&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;corrections-de-bogues-et-améliorations&#34;&gt;Corrections de bogues et améliorations&lt;/h2&gt;&#xA;&lt;p&gt;Les problèmes ci-dessous concernent PostgreSQL 17. Certains de ces problèmes&#xA;peuvent aussi concerner d&amp;rsquo;autres versions de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Les correctifs sont :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Amélioration du comportement des fonctions d&amp;rsquo;échappement de la bibliothèque &lt;a href=&#34;https://www.postgresql.org/docs/current/libpq.html&#34;&gt;&lt;code&gt;libpq&lt;/code&gt;&lt;/a&gt;.&#xA;Le correctif de la vulnérabilité &lt;a href=&#34;https://www.postgresql.org/support/security/CVE-2025-1094/&#34;&gt;CVE-2025-1094&lt;/a&gt;&#xA;a introduit une régression amenant les fonctions d&amp;rsquo;échappement à ne pas respecter&#xA;les tailles des chaînes de caractères fournies en paramètres, entraînant dans&#xA;certains cas des plantages. Ce problème peut impacter une bibliothèque cliente de&#xA;PostgreSQL en fonction de son intégration à la bibliothèque &lt;code&gt;libpq&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;Correction de fuites mémoire dans la commande &lt;a href=&#34;https://www.postgresql.org/docs/current/app-pgcreatesubscriber.html&#34;&gt;pg_createsubscriber&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;mise-à-jour&#34;&gt;Mise à jour&lt;/h2&gt;&#xA;&lt;p&gt;Toutes les publications de mises à jour de PostgreSQL sont&#xA;cumulatives. Comme pour les autres mises à jour mineures, il n&amp;rsquo;est pas&#xA;nécessaire d&amp;rsquo;extraire et de recharger les bases de données ni&#xA;d&amp;rsquo;utiliser &lt;code&gt;pg_upgrade&lt;/code&gt; pour appliquer cette mise à jour ;&#xA;il suffit simplement d&amp;rsquo;arrêter PostgreSQL et de mettre à jour les binaires.&lt;/p&gt;&#xA;&lt;p&gt;Les utilisateurs ayant sauté une ou plusieurs mises à jour peuvent&#xA;avoir besoin d&amp;rsquo;étapes additionnelles après la mise à jour.&#xA;Les notes de publication des versions précédentes fournissent les détails.&lt;/p&gt;&#xA;&lt;p&gt;Pour plus de détails, se référer à la &lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;note de publication de versions&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;liens&#34;&gt;Liens&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;Téléchargements&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;Notes de version&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/security/&#34;&gt;Page sur la sécurité&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/versioning/&#34;&gt;Politique de version&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/donate/&#34;&gt;Faire un don&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Si vous avez des corrections ou suggestions sur cette annonce de publication, merci de les envoyer à la mailing liste publique &lt;a href=&#34;https://www.postgresql.org/list/&#34;&gt;&lt;em&gt;pgsql-www@lists.postgresql.org&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 17.3 et autres correctifs</title>
    <updated>2025-02-14T15:00:00Z</updated>
    <id>tag:www.loxodata.com,2025-02-14:/post/postgresql-17-3/</id>
    <link href="http://www.loxodata.com/post/postgresql-17-3/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le PGDG (PostgreSQL Global Development Group) a publié une mise à jour&#xA;de toutes les versions supportées de PostgreSQL, incluant 17.3, 16.7,&#xA;15.11, 14.16, 13.19.&lt;/p&gt;&#xA;&lt;p&gt;Cette publication corrige également une vulnérabilité de sécurité et plus de 70 bogues&#xA;reportés dans les mois précédents.&lt;/p&gt;&#xA;&lt;p&gt;Cependant, le PGDG a annoncé mettre à disposition le &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-4-ooc-release/&#34;&gt;20 février&lt;/a&gt;&#xA;prochain un correctif suite à l&amp;rsquo;introduction d&amp;rsquo;une régression sur cette mise à jour.&#xA;Il est recommandé de ne pas procéder à cette mise à jour, mais d&amp;rsquo;attendre la&#xA;version 17.4.&lt;/p&gt;&#xA;&lt;h2 id=&#34;problèmes-de-sécurité&#34;&gt;Problèmes de sécurité&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/support/security/CVE-2025-1094/&#34;&gt;CVE-2025-1094&lt;/a&gt; :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;CVSS v3.1 Base Score: &lt;a href=&#34;https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?version=3.1&amp;amp;vector=AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H&#34;&gt;8.1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Supported, Vulnerable Versions: 13 - 17.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Une neutralisation inadéquate d&amp;rsquo;une syntaxe avec guillemets dans les fonctions de &lt;a href=&#34;https://www.postgresql.org/docs/current/libpq.html&#34;&gt;&lt;code&gt;libpq&lt;/code&gt;&lt;/a&gt; &lt;code&gt;PQescapeLiteral()&lt;/code&gt;, &lt;code&gt;PQescapeIdentifier()&lt;/code&gt;, &lt;code&gt;PQescapeString()&lt;/code&gt; et &lt;code&gt;PQescapeStringConn()&lt;/code&gt; permet de faire de l&amp;rsquo;injection SQL dans certains cas d&amp;rsquo;usage. Spécifiquement, l&amp;rsquo;injection SQL requiert à l&amp;rsquo;application d&amp;rsquo;utiliser le résultat de fonction pour construite l&amp;rsquo;entrée de &lt;code&gt;psql&lt;/code&gt;,&#xA;le terminal interactif de PostgreSQL. De même, une neutralisation inadéquate d&amp;rsquo;une syntaxe avec guillemets dans les programmes utilitaires de PostgreSQL en ligne de commande permet à une source d&amp;rsquo;arguments à ces commandes en ligne d&amp;rsquo;effectuer de l&amp;rsquo;injection SQL lorsque le paramètre &lt;a href=&#34;https://www.postgresql.org/docs/current/runtime-config-client.html#GUC-CLIENT-ENCODING&#34;&gt;&lt;code&gt;client_encoding&lt;/code&gt;&lt;/a&gt; est &lt;code&gt;BIG5&lt;/code&gt; et &lt;a href=&#34;https://www.postgresql.org/docs/current/runtime-config-preset.html#GUC-SERVER-ENCODING&#34;&gt;&lt;code&gt;server_encoding&lt;/code&gt;&lt;/a&gt; est soit &lt;code&gt;EUC_TW&lt;/code&gt; soit &lt;code&gt;MULE_INTERNAL&lt;/code&gt;. Les versions antérieures à PostgreSQL 17.3, 16.7, 15.11, 14.16 et 13.19 sont affectées.&lt;/p&gt;&#xA;&lt;p&gt;Le projet PostgreSQL remercie Stephen Fewer, Principal Security Researcher, Rapid7 pour avoir signalé ce problème.&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h2 id=&#34;corrections-de-bogues-et-améliorations&#34;&gt;Corrections de bogues et améliorations&lt;/h2&gt;&#xA;&lt;p&gt;Cette mise à jour corrige plus de 70 bogues ayant été reportés durant les mois précédents. Les problèmes ci-dessous concernent PostgreSQL 17. Certains de ces problèmes peuvent aussi concerner d&amp;rsquo;autres versions de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Les correctifs sont :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;restauration du comportement d&amp;rsquo;avant la version 17 concernant la troncature des noms&#xA;de bases de données de plus de 63 octets et les noms d&amp;rsquo;utilisateurs dans les&#xA;requêtes de connexion ;&lt;/li&gt;&#xA;&lt;li&gt;ne pas vérifier des privilèges de connexions et limites sur les processus&#xA;parallèles, mais les hériter du processus principal ;&lt;/li&gt;&#xA;&lt;li&gt;suppression du suffixe &lt;code&gt;Lock&lt;/code&gt; des noms d&amp;rsquo;évènements d&amp;rsquo;attente &lt;code&gt;LWLock&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;correction de la réutilisation de résultats obsolètes dans les agrégats de&#xA;fenêtrage qui peuvent conduire à des résultats incorrects ;&lt;/li&gt;&#xA;&lt;li&gt;correction de plusieurs conditions de concurrence pour &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-vacuum.html&#34;&gt;&lt;code&gt;vacuum&lt;/code&gt;&lt;/a&gt;&#xA;qui dans le pire des cas peut conduire à une corruption du catalogue système ;&lt;/li&gt;&#xA;&lt;li&gt;corrections sur la &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-truncate.html&#34;&gt;&lt;code&gt;TRUNCATE&lt;/code&gt;&lt;/a&gt;&#xA;de tables et d&amp;rsquo;index pour prévenir une éventuelle corruption ;&lt;/li&gt;&#xA;&lt;li&gt;correction sur le détachement d&amp;rsquo;une partition lorsque sa propre contrainte de&#xA;clé étrangère fait référence à une table partitionnée ;&lt;/li&gt;&#xA;&lt;li&gt;correction pour les codes de format &lt;code&gt;FFn&lt;/code&gt; (par exemple &lt;code&gt;FF1&lt;/code&gt;) pour &lt;code&gt;to_timestamp&lt;/code&gt;,&#xA;où un code de format entier avant le &lt;code&gt;FFn&lt;/code&gt; consommait tous les chiffres disponibles ;&lt;/li&gt;&#xA;&lt;li&gt;corrections pour &lt;code&gt;SQL/JSON&lt;/code&gt; et &lt;code&gt;XMLTABLE()&lt;/code&gt; pour mettre des entrées spécifiques&#xA;entre guillemets lorsque cela est nécessaire ;&lt;/li&gt;&#xA;&lt;li&gt;inclusion de l&amp;rsquo;option &lt;code&gt;ldapscheme&lt;/code&gt; dans la vue &lt;a href=&#34;https://www.postgresql.org/docs/current/view-pg-hba-file-rules.html&#34;&gt;&lt;code&gt;pg_hba_file_rules()&lt;/code&gt;&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;corrections pour &lt;a href=&#34;https://www.postgresql.org/docs/current/queries-union.html&#34;&gt;&lt;code&gt;UNION&lt;/code&gt;&lt;/a&gt;,&#xA;y compris le fait de ne pas fusionner des colonnes avec des collations non&#xA;compatibles ;&lt;/li&gt;&#xA;&lt;li&gt;corrections pouvant avoir un impact sur la disponibilité ou la vitesse de démarrage&#xA;d&amp;rsquo;une connexion à PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;correction de plusieurs fuites mémoire dans la sortie du décodage logique ;&lt;/li&gt;&#xA;&lt;li&gt;correction de plusieurs fuites mémoire avec le langage &lt;a href=&#34;https://www.postgresql.org/docs/current/plpython.html&#34;&gt;&lt;code&gt;PL/Python&lt;/code&gt;&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;ajout de l&amp;rsquo;autocomplétion pour la commande &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-copy.html&#34;&gt;&lt;code&gt;COPY&lt;/code&gt; (&lt;code&gt;MERGE INTO&lt;/code&gt;)&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;rendre &lt;a href=&#34;https://www.postgresql.org/docs/current/app-pgcontroldata.html&#34;&gt;&lt;code&gt;pg_controldata&lt;/code&gt;&lt;/a&gt;&#xA;plus résilient lors de l&amp;rsquo;affichage d&amp;rsquo;informations provenant de fichiers &lt;a href=&#34;https://www.postgresql.org/docs/current/wal-internals.html&#34;&gt;&lt;code&gt;pg_control&lt;/code&gt;&lt;/a&gt;&#xA;corrompus ;&lt;/li&gt;&#xA;&lt;li&gt;correction d&amp;rsquo;une fuite mémoire sur la commande &lt;a href=&#34;https://www.postgresql.org/docs/current/app-pgrestore.html&#34;&gt;&lt;code&gt;pg_restore&lt;/code&gt;&lt;/a&gt;&#xA;avec des données compressées via &lt;code&gt;zstd&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;correction de &lt;a href=&#34;https://www.postgresql.org/docs/current/app-pgbasebackup.html&#34;&gt;&lt;code&gt;pg_basebackup&lt;/code&gt;&lt;/a&gt;&#xA;pour gérer correctement les fichiers &lt;code&gt;pg_wal.tar&lt;/code&gt; de plus de 2GB sur Windows ;&lt;/li&gt;&#xA;&lt;li&gt;modification sur le module &lt;a href=&#34;https://www.postgresql.org/docs/current/earthdistance.html&#34;&gt;&lt;code&gt;earthdistance&lt;/code&gt;&lt;/a&gt;&#xA;pour utiliser le canevas des fonctions standards SQL pour corriger des problèmes&#xA;sur des mises à jour majeures vers la version 17 quand l&amp;rsquo;extension &lt;a href=&#34;https://www.postgresql.org/docs/current/earthdistance.html&#34;&gt;&lt;code&gt;earthdistance&lt;/code&gt;&lt;/a&gt;&#xA;est utilisée ;&lt;/li&gt;&#xA;&lt;li&gt;corrige des erreurs avec &lt;a href=&#34;https://www.postgresql.org/docs/current/pageinspect.html&#34;&gt;&lt;code&gt;pageinspect&lt;/code&gt;&lt;/a&gt;&#xA;dans des instances où la définition de la fonction &lt;code&gt;brin_page_items()&lt;/code&gt; n&amp;rsquo;est pas&#xA;à jour de la dernière version ;&lt;/li&gt;&#xA;&lt;li&gt;corrige des conditions de concurrence lors de tentative d&amp;rsquo;annulation d&amp;rsquo;une&#xA;requête distante avec &lt;a href=&#34;https://www.postgresql.org/docs/current/postgres-fdw.html&#34;&gt;&lt;code&gt;postgres_fdw&lt;/code&gt;&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Cette publication met aussi à jour les fichiers de fuseaux horaires avec la&#xA;publication de &lt;code&gt;tzdata&lt;/code&gt; 2025a pour les changements de lois DST au Paraguay, plus&#xA;des corrections historiques pour les Philippines.&lt;/p&gt;&#xA;&lt;h2 id=&#34;mise-à-jour&#34;&gt;Mise à jour&lt;/h2&gt;&#xA;&lt;p&gt;Toutes les publications de mises à jour de PostgreSQL sont&#xA;cumulatives. Comme pour les autres mises à jour mineures, il n&amp;rsquo;est pas&#xA;nécessaire d&amp;rsquo;extraire et de recharger les bases de données ni&#xA;d&amp;rsquo;utiliser &lt;code&gt;pg_upgrade&lt;/code&gt; pour appliquer cette mise à jour ;&#xA;il suffit simplement d&amp;rsquo;arrêter PostgreSQL et de mettre à jour les binaires.&lt;/p&gt;&#xA;&lt;p&gt;Les utilisateurs ayant sauté une ou plusieurs mises à jour peuvent&#xA;avoir besoin d&amp;rsquo;étapes additionnelles après la mise à jour.&#xA;Les notes de publication des versions précédentes fournissent les détails.&lt;/p&gt;&#xA;&lt;p&gt;Pour plus de détails, se référer à la &lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;note de publication de versions&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;liens&#34;&gt;Liens&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;Téléchargements&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;Notes de version&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/security/&#34;&gt;Page sur la sécurité&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/versioning/&#34;&gt;Politique de version&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/donate/&#34;&gt;Faire un don&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Si vous avez des corrections ou suggestions sur cette annonce de publication, merci de les envoyer à la mailing liste publique &lt;a href=&#34;https://www.postgresql.org/list/&#34;&gt;&lt;em&gt;pgsql-www@lists.postgresql.org&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>Correctif hors cycle pour PostgreSQL</title>
    <updated>2025-02-14T08:00:00Z</updated>
    <id>tag:www.loxodata.com,2025-02-14:/post/postgresql-17-4-ooc-release/</id>
    <link href="http://www.loxodata.com/post/postgresql-17-4-ooc-release/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le &lt;a href=&#34;https://www.postgresql.org/&#34;&gt;PGDG&lt;/a&gt; prévoit une livraison hors cycle pour le 20 février 2025 afin de corriger une régression introduite sur la &lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-173-167-1511-1416-and-1319-released-3015/&#34;&gt;mise à jour du 13 février 2025&lt;/a&gt; portant sur les versions mineures : 17.3, 16.7, 15.11, 14.16 et 13.19.&#xA;Dans cette mise à jour, vous retrouverez des correctifs pour les versions supportées (17.4, 16.8, 15.12, 14.17, 13.20). Bien que ces correctifs puissent ne pas impacter tous les utilisateurs de PostgreSQL, le PGDG&#xA;a préféré adresser le problème au plus tôt et ne pas attendre la prochaine échéance prévue le &lt;a href=&#34;https://www.postgresql.org/developer/roadmap/&#34;&gt;8 mai 2025&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Le correctif de sécurité &lt;a href=&#34;https://www.postgresql.org/support/security/CVE-2025-1094/&#34;&gt;CVE-2025-1094&lt;/a&gt;, traitant d&amp;rsquo;une vulnérabilité dans la librairie &lt;a href=&#34;https://www.postgresql.org/docs/current/libpq.html&#34;&gt;&lt;code&gt;libpq&lt;/code&gt;&lt;/a&gt; de PostgreSQL, a introduit une régression portant sur la gestion des chaînes de caractères (&amp;ldquo;C string&amp;rdquo;) terminée par un&#xA;caractère non nul. L&amp;rsquo;erreur pourrait être visible en fonction de comment un client PostgreSQL a implémenté ce comportement, et peut ne pas impacter tous les drivers PostgreSQL. Par précaution, le PGDG a avancé le cycle de mise à jour.&lt;/p&gt;&#xA;&lt;p&gt;Si vous êtes impacté par ce problème, il est recommandé d&amp;rsquo;attendre la sortie des versions 17.4, 16.8, 15.12, 14.17 et 13.29 avant de mettre à jour PostgreSQL.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 18 - Suppression de jointures inutiles</title>
    <updated>2025-03-07T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-03-07://2025/03/07/postgresql-18-self_join_elimination.html</id>
    <link href="https://blog.dalibo.com//2025/03/07/postgresql-18-self_join_elimination.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Reviers, le 7 mars 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fonctionnalité m’avait beaucoup impressionné en version 9.0, bien qu’elle&#xA;ait été éclipsée par la grande nouveauté, la réplication en natif. Cette&#xA;fonctionnalité avait pour but de supprimer les jointures inutiles. En fait, seul&#xA;un cas de jointure inutile dans un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;LEFT JOIN&lt;/code&gt; était traité. Depuis, beaucoup de&#xA;patchs ont circulé pour détecter d’autres cas, mais aucun n’a passé la sélection&#xA;jusqu’à la semaine dernière. La nouveauté concerne les jointures d’une table sur&#xA;elle-même. C’est ce que je vais détailler dans cet article.&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/portrait_guillaume.png&#34; alt=&#34;Guillaume Lelarge&#34; style=&#34;float: right; padding:10px; width:120px;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Prenons cette requête de jointure d’une table avec elle-même :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-sql highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;JOIN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1bis&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1bis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Sans contrainte particulière sur &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;c1&lt;/code&gt;, cette jointure ne peut être éludée. Cependant, si les&#xA;valeurs de la colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;c1&lt;/code&gt; sont uniques, le moteur n’a pas besoin de réaliser la jointure&#xA;pour obtenir le résultat.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nous allons prendre ce jeu de test :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-sql highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;INSERT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;INTO&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generate_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_000_000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;ALTER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ADD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;PRIMARY&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;KEY&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;VACUUM&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ANALYZE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Voici le plan d’exécution de la première requête en version 17 :&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-file&#34;&gt;Hash Join  (cost=30832.00..59603.01 rows=1000000 width=8)&#xA;  Hash Cond: (t1.c1 = t1bis.c1)&#xA;  -&amp;gt;  Seq Scan on t1  (cost=0.00..14425.00 rows=1000000 width=4)&#xA;  -&amp;gt;  Hash  (cost=14425.00..14425.00 rows=1000000 width=4)&#xA;        -&amp;gt;  Seq Scan on t1 t1bis  (cost=0.00..14425.00 rows=1000000 width=4)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;La jointure est bien réalisée. Et voici maintenant le plan d’exécution en version 18 :&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-file&#34;&gt;Seq Scan on t1 t1bis  (cost=0.00..14425.00 rows=1000000 width=8)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Il n’y a plus trace de la jointure. Le coût est de ce fait inférieur et la durée d’exécution l’est aussi : 530 ms en&#xA;version 17, contre 185 ms en version 18. De plus, la durée&#xA;d’optimisation/planification de la requête est elle aussi inférieure avec cette&#xA;optimisation : 0,20 ms contre 0,06 ms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans le cas où la contrainte n’est plus une clé primaire, mais une simple&#xA;contrainte d’unicité, le plan en sera un peu impacté :&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-file&#34;&gt;Seq Scan on t1 t1bis  (cost=0.00..14425.00 rows=1000000 width=8)&#xA;  Filter: (c1 IS NOT NULL)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;En effet, le filtre est nécessaire pour respecter la requête d’origine. Ce&#xA;filtre supplémentaire a un petit impact sur la durée d’exécution de la requête,&#xA;étant donné qu’elle passe à 220 ms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il est à noter que cette optimisation fonctionne aussi avec d’autres formes de&#xA;cette requête, par exemple :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-sql highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;EXISTS&lt;/span&gt;&#xA;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1bis&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1bis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&#xA;  &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Enfin, il faut savoir que cette optimisation est débrayable en configurant le&#xA;paramètre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;enable_self_join_elimination&lt;/code&gt; à &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;off&lt;/code&gt; en sachant qu’il est à &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;on&lt;/code&gt; par&#xA;défaut.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour terminer, il est évident qu’il est préférable de bien écrire les requêtes&#xA;mais quand l’application qui exécute la requête est propriétaire, il n’est pas&#xA;possible de modifier les requêtes exécutées. Quand un développeur utilise un&#xA;ORM, il n’a pas toujours la possibilité de changer la requête exécutée par&#xA;l’ORM. Et enfin, ce genre de requête peut aussi provenir de plusieurs vues&#xA;imbriquées qui finissent par en arriver à ce genre d’aberration.&#xA;Cette optimisation qui semble si évidente n’est pas du tout triviale : le&#xA;&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=fc069a3a6319b5bf40d2f0f1efceae1c9b7a68a8&#34;&gt;commit&lt;/a&gt;&#xA;a vingt-trois contributeurs, dont les plus aguerris des développeurs de PostgreSQL,&#xA;et &lt;a href=&#34;https://www.postgresql.org/message-id/flat/64486b0b-0404-e39e-322d-0801154901f3%40postgrespro.ru&#34;&gt;la discussion avait démarré en 2018&lt;/a&gt; !&#xA;&lt;!--&#xA;   vim: spelllang=fr spell&#xA;--&gt;&lt;/p&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>Linux Pratique - Maintenance d’une instance PostgreSQL</title>
    <updated>2025-03-03T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-03-03://2025/03/03/lp6.html</id>
    <link href="https://blog.dalibo.com//2025/03/03/lp6.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Reviers, 3 mars 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois un &lt;a href=&#34;https://blog.dalibo.com/2024/06/07/lp1.html&#34;&gt;serveur PostgreSQL&#xA;installé&lt;/a&gt;, plusieurs thématiques&#xA;sont à prendre en considération : la&#xA;&lt;a href=&#34;https://blog.dalibo.com/2024/09/09/lp3.html&#34;&gt;sauvegarde&lt;/a&gt;, la&#xA;&lt;a href=&#34;https://blog.dalibo.com/2024/11/18/lp4.html&#34;&gt;supervision&lt;/a&gt; et la maintenance.&#xA;C’est ce dernier point que nous allons voir dans cet article.&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/lp144.jpg&#34; alt=&#34;Linux Pratique 144&#34; style=&#34;float: right; padding: 10px; width: 300px;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il existe principalement deux types de maintenance à réaliser sur un serveur&#xA;PostgreSQL. Ils visent uniquement à préserver de bonnes performances du système&#xA;de bases de données. Il est question de lutter contre une fragmentation trop&#xA;importante des tables et des index (pour éviter une surconsommation des accès&#xA;disques et mémoires), et il est question de s’assurer d’avoir de bonnes&#xA;statistiques sur les données (pour avoir de bons plans d’exécution, et ainsi de&#xA;bonnes performances des requêtes). Cet article commence par expliquer ces types&#xA;de maintenance, puis aborde la question de sa mise en place et de son&#xA;automatisation.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;mise-à-jour-des-statistiques-sur-les-données&#34;&gt;Mise à jour des statistiques sur les données&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;C’est certainement le point le moins problématique et le plus compréhensible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour créer un plan d’exécution, l’optimiseur de requêtes de PostgreSQL se base&#xA;notamment sur des statistiques sur les données. Par exemple, pour choisir entre&#xA;un parcours de table et un parcours d’index, le ratio de valeurs filtrées est&#xA;une information importante. Plus ce ratio sera faible (c.-à-d. grand nombre de&#xA;lignes filtrées, peu de lignes renvoyées), plus un index sera intéressant pour&#xA;les performances. Mais pour avoir cette information du ratio, il faut avoir une&#xA;idée ou un résumé des données contenues dans chaque colonne. Pour cela,&#xA;PostgreSQL peut calculer, enregistrer et utiliser des statistiques sur ces&#xA;données. La commande &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; a pour responsabilité de générer ces&#xA;statistiques.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour le calcul des statistiques, un échantillon des lignes de la table est pris&#xA;en compte. Cet échantillon (en nombre de lignes) correspond au résultat de la&#xA;multiplication de la valeur du paramètre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;default_statistics_target&lt;/code&gt; avec une&#xA;valeur en dur (300). Ce paramètre vaut 100 par défaut, l’échantillon par défaut&#xA;est donc de 30000 lignes. Ces lignes sont prises au hasard, chacune dans un&#xA;bloc différent. Donc &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; lit par défaut 30000 blocs pour chaque table&#xA;(tout du moins pour les tables qui ont au moins 30000 blocs).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour chacune de ces lignes, la commande calcule les statistiques de chaque&#xA;colonne de la table, et les enregistre dans le catalogue système&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_statistic&lt;/code&gt;. Depuis la version 10, il peut aussi calculer des statistiques&#xA;sur le contenu de plusieurs colonnes. Nous parlons alors de statistiques&#xA;étendues, enregistrées dans les catalogues systèmes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_statistic_ext&lt;/code&gt; et&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_statistic_ext_data&lt;/code&gt;. Il est possible de regarder le contenu de ces&#xA;catalogues, mais c’est difficilement compréhensible pour un humain. Il est&#xA;préférable de passer par les vues &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stats&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stats_ext&lt;/code&gt;, qui ont été&#xA;spécialement créées pour être plus facilement appréhendables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Revenons à l’échantillon. Plus il est grand, plus les statistiques seront&#xA;précises. Cependant, plus il est grand, plus l’opération d’&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; sera&#xA;longue. Et cela peut paraître contre-intuitif, mais avoir plus de statistiques&#xA;va demander plus de travail à l’optimiseur qui mettra donc plus de temps à&#xA;proposer un plan d’exécution. Donc un échantillon plus grand n’est pas&#xA;automatiquement une bonne chose. Il faut faire la balance entre les gains sur&#xA;les plans générés et les pertes dues au calcul et à l’optimisation plus longue.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Même si la configuration basique est globale sur toutes les tables,&#xA;l’échantillon n’a en fait aucun intérêt d’être le même pour toutes les tables.&#xA;Chaque colonne de chaque table peut avoir une distribution spécifique des&#xA;données, et il pourrait donc être préférable de spécifier cette configuration&#xA;par colonne, voire par table. Même s’il n’est actuellement pas possible de la&#xA;spécifier par table, il est possible de le faire par colonne avec la commande&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ALTER TABLE&lt;/code&gt;. Par exemple :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;ALTER TABLE t1 ALTER COLUMN c1 SET STATISTICS 200;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Les statistiques sont calculées à l’exécution de la commande &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt;. Au fur&#xA;et à mesure des écritures dans la base, les statistiques vont devenir obsolètes&#xA;et il sera nécessaire de les calculer à nouveau. Autrement dit, il est&#xA;essentiel d’exécuter périodiquement cette commande. La fréquence de son&#xA;exécution dépend principalement de la fréquence des requêtes d’écriture de&#xA;données (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;INSERT&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;COPY&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;UPDATE&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;DELETE&lt;/code&gt;) ou plus exactement du nombre de&#xA;lignes impactées par ces requêtes.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;lutte-contre-la-fragmentation&#34;&gt;Lutte contre la fragmentation&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Au fil de l’utilisation d’une base de données de PostgreSQL, les tables&#xA;deviennent de plus en plus volumineuses si aucune opération de maintenance&#xA;n’est réalisée. En effet, lors d’opérations de mise à jour ou de suppression de&#xA;lignes dans une table, les lignes concernées ne sont pas supprimées directement&#xA;du fichier correspondant à cette table. Cela ralentirait beaucoup les écritures&#xA;si la suppression physique était immédiate. De plus, les lignes sont conservées&#xA;pour la session qui les a supprimées au cas où celle-ci devrait annuler la&#xA;suppression. Elles sont aussi conservées pour le cas où d’autres sessions&#xA;exécuteraient des lectures de la même table tant que la session qui supprime&#xA;ces lignes n’a pas validé sa transaction. Même si cette transaction est&#xA;validée, les lignes sont conservées au cas où les autres sessions utilisent un&#xA;niveau transactionnel qui leur permet toujours de voir ces anciennes lignes.&#xA;Bref, il existe plein de cas où ces lignes mises à jour ou supprimées doivent&#xA;rester accessibles à certaines sessions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Entrons un peu plus dans le détail des différentes opérations d’écriture. En&#xA;cas d’insertion (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;INSERT&lt;/code&gt; ou &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;COPY&lt;/code&gt;), soit il existe un emplacement de libre&#xA;dans un bloc de fichier, auquel cas la nouvelle ligne est enregistrée à cet&#xA;emplacement, soit il n’en existe pas de libre, ce qui cause l’ajout d’un&#xA;nouveau bloc, et l’enregistrement de la nouvelle ligne dans ce nouveau bloc.&#xA;L’index est modifié pour référencer la nouvelle ligne.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En cas de suppression (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;DELETE&lt;/code&gt;), la ligne ciblée est indiquée comme supprimée&#xA;dans le fichier de la table. L’index n’est pas touché et référence donc&#xA;toujours l’ancienne ligne.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En cas de mise à jour (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;UPDATE&lt;/code&gt;), PostgreSQL ne met pas à jour la ligne ciblée.&#xA;Il fait l’équivalent d’un Copy-On-Write, autrement dit une copie de la ligne&#xA;est effectuée dans le fichier de la table, la copie contient la nouvelle&#xA;(version de cette) ligne avec les données modifiées, l’ancienne (version de&#xA;cette) ligne est toujours présente avec les anciennes données. Comme indiqué&#xA;entre parenthèses, nous parlons plutôt de version de ligne, l’ancienne étant la&#xA;version originale, la nouvelle étant la version modifiée. Cette nouvelle&#xA;version est enregistrée comme toute nouvelle ligne. Donc, avec PostgreSQL, un&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;UPDATE&lt;/code&gt; est l’exact équivalent d’un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;DELETE&lt;/code&gt; de la ligne actuelle, suivi d’un&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;INSERT&lt;/code&gt; de la ligne avec les données modifiées. De ce fait, l’index se voit&#xA;ajouter (généralement) une nouvelle référence à cette ligne, mais avec un&#xA;pointeur indiquant l’emplacement de la nouvelle ligne, tout en conservant le&#xA;pointeur vers l’ancienne ligne.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;J’ai indiqué « l’index ». C’est évidemment à condition qu’il y ait un index sur cette table, et s’il y en a plusieurs, tous sont pris en compte, à quelques subtilités près (index partiel, mise à jour HOT).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nous nous retrouvons donc avec des lignes déclarées comme supprimées dans le&#xA;fichier, mais bien physiquement présentes dans le fichier. Pendant un moment,&#xA;elles restent visibles par certaines transactions. Cependant, au bout d’un&#xA;moment, toutes les transactions qui voyaient encore ces lignes se terminent. À&#xA;ce moment-là, aucune transaction ne peut voir ces lignes supprimées. Elles sont&#xA;pourtant toujours présentes dans le fichier de la table et il existe toujours&#xA;des références dans l’index qui pointent vers ces lignes. Pour ne pas perdre du&#xA;temps à chaque opération d’écriture dans la table, les développeurs de&#xA;PostgreSQL ont décidé qu’il faudrait exécuter une opération spécifique pour&#xA;trouver les lignes supprimées visibles par aucune session et les marquer d’une&#xA;façon particulière indiquant qu’il est possible de réutiliser l’espace qu’elles&#xA;occupent. Cette opération s’exécute en utilisant l’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cette opération réalise trois étapes :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;récupération de la liste des lignes actuellement invisibles par toutes les&#xA;transactions en cours ;&lt;/li&gt;&#xA;  &lt;li&gt;suppression des références de ces lignes dans les index de la table ;&lt;/li&gt;&#xA;  &lt;li&gt;mise à jour du fichier FSM indiquant les espaces libres réutilisables.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Ces trois étapes peuvent être exécutées plusieurs fois s’il n’est pas possible&#xA;de conserver en mémoire l’ensemble des lignes invisibles. La mémoire utilisée&#xA;pour cela dépend de la valeur du paramètre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;maintenance_work_mem&lt;/code&gt;, sachant que&#xA;l’opération &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ne pourra pas utiliser plus de 1 Go (ce qui représente&#xA;quand même 178 millions de lignes mortes).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois cette opération effectuée, un fichier FSM est présent sur disque. Tout&#xA;nouvel ajout de ligne (suite à un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;INSERT&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;COPY&lt;/code&gt; ou &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;UPDATE&lt;/code&gt;) lira ce fichier&#xA;pour trouver où placer la nouvelle ligne. Ceci permet d’utiliser les espaces&#xA;rendus disponibles et évite de faire grossir le fichier de la table.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans la majorité des cas, le nettoyage de la table et des index ne permet pas&#xA;aux fichiers de ces objets de perdre en volumétrie. Il permet principalement de&#xA;renseigner la structure FSM pour savoir où écrire sans faire grossir le&#xA;fichier. Cependant, si un ou plusieurs blocs en toute fin de fichier sont&#xA;complètement libérés de leurs lignes et qu’il est possible d’obtenir rapidement&#xA;un verrou exclusif sur la table, l’opération &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; pourra tronquer le&#xA;fichier pour rendre ces blocs au système de fichiers. De mon expérience, cela&#xA;est suffisamment peu fréquent pour être visible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour ce qui est de l’utilisation de l’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;, celle-ci peut viser&#xA;spécifiquement une table si son nom est indiqué. Par exemple, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM t1&lt;/code&gt;&#xA;permettra de traiter la table &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;t1&lt;/code&gt;. Si aucune table n’est indiquée, toutes les&#xA;tables de la base seront traitées.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; accepte plusieurs options. Vu le nombre (14 !), nous&#xA;n’allons pas les citer toutes ici. La plus fréquemment utilisée est l’option&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt;, qui permet de profiter des lectures de la table pour en plus mettre&#xA;à jour les statistiques sur les données, à l’image de l’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;PARALLEL&lt;/code&gt; permet de paralléliser le traitement des index d’une table&#xA;sur plusieurs CPU, avec un CPU par index. C’est particulièrement intéressant&#xA;pour les tables volumineuses dotées de nombreux index.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mais l’option la plus fréquemment évoquée est l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;FULL&lt;/code&gt;. Cette option&#xA;change complètement le travail de la commande &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;, et on peut se&#xA;questionner sur le bien-fondé de ne pas avoir créé une instruction spécifique&#xA;pour cette opération. En utilisant l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;FULL&lt;/code&gt;, nous forçons la réécriture&#xA;complète de la table et de ses index, ce qui aura pour conséquence une&#xA;diminution sur disque de la volumétrie des fichiers associés à ces objets.&#xA;Cette opération a cependant deux gros inconvénients : les objets sont&#xA;totalement verrouillés pendant cette opération (donc l’écriture et la lecture&#xA;par d’autres processus sont bloqués le temps du traitement), et il est&#xA;essentiel d’avoir la place nécessaire pour les nouveaux fichiers le temps du&#xA;traitement (l’estimation de la place nécessaire est très basique : comptez&#xA;exactement la même volumétrie que la table et ses index occupent avant&#xA;l’opération).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une autre opération fait à peu près la même chose : &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CLUSTER&lt;/code&gt;. La seule&#xA;différence avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM FULL&lt;/code&gt; est que &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CLUSTER&lt;/code&gt; trie en plus les données avant&#xA;de les stocker dans le nouveau fichier de table. Le tri se fait par rapport au&#xA;tri d’un index. Il faut donc indiquer à l’instruction la table à traiter et&#xA;l’index à suivre.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voilà pour ce qui est des tables, mais les index peuvent aussi se fragmenter.&#xA;Ils sont toujours correctement balancés, mais les blocs du fichier de l’index&#xA;peuvent ne pas être remplis. Dans ce cas, il convient de les réindexer.&#xA;L’opération est aussi lente que leur création, elle est aussi bloquante (pas de&#xA;lecture de l’index, pas d’écriture dans la table associée). Cette opération&#xA;utilise l’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX&lt;/code&gt;. Il est possible de réindexer un seul index&#xA;(&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX INDEX i1;&lt;/code&gt;), tous les index d’une table (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX TABLE t1;&lt;/code&gt;), tous&#xA;les index d’un schéma (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX SCHEMA s1;&lt;/code&gt;), tous les index d’une base&#xA;(&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX;&lt;/code&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cette instruction accepte deux options : &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CONCURRENTLY&lt;/code&gt; (pour éviter le verrou&#xA;sur les écritures dans la table, ce qui a pour conséquence une opération plus&#xA;longue et le risque d’obtenir au final un index invalide) et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;TABLESPACE&lt;/code&gt; (pour&#xA;placer le nouveau fichier de l’index dans un autre tablespace).&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;comment-savoir-quun-objet-est-fragmenté&#34;&gt;Comment savoir qu’un objet est fragmenté&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Il existe deux moyens. Les deux sont à utiliser.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Le premier est une estimation. Il permet d’avoir rapidement une idée de la&#xA;fragmentation. Cette estimation se base notamment sur les statistiques sur les&#xA;données et elle sera d’autant plus fiable que ces statistiques sont récentes.&#xA;Deux groupes de requêtes sont disponibles, le premier pour les tables, le&#xA;second pour les index Btree. Les autres méthodes d’indexation ne sont donc pas&#xA;couvertes, cependant le Btree est la méthode par défaut et la plus couramment&#xA;utilisée. Ces requêtes sont disponibles dans le &lt;a href=&#34;https://github.com/ioguix/pgsql-bloat-estimation/&#34;&gt;dépôt GitHub&#xA;pgsql-bloat-estimation&lt;/a&gt;.&#xA;Généralement, je place ces requêtes dans des vues pour une utilisation&#xA;facilitée. Cela me donnerait par exemple cette requête pour trouver les 20&#xA;tables les plus fragmentées :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT quote_ident(schemaname)||&#39;.&#39;||quote_ident(tblname) AS table,&#xA;       real_size AS taille,&#xA;       bloat_size AS taille_fragmentation,&#xA;       round(bloat_pct::numeric, 2) AS ratio_fragmentation&#xA;FROM v_table_bloat&#xA;ORDER BY bloat_size DESC&#xA;LIMIT 20;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Le second est une extension (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgstattuple&lt;/code&gt;) qui donnera une information exacte.&#xA;Cependant, pour donner une information exacte, les fonctions qu’elle propose&#xA;doivent parcourir les objets entiers, ce qui se révèle très lent par rapport&#xA;aux requêtes citées précédemment. L’extension a été mise à jour récemment pour&#xA;proposer une fonction d’approximation qui se base, elle, sur le contenu de la&#xA;Visibility Map et sur le contenu de la Free Space Map. Voici un exemple de&#xA;requête utilisant la fonction exacte pour récupérer là aussi les 20 tables les&#xA;plus fragmentées :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT quote_ident(n.nspname)||&#39;.&#39;||quote_ident(c.relname) AS table,&#xA;       s.table_len AS taille,&#xA;       s.dead_tuple_len AS taille_invisibles,&#xA;       s.free_space AS taille_libre&#xA;FROM pg_class c&#xA;  JOIN pg_namespace n ON n.oid=c.relnamespace,&#xA;  LATERAL pgstattuple(c.oid) s&#xA;WHERE c.relkind=&#39;r&#39;&#xA;ORDER BY s.dead_tuple_len DESC&#xA;LIMIT 20;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;et celle utilisant la fonction d’approximation :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT quote_ident(n.nspname)||&#39;.&#39;||quote_ident(c.relname) AS table,&#xA;       s.table_len AS taille,&#xA;       s.dead_tuple_len AS taille_invisibles,&#xA;       s.approx_free_space AS taille_libre&#xA;FROM pg_class c&#xA;  JOIN pg_namespace n ON n.oid=c.relnamespace,&#xA;  LATERAL pgstattuple_approx(c.oid) s&#xA;WHERE c.relkind=&#39;r&#39;&#xA;ORDER BY s.dead_tuple_len DESC&#xA;LIMIT 20;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Cette extension dispose aussi de fonctions pour tester les index des méthodes&#xA;d’accès Btree, GIN et Hash.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour revenir au début de ce chapitre, je disais qu’il fallait utiliser les&#xA;deux, sans expliquer pourquoi. Les fonctions exactes sont trop longues si vous&#xA;voulez les exécuter fréquemment sur des bases de grosse volumétrie. Une&#xA;stratégie intéressante est d’utiliser les vues ou fonctions d’estimation pour&#xA;avoir une idée des objets les plus fragmentés et d’utiliser les fonctions&#xA;exactes uniquement sur les tables suffisamment fragmentées pour valider ou non&#xA;les informations des estimations. Cela permet de connaître les tables à traiter&#xA;réellement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En ce qui concerne la supervision, il peut être intéressant de suivre la&#xA;volumétrie de la base et sa fragmentation. Cela peut se faire avec la requête&#xA;suivante :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT &#39;volumétrie de la base&#39; AS &#34;Type&#34;, pg_size_pretty(pg_database_size(current_database())) AS &#34;Size&#34;&#xA;UNION&#xA;SELECT &#39;volumétrie de la fragmentation des tables&#39;, pg_size_pretty(sum(bloat_size)::numeric) FROM v_table_bloat&#xA;UNION&#xA;SELECT &#39;volumétrie de la fragmentation des index&#39;, pg_size_pretty(sum(bloat_size)::numeric) FROM v_index_bloat;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Ceci n’est qu’un exemple, qui sera facile à adapter le cas échéant.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;comment-exécuter-les-opérations-de-maintenance&#34;&gt;Comment exécuter les opérations de maintenance&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Une exécution manuelle est possible, mais ne convient qu’en de rares cas.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il est préférable d’automatiser ces opérations. Les développeurs de PostgreSQL&#xA;en ont automatisé certaines en développant un sous-processus appelé autovacuum.&#xA;Ce sous-processus va traiter chacune des bases de l’instance et déclenchera si&#xA;besoin des opérations &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt;. Ce besoin est détecté en se basant&#xA;sur le nombre de lignes insérées, modifiées et supprimées pour l’&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; et&#xA;sur le nombre de lignes mortes pour le VACUUM. Ces informations font partie des&#xA;statistiques d’activité récupérées en temps réel par PostgreSQL. Une&#xA;configuration permet d’indiquer à partir de quel ratio de lignes nous&#xA;souhaitons voir ces opérations déclenchées. Ces ratios sont par défaut très&#xA;haut, ce qui fait que peu d’opérations sont déclenchées, mais il est possible&#xA;de les diminuer globalement ou table par table si vos bases subissent beaucoup&#xA;d’écriture.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les paramètres les plus importants de ce sous-processus sont :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_analyze_scale_factor&lt;/code&gt;, ratio de lignes écrites avant de lancer&#xA;un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_analyze_threshold&lt;/code&gt;, nombre minimum de lignes écrites avant de&#xA;lancer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_vacuum_scale_factor&lt;/code&gt;, ratio de lignes mortes avant de lancer un&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_vacuum_threshold&lt;/code&gt;, nombre minimum de lignes mortes avant de&#xA;lancer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_vacuum_insert_scale_factor&lt;/code&gt;, ratio de lignes insérées avant de&#xA;lancer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_vacuum_insert_threshold&lt;/code&gt;, ratio de lignes insérées avant de&#xA;lancer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Le sous-processus autovacuum calcule donc la valeur cible en additionnant le&#xA;nombre minimum et le ratio multiplié par le nombre de lignes, et compare cette&#xA;valeur cible au nombre de lignes mortes pour le cas d’un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;. Si le nombre&#xA;de lignes mortes dépasse la valeur cible, l’autovacuum lance un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; sur la&#xA;table concernée. Par défaut, le ratio est de 20 %. Sur une petite table, ce&#xA;n’est pas énorme. Sur une table volumineuse par contre, le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ne sera&#xA;lancé que très peu fréquemment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour le dire autrement, pour une table de 100 Go, il faudra attendre 20 Go de&#xA;fragmentation pour exécuter un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;. Ce n’est pas bon, il aurait fallu le&#xA;lancer bien avant. C’est pour cela qu’il est généralement conseillé de&#xA;descendre ce ratio et de le faire table par table pour prendre en compte leur&#xA;utilisation, leur fragmentation actuelle. Il est même parfois intéressant de&#xA;placer à zéro le ratio et de ne prendre en compte que le nombre minimum de&#xA;lignes, pour se baser sur un volume fixe de fragmentation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cependant, une configuration aussi détaillée demande du temps et des&#xA;connaissances. Le plus simple, dans un premier temps, est certainement de&#xA;diminuer les valeurs par défaut de manière globale. Il est fréquemment&#xA;conseillé de diviser les ratios pour 10.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il est à noter que l’autovacuum ne fait ni &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM FULL&lt;/code&gt;, ni &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX&lt;/code&gt;. La&#xA;raison en est que ces opérations nécessitent un verrou exclusif qui est&#xA;bloquant pour les autres sessions en cours d’exécution. Cela va donc générer de&#xA;fortes contentions à des moments généralement très actifs. Ces deux opérations&#xA;sont plutôt à lancer manuellement, quand le besoin s’en fait sentir ou quand il&#xA;est prévu une fenêtre de maintenance où il n’y aura pas d’autres accès à la&#xA;base.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans les autres paramètres intéressants, notons &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_work_mem&lt;/code&gt;. Ce&#xA;dernier a le même but que le paramètre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;maintenance_work_mem&lt;/code&gt;, mais ne concerne&#xA;que le processus autovacuum. Ainsi, il est possible d’avoir une configuration&#xA;pour ce sous-processus et une configuration pour les &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; manuels.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;en-conclusion&#34;&gt;En conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;autovacuum est votre (meilleur) ami. Certains le désactivent parce qu’il&#xA;consommerait beaucoup de ressources. Sans nier qu’il consomme effectivement des&#xA;ressources, il permet surtout d’en sauver grâce à des statistiques à jour et en&#xA;luttant contre le grossissement sans fin des tables. Dans la très grande&#xA;majorité des cas, le désactiver est une erreur.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si vous préférez passer par une exécution via cron, pourquoi pas, mais il faut&#xA;bien comprendre ce que l’on fait et pourquoi.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans tous les cas, comme l’a dit Robert Haas, un des principaux développeurs de&#xA;PostgreSQL, lors d’une conférence à Prague au PGConf.EU 2024 : “Vacuuming is&#xA;like exercising. If it hurts, you’re not doing it enough!” (« Le VACUUM, c’est&#xA;comme faire du sport. Si cela fait mal, c’est que vous n’en faites pas&#xA;assez ! »).&lt;/p&gt;&#xA;&#xA;&lt;hr /&gt;&#xA;&#xA;&lt;p&gt;Depuis quelques années, Guillaume Lelarge publie des articles dans le magazine&#xA;« Linux Pratique » édité par les Éditions Diamond. Avec leur accord, il reprend&#xA;ici une série destinée à guider l’installation, la maintenance et l’utilisation&#xA;de PostgreSQL.&lt;/p&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>La PGSession 17 en replay</title>
    <updated>2025-02-28T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-02-28://2025/02/28/replay_pgsession17.html</id>
    <link href="https://blog.dalibo.com//2025/02/28/replay_pgsession17.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Saint-Étienne, le 28 février 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La journée Conférences de la &lt;strong&gt;PGSession 17&lt;/strong&gt; s’est tenue le 15 janvier à Paris. Voici les liens vers les supports de présentation et les vidéos en replay !&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/pgsession17_speakers.png&#34; alt=&#34;Les conférenciers de la PGSession 17&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Un grand merci aux conférenciers pour leurs contributions : Matt, Julien, Pierre G., Clément, Guillaume A., Guillaume L., Loïc, Cédric, Pierre T. et Yann&lt;/strong&gt; (absent sur la photo).&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;les-conférences-en-replay&#34;&gt;Les conférences en replay&lt;/h3&gt;&#xA;&#xA;&lt;ol&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_pg17&#34;&gt;Les nouveautés de PostgreSQL 17&lt;/a&gt;&lt;/strong&gt;, par Cédric Martin et Guillaume Armède  (Dalibo)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_powa&#34;&gt;PoWA v.5 : quoi de neuf ?&lt;/a&gt;&lt;/strong&gt;, par Julien Rouhaud (Nile) et Pierre Giraud (Dalibo)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_rex-maif&#34;&gt;Retour d’expérience Client : le Socle Dalibo&lt;/a&gt;&lt;/strong&gt;, par Clément Paillier (MAIF)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_i3g&#34;&gt;2014-2024 : les 10 ans de l’Infrastructure Interne d’Information Géographique&lt;/a&gt;&lt;/strong&gt;, par Yann Convers (DRÉAL AuRA)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_azimutt&#34;&gt;Explorer, documenter et faire évoluer ses bases de données avec Azimutt&lt;/a&gt;&lt;/strong&gt;, par Loïc Knuchel (Azimutt)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_usual-suspects&#34;&gt;Usual Suspects : mais qui a mis la production dans cet état ?&lt;/a&gt;&lt;/strong&gt;, par Pierre Top (Octo Technology)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_dev-pg&#34;&gt;Développement d’une fonctionnalité pour PostgreSQL, du besoin au commit…&lt;/a&gt;&lt;/strong&gt;, par Guillaume Lelarge (Dalibo)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_recherche-hybride&#34;&gt;Observer les oiseaux autrement : la recherche hybride au service de nos amis ailés&lt;/a&gt;&lt;/strong&gt;, par Matt Cornillon (Google Cloud)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;figure style=&#34;float: right;padding: 10px;width: 250px;&#34;&gt;&#xA;  &lt;img style=&#34;padding: 0;&#34; src=&#34;/img/2023_chapeau_rouge.png&#34; alt=&#34;Chapeau rouge&#34; /&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;Les autres liens utiles :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;a href=&#34;https://dali.bo/pgsession17_playlist&#34;&gt;la playlist PGSession 17&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;a href=&#34;https://dali.bo/pgsessions_archives&#34;&gt;les supports de présentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Enfin, nous remercions chaleureusement notre prestataire &lt;strong&gt;Chapeau rouge&lt;/strong&gt; pour son accompagnement vidéo, toujours efficace et sympathique.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bon visionnage !&lt;/p&gt;&#xA;&#xA;&lt;hr /&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Des questions, des commentaires, des suggestions ?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Écrivez-nous à &lt;a href=&#34;mailto:contact@pgsessions.com&#34;&gt;contact@pgsessions.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>Plongez dans le monde de CloudNativePG #4 - Les sauvegardes !</title>
    <updated>2025-02-27T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-02-27://2025/02/27/cnpg-3.html</id>
    <link href="https://blog.dalibo.com//2025/02/27/cnpg-3.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Lyon, le 27 février 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;CloudNativePG&lt;/strong&gt; ou comment embarquer un éléphant sur un porte-conteneurs !&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les deux premiers articles étaient l’occasion de découvrir l’opérateur et comment&#xA;il nous aide à embarquer notre éléphant favori sur un porte-conteneurs 🐘.&#xA;Embarquer un éléphant est une chose, le repêcher s’il tombe à l’eau en est une&#xA;autre… Attaquons-nous à un sujet très important, les sauvegardes des instances&#xA;PostgreSQL 🛟 !&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/cnpg-header.png&#34; alt=&#34;moteur&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;un-peu-de-données&#34;&gt;Un peu de données&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Pour le moment nos instances ne contiennent pas grand-chose. Il est temps&#xA;d’insérer quelques données, notamment avec l’outil &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;. C’est l’occasion&#xA;pour moi de présenter l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; du plugin &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;cnpg&lt;/code&gt;. &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; est un&#xA;outil très connu dans le monde PostgreSQL. Il permet notamment de générer des&#xA;jeux de tests et d’effectuer des tests de charge (à ce sujet, avez-vous lu notre&#xA;&lt;a href=&#34;https://blog.dalibo.com/2025/02/13/cnpg-3.html&#34;&gt;dernier article&lt;/a&gt; de blog ?).&#xA;Les mainteneurs CloudNativePG ont intégré cet outil du projet cœur PostgreSQL,&#xA;dans leurs images, nous permettant ainsi de l’utiliser.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg pgbench postgresql &lt;span class=&#34;nt&#34;&gt;--&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--initialize&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--scale&lt;/span&gt; 10 &#xA;&lt;span class=&#34;go&#34;&gt;job/postgresql-pgbench-446336 created&#xA;&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl logs job/postgresql-pgbench-446336&#xA;&lt;span class=&#34;go&#34;&gt;dropping old tables...&#xA;creating tables...&#xA;generating data (client-side)...&#xA;100000 of 1000000 tuples (10%) of pgbench_accounts done (elapsed 0.02 s, remaining 0.21 s)&#xA;200000 of 1000000 tuples (20%) of pgbench_accounts done (elapsed 0.08 s, remaining 0.30 s)&#xA;300000 of 1000000 tuples (30%) of pgbench_accounts done (elapsed 0.14 s, remaining 0.33 s)&#xA;400000 of 1000000 tuples (40%) of pgbench_accounts done (elapsed 0.20 s, remaining 0.30 s)&#xA;500000 of 1000000 tuples (50%) of pgbench_accounts done (elapsed 0.25 s, remaining 0.25 s)&#xA;600000 of 1000000 tuples (60%) of pgbench_accounts done (elapsed 0.30 s, remaining 0.20 s)&#xA;700000 of 1000000 tuples (70%) of pgbench_accounts done (elapsed 0.36 s, remaining 0.15 s)&#xA;800000 of 1000000 tuples (80%) of pgbench_accounts done (elapsed 0.44 s, remaining 0.11 s)&#xA;900000 of 1000000 tuples (90%) of pgbench_accounts done (elapsed 0.52 s, remaining 0.06 s)&#xA;1000000 of 1000000 tuples (100%) of pgbench_accounts done (elapsed 0.57 s, remaining 0.00 s)&#xA;vacuuming...&#xA;creating primary keys...&#xA;done in 0.96 s (drop tables 0.09 s, create tables 0.00 s, client-side generate 0.61 s, vacuum 0.11 s, primary keys 0.15 s).&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;La commande a généré 157 Mo de données dans la base &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;app&lt;/code&gt; (qui pour rappel, est&#xA;créée automatiquement par l’opérateur)… Oui je sais ! C’est une toute petite&#xA;base, mais c’est pour de la démo ! Les sujets liés à de la volumétrie importante&#xA;arriveront plus tard 😇.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;sauvegarde-logique&#34;&gt;Sauvegarde logique&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;À l’heure actuelle l’opérateur ne permet pas de déclencher une sauvegarde&#xA;logique de manière déclarative. Pour autant, dès lors que l’instance est&#xA;accessible, il est tout à fait possible de créer une sauvegarde avec l’outil&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_dump&lt;/code&gt; (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ou pg_dumpall&lt;/code&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Par exemple, si je rends mon instance accessible avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl port-forward&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;go&#34;&gt;kubectl port-forward --address 0.0.0.0 postgresql-2 5432:5432&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;Forwarding from 0.0.0.0:5432 -&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;5432&#xA;&lt;span class=&#34;go&#34;&gt;Handling connection for 5432&#xA;[...]&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Je peux appeler la commande &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_dump&lt;/code&gt;, renseigner le mot de passe et obtenir mon&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;dump&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;pg_dump &lt;span class=&#34;nt&#34;&gt;-h&lt;/span&gt; localhost &lt;span class=&#34;nt&#34;&gt;-U&lt;/span&gt; app &lt;span class=&#34;nt&#34;&gt;-Fc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; sauvegarde.dump&#xA;&lt;span class=&#34;go&#34;&gt;Password:&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;ls&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;-lh&lt;/span&gt; sauvegarde.dump&#xA;&lt;span class=&#34;go&#34;&gt;-rw-rw-r-- 1 pierrick pierrick 2,7M janv. 22 17:36 sauvegarde.dump&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;L’exposition du port 5432 de l’instance est grandement facilitée par la commande&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl port-forward&lt;/code&gt;. Dans un environnement de production, la mise en œuvre&#xA;demandera un peu plus de travail 🙃.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En bref, il vous sera toujours possible d’effectuer des sauvegardes logiques&#xA;d’une instance déployée par CloudNativePG.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;sauvegarde-par-volume-snapshot&#34;&gt;Sauvegarde par &lt;em&gt;Volume Snapshot&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;L’opérateur supporte aussi la méthode de sauvegarde par &lt;em&gt;Volume Snapshot&lt;/em&gt;. C’est&#xA;une fonctionnalité Kubernetes que ne supporte pas encore tous les&#xA;&lt;em&gt;Containers Storage Interface&lt;/em&gt; (CSI). Ce ne sera pas l’objet de l’article&#xA;aujourd’hui, mais jetez tout de même un œil à cette fonctionnalité&#xA;(&lt;a href=&#34;https://cloudnative-pg.io/documentation/current/backup_volumesnapshot/&#34;&gt;Backup on Volume Snapshot&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;sauvegarde-physique-pitr&#34;&gt;Sauvegarde physique &lt;em&gt;PITR&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;À l’inverse d’une sauvegarde logique, qui se limite à une base de données&#xA;spécifique, une sauvegarde physique permet de sauvegarder l’instance dans sa&#xA;globalité. Le principe est de sauvegarder toute l’arborescence PostgreSQL, que&#xA;ce soit les fichiers de données, le contenu des index, les fichiers de configuration ou les éléments&#xA;propres au fonctionnement de PostgreSQL.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si en plus de cette sauvegarde, vous archivez régulièrement les journaux de&#xA;transactions (&lt;em&gt;WAL&lt;/em&gt;) alors vous avez mis en place une sauvegarde &lt;em&gt;PITR&lt;/em&gt; (&lt;em&gt;Point In&#xA;Time Recovery&lt;/em&gt;) qui vous permettra, en rejouant ces fichiers là, de restaurer&#xA;votre instance soit complètement, soit jusqu’à un certain point dans le passé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Notre formation&#xA;&lt;a href=&#34;https://public.dalibo.com/exports/formation/manuels/formations/dba3/dba3.handout.html#sauvegarde-physique-%C3%A0-chaud-et-pitr&#34;&gt;DBA3&lt;/a&gt;&#xA;traite de ce sujet de manière plus détaillée&lt;/em&gt; 😎.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ce petit rappel étant fait, passons au vif du sujet !&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Stockage objets&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’opérateur CloudNativePG repose sur l’outil &lt;a href=&#34;https://docs.pgbarman.org/release/3.13.0/user_guide/barman_cloud.html&#34;&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Barman&#xA;Cloud&lt;/code&gt;&lt;/a&gt;&#xA;pour les sauvegardes physiques et l’archivage continu. Il est embarqué dans&#xA;l’image qui est utilisée lors de la création d’une instance. Le stockage des&#xA;journaux et des sauvegardes se fera obligatoirement sur un système de stockage&#xA;objets. Cette &lt;a href=&#34;https://cloudnative-pg.io/documentation/current/appendixes/object_stores/&#34;&gt;page de&#xA;documentation&lt;/a&gt;&#xA;indique les principales solutions supportées.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour cette série d’articles, je vais utiliser la solution &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Object Storage&lt;/code&gt; de&#xA;Scaleway, compatible &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;S3&lt;/code&gt;. Les informations qui me seront nécessaires sont :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;Le nom du &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt; à utiliser : ce sera &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;backup-postgresql&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;Une clé d’accès API : &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;jenevaispasvousladonner&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;Le secret lié à cette clé &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;encoremoinslesecret&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;La région de stockage : &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fr-par&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Ces informations là sont à ajouter dans un objet &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Secret&lt;/code&gt; qui sera par la&#xA;suite renseigné dans la configuration de notre instance. Les informations&#xA;doivent être encodées en &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;BASE64&lt;/code&gt; dans le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;YAML&lt;/code&gt;. Voici un exemple de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Secret&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Secret&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Opaque&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;ACCESS_KEY_ID&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;amVuZXZhaXNwYXN2b3VzbGFkb25uZXLCoA==&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;ACCESS_REGION&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ZnItcGFy&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;ACCESS_SECRET_KEY&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ZW5jb3JlbW9pbnNsZXNlY3JldMKg&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;N’oubliez pas de créer cet objet avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl apply&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Configuration&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Maintenant que nous avons un espace de stockage, voyons la configuration de&#xA;notre instance pour la mise en place de cette sauvegarde &lt;em&gt;PITR&lt;/em&gt;. Elle se fait&#xA;dans la section &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;backup.barmanObjectStore&lt;/code&gt; de notre objet &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Cluster&lt;/code&gt;.&#xA;Voilà à quoi ressemblerait notre définition :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql.cnpg.io/v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Cluster&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;imageName&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ghcr.io/cloudnative-pg/postgresql:17.0&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;instances&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;storage&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;20Gi&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;backup&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;barmanObjectStore&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;destinationPath&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;s3://backup-postgresql/&#34;&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;endpointURL&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;https://s3.fr-par.scw.cloud&#34;&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;s3Credentials&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;accessKeyId&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_KEY_ID&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;secretAccessKey&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_SECRET_KEY&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;region&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_REGION&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;destinationPath&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;endpointURL&lt;/code&gt; sont propres à la solution de stockage&#xA;choisie. Des exemples existent pour vous aider à configurer cela&#xA;(voir la page &lt;a href=&#34;https://cloudnative-pg.io/documentation/current/samples/&#34;&gt;Samples&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Lors de la création du &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Cluster&lt;/code&gt; PostgreSQL, les informations du &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Secret&lt;/code&gt;&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;s3-scaleway&lt;/code&gt; sont récupérées et l’archivage des journaux se fait&#xA;automatiquement sur le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt; S3.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Archivage des journaux&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans les traces de notre instance, nous voyons désormais que les journaux sont&#xA;bien archivés. Voici l’exemple d’une trace &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;JSON&lt;/code&gt; mise en forme avec l’outil&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;jq&lt;/code&gt; où nous pouvons voir, dans le champ &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;msg&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;endTime&lt;/code&gt; par exemple, que le&#xA;journal a bien été archivé.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-json highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;level&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;info&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;ts&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;2025-01-23T09:57:03.786672436Z&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;logger&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;wal-archive&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;msg&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;Archived WAL file&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;logging_pod&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;postgresql-1&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;walName&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;/var/lib/postgresql/data/pgdata/pg_wal/000000010000000000000005&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;startTime&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;2025-01-23T09:57:00.327727678Z&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;endTime&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;2025-01-23T09:57:03.786579567Z&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;elapsedWalTime&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;3.458851895&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Côté Scaleway, toute une arborescence a été créée dans le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt;&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;backup-postgresql&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;go&#34;&gt;backup-postgresql&#xA;└── postgresql&#xA;    └── wals&#xA;        └── 0000000100000000&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;postgresql&lt;/code&gt;, qui correspond au &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;name&lt;/code&gt; de notre cluster PostgreSQL ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;wals&lt;/code&gt;, qui contient les dossiers correspondant aux différentes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;timelines&lt;/code&gt; de&#xA;l’instance ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;0000000100000000&lt;/code&gt;, qui contient les journaux.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Sauvegarde&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’opérateur CloudNativePG étend l’API Kubernetes avec une nouvelle ressource&#xA;appelée &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Backup&lt;/code&gt;. En créant une ressource de ce type, une sauvegarde physique&#xA;sera déclenchée et stockée dans le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt; associé à notre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Cluster&lt;/code&gt;. Le nom du&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Cluster&lt;/code&gt; doit évidemment être mentionné dans la ressource pour que les&#xA;informations du stockage S3 soient récupérées.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Créons le fichier &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;sauvegarde.yaml&lt;/code&gt; avec le contenu suivant :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql.cnpg.io/v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Backup&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;premiere-sauvegarde&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;cluster&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Et créons cette ressource avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl apply -f sauvegarde.yaml&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl apply &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; sauvegarde.yaml&#xA;&lt;span class=&#34;go&#34;&gt;backup.postgresql.cnpg.io/premiere-sauvegarde created&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt; contient désormais le dossier &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;base&lt;/code&gt; qui contiendra les différentes&#xA;sauvegardes effectuées. Celle qui vient d’être faite est bien présente dans le&#xA;dossier.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;go&#34;&gt;backup-postgresql&#xA;└── postgresql&#xA;    ├── base&#xA;    │   └── 20250123T105602&#xA;    │      ├── backup.info&#xA;    │      └── data.tar&#xA;    └── wals&#xA;        └── 0000000100000000&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Pour information, l’opérateur CloudNativePG est configuré pour effectuer la&#xA;sauvegarde à partir d’un secondaire pour ne pas charger l’instance&#xA;primaire. C’est ce que l’on peut voir dans les traces de l’opérateur. Le champ&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pod&lt;/code&gt; indique bien que c’est le secondaire qui a été choisi.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-json highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;level&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;info&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;ts&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;2025-01-23T10:56:02.112865913Z&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;msg&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;Starting backup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;controller&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;backup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;controllerGroup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;postgresql.cnpg.io&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;controllerKind&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;Backup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;Backup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;    &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;name&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;premiere-sauvegarde&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;    &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;namespace&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;default&#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;namespace&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;default&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;name&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;premiere-sauvegarde&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;reconcileID&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;a91635aa-0c72-4c88-98c8-f7de4c2da83a&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;cluster&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;postgresql&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;pod&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;postgresql-2&#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Cette configuration par défaut peut être surchargée avec l’option&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;target: &#34;primary&#34;&lt;/code&gt; de la ressource &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Backup&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;réutiliser-cette-sauvegarde&#34;&gt;Réutiliser cette sauvegarde&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;J’aurais pu titrer cette partie &lt;em&gt;Restauration de l’instance&lt;/em&gt;, mais je ne l’ai&#xA;volontairement pas fait pour proposer un autre angle pour aborder ce sujet.&#xA;Évidemment, dès lors qu’une sauvegarde existe, vous pouvez l’utiliser pour&#xA;restaurer une instance en panne. Ce sera très probablement un article de blog&#xA;(ça y est la liste d’articles s’allonge…😏).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les équipes de développement ont souvent besoin de données de production à jour&#xA;pour tester leur nouvelle version (je fais simple et ne pas rentrer dans&#xA;les problématiques d’&lt;a href=&#34;https://blog.dalibo.com/2024/11/15/postgresql_anonymizer_exports_anonymises.html&#34;&gt;anonymisation&lt;/a&gt; des données par exemple). L’idée ici est de&#xA;déployer une nouvelle instance sur un nouveau cluster Kubernetes à partir de&#xA;cette sauvegarde là.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sur un autre cluster Kubernetes, appelé &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;k8s-demo&lt;/code&gt;, j’installe l’opérateur &#xA;CloudNativePG et crée le cluster &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;postgresql-dev&lt;/code&gt; défini de cette manière :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql.cnpg.io/v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Cluster&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql-dev&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;imageName&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ghcr.io/cloudnative-pg/postgresql:17.0&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;instances&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;storage&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;20Gi&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;bootstrap&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;recovery&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;externalClusters&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;pi&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;barmanObjectStore&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;destinationPath&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;s3://backup-postgresql/&#34;&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;endpointURL&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;https://s3.fr-par.scw.cloud&#34;&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;s3Credentials&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;accessKeyId&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_KEY_ID&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;secretAccessKey&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_SECRET_KEY&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;region&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_REGION&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Les deux instructions intéressantes ici sont &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;bootstrap&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;externalClusters&lt;/code&gt;.&#xA;Elles permettent d’indiquer que la création de notre instance PostgreSQL, doit se&#xA;faire à partir de la sauvegarde qui se trouve sur le stockage S3 indiqué.&#xA;Si vous faites le test, n’oubliez pas de créer le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Secret&lt;/code&gt; &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;s3-scaleway&lt;/code&gt; dans le&#xA;cluster &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;k8s-dev&lt;/code&gt;. Il contient les informations de connexion au S3.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Pod&lt;/code&gt; spécifique va être déployé. Son nom est plutôt parlant :&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;postgresql-dev-1-full-recovery-xxxxx&lt;/code&gt;. Une restauration de type &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;full&lt;/code&gt; est en&#xA;train de se faire à partir de la sauvegarde S3. Lorsque celle-ci est terminée,&#xA;le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Pod&lt;/code&gt; est créé et votre instance est accessible, les données sont bien présentes sur l’instance du pod postgresql-dev.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;-it&lt;/span&gt; postgresql-dev-1 &lt;span class=&#34;nt&#34;&gt;--&lt;/span&gt; psql &lt;span class=&#34;nt&#34;&gt;-d&lt;/span&gt; app &lt;span class=&#34;nt&#34;&gt;-c&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\d&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;t&#34;&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;Defaulted container &#34;postgres&#34; out of: postgres, bootstrap-controller (init)&#xA;             List of relations&#xA; Schema |       Name       | Type  | Owner &#xA;--------+------------------+-------+-------&#xA; public | pgbench_accounts | table | app&#xA; public | pgbench_branches | table | app&#xA; public | pgbench_history  | table | app&#xA; public | pgbench_tellers  | table | app&#xA;(4 rows)&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Vous avez donc une nouvelle instance, créée à partir d’une sauvegarde de votre&#xA;instance de production.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Petit truc à savoir 💡 : l’opérateur utilise par défaut la sauvegarde la plus &#xA;récente disponible dans le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt;. Ce fonctionnement est ajustable selon votre&#xA;besoin.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Nous venons de voir comment sauvegarder notre instance avec CloudNativePG et&#xA;l’outil &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Barman&lt;/code&gt; sur une solution de stockage objets 🛟. La mise en place est&#xA;plutôt simple. J’ai volontairement fait une sauvegarde basique, sans rentrer&#xA;dans les détails. Sachez qu’il existe de nombreuses options, notamment pour ce&#xA;qui est de la compression ou de la rétention des sauvegardes. À vous de jouer !&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Des questions, des commentaires ? &lt;a href=&#34;mailto:pierrick.chovelon@dalibo.com?subject=[Commentaire-Blog] CloudNativePG&#34;&gt;Écrivez-nous !&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>Plongez dans le monde de CloudNativePG #3 - Stockage et performance</title>
    <updated>2025-02-13T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-02-13://2025/02/13/cnpg-3.html</id>
    <link href="https://blog.dalibo.com//2025/02/13/cnpg-3.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Vallée de Munster, 13 février 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Récemment, Dalibo a été sollicité par un client pour réaliser une étude&#xA;sur l’exploitation de PostgreSQL dans Kubernetes. Ce client avait&#xA;légitimement des questions concernant &lt;strong&gt;le stockage pour PostgreSQL&lt;/strong&gt;. Ce&#xA;dernier nous a explicitement demandé notre avis concernant Longhorn, une&#xA;solution de stockage répliqué et distribué pour Kubernetes.&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;Bien que nous ayons quelques hypothèses à ce sujet, la solution a&#xA;suscité notre intérêt. Nous avons donc voulu évaluer/explorer cette&#xA;solution de stockage de manière approfondie. Nous vous proposons dans&#xA;cet article une présentation de Longhorn, mais aussi d’une partie des&#xA;tests que nous avons réalisés pour PostgreSQL sur ce type&#xA;d’architecture. Ce sera l’occasion d’évoquer succinctement l’utilisation&#xA;du plugin &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl&lt;/code&gt; de l’opérateur &lt;strong&gt;CloudNativePG&lt;/strong&gt;, ce plugin sera utilisé&#xA;pour lancer &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; dans un environnement conteneurisé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/cnpg-header.png&#34; alt=&#34;moteur&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h1 id=&#34;présentation-longhorn&#34;&gt;Présentation Longhorn&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Longhorn est une solution de stockage (&lt;em&gt;block storage&lt;/em&gt;) persistant dite&#xA;hautement disponible et distribuée pour les Kubernetes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cette solution intègre des fonctionnalités de synchronisation des&#xA;données, de prise d’instantané et de sauvegarde incrémentielle des&#xA;volumes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Longhorn permet entre autre :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;La réplication du stockage entre plusieurs nœuds Kubernetes ;&lt;/li&gt;&#xA;  &lt;li&gt;La mise en place d’un stockage type “hyperconvergé”, le stockage se&#xA;fait par dessus Kubernetes. Il est par exemple possible de combiner&#xA;des nœuds de calcul et de stockage ;&lt;/li&gt;&#xA;  &lt;li&gt;De facilement exporter les données vers du stockage de type S3 ou&#xA;NFS. Pour par exemple stocker et planifier des sauvegardes ;&lt;/li&gt;&#xA;  &lt;li&gt;D’effectuer des instantanés (&lt;em&gt;snapshot&lt;/em&gt;) ;&lt;/li&gt;&#xA;  &lt;li&gt;D’avoir une interface web de gestion.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2 id=&#34;installation-de-longhorn&#34;&gt;Installation de Longhorn&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Nous avons réalisé une installation de base de Longhorn en utilisant la&#xA;procédure suivante:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Appliquer le &lt;em&gt;manifest&lt;/em&gt; distribué par le projet :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl apply &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; https://raw.githubusercontent.com/longhorn/longhorn/v1.8.0/deploy/longhorn.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Vérifier la présence des composants pour le fonctionnement de base&#xA;dans l’espace de nom &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;longhorn-system&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get pods &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt; longhorn-system&#xA;&lt;span class=&#34;go&#34;&gt;NAME                                                READY   STATUS    RESTARTS      AGE&#xA;csi-attacher-79866cdcf8-bs22m                       1/1     Running   1 (11m ago)   12m&#xA;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;...&#xA;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;longhorn-driver-deployer-64c9779f48-v4t55           1/1     Running   0             19m&#xA;longhorn-manager-xds9c                              2/2     Running   0             19m&#xA;longhorn-ui-5677d74dfd-c97p7                        1/1     Running   0             19m&#xA;longhorn-ui-5677d74dfd-dcckd                        1/1     Running   0             19m&#xA;&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get deployments &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt; longhorn-system&#xA;&lt;span class=&#34;go&#34;&gt;NAME                       READY   UP-TO-DATE   AVAILABLE   AGE&#xA;csi-attacher               3/3     3            3           19m&#xA;csi-provisioner            3/3     3            3           19m&#xA;csi-resizer                3/3     3            3           19m&#xA;csi-snapshotter            3/3     3            3           19m&#xA;longhorn-driver-deployer   1/1     1            1           25m&#xA;longhorn-ui                2/2     2            2           25&#xA;&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get services &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt; longhorn-system&#xA;&lt;span class=&#34;go&#34;&gt;NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;longhorn-admission-webhook    ClusterIP   10.96.9.151     &amp;lt;none&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;9502/TCP   31m&#xA;&lt;span class=&#34;c&#34;&gt;...&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;longhorn-recovery-backend     ClusterIP   10.96.235.98    &amp;lt;none&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;9503/TCP   31m&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Vérifier la présence des deux classes de stockage définies par le&#xA;&lt;em&gt;manifest&lt;/em&gt; de Longhorn&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get storageclasses.storage.k8s.io&#xA;&lt;span class=&#34;go&#34;&gt;NAME                 PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE&#xA;longhorn (default)   driver.longhorn.io      Delete          Immediate              true                   16m&#xA;longhorn-static      driver.longhorn.io      Delete          Immediate              true                   16m&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Et pour finir, consulter l’interface de gestion (nous utilisons ici,&#xA;une simple redirection de port) :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl port-forward services/longhorn-frontend &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; longhorn-system 8080:80&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;&#xA;    &lt;p&gt;Nous pouvons maintenant ouvrir l’interface de gestion dans notre&#xA;navigateur &lt;a href=&#34;http://127.0.0.1:8080&#34;&gt;http://127.0.0.1:8080&lt;/a&gt;&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Nous avons maintenant un cluster Kubernetes en mesure d’utiliser du&#xA;stockage distribué. L’utilisation de Longhorn permet potentiellement de&#xA;réduire le risque de perdre des données lors de la perte d’un nœud&#xA;Kubernetes. L’interface web de gestion donne un bref aperçu des&#xA;nombreuses options offertes par cette solution de stockage. Pour plus&#xA;des informations complémentaires concernant les fonctionnalités, le&#xA;fonctionnement interne de et la réplication inter nœud, nous vons&#xA;invitons à consulter la &lt;a href=&#34;https://longhorn.io/docs/1.8.0/concepts/&#34;&gt;documentation officielle du&#xA;projet&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Avant de continuer, il nous semble utile de rappeler que notre&#xA;installation (de Longhorn) est uniquement pour des tests. Pour un&#xA;système de production, il est strictement nécessaire de se questionner&#xA;concernant divers sujets que nous n’aborderons pas ici (par exemple:&#xA;CAP, fencing, sauvegarde…).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Après ces quelques vérifications et un rapide tour de l’interface de&#xA;gestion, nous pouvons démarrer nos tests.&lt;/p&gt;&#xA;&#xA;&lt;h2 id=&#34;tester-avec-du-stockage-répliqué&#34;&gt;Tester avec du stockage répliqué&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Dans ce paragraphe, nous allons mesurer la charge disque que Longhorn&#xA;est capable d’encaisser avec un volume composé de 3 réplicas&#xA;(configuration fournie par défaut). Nous lancerons aussi quelques tests&#xA;avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; sur une instance PostgreSQL. Comme annoncé dans&#xA;l’introduction, nous utiliserons pour cela le &lt;a href=&#34;https://cloudnative-pg.io/documentation/current/kubectl-plugin/#kubectl-plugin&#34;&gt;&lt;em&gt;plugin&#xA;CNPG&lt;/em&gt;&lt;/a&gt;&#xA;pour kubectl. Pour finir, l’opérateur CNPG sera aussi utilisé pour nous&#xA;faciliter la création de nos instances PostgreSQL de tests.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;lancer-fio&#34;&gt;Lancer &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Avant d’effectuer nos tests avec PostgreSQL, nous allons utiliser &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;&#xA;pour évaluer les performances brutes de notre stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour cela, nous pouvons lancer la commande suivante :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg fio fio-test-perf &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; default &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    --pvcSize 2Gi --storageClass longhorn --dry-run |\&#xA;    sed -e &#39;s/runtime=60/runtime=3600/g&#39;|kubectl apply -f -&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Cette commande va exécuter &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; pendant une heure avec un volume&#xA;dédié de 2 Gi. En fin d’exécution, les résultats sont récupérables via&#xA;une page web. Il est possible de consulter cette page en exposant le&#xA;service dédié :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl port-forward &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; fio deployment/fio-test-perf 8000&#xA;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;open http://127.0.0.1:8000&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;La page (consultable sur &lt;a href=&#34;http://127.0.0.1:8000&#34;&gt;http://127.0.0.1:8000&lt;/a&gt;) présente des&#xA;graphiques et les &lt;em&gt;logs&lt;/em&gt; de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;. Pour nos tests sur du stockage&#xA;répliqué la bande passante moyenne mesurée est de 2800 IOPs &lt;strong&gt;en&#xA;lecture&lt;/strong&gt; :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/read_iops_noreplica.1-2Dtrend.png&#34; alt=&#34;IOPs sur volume avec réplication&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour mesurer la capacité théorique en écriture, nous pouvons relancer&#xA;notre test en utilisant le scénario &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;write&lt;/code&gt; de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;. Pour modifier les&#xA;différents paramètres de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;, nous exportons le &lt;em&gt;manifest&lt;/em&gt; généré avec&#xA;le plugin CloudNativePG de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl&lt;/code&gt; pour ensuite le modifier :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg fio fio-test-perf-write &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; default &lt;span class=&#34;nt&#34;&gt;--pvcSize&lt;/span&gt; 2Gi &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;gp&#34;&gt;    --storageClass longhorn --dry-run &amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/tmp/scenario.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;On modifie la &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ConfigMap&lt;/code&gt; pour &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; qui se trouve dans le fichier&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;/tmp/scenario.yaml&lt;/code&gt; (on change à minima l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;rw&lt;/code&gt; de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;read&lt;/code&gt; a&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;write&lt;/code&gt;) :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ConfigMap&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;fio-test-perf&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;default&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;job&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;pi&#34;&gt;|-&lt;/span&gt;&#xA;    &lt;span class=&#34;s&#34;&gt;[write]&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;direct=1&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;bs=8k&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;size=1G&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;time_based=1&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;runtime=3600&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;ioengine=libaio&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;iodepth=32&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;end_fsync=1&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;log_avg_msec=1000&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;directory=/data&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;rw=write&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;write_bw_log=read&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;write_lat_log=read&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;write_iops_log=read&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;...&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;L’exécution de ce scénario génère le graphique suivant :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/write_iops_withreplica.1-2Dtrend.png&#34; alt=&#34;IOPs en écriture sur volume avec réplication&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nous pouvons conclure que Longhorn avec 3 réplicas sur notre&#xA;infrastructure de test peut encaisser :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;2819 IOPs en lecture&lt;/li&gt;&#xA;  &lt;li&gt;1316 IOPs en écriture&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3 id=&#34;tester-avec-une-instance-postgresql&#34;&gt;Tester avec une instance PostgreSQL&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Nous allons maintenant utiliser &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; sur un cluster PostgreSQL. Ce&#xA;cluster sera composé d’une seule instance PostgreSQL. Les données de&#xA;notre instance se trouveront sur du stockage répliqué sur 3 nœuds&#xA;Kubernetes (configuration de base de la classe de stockage &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;longhorn&lt;/code&gt;).&#xA;Nous commençons par déclarer une instance avec la classe de stockage&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;longhorn&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl apply &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; - &lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;no&#34;&gt;EOF&lt;/span&gt;&lt;span class=&#34;sh&#34;&gt;&#xA;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;apiVersion: postgresql.cnpg.io/v1&#xA;kind: Cluster&#xA;metadata:&#xA;  name: cluster-longhorn&#xA;spec:&#xA;  instances: 1&#xA;  storage:&#xA;    storageClass: longhorn&#xA;    size: 10Gi&#xA;  resources:&#xA;    requests:&#xA;      memory: 1Gi&#xA;      cpu: &#39;1&#39;&#xA;    limits:&#xA;      memory: 2Gi&#xA;      cpu: &#39;2&#39;&#xA;  postgresql:&#xA;    parameters:&#xA;      shared_buffers: 256MB&#xA;      effective_io_concurrency: &#39;300&#39;&#xA;      random_page_cost: &#39;1.1&#39;&#xA;EOF&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Cette instance (après initialisation) est utilisable et testable en&#xA;suivant les étapes suivantes :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Garnir la base &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;app&lt;/code&gt; de notre instance avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;. Pour cette&#xA;opération, nous utilisons le plugin &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl&lt;/code&gt; de CloudNativePG pour&#xA;déployer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt; (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;job-instance-longhorn&lt;/code&gt; ici) dédié à &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;.&#xA;Les options &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--initialize&lt;/code&gt; &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--scale 250&lt;/code&gt; sont placées après un&#xA;double tiret. En fonction de nos besoins, il est possible d’ajouter&#xA;des options complémentaires pour &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg pgbench &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    --job-name job-instance-longhorn cluster-longhorn \&#xA;    -- --initialize --scale 250&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Surveiller le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Pod&lt;/code&gt; correspondant à &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;&#xA;(&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;job-instance-longhorn-djgwb&lt;/code&gt;) :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get pods&#xA;&lt;span class=&#34;go&#34;&gt;NAME                              READY   STATUS      RESTARTS   AGE&#xA;cluster-longhorn-1                1/1     Running     0          8m34s&#xA;cluster-longhorn-1-initdb-6bgsb   0/1     Completed   0          9m&#xA;job-instance-longhorn-djgwb       1/1     Running     0          3m33s&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Récupérer les résultats de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; en affichant les journaux du&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl logs &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt; default job/job-instance-longhorn-client1&#xA;&lt;span class=&#34;go&#34;&gt;dropping old tables...&#xA;NOTICE:  table &#34;pgbench_accounts&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_branches&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_history&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_tellers&#34; does not exist, skipping&#xA;creating tables...&#xA;generating data (client-side)...&#xA;100000 of 25000000 tuples (0%) of pgbench_accounts done (elapsed 0.08 s, remaining 20.13 s) &#xA;200000 of 25000000 tuples (0%) of pgbench_accounts done (elapsed 0.14 s, remaining 17.49 s)&#xA;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;...&#xA;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;24900000 of 25000000 tuples (99%) of pgbench_accounts done (elapsed 200.00 s, remaining 0.80 s)&#xA;25000000 of 25000000 tuples (100%) of pgbench_accounts done (elapsed 201.36 s, remaining 0.00 s)&#xA;vacuuming...&#xA;creating primary keys...&#xA;done in 336.58 s (drop tables 0.01 s, create tables 0.14 s, client-side generate 203.41 s, vacuum 13.16 s, primary keys 119.86 s).&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Les informations utiles se trouvent à la fin :&lt;/p&gt;&#xA;&#xA;    &lt;ul&gt;&#xA;      &lt;li&gt;durée : 336.58 s&lt;/li&gt;&#xA;      &lt;li&gt;temps création des clés primaires : 119.86 s&lt;/li&gt;&#xA;      &lt;li&gt;client-side generate - principalement temps pour garnir les&#xA;tables : 203.41 s&lt;/li&gt;&#xA;    &lt;/ul&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Si nécessaire, nous pouvons aussi récupérer la taille (3746 MB) de&#xA;la base en utilisant cette commande :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;default &lt;span class=&#34;nt&#34;&gt;--stdin&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--tty&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    -ti cluster-longhorn-1  \&#xA;    -- psql -c &#34;SELECT pg_size_pretty(pg_database_size(&#39;app&#39;))&#34;&#xA;Defaulted container &#34;postgres&#34; out of: postgres, bootstrap-controller (init)&#xA; pg_size_pretty&#xA;----------------&#xA; 3746 MB&#xA;(1 row)&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Maintenant que notre base de test est en place, nous lançons&#xA;successivement des tâches (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt;) pour &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; en augmentant&#xA;progressivement la valeur de l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--client&lt;/code&gt; (et ce afin&#xA;d’établir le tableau visible plus bas) :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg pgbench &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    --job-name job-instance-longhorn-client1 cluster-longhorn \&#xA;    -- --time 300 --client 1 --jobs 1&#xA;job/job-instance-longhorn-client1 create&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl logs &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; job/job-instance-longhorn-client1&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;&#xA;    &lt;p&gt;Cette dernière étape permet d’établir ce tableau (variation de&#xA;l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--client&lt;/code&gt;) :&lt;/p&gt;&#xA;&#xA;    &lt;table&gt;&#xA;      &lt;thead&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--client&lt;/code&gt;&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;TPS&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;Latence moyenne&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;initial connection time&lt;/th&gt;&#xA;        &lt;/tr&gt;&#xA;      &lt;/thead&gt;&#xA;      &lt;tbody&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;1&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;52&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;18.906&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;28.819&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;2&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;109&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;18.260&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;22.341&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;4&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;201&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;19.850&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;24.132&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;8&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;313&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;24.256&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;108.819&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;16&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;409&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;39.026&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;57.023&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;      &lt;/tbody&gt;&#xA;    &lt;/table&gt;&#xA;  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2 id=&#34;tester-avec-du-stockage-non-répliqué&#34;&gt;Tester avec du stockage non répliqué&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Dans cette section, nous allons réaliser notre batterie de tests (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt;&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; et plusieurs exécutions de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;) en utilisant du stockage non&#xA;répliqué.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On commence par ajouter une classe de stockage utilisant Longhorn en&#xA;positionnant le nombre de réplica à 1 (la partie importante est la ligne&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;numberOfReplicas: &#34;1&#34;&lt;/code&gt;) :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl apply &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; - &lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;no&#34;&gt;EOF&lt;/span&gt;&lt;span class=&#34;sh&#34;&gt;&#xA;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;---&#xA;allowVolumeExpansion: true&#xA;apiVersion: storage.k8s.io/v1&#xA;kind: StorageClass&#xA;metadata:&#xA;  name: longhorn-noreplica&#xA;parameters:&#xA;  dataEngine: v1&#xA;  dataLocality: disabled&#xA;  disableRevisionCounter: &#34;true&#34;&#xA;  fromBackup: &#34;&#34;&#xA;  fsType: ext4&#xA;  numberOfReplicas: &#34;1&#34;&#xA;  staleReplicaTimeout: &#34;30&#34;&#xA;  unmapMarkSnapChainRemoved: ignored&#xA;provisioner: driver.longhorn.io&#xA;reclaimPolicy: Delete&#xA;volumeBindingMode: Immediate&#xA;EOF&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Nous pouvons vérifier la présence de cette nouvelle classe et reprendre&#xA;nos tests en adaptant la classe de stockage :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get storageclasses.storage.k8s.io longhorn-noreplica&#xA;&lt;span class=&#34;go&#34;&gt;NAME                 PROVISIONER          RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE&#xA;longhorn-noreplica   driver.longhorn.io   Delete          Immediate           true                   4d&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;h3 id=&#34;lancer-fio-1&#34;&gt;Lancer fio&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;On lance un nouveau &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt; pour &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; en spécifiant notre nouvelle classe&#xA;de stockage :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg fio fio-test-perf-noreplica &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; default &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    --pvcSize 2Gi --storageClass longhorn-noreplica --dry-run |\&#xA;    sed -e &#39;s/runtime=60/runtime=3600/g&#39; | kubectl apply -f -&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Pour ensuite consulter les résultats, on expose le port 80 de notre&#xA;déploiement :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl port-forward deployment/fio-test-perf-noreplica 8000&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/read_iops_noreplica.1-2Dtrend.png&#34; alt=&#34;IOPs en lecture sur volume sans réplication&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Et exécuter le test en écriture et consulter les résultats :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/write_iops_noreplica.1-2Dtrend.png&#34; alt=&#34;IOPs en écriture sur volume sans réplication&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nous constatons que notre solution de stockage configurée sans&#xA;réplication est en mesure d’encaisser en moyenne :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;2493 IOPs en lecture&lt;/li&gt;&#xA;  &lt;li&gt;2289 IOPs en écriture&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Par rapport à une instance utilisant du stockage répliqué, on remarque&#xA;une différence importante pour les écritures (presque 1000 IOPS en&#xA;plus).&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;tester-avec-une-instance-postgresql-1&#34;&gt;Tester avec une instance PostgreSQL&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Après avoir testé avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;, nous allons réaliser la même batterie de&#xA;tests avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; que pour notre première instance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On commence par déclarer une nouvelle instance PostgreSQL en utilisant&#xA;notre nouvelle classe de stockage, pour ensuite :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;Garnir cette seconde instance avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; et les options&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--initialize&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--scale 250&lt;/code&gt;&lt;/li&gt;&#xA;  &lt;li&gt;Lancer plusieurs tâches pour simuler progressivement 1, 2, 4, 8 et&#xA;16 clients PostgreSQL.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Ce qui va nous permettre de comparer les deux configurations avec et&#xA;sans réplication synchrone au niveau stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Le résultat du garnissage d’une base indique ceci :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl logs &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;jobs&lt;/span&gt;/job-instance-longhorn-noreplica&#xA;&lt;span class=&#34;go&#34;&gt;dropping old tables...&#xA;NOTICE:  table &#34;pgbench_accounts&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_branches&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_history&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_tellers&#34; does not exist, skipping&#xA;creating tables...&#xA;generating data (client-side)...&#xA;100000 of 25000000 tuples (0%) of pgbench_accounts done (elapsed 0.06 s, remaining 15.69 s)&#xA;200000 of 25000000 tuples (0%) of pgbench_accounts done (elapsed 0.31 s, remaining 37.95 s)&#xA;300000 of 25000000 tuples (1%) of pgbench_accounts done (elapsed 0.39 s, remaining 31.78 s)&#xA;24900000 of 25000000 tuples (99%) of pgbench_accounts done (elapsed 100.51 s, remaining 0.48 s)&#xA;25000000 of 25000000 tuples (100%) of pgbench_accounts done (elapsed 100.58 s, remaining 0.00 s)&#xA;vacuuming...&#xA;creating primary keys...&#xA;done in 203.71 s (drop tables 0.01 s, create tables 0.09 s, client-side generate 102.00 s, vacuum 11.99 s, primary keys 89.62 s).&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Ces informations nous montrent que sans réplication le garnissage de&#xA;notre base prend approximativement 1/3 de temps en moins :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;durée : 203.71 s (336.58 s lors de notre première exécution)&lt;/li&gt;&#xA;  &lt;li&gt;temps création des clés primaires : 89.62 s, (cela représente 30 s&#xA;de moins que pour une instance avec du stockage répliqué)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;em&gt;client-side generate&lt;/em&gt; - (principalement du temps pour garnir les&#xA;tables) : 102.00 secondes, ce qui correspond à 101 secondes de moins&#xA;que notre première instance avec du stockage répliqué&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Et les résultats des différents jobs avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;, nous permettent&#xA;d’établir le tableau suivant :&lt;/p&gt;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th style=&#34;text-align: center&#34;&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--client&lt;/code&gt;&lt;/th&gt;&#xA;      &lt;th style=&#34;text-align: center&#34;&gt;TPS&lt;/th&gt;&#xA;      &lt;th style=&#34;text-align: center&#34;&gt;Latence moyenne&lt;/th&gt;&#xA;      &lt;th style=&#34;text-align: center&#34;&gt;initial connection time&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;1&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;63&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;13.953&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;19.090&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;2&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;144&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;13.864&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;43.447&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;4&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;242&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;19.433&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;25.395&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;8&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;329&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;24.300&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;138.927&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;16&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;412&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;38.839&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;157.923&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;p&gt;Les lectures restent sensiblement identiques. Il pourrait être utile de&#xA;vérifier le comportement du cache ou des caches (PostgreSQL, système…)&#xA;pour en savoir plus concernant les lectures.&lt;/p&gt;&#xA;&#xA;&lt;h1 id=&#34;conclusion---stockage-distribué-avec-postgresql&#34;&gt;Conclusion - Stockage distribué avec PostgreSQL&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Intuitivement, sur la base de notre connaissance d’autres solutions de&#xA;stockage et du fonctionnement de PostgreSQL, on aurait tendance à&#xA;conseiller de désactiver la réplication au niveau du stockage pour&#xA;laisser PostgreSQL s’occuper de la réplication.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les résultats de nos tests (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; lors des phases d’initialisations)&#xA;démontrent un impact (&lt;em&gt;Write amplification&lt;/em&gt;) notable sur les écritures.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;D’ailleurs, on retrouve dans la documentation de CloudNativePG un&#xA;paragraphe spécifique concernant ce type de solution.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Most block storage solutions in Kubernetes, such as Longhorn and Ceph,&#xA;recommend having multiple replicas of a volume to enhance resiliency.&#xA;This approach works well for workloads that lack built-in resiliency.&lt;/p&gt;&#xA;&#xA;  &lt;p&gt;However, CloudNativePG integrates this resiliency directly into the&#xA;Postgres Cluster through the number of instances and the persistent&#xA;volumes attached to them, as explained in “Synchronizing the state”.&lt;/p&gt;&#xA;&#xA;  &lt;p&gt;As a result, defining additional replicas at the storage level can&#xA;lead to write amplification, unnecessarily increasing disk I/O and&#xA;space usage.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://cloudnative-pg.io/documentation/1.25/storage/&#34;&gt;https://cloudnative-pg.io/documentation/1.25/storage/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nos tests et la documentation valident donc nos intuitions. Lors de&#xA;l’utilisation de PostgreSQL sur des technologies de stockage avancées,&#xA;il est souvent souhaitable de s’appuyer sur les mécanismes natifs (de&#xA;PostgreSQL) pour gérer la réplication. Dit plus simplement Longhorn,&#xA;dans sa configuration de base, ne nous semble pas adapté pour notre SGBD&#xA;favori et pourrait même avoir des effets indésirables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Concernant les lectures disque, on constate que Longhorn, de par son&#xA;architecture, n’apporte pas grand-chose pour PostgreSQL. Lors de nos&#xA;tests, c’est surtout le cache système et de PostgreSQL qui semblent être&#xA;bénéfiques. On aurait d’ailleurs pu présenter des tests spécifiques pour&#xA;démontrer cela (pourquoi pas dans un prochain article ?!).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cet article, nous a permis de présenter quelques fonctionnalités&#xA;fournies avec le plugin &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl&lt;/code&gt; de CloudNativePG. Nous avons aussi un&#xA;bref aperçu du fonctionnement de Longhorn. Dans le cadre de nos&#xA;recherches et tests, nous avons traité plus en profondeur cette&#xA;technologie. Nous avons retenu ici, la partie la plus pertinente pour&#xA;PostgreSQL. D’autres articles concernant PostgreSQL et Kubernetes&#xA;arriveront prochainement sur notre blog.&lt;/p&gt;&#xA;&#xA;&lt;!--&#xA;    vim: spelllang=fr spell&#xA;  --&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>La suite des patchs sur la parallélisation</title>
    <updated>2025-02-10T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-02-10://2025/02/10/patchs_parallelisations_2.html</id>
    <link href="https://blog.dalibo.com//2025/02/10/patchs_parallelisations_2.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Reviers, le 10 février 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cela fait plusieurs mois maintenant que nous avons envoyé des patchs sur la&#xA;&lt;a href=&#34;https://www.postgresql.org/list/pgsql-hackers/&#34;&gt;liste de discussion des développeurs de PostgreSQL&lt;/a&gt; pour&#xA;améliorer la supervision de la parallélisation. J’avais promis de revenir&#xA;vers vous à ce sujet. Je l’ai fait lors d’une conférence à la &lt;a href=&#34;https://dali.bo/pgsession17_conf_dev-pg&#34;&gt;PGSession 17&lt;/a&gt;&#xA;et je vais revenir rapidement ici sur ce sujet pour ceux et celles qui n’ont&#xA;pas pu y assister.&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/portrait_guillaume.png&#34; alt=&#34;Guillaume Lelarge&#34; style=&#34;float: right; padding:10px; width:120px;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En septembre 2024, Benoît et moi avons envoyé quatre patchs pour améliorer la supervision de la parallélisation d’une requête. Détaillons ces patchs et le retour qu’ils ont reçu.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;patch-1--traces-supplémentaires&#34;&gt;Patch #1 : traces supplémentaires&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;L’idée des quatre participants (Benoît, Franck, Jehan-Guillaume et moi) du&#xA;&lt;a href=&#34;https://blog.dalibo.com/2024/09/16/cowork_parallelisation.html&#34;&gt;cowork de Nantes&lt;/a&gt; est d’avoir une trace permettant de savoir quand la&#xA;parallélisation d’un nœud d’une requête a été demandée, le niveau de parallélisation demandé&#xA;(nombre de workers planifiés), et le niveau de parallélisation atteint&#xA;(nombre de workers réellement exécutés). Voici un exemple de la trace&#xA;proposée :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;LOG:  1 parallel nodes planned (1 obtained all their workers, 0 obtained none), 2 workers planned (2 workers launched)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Savoir qu’il n’y a aucune requête parallélisée ou, au contraire, savoir qu’il y&#xA;en a plein, peut aider à quantifier les ressources allouées à la machine&#xA;(ici, le nombre de CPU).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Savoir qu’il y a eu moins de workers exécutés que planifiés peut démontrer un&#xA;problème de configuration (notamment sur les paramètres&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;max_worker_processes&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;max_parallel_workers&lt;/code&gt; et&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;max_parallel_workers_per_gather&lt;/code&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;À Dalibo, on tient à conseiller nos clients en nous basant sur des constatations&#xA;et force est d’avouer que cette trace supplémentaire nous aiderait&#xA;grandement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ces traces ont donc un intérêt et le patch a logiquement suscité un intérêt de la part de la communauté. Suite aux réactions, le patch a été amélioré. Il en est aujourd’hui à sa version 6 et est divisé en plusieurs parties :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0001-Add-a-guc-for-parallel-worker-logging.patch&lt;/code&gt; ajoute un paramètre&#xA;de configuration (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;log_parallel_workers&lt;/code&gt;) permettant de contrôler la trace sur&#xA;la parallélisation avec trois options : désactivé, activé pour toutes les&#xA;opérations, activé seulement quand des workers manquaient.&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0002-Implements-logging-for-parallel-worker-usage-in-inde.patch&lt;/code&gt; ajoute&#xA;la trace sur les requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CREATE INDEX&lt;/code&gt; (attention, seuls les index B-tree&#xA;et BRIN peuvent profiter de la parallélisation à leur création).&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0003-Setup-counters-for-parallel-vacuums.patch&lt;/code&gt; ajoute les compteurs de&#xA;parallélisation pour tracer la parallélisation des requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;.&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0004-Implements-logging-for-parallel-worker-usage-in-vacu.patch&lt;/code&gt; ajoute&#xA;les traces sur la parallélisation des requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;.&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0005-Implements-logging-for-parallel-worker-usage-in-quer.patch&lt;/code&gt; ajoute&#xA;les traces sur la parallélisation des requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;SELECT&lt;/code&gt; (les compteurs ont&#xA;été ajoutés par un autre patch dont nous parlerons après).&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;La trace est devenue plus simple :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;launched 3 parallel workers (planned: 4)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Le but de la division en plusieurs patchs est de mieux comprendre la&#xA;structure du patch global, de faciliter sa relecture, puis de permettre au&#xA;&lt;em&gt;commiter&lt;/em&gt; d’intégrer uniquement les parties qui lui semblent intéressantes et finalisées,&#xA;si le patch global nécessite encore des discussions. Cela donne ainsi plus de&#xA;chance au développeur de voir au moins une partie de son patch intégrée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Actuellement, ce patch n’a pas été intégré. Il &lt;a href=&#34;https://commitfest.postgresql.org/51/4291/&#34;&gt;fait partie du commit fest de&#xA;janvier&lt;/a&gt;, à l’état &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Needs review&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;patch-2--pg_stat_database&#34;&gt;Patch #2 : pg_stat_database&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette vue nous intéresse pour cumuler par base le nombre de workers de&#xA;parallélisation planifiés et le nombre de ceux réellement exécutés. Le patch&#xA;initial proposait quatre nouvelles colonnes, deux pour les requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;SELECT&lt;/code&gt;&#xA;et deux pour les requêtes DDL (actuellement, seules les commandes DDL &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CREATE&#xA;INDEX&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; sont parallélisables).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Là aussi, une bonne discussion a eu lieu sur l’intérêt de ces différentes&#xA;colonnes. Autant la présence de colonnes pour les requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;SELECT&lt;/code&gt; ne&#xA;suscite pas trop d’objections, autant celle des colonnes pour les requêtes&#xA;DDL est fortement contestée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’argument principal contre ces colonnes est qu’un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CREATE INDEX&lt;/code&gt; et un&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; sont des opérations manuelles et que l’opérateur peut voir lui-même&#xA;quand il lance l’opération si cette opération est parallélisée. Pour moi, cet&#xA;argument a du sens. Pour les « petits malins » qui objecteront qu’un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;&#xA;est automatisé via le processus &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum&lt;/code&gt;, je répondrais qu’ils ont bien&#xA;raison, mais que ce &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; automatisé n’utilise pas la clause &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;PARALLEL&lt;/code&gt;&#xA;qui permettrait sa parallélisation. Pour le dire autrement, l’&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum&lt;/code&gt; ne&#xA;peut pas exécuter un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; parallélisé actuellement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Donc l’argument est difficilement contestable et, de ce fait, &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=e7a9496de9&#34;&gt;seule la&#xA;moitié du patch a été appliquée dans ce commit&lt;/a&gt;. Et voici le résultat&#xA;lorsqu’on interroge ces nouvelles colonnes :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT datname, parallel_workers_to_launch, parallel_workers_launched&#xA;FROM pg_stat_database&#xA;WHERE datname IS NOT null;&#xA;&#xA;  datname  | parallel_workers_to_launch | parallel_workers_launched&#xA;-----------+----------------------------+---------------------------&#xA; postgres  |                         50 |                        45&#xA; template1 |                          0 |                         0&#xA; template0 |                          0 |                         0&#xA;(3 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;h3 id=&#34;patch-3--pg_stat_statements&#34;&gt;Patch #3 : pg_stat_statements&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;La vue &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_statements&lt;/code&gt; donne des informations sur les requêtes exécutées.&#xA;Connaître la durée d’exécution, le nombre d’exécutions, l’utilisation du cache&#xA;ou de JIT sur ces requêtes aide beaucoup à leur optimisation. Il nous a donc&#xA;semblé intéressant d’ajouter des informations sur la parallélisation par&#xA;requête.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Le premier patch était un peu naïf, proposant ainsi sept nouvelles colonnes.&#xA;Beaucoup ont été contestées et au final, le patch, en sa version 3, a été&#xA;divisé en deux parties, bien plus modestes :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;v3-0001-Introduce-two-new-counters-in-EState.patch&lt;/code&gt; ajoute les compteurs de&#xA;parallélisation pour tracer la parallélisation des requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;SELECT&lt;/code&gt; (ces&#xA;compteurs sont aussi utilisés par les nouvelles colonnes de la vue&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_database&lt;/code&gt;).&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;v3-0002-Add-parallel-columns-to-pg_stat_statements.patch&lt;/code&gt; ajoute les deux colonnes acceptées dans &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_statements&lt;/code&gt;.&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Ces deux parties ont été acceptées et intégrées (&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=de3a2ea3b2&#34;&gt;commit du patch v3-0001&lt;/a&gt;,&#xA;et &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=cf54a2c002&#34;&gt;commit du patch v3-0002&lt;/a&gt;). Ce que je retire de la discussion sur ce&#xA;patch, c’est qu’il faut proposer un nombre très limité de changements à la&#xA;fois pour qu’il y ait une chance que ce soit accepté. Et de faire ça&#xA;plusieurs fois si nécessaire, en avançant petit à petit, par itération.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici le résultat lorsqu’on interroge ces deux nouvelles colonnes :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT query, parallel_workers_to_launch, parallel_workers_launched&#xA;FROM pg_stat_statements&#xA;WHERE query LIKE &#39;SELECT%t1%&#39;;&#xA;&#xA;                query                | parallel_workers_to_launch | parallel_workers_launched&#xA;-------------------------------------+----------------------------+---------------------------&#xA; SELECT count(*) FROM t1             |                          2 |                         2&#xA; SELECT count(*) FROM t1 WHERE id&amp;gt;$1 |                          4 |                         4&#xA; SELECT * FROM t1                    |                          0 |                         0&#xA;(3 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;h3 id=&#34;patch-4--pg_stat_all_tables-et-pg_stat_all_indexes&#34;&gt;Patch #4 : pg_stat_all_tables et pg_stat_all_indexes&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Je ne vais pas m’éterniser sur ce patch. Il m’avait semblé intéressant de&#xA;connaître les tables qui étaient parcourues en parallélisé, pour améliorer la&#xA;configuration spécifique des tables en question avec un :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;ALTER TABLE ... WITH (parallel_workers=X);&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Le retour a été unanime. L’intérêt est très limité, voire nul. Je reconnais&#xA;qu’il est limité, mais je réfute qu’il est nul. Ceci étant dit, je n’ai pas&#xA;d’arguments supplémentaires pour défendre cette position, et j’ai donc&#xA;préféré consacrer mon énergie à l’argumentation pour les autres patchs,&#xA;notamment celui sur les traces.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://commitfest.postgresql.org/50/5238/&#34;&gt;Ce patch n’est officiellement pas rejeté&lt;/a&gt;, il serait certainement mieux que je&#xA;le déclare abandonné.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;pour-finir&#34;&gt;Pour finir&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Deux patchs acceptés sur quatre, et partiellement en plus. C’est une&#xA;demi-victoire. Il n’empêche que nous aurons ainsi plus de métriques sur la&#xA;parallélisation et que cela pourrait nous aider à améliorer sa configuration.&#xA;Et rien n’empêche de revenir plus tard avec les bouts non acceptés et&#xA;quelques arguments supplémentaires, venant de l’expérience rencontrée chez&#xA;nos clients.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tout le travail réalisé pour écrire un patch et réussir à le faire intégrer peut&#xA;sembler lourd mais la qualité du code et sa stabilité sont à ce prix.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cet article sera mis à jour quand les vidéos de la pgsession 17 seront&#xA;disponibles pour y mettre l lien vers ma conférence.&#xA;&lt;!--&#xA;Les vidéos de la pgsession 17 sont disponibles sur le [canal Dalibo de&#xA;YouTube], [playlist pgessions 17]. Vous y trouverez notamment [celle de ma&#xA;conférence], parlant de ce sujet, mais aussi de comment contribuer au&#xA;développement de PostgreSQL et de l&#39;organisation mise en place à Dalibo pour&#xA;permettre notre contribution.&#xA;--&gt;&lt;/p&gt;&#xA;&#xA;&lt;!--&#xA;[celle de ma conférence]: FIXME lien youtube&#xA;[canal Dalibo de YouTube]: https://www.youtube.com/c/dalibo&#xA;[playlist pgessions 17]: FIXME lien playlist YouTube&#xA;--&gt;&#xA;&#xA;&lt;!--&#xA;   vim: spelllang=fr spell&#xA;--&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL : optimiser vos opérations vacuum et analyze !</title>
    <updated>2025-02-26T11:00:21Z</updated>
    <id>tag:blog.capdata.fr,2025-02-26:/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&amp;#038;title=PostgreSQL%20%3A%20optimiser%20vos%20op%C3%A9rations%20vacuum%20et%20analyze%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%20%3A%20optimiser%20vos%20op%C3%A9rations%20vacuum%20et%20analyze%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-medium wp-image-10677&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2025/02/vacuum-300x200.png&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;200&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2025/02/vacuum-300x200.png 300w, https://blog.capdata.fr/wp-content/uploads/2025/02/vacuum-768x513.png 768w, https://blog.capdata.fr/wp-content/uploads/2025/02/vacuum.png 800w&#34; sizes=&#34;auto, (max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Hello&lt;/p&gt;&#xA;&lt;p&gt;pour commencer cette année 2025 , voici un petit article PostgreSQL ou l&amp;#8217;on vous présente comment optimiser les opérations de maintenance que sont les VACUUM et les ANALYZE.&lt;/p&gt;&#xA;&lt;p&gt;Ces 2 opérations sont essentielles pour conserver des performances optimales pour notre instance et garantir au planner de construire des plans d&amp;#8217;exécutions optimisés.&lt;/p&gt;&#xA;&lt;p&gt;les opérations VACUUM et/ou ANALYZE peuvent être longues et sources de nombreuses écritures dans les WALs sur des tables volumineuses.&lt;br /&gt;&#xA;C&amp;#8217;est pourquoi, et ce depuis la version &lt;strong&gt;PostgreSQL 16&lt;/strong&gt;, il est possible de modifier le comportement de ces opérations en affectant une taille de buffer. Il s&amp;#8217;agit du &amp;#8220;&lt;a href=&#34;https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-VACUUM-BUFFER-USAGE-LIMIT&#34;&gt;buffer_usage_limit&lt;/a&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Principe de fonctionnement.&lt;/h2&gt;&#xA;&lt;p&gt;Ce procédé s&amp;#8217;appuie sur le principe de &amp;#8220;ring buffer&amp;#8221; configuré pour PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Attention, à ne pas confondre, évidement, avec les &amp;#8220;rings buffer&amp;#8221; de SQL Server !!&lt;/p&gt;&#xA;&lt;p&gt;Pour rappel, PostgreSQL utilise cette stratégie de &amp;#8220;ring buffer&amp;#8221; afin de dédier un espace mémoire pour les opérations lourdes , telles, la lecture séquentielle sur une table volumineuse, un CREATE TABLE AS SELECT, un COPY&amp;#8230;. mais aussi un VACUUM !&lt;/p&gt;&#xA;&lt;p&gt;En fait, cet espace est utilisé pour éviter de &amp;#8220;flusher&amp;#8221; sur disque de manière trop brutale les pages en mémoire montées dans le &amp;#8220;&lt;strong&gt;shared buffer&lt;/strong&gt;&amp;#8220;. Cela pénaliserait en grande partie toute opération concurrente à notre traitement actif puisqu&amp;#8217;elle n&amp;#8217;aurait plus d&amp;#8217;espace pour mettre ses propres pages en mémoire.&lt;/p&gt;&#xA;&lt;p&gt;Jusqu&amp;#8217;à la version PostgreSQL 16, cet espace mémoire était défini à&lt;strong&gt; 256Ko&lt;/strong&gt;. Ainsi, au cours d&amp;#8217;une lecture séquentielle, chaque page  de &lt;strong&gt;8Ko&lt;/strong&gt; par défaut, est montée en mémoire dans cet espace si le nombre de pages totales à traiter pour la table, dépasse 1/4 du paramètre &amp;#8220;&lt;strong&gt;shared_buffer&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Il en est de même pour une opération VACUUM ou ANALYZE qui utilise également ce ring buffer et permet d&amp;#8217;optimiser cette opération.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Nouveautés PostgreSQL 16 et PostgreSQL 17&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Depuis la version PostgreSQL 16, il est possible de configurer la taille du buffer de façon unitaire. Par exemple, lors d&amp;#8217;un VACUUM, il est tout à fait possible de choisir une valeur pour &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Depuis le version PostgreSQL 17, la valeur par défaut affectée à &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8221; est de &lt;strong&gt;2Mo&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Il vous est possible de paramétrer la valeur de &lt;strong&gt;128Ko&lt;/strong&gt; jusqu&amp;#8217;à &lt;strong&gt;16Go&lt;/strong&gt;. Attention, cependant, cette valeur ne peux excéder &lt;strong&gt;1/8&lt;/strong&gt; du paramètre &amp;#8220;&lt;strong&gt;shared_buffer&lt;/strong&gt;&amp;#8220;.&lt;br /&gt;&#xA;Si vous faites le calcul, pour un serveur comportant &lt;strong&gt;32Go de RAM&lt;/strong&gt;, vous ne pourrez obtenir, au plus, &lt;strong&gt;1Go&lt;/strong&gt; pour votre ring buffer.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h5&gt;Cas d&amp;#8217;utilisation pour un VACUUM&lt;/h5&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Sur une instance PostgreSQL 13, nous lançons un VACUUM simple sur une table de 2,5Go. Nous utilisons une base exemple créée via &amp;#8220;pgbench&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;Nous avons utilisé les options &amp;#8220;&lt;strong&gt;DISABLE_PAGE_SKIPPING&lt;/strong&gt;&amp;#8221; pour analyser, dans un premier temps, tous les blocs de notre table et ne pas sur baser sur les informations de la visibility_map.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum (verbose,DISABLE_PAGE_SKIPPING) public.pgbench_accounts;&#xD;&#xA;INFO: 00000: aggressively vacuuming &amp;quot;public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: lazy_scan_heap, vacuumlazy.c:797&#xD;&#xA;INFO: 00000: &amp;quot;pgbench_accounts&amp;quot;: found 0 removable, 20000000 nonremovable row versions in 327869 out of 327869 pages&#xD;&#xA;DETAIL: 0 dead row versions cannot be removed yet, oldest xmin: 196215&#xD;&#xA;There were 0 unused item identifiers.&#xD;&#xA;Skipped 0 pages due to buffer pins, 0 frozen pages.&#xD;&#xA;0 pages are entirely empty.&#xD;&#xA;CPU: user: 1.34 s, system: 0.67 s, elapsed: 18.90 s.&#xD;&#xA;LOCATION: lazy_scan_heap, vacuumlazy.c:1759&#xD;&#xA;VACUUM&#xD;&#xA;Time: 18920.292 ms (00:18.920)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Le temps passé pour cette opération est d&amp;#8217;un peu plus de 18 secondes en temps CPU pour analyser les 327869 blocs de notre table. Soit une taille de 2.5Go.&lt;/p&gt;&#xA;&lt;p&gt;Nous effectuons la même opération sur cette même table, mais sur un moteur &lt;strong&gt;PostgreSQL 17&lt;/strong&gt;. Nous positionnons le paramètre &lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;  à &lt;strong&gt;8Mo&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (verbose,DISABLE_PAGE_SKIPPING,BUFFER_USAGE_LIMIT &#39;8MB&#39;) public.pgbench_accounts;&#xD;&#xA;INFO: 00000: aggressively vacuuming &amp;quot;pgbenchmark.public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: heap_vacuum_rel, vacuumlazy.c:475&#xD;&#xA;INFO: 00000: finished vacuuming &amp;quot;pgbenchmark.public.pgbench_accounts&amp;quot;: index scans: 0&#xD;&#xA;pages: 0 removed, 327869 remain, 327869 scanned (100.00% of total)&#xD;&#xA;tuples: 0 removed, 20000000 remain, 0 are dead but not yet removable&#xD;&#xA;removable cutoff: 208163, which was 0 XIDs old when operation ended&#xD;&#xA;new relfrozenxid: 208163, which is 5 XIDs ahead of previous value&#xD;&#xA;frozen: 0 pages from table (0.00% of total) had 0 tuples frozen&#xD;&#xA;index scan not needed: 0 pages from table (0.00% of total) had 0 dead item identifiers removed&#xD;&#xA;avg read rate: 134.208 MB/s, avg write rate: 0.034 MB/s&#xD;&#xA;buffer usage: 330350 hits, 325508 misses, 83 dirtied&#xD;&#xA;WAL usage: 84 records, 83 full page images, 684232 bytes&#xD;&#xA;system usage: CPU: user: 1.41 s, system: 0.64 s, elapsed: 18.94 s&#xD;&#xA;LOCATION: heap_vacuum_rel, vacuumlazy.c:763&#xD;&#xA;VACUUM&#xD;&#xA;Time: 18955.006 ms (00:18.955)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;C&amp;#8217;est  à peu de chose près, dans le même temps d&amp;#8217;exécution. soir 18 secondes.&lt;/p&gt;&#xA;&lt;p&gt;La suite consiste à redémarrer l&amp;#8217;instance PostgreSQL 17 et constater les temps d&amp;#8217;exécution pour chaque occurrence de lancement.&lt;br /&gt;&#xA;Nous exécutons donc, les mêmes ordres VACUUM, mais sans l&amp;#8217;option &amp;#8220;&lt;strong&gt;DISABLE_PAGE_SKIPPING&lt;/strong&gt;&amp;#8221;&lt;/p&gt;&#xA;&lt;p&gt;Sur la version PostgreSQL 13, nous voyons qu&amp;#8217;à la première exécution, juste après redémarrage, nous sommes à 32 millisecondes. Et à chaque exécution suivante, nous ne descendons pas en dessous de 15 millisecondes&amp;#8230;.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 32.149 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 15.001 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 15.295 ms&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;En version PostgreSQL 17, nous faisons également un &amp;#8220;flush&amp;#8221; des pages dans le buffer cache à chaque exécution, tout en modifiant la valeur de &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (BUFFER_USAGE_LIMIT &#39;128kB&#39;) public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 18.098 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (BUFFER_USAGE_LIMIT &#39;8MB&#39;) public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 6.461 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (BUFFER_USAGE_LIMIT &#39;16MB&#39;) public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 4.333 ms&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Le constat est simple, plus nous augmentons le &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8220;, et plus le temps d&amp;#8217;exécution du VACUUM diminue.&lt;/p&gt;&#xA;&lt;p&gt;Nous comprendrons donc que sur une table de plus de 100Go, le gain peut être assez important.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h5&gt;Cas d&amp;#8217;utilisation pour un ANALYZE&lt;/h5&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Pour l&amp;#8217;instance PostgreSQL 13, nous exécutons le calcul de statistiques sur cette même table&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum (analyze,verbose) public.pgbench_accounts;&#xD;&#xA;INFO: 00000: vacuuming &amp;quot;public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: lazy_scan_heap, vacuumlazy.c:802&#xD;&#xA;INFO: 00000: &amp;quot;pgbench_accounts&amp;quot;: found 0 removable, 52 nonremovable row versions in 1 out of 327869 pages&#xD;&#xA;DETAIL: 0 dead row versions cannot be removed yet, oldest xmin: 196278&#xD;&#xA;There were 0 unused item identifiers.&#xD;&#xA;Skipped 0 pages due to buffer pins, 0 frozen pages.&#xD;&#xA;0 pages are entirely empty.&#xD;&#xA;CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s.&#xD;&#xA;LOCATION: lazy_scan_heap, vacuumlazy.c:1759&#xD;&#xA;INFO: 00000: analyzing &amp;quot;public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: do_analyze_rel, analyze.c:336&#xD;&#xA;INFO: 00000: &amp;quot;pgbench_accounts&amp;quot;: scanned 30000 of 327869 pages, containing 1830000 live rows and 0 dead rows; 30000 rows in sample, 20000009 estimated total rows&#xD;&#xA;LOCATION: acquire_sample_rows, analyze.c:1190&#xD;&#xA;VACUUM&#xD;&#xA;Time: 29526.404 ms (00:29.526)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Nous sommes autour de 29 secondes pour analyser 30000 pages sur les 32769 que composent cette table.&lt;br /&gt;&#xA;Le sample est choisi en fonction de la valeur de &amp;#8220;&lt;strong&gt;default_statistics_target&lt;/strong&gt;&amp;#8220;, par défaut à 100, avec 30000 lignes analysées par défaut.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Sur la version PostgreSQL 17, les résultats sont les suivants&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (analyze,verbose,BUFFER_USAGE_LIMIT &#39;128kB&#39;) public.pgbench_accounts;&#xD;&#xA;INFO: 00000: vacuuming &amp;quot;pgbenchmark.public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: heap_vacuum_rel, vacuumlazy.c:480&#xD;&#xA;INFO: 00000: finished vacuuming &amp;quot;pgbenchmark.public.pgbench_accounts&amp;quot;: index scans: 0&#xD;&#xA;pages: 0 removed, 327869 remain, 1 scanned (0.00% of total)&#xD;&#xA;tuples: 0 removed, 20000000 remain, 0 are dead but not yet removable&#xD;&#xA;removable cutoff: 208163, which was 0 XIDs old when operation ended&#xD;&#xA;frozen: 0 pages from table (0.00% of total) had 0 tuples frozen&#xD;&#xA;index scan not needed: 0 pages from table (0.00% of total) had 0 dead item identifiers removed&#xD;&#xA;avg read rate: 46.211 MB/s, avg write rate: 0.000 MB/s&#xD;&#xA;buffer usage: 37 hits, 100 misses, 0 dirtied&#xD;&#xA;WAL usage: 0 records, 0 full page images, 0 bytes&#xD;&#xA;system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.01 s&#xD;&#xA;LOCATION: heap_vacuum_rel, vacuumlazy.c:763&#xD;&#xA;INFO: 00000: analyzing &amp;quot;public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: do_analyze_rel, analyze.c:321&#xD;&#xA;INFO: 00000: &amp;quot;pgbench_accounts&amp;quot;: scanned 30000 of 327869 pages, containing 1830000 live rows and 0 dead rows; 30000 rows in sample, 20000009 estimated total rows&#xD;&#xA;LOCATION: acquire_sample_rows, analyze.c:1301&#xD;&#xA;VACUUM&#xD;&#xA;Time: 8151.201 ms (00:08.151)&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (analyze,BUFFER_USAGE_LIMIT &#39;8MB&#39;) public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 7282.546 ms (00:07.283)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Les différences de gains sont moins impressionnantes que sur un simple VACUUM à chaque changement de &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8220;, mais on voit qu&amp;#8217;en version PostgreSQL 17, nous sommes tout de même 4 fois plus rapide qu&amp;#8217;en version PostgreSQL 13.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h4&gt;Remarques&lt;/h4&gt;&#xA;&lt;p&gt;Gardez à l&amp;#8217;esprit que la valeur de &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&amp;#8221;&lt;/strong&gt; est plafonnée à &lt;strong&gt;1/8 &lt;/strong&gt;de&lt;strong&gt; &amp;#8220;shared_buffer&amp;#8221;&lt;/strong&gt;. Inutile donc de mettre à 1024Mo, si vous ne possédez que 8Go de RAM.&lt;/p&gt;&#xA;&lt;p&gt;Attention si vous mettez une valeur trop grande, les transactions concurrentes effectuant des lectures séquentielles seront pénalisées par les opérations VACUUM. D&amp;#8217;ailleurs, il est possible de mettre &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8221; à 0, mais ceci n&amp;#8217;est pas conseillé lors d&amp;#8217;une activité transactionnelle en cours.&lt;/p&gt;&#xA;&lt;p&gt;Pour aller plus loin dans l&amp;#8217;optimisation d&amp;#8217;une opération de vacuum, vous pouvez également passer le paramètre &amp;#8220;&lt;strong&gt;INDEX_CLEANUP&lt;/strong&gt;&amp;#8221; à &lt;strong&gt;off&lt;/strong&gt;. Ceci aura pour effet de ne pas s&amp;#8217;occuper de traiter les entrées des index qui pointent sur les lignes mortes de la table.&lt;br /&gt;&#xA;Un &amp;#8220;&lt;strong&gt;REINDEX&lt;/strong&gt;&amp;#8221; sera alors nécessaire à la fin du VACUUM sur les index de la table.&lt;/p&gt;&#xA;&lt;p&gt;De plus, il est possible de positionner l&amp;#8217;option &amp;#8220;&lt;strong&gt;SKIP_DATABASE_STATS&lt;/strong&gt;&amp;#8221; afin d&amp;#8217;indiquer à l&amp;#8217;ordre VACUUM de ne pas rechercher l&amp;#8217;ID de transaction le plus ancien pour l&amp;#8217;ensemble des tables de la base et de geler celui-ci (datfrozenid).&lt;/p&gt;&#xA;&lt;p&gt;Les opérations VACUUM sur les grosses tables seront bien entendu optimisées mais attention aux plages de maintenance choisies !!&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Bonne journée à vous.&lt;/p&gt;&#xA;&lt;p&gt;Emmanuel Rami&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-13-les-nouveautes-interessantes/&#34; rel=&#34;bookmark&#34; title=&#34;30 octobre 2020&#34;&gt;PostgreSQL 13 : présentation&lt;/a&gt; (Emmanuel RAMI) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pruning-de-partitions-sous-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;7 décembre 2020&#34;&gt;&amp;#8220;Pruning&amp;#8221; de partitions sous PostgreSQL ou comment bien élaguer !&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/requetes-consommatrices-sous-postgresql-episode-1/&#34; rel=&#34;bookmark&#34; title=&#34;24 mai 2016&#34;&gt;Requêtes consommatrices sous PostgreSQL (épisode 1)&lt;/a&gt; (David Baffaleuf) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/nouveautes-mysql-8-0-les-histogrammes/&#34; rel=&#34;bookmark&#34; title=&#34;25 juin 2019&#34;&gt;Nouveautés MySQL 8.0 : Les Histogrammes&lt;/a&gt; (Capdata team) [MySQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/replication-logique-avec-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;23 janvier 2020&#34;&gt;Réplication logique avec PostgreSQL&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 4.371 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&amp;#038;title=PostgreSQL%20%3A%20optimiser%20vos%20op%C3%A9rations%20vacuum%20et%20analyze%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%20%3A%20optimiser%20vos%20op%C3%A9rations%20vacuum%20et%20analyze%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/&#34;&gt;PostgreSQL : optimiser vos opérations vacuum et analyze !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Hello pour commencer cette année 2025 , voici un petit article PostgreSQL ou l&amp;#8217;on vous présente comment optimiser les opérations de maintenance que sont les VACUUM et les ANALYZE. Ces 2 opérations sont essentielles pour conserver des performances optimales pour&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/&#34;&gt;PostgreSQL : optimiser vos opérations vacuum et analyze !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>La montée de version en zero-downtime : merci la réplication !</title>
    <updated>2024-12-19T10:28:41Z</updated>
    <id>tag:blog.capdata.fr,2024-12-19:/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&amp;#038;title=La%20mont%C3%A9e%20de%20version%20en%20zero-downtime%20%3A%20merci%20la%20r%C3%A9plication%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=La%20mont%C3%A9e%20de%20version%20en%20zero-downtime%20%3A%20merci%20la%20r%C3%A9plication%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;h1&gt;Introduction :&lt;/h1&gt;&#xA;&lt;p&gt;Dans le monde des bases de données, garantir une disponibilité continue est une exigence incontournable, surtout pour les systèmes critiques où chaque minute d&amp;#8217;arrêt peut entraîner des pertes significatives. Lorsqu’il s’agit de migrer une base de données vers une nouvelle version, ce défi prend une toute autre dimension. Comment mettre à jour votre système sans interrompre les services, tout en préservant l’intégrité des données ?&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL offre une solution élégante : la réplication logique. Cet outil permet de transférer des données de manière fluide entre différentes versions de PostgreSQL, tout en maintenant la base de données source opérationnelle. Dans cet article, nous allons explorer étape par étape comment utiliser cette fonctionnalité pour réaliser une montée de version sans temps d&amp;#8217;arrêt, du déploiement initial à la bascule finale vers la nouvelle version.&lt;/p&gt;&#xA;&lt;p&gt;Que vous soyez en train de planifier une migration ou simplement curieux de découvrir les possibilités offertes par PostgreSQL, suivez ce guide pratique qui vous permettra de transformer un défi complexe en une opération maîtrisée et efficace.&lt;/p&gt;&#xA;&lt;h1&gt;Le test :&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;h3&gt;Préparation&lt;/h3&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Pour tester cette nouvelle méthode, nous aurons besoin de deux instances PostgreSQL. Pour cet article j&amp;#8217;ai choisit de démontrer la technique en migrant d&amp;#8217;une version 14 à une version 17 de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Je commence donc par installer les versions sur deux machines différentes pouvant communiquer entre elles (c&amp;#8217;est important) :&lt;/p&gt;&#xA;&lt;p&gt;Sur les deux machines nous pouvons exécuter les commandes suivantes :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# sudo apt update sudo apt upgrade -y&#xD;&#xA;&#xD;&#xA;...&#xD;&#xA;&#xD;&#xA;root@ip-192-1-1-246:~# sudo apt -y install gnupg2 wget vim&#xD;&#xA;&#xD;&#xA;...&#xD;&#xA;&#xD;&#xA;root@ip-192-1-1-246:~# sudo sh -c &#39;echo &amp;quot;deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main&amp;quot; &amp;amp;gt; /etc/apt/sources.list.d/pgdg.list&#39;&#xD;&#xA;root@ip-192-1-1-246:~# curl -fsSL https://www.postgresql.org/media/keys/ACCC4CF8.asc|sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/postgresql.gpg&#xD;&#xA;&#xD;&#xA;root@ip-192-1-1-246:~# sudo apt -y update&#xD;&#xA;Get:1 file:/etc/apt/mirrors/debian.list Mirrorlist [38 B]&#xD;&#xA;Get:2 file:/etc/apt/mirrors/debian-security.list Mirrorlist [47 B]&#xD;&#xA;Hit:3 https://cdn-aws.deb.debian.org/debian bookworm InRelease&#xD;&#xA;Hit:4 https://cdn-aws.deb.debian.org/debian bookworm-updates InRelease&#xD;&#xA;Hit:5 https://cdn-aws.deb.debian.org/debian bookworm-backports InRelease&#xD;&#xA;Hit:6 https://cdn-aws.deb.debian.org/debian-security bookworm-security InRelease&#xD;&#xA;Get:7 http://apt.postgresql.org/pub/repos/apt bookworm-pgdg InRelease [129 kB]&#xD;&#xA;Get:8 http://apt.postgresql.org/pub/repos/apt bookworm-pgdg/main amd64 Packages [359 kB]&#xD;&#xA;Fetched 489 kB in 1s (348 kB/s)&#xD;&#xA;Reading package lists... Done&#xD;&#xA;Building dependency tree... Done&#xD;&#xA;Reading state information... Done&#xD;&#xA;All packages are up to date.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Puis sur notre première machine :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# sudo apt install postgresql-14&#xD;&#xA;Reading package lists... Done&#xD;&#xA;Building dependency tree... Done&#xD;&#xA;Reading state information... Done&#xD;&#xA;The following additional packages will be installed:&#xD;&#xA;libcommon-sense-perl libgdbm-compat4 libio-pty-perl libipc-run-perl&#xD;&#xA;libjson-perl libjson-xs-perl libllvm16 libperl5.36 libpq5 libsensors-config&#xD;&#xA;libsensors5 libtypes-serialiser-perl libxslt1.1 libz3-4 logrotate perl&#xD;&#xA;perl-modules-5.36 postgresql-client-14 postgresql-client-common&#xD;&#xA;postgresql-common ssl-cert sysstat&#xD;&#xA;&#xD;&#xA;...&#xD;&#xA;&#xD;&#xA;root@ip-192-1-1-246:~# systemctl status postgresql@14-main.service&#xD;&#xA;● postgresql@14-main.service - PostgreSQL Cluster 14-main&#xD;&#xA;Loaded: loaded (/lib/systemd/system/postgresql@.service; enabled-runtime;&amp;amp;gt;&#xD;&#xA;Active: active (running) since Wed 2024-12-04 09:43:55 UTC; 2min 55s ago&#xD;&#xA;Process: 15248 ExecStart=/usr/bin/pg_ctlcluster --skip-systemctl-redirect &amp;amp;gt;&#xD;&#xA;Main PID: 15253 (postgres)&#xD;&#xA;Tasks: 7 (limit: 4633)&#xD;&#xA;Memory: 17.3M&#xD;&#xA;CPU: 239ms&#xD;&#xA;CGroup: /system.slice/system-postgresql.slice/postgresql@14-main.service&#xD;&#xA;├─15253 /usr/lib/postgresql/14/bin/postgres -D /var/lib/postgresq&amp;amp;gt;&#xD;&#xA;├─15255 &amp;quot;postgres: 14/main: checkpointer &amp;quot;&#xD;&#xA;├─15256 &amp;quot;postgres: 14/main: background writer &amp;quot;&#xD;&#xA;├─15257 &amp;quot;postgres: 14/main: walwriter &amp;quot;&#xD;&#xA;├─15258 &amp;quot;postgres: 14/main: autovacuum launcher &amp;quot;&#xD;&#xA;├─15259 &amp;quot;postgres: 14/main: stats collector &amp;quot;&#xD;&#xA;└─15260 &amp;quot;postgres: 14/main: logical replication launcher &amp;quot;&#xD;&#xA;&#xD;&#xA;Dec 04 09:43:53 ip-192-1-1-246 systemd[1]: Starting postgresql@14-main.service&amp;amp;gt;&#xD;&#xA;Dec 04 09:43:55 ip-192-1-1-246 systemd[1]: Started postgresql@14-main.service &amp;amp;gt;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Puis sur la deuxième machine :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;admin@ip-192-1-1-89:~$ sudo apt install postgresql-17&#xD;&#xA;Reading package lists... Done&#xD;&#xA;Building dependency tree... Done&#xD;&#xA;Reading state information... Done&#xD;&#xA;The following additional packages will be installed:&#xD;&#xA;libcommon-sense-perl libgdbm-compat4 libio-pty-perl libipc-run-perl&#xD;&#xA;libjson-perl libjson-xs-perl libllvm16 libperl5.36 libpq5 libsensors-config&#xD;&#xA;libsensors5 libtypes-serialiser-perl libxslt1.1 libz3-4 logrotate perl&#xD;&#xA;perl-modules-5.36 postgresql-client-17 postgresql-client-common&#xD;&#xA;postgresql-common ssl-cert sysstat&#xD;&#xA;&#xD;&#xA;admin@ip-192-1-1-89:~$ systemctl status postgresql@17-main.service&#xD;&#xA;● postgresql@17-main.service - PostgreSQL Cluster 17-main&#xD;&#xA;Loaded: loaded (/lib/systemd/system/postgresql@.service; enabled-runtime; &amp;amp;gt;&#xD;&#xA;Active: active (running) since Wed 2024-12-04 09:52:33 UTC; 2min 13s ago&#xD;&#xA;Process: 15235 ExecStart=/usr/bin/pg_ctlcluster --skip-systemctl-redirect 1&amp;amp;gt;&#xD;&#xA;Main PID: 15240 (postgres)&#xD;&#xA;Tasks: 6 (limit: 4633)&#xD;&#xA;Memory: 20.5M&#xD;&#xA;CPU: 332ms&#xD;&#xA;CGroup: /system.slice/system-postgresql.slice/postgresql@17-main.service&#xD;&#xA;├─15240 /usr/lib/postgresql/17/bin/postgres -D /var/lib/postgresql&amp;amp;gt;&#xD;&#xA;├─15241 &amp;quot;postgres: 17/main: checkpointer &amp;quot;&#xD;&#xA;├─15242 &amp;quot;postgres: 17/main: background writer &amp;quot;&#xD;&#xA;├─15244 &amp;quot;postgres: 17/main: walwriter &amp;quot;&#xD;&#xA;├─15245 &amp;quot;postgres: 17/main: autovacuum launcher &amp;quot;&#xD;&#xA;└─15246 &amp;quot;postgres: 17/main: logical replication launcher &amp;quot;&#xD;&#xA;&#xD;&#xA;Dec 04 09:52:31 ip-192-1-1-89 systemd[1]: Starting postgresql@17-main.service -&amp;amp;gt;&#xD;&#xA;Dec 04 09:52:33 ip-192-1-1-89 systemd[1]: Started postgresql@17-main.service -&amp;amp;gt;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Nos deux instances sont maintenant installées. Sur notre première base de données, nous allons créer une base, avec deux tables, et quelques lignes.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:/etc/postgresql/14/main$ psql&#xD;&#xA;psql (14.15 (Debian 14.15-1.pgdg120+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# CREATE DATABASE mydb;&#xD;&#xA;CREATE DATABASE&#xD;&#xA;postgres=# \c mydb&#xD;&#xA;You are now connected to database &amp;quot;mydb&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;mydb=# CREATE TABLE customers (&#xD;&#xA;id SERIAL PRIMARY KEY,&#xD;&#xA;name TEXT NOT NULL,&#xD;&#xA;email TEXT UNIQUE,&#xD;&#xA;created_at TIMESTAMP DEFAULT NOW()&#xD;&#xA;);&#xD;&#xA;CREATE TABLE&#xD;&#xA;mydb=# CREATE TABLE orders (&#xD;&#xA;id SERIAL PRIMARY KEY,&#xD;&#xA;customer_id INT REFERENCES customers(id),&#xD;&#xA;amount NUMERIC(10,2) NOT NULL,&#xD;&#xA;order_date TIMESTAMP DEFAULT NOW()&#xD;&#xA;);&#xD;&#xA;CREATE TABLE&#xD;&#xA;mydb=# INSERT INTO customers (name, email) VALUES&#xD;&#xA;(&#39;Alice&#39;, &#39;alice@example.com&#39;),&#xD;&#xA;(&#39;Bob&#39;, &#39;bob@example.com&#39;),&#xD;&#xA;(&#39;Charlie&#39;, &#39;charlie@example.com&#39;);&#xD;&#xA;INSERT 0 3&#xD;&#xA;mydb=# INSERT INTO orders (customer_id, amount) VALUES&#xD;&#xA;(1, 50.75),&#xD;&#xA;(2, 20.00),&#xD;&#xA;(1, 75.00);&#xD;&#xA;INSERT 0 3&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;2. Configurer la base de données source&lt;/h3&gt;&#xA;&lt;p&gt;Sur notre première machine, nous allons modifier les paramètres du fichier de configuration de PostgreSQL pour permettre de pouvoir créer la réplication :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# su - postgres&#xD;&#xA;postgres@ip-192-1-1-246:~$ cd /etc/postgresql/14/main&#xD;&#xA;postgres@ip-192-1-1-246:/etc/postgresql/14/main$ vi postgresql.conf&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il s&amp;#8217;agit de modifier les paramètres suivants :&lt;/p&gt;&#xA;&lt;blockquote&gt;&lt;p&gt;wal_level = logical&lt;br /&gt;&#xA;max_replication_slots = 4&lt;br /&gt;&#xA;max_wal_senders = 4&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;Nous modifierons ensuite le pg_hba pour rajouter l&amp;#8217;autorisation de connexion entre les deux machines :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:/etc/postgresql/14/main$ vi pg_hba.conf&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il suffira de rajouter une ligne :&lt;/p&gt;&#xA;&lt;blockquote&gt;&lt;p&gt;host replication &lt;span class=&#34;hljs-attribute&#34;&gt;all&lt;/span&gt; &amp;lt;destination_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host replication all &amp;lt;source_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host all replication &amp;lt;destination_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host all replication &amp;lt;source-ip&amp;gt; scram-sha-256&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;Il ne faut pas oublier de redémarrer le serveur PostgreSQL une fois ces modifications effectuées :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# systemctl stop postgresql@14-main.service&#xD;&#xA;root@ip-192-1-1-246:~# systemctl start postgresql@14-main.service&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;3. Configurer la base de donnée de destination&lt;/h3&gt;&#xA;&lt;p&gt;Après avoir configuré notre base de donnée depuis laquelle nous allons faire notre migration, il nous faut a présent configurer celle qui va recevoir la nouvelle base de donnée migrée.&lt;/p&gt;&#xA;&lt;p&gt;Pour cela, nous allons répéter les étapes de configuration de la base de donnée source, en les adaptant sur notre base de donnée de destination : modifier le postgresql.conf, puis le pg_hba.conf, redémarrer ensuite la base de données&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-89:~$ cd /etc/postgresql/17/main/&#xD;&#xA;postgres@ip-192-1-1-89:/etc/postgresql/17/main$ vi postgresql.conf&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;blockquote&gt;&lt;p&gt;wal_level = logical&lt;br /&gt;&#xA;max_replication_slots = 4&lt;br /&gt;&#xA;max_wal_senders = 4&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:/etc/postgresql/14/main$ vi pg_hba.conf&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;blockquote&gt;&lt;p&gt;host replication &lt;span class=&#34;hljs-attribute&#34;&gt;all&lt;/span&gt; &amp;lt;destination_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host replication all &amp;lt;source_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host all replication &amp;lt;destination_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host all replication &amp;lt;source-ip&amp;gt; scram-sha-256&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# systemctl stop postgresql@14-main.service&#xD;&#xA;root@ip-192-1-1-246:~# systemctl start postgresql@14-main.service&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il ne faudra pas oublier de créer la base de donnée ainsi que toutes les structures de tables et autres objets dans notre base cible pour qu&amp;#8217;elle puisse recevoir les données. Pour avoir les scripts de création de la base de données, vous pouvez faire un pg_dump avec l&amp;#8217;option&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-89:~$ psql&#xD;&#xA;psql (17.2 (Debian 17.2-1.pgdg120+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# CREATE DATABASE mydb;&#xD;&#xA;CREATE DATABASE&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;N&amp;#8217;oubliez pas de donner tout les droits à votre utilisateur de replication pour qu&amp;#8217;il puisse lire, écrire&amp;#8230; Sur votre base de données repliquée, sur la source, comme sur la destination :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# GRANT ALL PRIVILEGES ON DATABASE &amp;quot;mydb&amp;quot; to replication;&#xD;&#xA;GRANT&#xD;&#xA;&#xD;&#xA;mydb=# GRANT ALL PRIVILEGES ON all tables in schema public to replication;&#xD;&#xA;GRANT&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;4. Mise en place de la réplication logique&lt;/h3&gt;&#xA;&lt;p&gt;Maintenant que nos deux environnement sont bien en place, nous sommes prêts à mettre en route le processus de réplication logique pour commencer à transférer les données. Les étapes du dessous ont demandé une première intervention hors horaire de prod, notamment pour redémarrer le service postgreSQL, mais le but d&amp;#8217;une migration avec réplication logique, c&amp;#8217;est de pouvoir ensuite n&amp;#8217;avoir rien à toucher jusqu&amp;#8217;au moment de basculer les applicatifs d&amp;#8217;une ip a une autre.&lt;/p&gt;&#xA;&lt;p&gt;Sur notre machine source, on créé la publication qui va nous servir à transférer nos tables :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:~$ psql&#xD;&#xA;psql (14.15 (Debian 14.15-1.pgdg120+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# \c mydb&#xD;&#xA;You are now connected to database &amp;quot;mydb&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;mydb=# CREATE PUBLICATION my_pub FOR ALL TABLES;&#xD;&#xA;CREATE PUBLICATION&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;On va ensuite créé la souscription sur la base de données cible de notre migration :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;mydb=# create subscription my_sub connection &#39;host=192.1.1.246 port=5432 dbname=mydb user=replication password=replication&#39;publication my_pub;&#xD;&#xA;NOTICE: created replication slot &amp;quot;my_sub&amp;quot; on publisher&#xD;&#xA;CREATE SUBSCRIPTION&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Maintenant que la subscription est en place, on peut vérifier qu&amp;#8217;elle fonctionne. Pendant ce temps, la vrai production, sur la version 14, peut continuer à fonctionner, elle sera automatiquement repliquée sur la nouvelle version 17.&lt;/p&gt;&#xA;&lt;p&gt;On peut vérifier ou en est notre replication avec la commande &lt;span class=&#34;hljs-keyword&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;hljs-operator&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;hljs-keyword&#34;&gt;FROM&lt;/span&gt; pg_stat_subscription;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;mydb=# SELECT * FROM pg_stat_subscription;&#xD;&#xA;-[ RECORD 1 ]---------+------------------------------&#xD;&#xA;subid | 16422&#xD;&#xA;subname | my_sub&#xD;&#xA;worker_type | apply&#xD;&#xA;pid | 16076&#xD;&#xA;leader_pid |&#xD;&#xA;relid |&#xD;&#xA;received_lsn | 0/1733988&#xD;&#xA;last_msg_send_time | 2024-12-04 14:23:59.873074+00&#xD;&#xA;last_msg_receipt_time | 2024-12-04 14:23:59.872357+00&#xD;&#xA;latest_end_lsn | 0/1733988&#xD;&#xA;latest_end_time | 2024-12-04 14:23:59.873074+00&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;5. Test de replication, bascule, et nettoyage&lt;/h3&gt;&#xA;&lt;p&gt;Une fois que la synchronisation de votre replication logique est terminée, ce qui peut prendre un certain temps si vous avez beaucoup de données, vous pouvez constater de vous même sur les lignes que vous ajoutez, modifiez ou supprimez sur votre instance source sont repliquées sur l&amp;#8217;instance de destination.&lt;/p&gt;&#xA;&lt;p&gt;Par exemple, ajoutons un nouveau customer sur notre base source :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:~$ psql&#xD;&#xA;psql (14.15 (Debian 14.15-1.pgdg120+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# \c mydb&#xD;&#xA;You are now connected to database &amp;quot;mydb&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;mydb=# INSERT INTO customers (name, email) VALUES (&#39;Diana&#39;, &#39;diana@example.com&#39;);&#xD;&#xA;INSERT 0 1&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Si nous allons requêter sur notre instance de destination :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;mydb=# select * from customers where name=&#39;Diana&#39;;&#xD;&#xA;id | name | email | created_at&#xD;&#xA;----+-------+-------------------+----------------------------&#xD;&#xA;4 | Diana | diana@example.com | 2024-12-04 14:31:05.708031&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Quand vous vous êtes bien assuré que tout fonctionne, vous pouvez alors rediriger les drivers odbc de vos applications vers le nouveau serveur et non plus l&amp;#8217;ancien.&lt;/p&gt;&#xA;&lt;p&gt;Une fois que cela est fait, vous pouvez alors supprimer le lien de replication, puisque l&amp;#8217;ancienne instance ne sera plus alimentée, et même supprimer l&amp;#8217;ancienne version si vous n&amp;#8217;en avez plus l&amp;#8217;utilité.&lt;/p&gt;&#xA;&lt;p&gt;Sur la destination, notre nouveau serveur de prod :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;DROP SUBSCRIPTION my_sub;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Sur la source, ancien serveur qui va être supprimé :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;DROP PUBLICATION my_pub;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h1&gt;Conclusion&lt;/h1&gt;&#xA;&lt;p&gt;La réplication logique se distingue comme l’une des meilleures solutions pour minimiser le temps d’arrêt lors d’une migration de version PostgreSQL. En permettant une synchronisation continue des données entre deux instances, elle garantit une transition en douceur sans jamais interrompre les services en cours. Cela en fait un choix idéal pour les environnements critiques où la disponibilité est primordiale.&lt;/p&gt;&#xA;&lt;h3&gt;Avantages :&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Zéro downtime :&lt;/strong&gt; la source reste opérationnelle pendant toute la migration.&lt;br /&gt;&#xA;&lt;strong&gt;Flexibilité :&lt;/strong&gt; possibilité de migrer vers une infrastructure différente (nouveau matériel, cloud, etc.).&lt;br /&gt;&#xA;&lt;strong&gt;Granularité :&lt;/strong&gt; la réplication logique peut se limiter à certaines tables si nécessaire.&lt;/p&gt;&#xA;&lt;h3&gt;Inconvénients :&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Complexité initiale :&lt;/strong&gt; la configuration et les tests nécessitent une bonne maîtrise des paramètres de PostgreSQL.&lt;br /&gt;&#xA;&lt;strong&gt;Impact sur les performances :&lt;/strong&gt; la charge de réplication peut légèrement affecter les performances de la base source, surtout avec un grand volume de données.&lt;br /&gt;&#xA;&lt;strong&gt;Non pris en charge pour certains types de données :&lt;/strong&gt; les types spécifiques ou les extensions non standards ne sont pas toujours compatibles avec la réplication logique.&lt;/p&gt;&#xA;&lt;p&gt;Si la réplication logique est souvent la méthode privilégiée pour des mises à jour critiques, elle n’est pas la seule option. Des alternatives comme les outils de sauvegarde et restauration ou la réplication physique peuvent répondre à d’autres besoins spécifiques, notamment pour des bases de données très volumineuses ou des scénarios nécessitant une réplication complète du système.&lt;/p&gt;&#xA;&lt;p&gt;Dans tous les cas, le choix de la méthode dépendra de votre contexte, de vos contraintes techniques et de vos objectifs métier. Prenez le temps d’évaluer les différentes options pour garantir une migration réussie et sans surprise.&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/replication-logique-avec-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;23 janvier 2020&#34;&gt;Réplication logique avec PostgreSQL&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/migration-postgresql-via-slony-i-ou-comment-reduire-le-temps-de-coupure/&#34; rel=&#34;bookmark&#34; title=&#34;27 janvier 2020&#34;&gt;Migration PostgreSQL via SLONY-I ou comment réduire le temps de coupure&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/migrer-dun-cluster-galera-mariadb-10-3-vers-mariadb-10-5-avec-la-replication-logique/&#34; rel=&#34;bookmark&#34; title=&#34;25 février 2022&#34;&gt;Migrer d&amp;#8217;un cluster Galera MariaDB 10.3 vers MariaDB 10.5 avec la réplication logique&lt;/a&gt; (David Baffaleuf) [ContainerMySQLNon classé]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/comparatif-des-gestionnaires-de-vip-dans-un-cluster-patroni-episode-1-keepalived/&#34; rel=&#34;bookmark&#34; title=&#34;6 mars 2022&#34;&gt;Comparatif des gestionnaires de VIP dans un cluster Patroni : épisode 1 (KEEPALIVED)&lt;/a&gt; (David Baffaleuf) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pyrseas-et-postgresql-comparer-facilement-des-schema-de-base-de-donnees/&#34; rel=&#34;bookmark&#34; title=&#34;3 janvier 2023&#34;&gt;Pyrseas et Postgresql : Comparer facilement des schémas de base de données&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 2.979 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&amp;#038;title=La%20mont%C3%A9e%20de%20version%20en%20zero-downtime%20%3A%20merci%20la%20r%C3%A9plication%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=La%20mont%C3%A9e%20de%20version%20en%20zero-downtime%20%3A%20merci%20la%20r%C3%A9plication%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/&#34;&gt;La montée de version en zero-downtime : merci la réplication !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Introduction : Dans le monde des bases de données, garantir une disponibilité continue est une exigence incontournable, surtout pour les systèmes critiques où chaque minute d&amp;#8217;arrêt peut entraîner des pertes significatives. Lorsqu’il s’agit de migrer une base de données vers&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/&#34;&gt;La montée de version en zero-downtime : merci la réplication !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>pg_vector : l’IA et PostgreSQL</title>
    <updated>2024-12-03T07:22:34Z</updated>
    <id>tag:blog.capdata.fr,2024-12-03:/index.php/pg_vector-lia-et-postgresql/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&amp;#038;title=pg_vector%20%3A%20l%E2%80%99IA%20et%20PostgreSQL&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=pg_vector%20%3A%20l%E2%80%99IA%20et%20PostgreSQL&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;h2&gt;1. Introduction : L&amp;#8217;intelligence artificielle et le rôle des bases de données&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;#8217;intelligence artificielle (IA) connaît une popularité croissante, des assistants virtuels aux voitures autonomes, en passant par les recommandations de films et de produits. Mais pour que ces technologies fonctionnent, elles ont besoin de données, souvent en grande quantité. C’est là qu’interviennent les bases de données : elles stockent, gèrent et permettent d&amp;#8217;accéder à ces données de manière efficace.&lt;/p&gt;&#xA;&lt;p&gt;Les bases de données, comme PostgreSQL, ont donc un rôle clé dans l’IA. Mais l&amp;#8217;IA ne traite pas toujours des informations simples comme des noms ou des chiffres ; souvent, elle doit manipuler des informations complexes, comme des représentations numériques d&amp;#8217;images, de sons, ou de textes. Pour gérer ces données spécifiques, il faut des outils adaptés, et c&amp;#8217;est là que l&amp;#8217;extension pg_vector de PostgreSQL entre en jeu.&lt;/p&gt;&#xA;&lt;h2&gt;2. Les vecteurs en informatique et dans pg_vector&lt;/h2&gt;&#xA;&lt;p&gt;Dans le cadre de l’informatique, un vecteur est simplement une liste de nombres. Ces nombres peuvent représenter n’importe quoi : les caractéristiques d’un produit, les mots d’un texte ou même une image. Par exemple, pour un document texte, chaque mot peut être transformé en une série de nombres qui capture son sens dans un certain contexte.&lt;/p&gt;&#xA;&lt;p&gt;L’extension pg_vector permet à PostgreSQL de stocker et de manipuler ces vecteurs. Elle offre un moyen simple de les utiliser directement dans une base de données. Imaginons que nous avons des centaines de documents et que nous souhaitions rechercher les plus similaires à un texte donné : en stockant les représentations numériques (ou embeddings) de ces documents sous forme de vecteurs, nous pouvons facilement comparer leur similarité grâce à pg_vector.&lt;/p&gt;&#xA;&lt;h2&gt;3. Le lien entre l&amp;#8217;IA et les vecteurs&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;#8217;intelligence artificielle repose sur la capacité à comprendre et traiter des informations complexes. Par exemple, quand une IA doit reconnaître une image, elle ne &amp;#8220;voit&amp;#8221; pas comme nous. Au lieu de cela, l&amp;#8217;image est transformée en une série de nombres, un vecteur, qui représente ses caractéristiques (couleurs, formes, etc.).&lt;/p&gt;&#xA;&lt;p&gt;Le même principe s’applique au texte. Les modèles de traitement du langage, comme ceux utilisés par les moteurs de recherche ou les chatbots, transforment chaque mot ou phrase en vecteur. Ces vecteurs capturent le sens des mots et permettent à l&amp;#8217;IA de manipuler des informations complexes sans &amp;#8220;comprendre&amp;#8221; le langage humain.&lt;/p&gt;&#xA;&lt;p&gt;C&amp;#8217;est ici que les embeddings entrent en jeu. Un embedding est un vecteur qui représente des données sous une forme que l’IA peut utiliser. Par exemple, dans un système de recommandation, chaque produit est converti en un embedding, et les produits les plus proches de celui que nous venons de consulter (en termes de vecteur) nous seront recommandés. Grâce à pg_vector, ces embeddings peuvent être stockés et comparés directement dans une base de données.&lt;/p&gt;&#xA;&lt;h2&gt;4. Pourquoi est-ce utile ?&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;#8217;extension pg_vector est très utile pour des applications qui nécessitent la recherche par similarité. Par exemple, dans un moteur de recherche, si nous voulons trouver les documents les plus proches d&amp;#8217;un texte donné, pg_vector permet de comparer les vecteurs (ou embeddings) de chaque document pour voir lesquels sont les plus similaires.&lt;/p&gt;&#xA;&lt;p&gt;Autre exemple, dans une plateforme de streaming musical, chaque chanson peut être convertie en vecteur qui représente ses caractéristiques (comme le tempo, la tonalité, etc.). Grâce à pg_vector, on peut facilement recommander des chansons similaires à celles que nous écoutons.&lt;/p&gt;&#xA;&lt;p&gt;L’avantage de pg_vector, c’est qu’il permet de gérer ces vecteurs directement dans la base de données, ce qui évite de passer par des systèmes externes plus complexes. Cela simplifie le développement et améliore la performance, car tout est géré au même endroit.&lt;/p&gt;&#xA;&lt;h2&gt;5. Le test&lt;/h2&gt;&#xA;&lt;p&gt;Pour démontrer le fonctionnement de l&amp;#8217;extension, rien de tel qu&amp;#8217;un petit test pour éprouver les fonctionnalités qu&amp;#8217;elle propose. Le test sera plutôt simple et succinct pour être accessible. Le prérequi est d&amp;#8217;avoir une version PostgreSQL 14 ou plus récente d&amp;#8217;installée.&lt;/p&gt;&#xA;&lt;h3&gt;Etape 1 :&lt;/h3&gt;&#xA;&lt;p&gt;On commence par installer l&amp;#8217;extension pg_vector. Pour cela, nous allons avoir besoin d&amp;#8217;un certain nombre d&amp;#8217;outils pour le faire fonctionner. Une partie de ces outils sont disponible dans la distribution dev de PostgreSQL&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# sudo apt install postgresql-server-dev-14&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Nous aurons également besoin de gcc et make :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# apt install make&#xD;&#xA;root@ip-192-1-1-201:~# apt-get install gcc&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;On effectue ensuite un git clone du projet :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# git clone https://github.com/pgvector/pgvector.git&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Et une fois que c&amp;#8217;est fait, on l&amp;#8217;installe avec make :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# cd pgvector&#xD;&#xA;root@ip-192-1-1-201:~# make &amp;amp;amp;&amp;amp;amp; sudo make install&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;Etape 2 :&lt;/h3&gt;&#xA;&lt;p&gt;On se connecte à PostgreSQL pour créer l&amp;#8217;extension. Au passage, on créé aussi une base de données pour faire nos test.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# su - postgres&#xD;&#xA;postgres@ip-192-1-1-201:~$ psql&#xD;&#xA;psql (14.13 (Ubuntu 14.13-0ubuntu0.22.04.1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# create database test_vector;&#xD;&#xA;CREATE DATABASE&#xD;&#xA;postgres=# \c test_vector&#xD;&#xA;You are now connected to database &amp;quot;test_vector&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;test_vector=# CREATE EXTENSION vector;&#xD;&#xA;CREATE EXTENSION&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Et dans la foulée, on crée une table qui contient les vecteurs sur lesquels nous allons faire les test&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;test_vector=# CREATE TABLE documents (&#xD;&#xA;id SERIAL PRIMARY KEY,&#xD;&#xA;title TEXT,&#xD;&#xA;embedding vector(3) -- vecteur de dimension 3 pour cet exemple&#xD;&#xA;);&#xD;&#xA;CREATE TABLE&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Insertion des données d&amp;#8217;exemple :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;test_vector=# INSERT INTO documents (title, embedding) VALUES&#xD;&#xA;(&#39;Document 1&#39;, &#39;[0.1, 0.2, 0.3]&#39;),&#xD;&#xA;(&#39;Document 2&#39;, &#39;[0.4, 0.5, 0.6]&#39;),&#xD;&#xA;(&#39;Document 3&#39;, &#39;[0.9, 0.8, 0.7]&#39;);&#xD;&#xA;INSERT 0 3&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;Etape 3 :&lt;/h3&gt;&#xA;&lt;p&gt;Nous avons deux types de choses à tester pour montrer l&amp;#8217;efficacité de notre extension. En effet, pour rechercher un vecteur, deux modes s&amp;#8217;offrent à nous :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;h4&gt;La distance cosinus&lt;/h4&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;La distance cosinus mesure non pas combien deux vecteurs sont éloignés, mais l&amp;#8217;angle entre eux. C’est un peu comme comparer la direction dans laquelle pointent deux vecteurs plutôt que la distance réelle entre eux.&lt;/p&gt;&#xA;&lt;p&gt;Imaginons que nous sommes en train de lancer deux flèches. La distance cosinus nous dira si les deux flèches pointent dans la même direction (sont similaires) ou si elles pointent dans des directions très différentes (sont moins similaires).&lt;/p&gt;&#xA;&lt;p&gt;Dans le cadre de l’IA, cette mesure est souvent utilisée pour comparer des embeddings (représentations numériques complexes), car elle se concentre sur la relation entre les éléments, indépendamment de leur taille exacte.&lt;/p&gt;&#xA;&lt;p&gt;Exemple simple :&lt;/p&gt;&#xA;&lt;p&gt;Prenons les deux films :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Film A : &lt;code&gt;[1, 5, 50, 120]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Film B : &lt;code&gt;[2, 4, 45, 110]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La distance cosinus ne va pas se soucier de la différence de valeur entre chaque composant, mais va regarder si les deux films ont des proportions similaires. Autrement dit, est-ce que leur &amp;#8220;profil&amp;#8221; général est proche ou éloigné ?&lt;/p&gt;&#xA;&lt;p&gt;Pour tester cette distance, dans notre pg vector, on utilise la méthode suivante :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;test_vector=# SELECT title, embedding, embedding &amp;amp;lt;=&amp;amp;gt; &#39;[0.2, 0.1, 0.3]&#39; AS distance&#xD;&#xA;FROM documents&#xD;&#xA;ORDER BY embedding &amp;amp;lt;=&amp;amp;gt; &#39;[0.2, 0.1, 0.3]&#39; ASC&#xD;&#xA;LIMIT 3;&#xD;&#xA;title | embedding | distance&#xD;&#xA;------------+---------------+---------------------&#xD;&#xA;Document 2 | [0.4,0.5,0.6] | 0.05582537807240784&#xD;&#xA;Document 1 | [0.1,0.2,0.3] | 0.07142855242198809&#xD;&#xA;Document 3 | [0.9,0.8,0.7] | 0.09815280896106982&#xD;&#xA;(3 rows)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Le symbole &amp;lt;=&amp;gt; représente une distance cosinus.&lt;/p&gt;&#xA;&lt;h4&gt;2. La distance Euclidienne&lt;/h4&gt;&#xA;&lt;p&gt;Imaginons que nous sommes sur une carte avec deux points : le point A et le point B. La distance euclidienne, c&amp;#8217;est la façon la plus intuitive de mesurer la distance entre ces deux points, comme si nous tracions une ligne droite entre eux. Pour parler en terme simple, c’est la &amp;#8220;distance à vol d&amp;#8217;oiseau&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;Dans le cadre des vecteurs, la distance euclidienne mesure la différence entre deux vecteurs, un peu comme si chaque vecteur était un point sur une carte en plusieurs dimensions. Plus cette distance est petite, plus les deux vecteurs (et donc les objets qu’ils représentent) sont similaires.&lt;/p&gt;&#xA;&lt;p&gt;Exemple simple :&lt;/p&gt;&#xA;&lt;p&gt;Imaginons deux films représentés par les vecteurs suivants :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Film A&lt;/strong&gt; : &lt;code&gt;[1, 5, 50, 120]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Film B&lt;/strong&gt; : &lt;code&gt;[2, 4, 45, 110]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La distance euclidienne va calculer la différence entre chaque nombre des deux vecteurs et déterminer à quel point ces films sont proches en termes de caractéristiques (genre, nombre d’acteurs, budget, etc.).&lt;/p&gt;&#xA;&lt;p&gt;Dans pg_vector on peut le tester ainsi :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;test_vector=# SELECT title, embedding, embedding &amp;amp;lt;-&amp;amp;gt; &#39;[0.2, 0.1, 0.3]&#39; AS distance&#xD;&#xA;FROM documents&#xD;&#xA;ORDER BY embedding &amp;amp;lt;-&amp;amp;gt; &#39;[0.2, 0.1, 0.3]&#39; ASC&#xD;&#xA;LIMIT 3;&#xD;&#xA;title | embedding | distance&#xD;&#xA;------------+---------------+--------------------&#xD;&#xA;Document 1 | [0.1,0.2,0.3] | 0.1414213612422477&#xD;&#xA;Document 2 | [0.4,0.5,0.6] | 0.5385165006363984&#xD;&#xA;Document 3 | [0.9,0.8,0.7] | 1.0677078185041473&#xD;&#xA;(3 rows)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Elle est représentée par le cigle &amp;lt;-&amp;gt; dans pg_vector.&lt;/p&gt;&#xA;&lt;h4&gt;3. Quand choisir l&amp;#8217;une ou l&amp;#8217;autre des distances ?&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;La distance euclidienne est utile quand tu veux mesurer la différence globale entre deux objets. Elle est facile à comprendre et à utiliser pour des comparaisons directes.&lt;/li&gt;&#xA;&lt;li&gt;La distance cosinus est utile quand tu veux savoir si deux objets sont globalement similaires dans leur profil, indépendamment de leur taille ou de leur échelle. Elle est souvent utilisée pour comparer des documents textuels ou des données complexes en IA&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Conclusion&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;#8217;extension pg_vector apporte une fonctionnalité puissante à PostgreSQL, permettant de manipuler des données complexes sous forme de vecteurs. Que ce soit pour des systèmes de recommandation, des moteurs de recherche ou toute autre application liée à l’intelligence artificielle, elle offre un moyen simple et efficace d&amp;#8217;intégrer l&amp;#8217;IA dans les bases de données. Et tout cela, sans avoir besoin de comprendre des mathématiques avancées : il suffit de savoir que ces vecteurs permettent de traiter des informations complexes de manière très efficace.&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/&#34; rel=&#34;bookmark&#34; title=&#34;3 avril 2024&#34;&gt;pg_recursively_delete : Simplifier les suppressions récursives&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pyrseas-et-postgresql-comparer-facilement-des-schema-de-base-de-donnees/&#34; rel=&#34;bookmark&#34; title=&#34;3 janvier 2023&#34;&gt;Pyrseas et Postgresql : Comparer facilement des schémas de base de données&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-planifier-une-tache-avec-pg_cron/&#34; rel=&#34;bookmark&#34; title=&#34;24 septembre 2019&#34;&gt;PostgreSQL : planifier une tâche avec pg_cron&lt;/a&gt; (Emmanuel RAMI) [Non classéPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/openrowset-episode-1/&#34; rel=&#34;bookmark&#34; title=&#34;13 juillet 2011&#34;&gt;OPENROWSET, épisode 1&lt;/a&gt; (David Baffaleuf) [SQL Server]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/transparent-data-encryption-pour-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;13 mai 2022&#34;&gt;Transparent Data Encryption pour PostgreSQL&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 2.786 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&amp;#038;title=pg_vector%20%3A%20l%E2%80%99IA%20et%20PostgreSQL&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=pg_vector%20%3A%20l%E2%80%99IA%20et%20PostgreSQL&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pg_vector-lia-et-postgresql/&#34;&gt;pg_vector : l&amp;#8217;IA et PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/pg_vector-lia-et-postgresql/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;1. Introduction : L&amp;#8217;intelligence artificielle et le rôle des bases de données L&amp;#8217;intelligence artificielle (IA) connaît une popularité croissante, des assistants virtuels aux voitures autonomes, en passant par les recommandations de films et de produits. Mais pour que ces technologies&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/pg_vector-lia-et-postgresql/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pg_vector-lia-et-postgresql/&#34;&gt;pg_vector : l&amp;#8217;IA et PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 17 : des sauvegardes incrémentales avec pg_basebackup</title>
    <updated>2024-07-16T11:24:05Z</updated>
    <id>tag:blog.capdata.fr,2024-07-16:/index.php/postgresql-17-sauvegardes-incrementales/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&amp;#038;title=PostgreSQL%2017%20%3A%20des%20sauvegardes%20incr%C3%A9mentales%20avec%20pg_basebackup&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%2017%20%3A%20des%20sauvegardes%20incr%C3%A9mentales%20avec%20pg_basebackup&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-full wp-image-10592&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2024/07/SalesGrowth.jpg&#34; alt=&#34;&#34; width=&#34;279&#34; height=&#34;180&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Bonjour&lt;/p&gt;&#xA;&lt;p&gt;Les 11 et 12 juin derniers, nous étions aux journées PGDAY à Lille pour découvrir les nouveautés autour de PostgreSQL.&lt;br /&gt;&#xA;Cette conférence regroupe différents professionnels, de la communauté francophone, qui agissent en contribuant sur des sujets techniques mais aussi sur les bonnes pratiques afin d&amp;#8217;utiliser PostgreSQL dans les meilleurs conditions.&lt;/p&gt;&#xA;&lt;p&gt;Un article m&amp;#8217;a particulièrement intéressé cette année, c&amp;#8217;est celui de &lt;a href=&#34;https://www.linkedin.com/in/stefan-fercot/?originalSubdomain=be&#34;&gt;Stefan Fercot&lt;/a&gt; Senior DBA PostgreSQL qui vit en Belgique, et travaille pour une société allemande experte dans les solutions PostgreSQL. Sa présentation portait sur le sujet &amp;#8220;démystifier les sauvegardes incrémentales sous PostgreSQL&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;J&amp;#8217;ai écouté sa conférence tout en ayant hâte de tester sa mise en place dès mon retour de Lille.&lt;/p&gt;&#xA;&lt;p&gt;Je tiens à remercier Stefan pour son travail sur ce sujet sauvegardes PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Tout d&amp;#8217;abord, il faut savoir que les sujets sauvegardes incrémentales ont été déjà abordés avec des outils comme &lt;strong&gt;Barman&lt;/strong&gt; ou &lt;strong&gt;Pg_BackRest&lt;/strong&gt;, et que certaines instances PostgreSQL de production sont sauvegardées via ces mécanismes depuis quelques années maintenant.&lt;/p&gt;&#xA;&lt;p&gt;Ici, nous parlons de la solution &amp;#8220;backup incremental&amp;#8221; inclu nativement dans le moteur PostgreSQL, et disponible avec l&amp;#8217;outil &amp;#8220;&lt;strong&gt;pg_basebackup&lt;/strong&gt;&amp;#8220;. C&amp;#8217;est d&amp;#8217;ailleurs ce point que Stefan a souligné durant la journée PGDAY du 11 juin dernier.&lt;/p&gt;&#xA;&lt;p&gt;Cette nouvelle fonctionnalité fait partie de la version &lt;strong&gt;PostgreSQL 17&lt;/strong&gt; qui est pour le moment, en version&lt;strong&gt; Beta 2&lt;/strong&gt;.&lt;br /&gt;&#xA;Celle ci devrait sortir, comme à l&amp;#8217;accoutumé, au cour de l&amp;#8217;automne prochain.&lt;/p&gt;&#xA;&lt;p&gt;Preuve que PostgreSQL est en perpétuel évolution, et rejoint la liste des SGBD étant capable, comme peuvent le faire Oracle et SQL Server, de proposer nativement des sauvegardes incrémentales.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Installation de PostgreSQL 17&lt;/h2&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Pour tester cette fonctionnalité, nous devons installer la toute dernière version de PostgreSQL , la 17 beta 2. Attention, celle ci n&amp;#8217;étant pas disponible dans les dépôts PGDG, nous devons nous charger d&amp;#8217;installer cette version via le site postgresql.org&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://download.postgresql.org/pub/repos/yum/testing/17/redhat/rhel-8-x86_64/&#34;&gt;https://download.postgresql.org/pub/repos/yum/testing/17/redhat/rhel-8-x86_64/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Nous disposons d&amp;#8217;un serveur Linux fork Red Hat 8 (Rocky Linux). Il nous faut donc télécharger les &amp;#8220;rpm&amp;#8221; liés à cette version.&lt;/p&gt;&#xA;&lt;p&gt;Les packages dont nous avons besoin sont les suivants&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# ls -lrt postgresql1* | awk &#39;{print$9}&#39;&#xD;&#xA;postgresql17-contrib-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;postgresql17-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;postgresql17-libs-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;postgresql17-server-17-beta2_1PGDG.rhel8.x86_64.rpm&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Nous les installons avec le compte &lt;strong&gt;root&lt;/strong&gt; de notre serveur.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[root@ tmp]# rpm -i postgresql17-libs-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;[root@ tmp]# rpm -i postgresql17-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;[root@ tmp]# rpm -i postgresql17-server-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;[root@ tmp]# rpm -i postgresql17-contrib-17-beta2_1PGDG.rhel8.x86_64.rpm&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Comme nous sommes sur un environnement &amp;#8220;Red Hat like&amp;#8221;, la création d&amp;#8217;une première instance via &amp;#8220;initdb&amp;#8221; est nécessaire.&lt;br /&gt;&#xA;Surtout, ne pas oublier d&amp;#8217;activer les &amp;#8220;data checksums&amp;#8221; (option -k), nous verrons pourquoi dans la suite de cet article. La suite est à faire avec le compte &lt;strong&gt;postgres&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ initdb -D /data/postgres/17/pg_data -k&#xD;&#xA;The files belonging to this database system will be owned by user &amp;quot;postgres&amp;quot;.&#xD;&#xA;This user must also own the server process.&#xD;&#xA;&#xD;&#xA;The database cluster will be initialized with locale &amp;quot;en_US.UTF-8&amp;quot;.&#xD;&#xA;The default database encoding has accordingly been set to &amp;quot;UTF8&amp;quot;.&#xD;&#xA;The default text search configuration will be set to &amp;quot;english&amp;quot;.&#xD;&#xA;&#xD;&#xA;Data page checksums are enabled.&#xD;&#xA;&#xD;&#xA;creating directory /data/postgres/17/pg_data ... ok&#xD;&#xA;creating subdirectories ... ok&#xD;&#xA;selecting dynamic shared memory implementation ... posix&#xD;&#xA;selecting default &amp;quot;max_connections&amp;quot; ... 100&#xD;&#xA;selecting default &amp;quot;shared_buffers&amp;quot; ... 128MB&#xD;&#xA;selecting default time zone ... UTC&#xD;&#xA;creating configuration files ... ok&#xD;&#xA;running bootstrap script ... ok&#xD;&#xA;performing post-bootstrap initialization ... ok&#xD;&#xA;syncing data to disk ... ok&#xD;&#xA;&#xD;&#xA;initdb: warning: enabling &amp;quot;trust&amp;quot; authentication for local connections&#xD;&#xA;initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.&#xD;&#xA;&#xD;&#xA;Success. You can now start the database server using:&#xD;&#xA;&#xD;&#xA;pg_ctl -D /data/postgres/17/pg_data -l logfile start&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Démarrer cette instance pour s&amp;#8217;assurer que tout fonctionne&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ pg_ctl -D /data/postgres/17/pg_data -l logfile start&#xD;&#xA;waiting for server to start.... done&#xD;&#xA;server started&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Notre version enregistrée est bien une Beta 2. Version qui ne doit pas être mise sur un environnement de production comme le rappelle le site de la communauté PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ psql&#xD;&#xA;(postgres@[local]:5437) [postgres] &amp;gt; select * from version();&#xD;&#xA;version&#xD;&#xA;------------------------------------------------------------------------------------------------------------&#xD;&#xA;PostgreSQL 17beta2 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-22), 64-bit&#xD;&#xA;(1 row)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Upgrade de version&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Comme nous disposions deja d&amp;#8217;une version PostgreSQL15 sur ce serveur, nous passons par un upgrade via l&amp;#8217;outil &amp;#8220;pg_upgrade&amp;#8221; toujours disponible dans cette nouvelle version.&lt;/p&gt;&#xA;&lt;p&gt;Lancer pg_upgrade en mode check&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ pg_upgrade -b /usr/pgsql-15/bin/ -B /usr/pgsql-17/bin/ -c -d /data/postgres/15/pg_data/ -D /data/postgres/17/pg_data/ -p 5434 -P 5437&#xD;&#xA;.....&#xD;&#xA;.....&#xD;&#xA;&#xD;&#xA;*Clusters are compatible*&#xD;&#xA;&amp;quot;/usr/pgsql-17/bin/pg_ctl&amp;quot; -w -D &amp;quot;/data/postgres/17/pg_data&amp;quot; -o &amp;quot;&amp;quot; -m smart stop  &amp;quot;/data/postgres/17/pg_data/pg_upgrade_output.d/20240708T085906.955/log/pg_upgrade_server.log&amp;quot; &lt;/pre&gt;&#xA;&lt;p&gt;la log est générée dans le $PGDATA de la version 17.&lt;/p&gt;&#xA;&lt;p&gt;Puis lancer l&amp;#8217;exécution de pg_upgrade&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ pg_upgrade -b /usr/pgsql-15/bin/ -B /usr/pgsql-17/bin/ -d /data/postgres/15/pg_data/ -D /data/postgres/17/pg_data/ -p 5434 -P 5437&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Effectuer une sauvegarde&lt;/h2&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Prérequis&lt;/h3&gt;&#xA;&lt;p&gt;Avant de pouvoir effectuer une première sauvegarde avec l&amp;#8217;outil &amp;#8220;&lt;strong&gt;pg_basebackup&lt;/strong&gt;&amp;#8221; natif, il est primordial de respecter certains prérequis important.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;L&amp;#8217;instance PostgreSQL doit être créée avec les &amp;#8216;data checksums&amp;#8217; activés. Si ce n&amp;#8217;est pas le cas, utiliser l&amp;#8217;outil &amp;#8220;&lt;strong&gt;pg_checksums&lt;/strong&gt;&amp;#8221; avec l&amp;#8217;option &amp;#8220;&lt;strong&gt;-e&lt;/strong&gt;&amp;#8220;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Si vous lancez une sauvegarde full puis une incrémentale immédiatement, vous avez toutes les chances de tomber sur cette erreur&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;pg_basebackup: error: could not initiate base backup: ERROR: incremental backups cannot be taken unless WAL summarization is enabled&lt;/pre&gt;&#xA;&lt;p&gt;En effet, pour avoir toutes les informations concernant les blocks modifiés, PostgreSQL a besoin de tracer dans les WALs toutes les modifications sur les objets en base.&lt;br /&gt;&#xA;Pour les DBA Oracle, le &amp;#8220;block change tracking&amp;#8221; de la version Enterprise Edition vous parlera très certainement&amp;#8230;.&lt;br /&gt;&#xA;Il s&amp;#8217;agit ici de la même fonctionnalité, c&amp;#8217;est à dire, tracer les modifications effectuées dans les blocks de données.&lt;br /&gt;&#xA;Cette option est le &amp;#8220;&lt;strong&gt;summarize_wal&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Pour activer l&amp;#8217;option, nous aurons 2 paramètres à modifier, soit via un ALTER SYSTEM directement sous psql, ou bien dans le fichier &amp;#8220;postgresql.conf&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres backup]$ vi $PGDATA/postgresql.conf&#xD;&#xA;...&#xD;&#xA;&#xD;&#xA;# - WAL Summarization -&#xD;&#xA;&#xD;&#xA;#summarize_wal = off # run WAL summarizer process?&#xD;&#xA;#wal_summary_keep_time = &#39;10d&#39; # when to remove old summary files, 0 = never&lt;/pre&gt;&#xA;&lt;p&gt;Le premier paramètre permet d&amp;#8217;activer cette option.&lt;br /&gt;&#xA;Le second définit un temps de conservation des informations concernant les blocks modifiés entre une sauvegarde FULL et un incrémentale.&lt;/p&gt;&#xA;&lt;p&gt;Nous activons donc l&amp;#8217;option &amp;#8220;&lt;strong&gt;summarize_wal&lt;/strong&gt;&amp;#8221; et la passons à &lt;strong&gt;ON&lt;/strong&gt; et laissons à 10 jours le &amp;#8220;&lt;strong&gt;wal_summary_keep_time&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Attention, activez ces deux paramètres avant votre première sauvegarde FULL. Si vous le faites après, vous risquez de rencontrer l&amp;#8217;erreur suivante&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;pg_basebackup: error: could not initiate base backup: ERROR: WAL summaries are required on timeline 1 from 1/AA000028 to 1/AC000060, but the summaries for that timeline and LSN range are incomplete&#xD;&#xA;DETAIL: The first unsummarized LSN in this range is 1/AA000028.&lt;/pre&gt;&#xA;&lt;p&gt;Le LSN pris lors de la première sauvegarde FULL n&amp;#8217;est pas reconnu, et donc la sauvegarde incrémentale ne peut s&amp;#8217;appuyer dessus.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Redémarrer l&amp;#8217;instance une fois les modifications effectuées&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ pg_ctl -D /data/postgres/17/pg_data/ restart&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Lancer une sauvegarde FULL&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Voici la nouvelle option présente pour l&amp;#8217;outil &amp;#8220;&lt;strong&gt;pg_basebackup&lt;/strong&gt;&amp;#8221;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres -]$ pg_basebackup --help&#xD;&#xA;pg_basebackup takes a base backup of a running PostgreSQL server.&#xD;&#xA;&#xD;&#xA;Usage:&#xD;&#xA;pg_basebackup [OPTION]...&#xD;&#xA;&#xD;&#xA;Options controlling the output:&#xD;&#xA;-D, --pgdata=DIRECTORY receive base backup into directory&#xD;&#xA;-F, --format=p|t output format (plain (default), tar)&#xD;&#xA;-i, --incremental=OLDMANIFEST&#xD;&#xA;take incremental backup&#xD;&#xA;-r, --max-rate=RATE maximum transfer rate to transfer data directory&#xD;&#xA;(in kB/s, or use suffix &amp;quot;k&amp;quot; or &amp;quot;M&amp;quot;)&#xD;&#xA;&#xD;&#xA;.... &lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Depuis la &lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-13-les-nouveautes-interessantes/&#34;&gt;version 13&lt;/a&gt; de PostgreSQL, nous disposons pour chaque sauvegarde, d&amp;#8217;un fichier nommé &amp;#8220;backup_manifest&amp;#8221;. Il s&amp;#8217;agit d&amp;#8217;un fichier json qui recense entièrement les objets bases de données sauvegardés avec leur emplacement, leur taille, leur date de modification et leur &amp;#8220;checksum&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;Celui ci est essentiel pour vérifier l&amp;#8217;intégrité de notre sauvegarde avec &amp;#8220;&lt;strong&gt;pg_verifybackup&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Nous pouvons à présent faire une première sauvegarde FULL de notre instance PG17.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres -]$ pg_basebackup -D /data/postgres/backup/pg_basebackup/PG17 -F p -l &amp;quot;Full Backup PG17&amp;quot; -P -v&#xD;&#xA;pg_basebackup: initiating base backup, waiting for checkpoint to complete&#xD;&#xA;pg_basebackup: checkpoint completed&#xD;&#xA;pg_basebackup: write-ahead log start point: 1/AD000028 on timeline 1&#xD;&#xA;pg_basebackup: starting background WAL receiver&#xD;&#xA;pg_basebackup: created temporary replication slot &amp;quot;pg_basebackup_8048&amp;quot;&#xD;&#xA;3097788/3097788 kB (100%), 1/1 tablespace&#xD;&#xA;pg_basebackup: write-ahead log end point: 1/AD000158&#xD;&#xA;pg_basebackup: waiting for background process to finish streaming ...&#xD;&#xA;pg_basebackup: syncing data to disk ...&#xD;&#xA;pg_basebackup: renaming backup_manifest.tmp to backup_manifest&#xD;&#xA;pg_basebackup: base backup completed&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Puis on effectue quelques transactions : création d&amp;#8217;une table et insertions de données sur cette table de test&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5437) [manu] $ &amp;gt; create table backup (nom varchar(20), type varchar(20), date_backup date);&#xD;&#xA;CREATE TABLE&#xD;&#xA;Time: 3.344 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; insert into backup values (&#39;sauvegarde&#39;,&#39;FULL&#39;,&#39;2024-07-08 12:00:00&#39;);&#xD;&#xA;INSERT 0 1&#xD;&#xA;Time: 3.612 ms&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; insert into backup values (&#39;sauvegarde&#39;,&#39;incremental&#39;,&#39;2024-07-08 13:00:00&#39;);&#xD;&#xA;INSERT 0 1&#xD;&#xA;Time: 1.461 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; select * from backup;&#xD;&#xA;nom | type | date_backup&#xD;&#xA;------------+-------------+-------------&#xD;&#xA;sauvegarde | FULL | 2024-07-08&#xD;&#xA;sauvegarde | incremental | 2024-07-08&#xD;&#xA;(2 rows)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Repérer le fichier &amp;#8220;backup_manifest&amp;#8221; de la sauvegarde FULL réalisée dans le dossier &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17&lt;/strong&gt;&amp;#8221;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres PG17]$ ls -lrt backup*&#xD;&#xA;-rw-------. 1 postgres postgres 218 Jul 8 09:19 backup_label&#xD;&#xA;-rw-------. 1 postgres postgres 433295 Jul 8 09:20 backup_manifest&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Effectuer une sauvegarde incrémentale&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;A partir de là, lancer une sauvegarde incrémentale. Nous utilisons l&amp;#8217;option &amp;#8220;&lt;strong&gt;-i&lt;/strong&gt;&amp;#8221; pour indiquer à &lt;strong&gt;pg_basebackup&lt;/strong&gt; ou est situé le &amp;#8220;backup_manifest&amp;#8221; de la dernière sauvegarde FULL.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_basebackup -D /data/postgres/backup/pg_basebackup/PG17_incr -l &amp;quot;Incremental Backup PG17&amp;quot; -P -v -i /data/postgres/backup/pg_basebackup/PG17/backup_manifest&#xD;&#xA;pg_basebackup: initiating base backup, waiting for checkpoint to complete&#xD;&#xA;pg_basebackup: checkpoint completed&#xD;&#xA;pg_basebackup: write-ahead log start point: 1/AF000028 on timeline 1&#xD;&#xA;pg_basebackup: starting background WAL receiver&#xD;&#xA;pg_basebackup: created temporary replication slot &amp;quot;pg_basebackup_8139&amp;quot;&#xD;&#xA;12485/3097787 kB (100%), 1/1 tablespace&#xD;&#xA;pg_basebackup: write-ahead log end point: 1/AF000120&#xD;&#xA;pg_basebackup: waiting for background process to finish streaming ...&#xD;&#xA;pg_basebackup: syncing data to disk ...&#xD;&#xA;pg_basebackup: renaming backup_manifest.tmp to backup_manifest&#xD;&#xA;pg_basebackup: base backup completed&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;S&amp;#8217;il l&amp;#8217;on compare les deux répertoires de sauvegardes &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17&lt;/strong&gt;&amp;#8221; et &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17_incr&lt;/strong&gt;&amp;#8220;, nous voyons que les tailles sont bien différentes&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ du -h /data/postgres/backup/pg_basebackup/PG17&#xD;&#xA;......&#xD;&#xA;3.0G /data/postgres/backup/pg_basebackup/PG17&#xD;&#xA;&#xD;&#xA;[postgres - ]$ du -h /data/postgres/backup/pg_basebackup/PG17_incr&#xD;&#xA;......&#xD;&#xA;35M /data/postgres/backup/pg_basebackup/PG17_incr&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Un volume de 3Go pour la sauvegarde FULL de l&amp;#8217;instance contre 35Mo pour l&amp;#8217;incrémentale.&lt;br /&gt;&#xA;La taille occupée par les objets dans chacune des bases est bien plus faible dans la sauvegarde incrémentale.&lt;/p&gt;&#xA;&lt;p&gt;Nous continuons à insérer des données :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt; [postgres - ]$ psql -d manu&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; select * from backup;&#xD;&#xA;nom | type | date_backup&#xD;&#xA;------------+-------------+-------------&#xD;&#xA;sauvegarde | FULL | 2024-07-08&#xD;&#xA;sauvegarde | incremental | 2024-07-08&#xD;&#xA;(2 rows)&#xD;&#xA;&#xD;&#xA;Time: 0.614 ms&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; insert into backup values (&#39;sauvegarde&#39;,&#39;incremental 2&#39;,&#39;2024-07-08 14:00:00&#39;);&#xD;&#xA;INSERT 0 1&#xD;&#xA;Time: 1.436 ms&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; select * from backup;&#xD;&#xA;nom | type | date_backup&#xD;&#xA;------------+---------------+-------------&#xD;&#xA;sauvegarde | FULL | 2024-07-08&#xD;&#xA;sauvegarde | incremental | 2024-07-08&#xD;&#xA;sauvegarde | incremental 2 | 2024-07-08&#xD;&#xA;(3 rows)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Puis on lance une seconde sauvegarde incrémentale :&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_basebackup -D /data/postgres/backup/pg_basebackup/PG17_incr_2 -l &amp;quot;Incremental 2 Backup PG17&amp;quot; -P -v -i /data/postgres/backup/pg_basebackup/PG17_incr/backup_manifest&#xD;&#xA;pg_basebackup: initiating base backup, waiting for checkpoint to complete&#xD;&#xA;pg_basebackup: checkpoint completed&#xD;&#xA;pg_basebackup: write-ahead log start point: 1/B1000028 on timeline 1&#xD;&#xA;pg_basebackup: starting background WAL receiver&#xD;&#xA;pg_basebackup: created temporary replication slot &amp;quot;pg_basebackup_8313&amp;quot;&#xD;&#xA;12260/3097787 kB (100%), 1/1 tablespace&#xD;&#xA;pg_basebackup: write-ahead log end point: 1/B1000120&#xD;&#xA;pg_basebackup: waiting for background process to finish streaming ...&#xD;&#xA;pg_basebackup: syncing data to disk ...&#xD;&#xA;pg_basebackup: renaming backup_manifest.tmp to backup_manifest&#xD;&#xA;pg_basebackup: base backup completed&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Nous remarquons l&amp;#8217;appel au &amp;#8220;backup manifest&amp;#8221; de la dernière sauvegarde incrémentale présente dans le répertoire &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17_incr&lt;/strong&gt;&amp;#8221;&lt;/p&gt;&#xA;&lt;p&gt;Si l&amp;#8217;on regarde la taille de ce nouveau backup&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres pg_basebackup]$ du -h PG17_incr_2&#xD;&#xA;.......&#xD;&#xA;35M PG17_incr_2&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;A nouveau 35 Mo, mais vu le peu de modifications effectuées, la taille n&amp;#8217;est pas très représentative.&lt;/p&gt;&#xA;&lt;p&gt;Ce qu&amp;#8217;il faut retenir, c&amp;#8217;est qu&amp;#8217;en fonction du fichier &amp;#8220;backup manifest&amp;#8221; pris lors de l&amp;#8217;appel à &lt;strong&gt;pg_basebackup&lt;/strong&gt;, vous pourrez faire soit&lt;br /&gt;&#xA;&amp;#8211; une sauvegarde incrémentale qui prendra les dernières modifications depuis la dernière sauvegarde incrémentale effectuée.&lt;br /&gt;&#xA;&amp;#8211; une sauvegarde différentielle qui prendra les modifications faites depuis la dernière sauvegarde FULL si vous vous appuyez toujours sur le &amp;#8220;backup manifest&amp;#8221; de votre sauvegarde FULL.&lt;/p&gt;&#xA;&lt;p&gt;C&amp;#8217;est donc ce fichier json &amp;#8220;backup manifest&amp;#8221; qui a un rôle essentiel dans l&amp;#8217;élaboration de votre stratégie de sauvegarde au fur et à mesure du temps.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Et la restauration , comment ca se passe ?&lt;/h2&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Si l&amp;#8217;on souhaite restaurer tous ces jeux de sauvegardes, nous utilisons un nouvel outil qui est &amp;#8220;&lt;strong&gt;pg_combinebackup&lt;/strong&gt;&amp;#8220;.&lt;br /&gt;&#xA;Cet outil permet de &amp;#8220;merger&amp;#8221; les différentes sauvegardes dans un et un seul dossier que l&amp;#8217;on restaurera par la suite.&lt;/p&gt;&#xA;&lt;p&gt;Dans notre exemple, nous avons fait 1 sauvegarde FULL puis 2 incrémentales.&lt;br /&gt;&#xA;Nous allons donc restaurer ces 3 jeux de sauvegardes afin de retrouver les données. A noter qu&amp;#8217;il existe une option &amp;#8220;&amp;#8211;dry-run&amp;#8221; pour tester la commande&lt;/p&gt;&#xA;&lt;p&gt;Exécuter la commande en prenant en paramètre les dossiers de sauvegardes dans l&amp;#8217;ordre chronologique.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_combinebackup -n -o /data/postgres/backup/pg_basebackup/PG17_ALL /data/postgres/backup/pg_basebackup/PG17 /data/postgres/backup/pg_basebackup/PG17_incr /data/postgres/backup/pg_basebackup/PG17_incr_2 &lt;/pre&gt;&#xA;&lt;p&gt;Si aucune erreur en sortie, on exécute sans l&amp;#8217;option &amp;#8220;dry run&amp;#8221;.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; [postgres - ]$ pg_combinebackup -o /data/postgres/backup/pg_basebackup/PG17_ALL /data/postgres/backup/pg_basebackup/PG17 /data/postgres/backup/pg_basebackup/PG17_incr /data/postgres/backup/pg_basebackup/PG17_incr_2 &lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Le répertoire &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17_ALL&lt;/strong&gt;&amp;#8221; ainsi généré, doit avoir une taille très légèrement supérieure au dossier de la sauvegarde FULL.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ du -h PG17_ALL&#xD;&#xA;....&#xD;&#xA;3.0G PG17_ALL&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Dernière étape, nous passons à la restauration des données.&lt;/p&gt;&#xA;&lt;p&gt;Nous arrêtons l&amp;#8217;instance PG17&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_ctl -D /data/postgres/17/pg_data/ stop&#xD;&#xA;waiting for server to shut down.... done&#xD;&#xA;server stopped&lt;/pre&gt;&#xA;&lt;p&gt;Nous supprimons les données dans $PGDATA&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ rm -rf /data/postgres/17/pg_data/* &lt;/pre&gt;&#xA;&lt;p&gt;Puis nous restaurons ce jeu complet de données avec une simple copie.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ cp -r /data/postgres/backup/pg_basebackup/PG17_ALL/* /data/postgres/17/pg_data/ &lt;/pre&gt;&#xA;&lt;p&gt;Enfin redémarrons l&amp;#8217;instance&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_ctl -D /data/postgres/17/pg_data/ start&#xD;&#xA;waiting for server to start....2024-07-08 10:51:45.671 UTC [8909] LOG: redirecting log output to logging collector process&#xD;&#xA;2024-07-08 10:51:45.671 UTC [8909] HINT: Future log output will appear in directory &amp;quot;log&amp;quot;.&#xD;&#xA;done&#xD;&#xA;server started&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Puis contrôler que nous récupérons bien toutes les lignes de notre table &amp;#8220;backup&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres@ip-172-44-2-96 pg_basebackup]$ psql -d manu&#xD;&#xA;(postgres@[local]:5437) [manu] primaire $ &amp;gt; select * from backup;&#xD;&#xA;nom | type | date_backup&#xD;&#xA;------------+---------------+-------------&#xD;&#xA;sauvegarde | FULL | 2024-07-08&#xD;&#xA;sauvegarde | incremental | 2024-07-08&#xD;&#xA;sauvegarde | incremental 2 | 2024-07-08&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;&lt;/h3&gt;&#xA;&lt;h3&gt;&lt;/h3&gt;&#xA;&lt;h3&gt;Remarques&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Attention, toujours vérifier les sauvegardes à chaque étape avec l&amp;#8217;outil &lt;strong&gt;pg_verifybackup &lt;/strong&gt;car rien ne garantit qu&amp;#8217;au moment de l&amp;#8217;appel à &lt;strong&gt;pg_combinebackup&lt;/strong&gt; les différents jeux de sauvegardes FULL et/ou incrémentales ne soient pas corrompus.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Assurez vous d&amp;#8217;être en mode &amp;#8220;data_checksum&amp;#8221; activé et ne pas changer de mode entre les jeux de backup. Le &amp;#8220;backup manifest&amp;#8221; s&amp;#8217;appuie sur ce paramétrage pour valider les checksums de chaque fichier.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Le mode TAR pour &lt;strong&gt;pg_basebackup&lt;/strong&gt; n&amp;#8217;est pas compatible pour les sauvegardes full et incrémentales même si celui ci est possible. Mais c&amp;#8217;est à vous de détarer les fichiers &amp;#8220;&lt;strong&gt;base.tar.gz&lt;/strong&gt;&amp;#8221; Et au moment de la restauration  avec &amp;#8220;&lt;strong&gt;pg_combinebackup&lt;/strong&gt;&amp;#8220;, une possible corruption est rencontrée.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_combinebackup -o /data/postgres/backup/pg_basebackup/PG17_all_tar /data/postgres/backup/pg_basebackup/PG17_TAR /data/postgres/backup/pg_basebackup/PG17_incr_TAR&#xD;&#xA;pg_combinebackup: error: could not write to file &amp;quot;/data/postgres/backup/pg_basebackup/PG17_all_tar/base/25284/25332&amp;quot;, offset 122470400: wrote 380928 of 409600&#xD;&#xA;pg_combinebackup: removing output directory &amp;quot;/data/postgres/backup/pg_basebackup/PG17_all_tar&amp;quot; &lt;/pre&gt;&#xA;&lt;p&gt;La compression a potentiellement ajoutée une corruption ne rendant pas possible l&amp;#8217;opération de &amp;#8220;merge&amp;#8221; des données.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;La restauration PITR est possible bien entendu. N&amp;#8217;oubliez pas de créer le &amp;#8220;&lt;strong&gt;recovery.signal&lt;/strong&gt;&amp;#8221; dans $PGDATA et de définir dans le fichier &amp;#8220;postgresql.conf&amp;#8221; les quelques paramètres suivants&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #3366ff;&#34;&gt;recovery_target_name &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #3366ff;&#34;&gt;recovery_target_time &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #3366ff;&#34;&gt;recovery_target_xid &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #3366ff;&#34;&gt;recovery_target_lsn &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #808000;&#34;&gt;recovery_target_inclusive = off ou on&lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #808000;&#34;&gt;recovery_target_timeline = &amp;#8216;latest&amp;#8217; &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #808000;&#34;&gt;recovery_target_action = &amp;#8216;pause&amp;#8217; &lt;/span&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://s.w.org/images/core/emoji/15.0.3/72x72/1f642.png&#34; alt=&#34;🙂&#34; class=&#34;wp-smiley&#34; style=&#34;height: 1em; max-height: 1em;&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-la-streaming-replication-en-12/&#34; rel=&#34;bookmark&#34; title=&#34;19 novembre 2019&#34;&gt;PostgreSQL : la streaming replication en 12.&lt;/a&gt; (Emmanuel RAMI) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-13-les-nouveautes-interessantes/&#34; rel=&#34;bookmark&#34; title=&#34;30 octobre 2020&#34;&gt;PostgreSQL 13 : présentation&lt;/a&gt; (Emmanuel RAMI) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/oracle-rds-effectuer-des-backup-rman-en-mode-paas/&#34; rel=&#34;bookmark&#34; title=&#34;25 juin 2019&#34;&gt;Oracle RDS : effectuer des backup RMAN en mode PaaS.&lt;/a&gt; (Emmanuel RAMI) [AWSNon classéOracle]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-comparatif-entre-barman-et-pgbackrest/&#34; rel=&#34;bookmark&#34; title=&#34;4 février 2020&#34;&gt;PostgreSQL : Comparatif entre Barman et pgBackRest&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/haute-disponibilite-de-postgresql-avec-patroni/&#34; rel=&#34;bookmark&#34; title=&#34;2 février 2022&#34;&gt;Haute disponibilité de PostgreSQL avec Patroni&lt;/a&gt; (Ludovic AUGEREAU) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 4.229 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&amp;#038;title=PostgreSQL%2017%20%3A%20des%20sauvegardes%20incr%C3%A9mentales%20avec%20pg_basebackup&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%2017%20%3A%20des%20sauvegardes%20incr%C3%A9mentales%20avec%20pg_basebackup&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-17-sauvegardes-incrementales/&#34;&gt;PostgreSQL 17 : des sauvegardes incrémentales avec pg_basebackup&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/postgresql-17-sauvegardes-incrementales/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&amp;#160; Bonjour Les 11 et 12 juin derniers, nous étions aux journées PGDAY à Lille pour découvrir les nouveautés autour de PostgreSQL. Cette conférence regroupe différents professionnels, de la communauté francophone, qui agissent en contribuant sur des sujets techniques mais&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-17-sauvegardes-incrementales/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-17-sauvegardes-incrementales/&#34;&gt;PostgreSQL 17 : des sauvegardes incrémentales avec pg_basebackup&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>PGO : la suite</title>
    <updated>2024-05-29T08:58:17Z</updated>
    <id>tag:blog.capdata.fr,2024-05-29:/index.php/pgo-la-suite/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&amp;#038;title=PGO%20%3A%20la%20suite&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PGO%20%3A%20la%20suite&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;La gestion efficace des clusters PostgreSQL dans un environnement Kubernetes est un défi complexe auquel sont confrontées de nombreuses entreprises aujourd&amp;#8217;hui. PGO offre une solution déclarative qui automatise la gestion des clusters PostgreSQL, simplifiant ainsi le déploiement, la mise à l&amp;#8217;échelle et la gestion des bases de données PostgreSQL dans un environnement Kubernetes.&lt;/p&gt;&#xA;&lt;p&gt;Pour faire suite à l&amp;#8217;article de David sur PGO et à la demande d&amp;#8217;un de nos clients, j&amp;#8217;ai réalisé une étude approfondie de plusieurs fonctionnalités de PGO.&lt;br /&gt;&#xA;Cet article va faire un petit tour d&amp;#8217;horizon des outils principaux inclus dans l&amp;#8217;implémentation de PGO. Que ce soit pour la sauvegarde avec pgbackrest, pour la balance des connexion avec pgbouncer ou pour le monitoring avec prometheus, PGO ne manque pas d&amp;#8217;utilitaire dont l&amp;#8217;utilisation est facilitée par la solution tout embarqué.&lt;/p&gt;&#xA;&lt;h3&gt;Pgbackrest :&lt;/h3&gt;&#xA;&lt;h4&gt;Utilité :&lt;/h4&gt;&#xA;&lt;p&gt;PgBackRest est une solution de sauvegarde et de restauration pour les bases de données PostgreSQL qui propose plusieurs fonctionnalités, telles que la sauvegarde et la restauration parallèles, la compression, les sauvegardes complètes, différentielles et incrémentielles, la rotation des sauvegardes et l&amp;#8217;expiration des archives, l&amp;#8217;intégrité des sauvegardes, etc. Il prend en charge plusieurs référentiels, qui peuvent être situés localement ou à distance via TLS/SSH, ou être des stockages fournis par le cloud comme S3/GCS/Azure.&lt;br /&gt;&#xA;L&amp;#8217;architecture de pgbackrest pour PGO est la suivante :&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image1.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-medium wp-image-10564&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image1-300x168.png&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;168&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image1-300x168.png 300w, https://blog.capdata.fr/wp-content/uploads/2024/05/Image1.png 605w&#34; sizes=&#34;auto, (max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h4&gt;Mise en place :&lt;/h4&gt;&#xA;&lt;p&gt;On peut imaginer plusieurs moyens de mettre en place le pgbackrest. Dans un premier temps, nous avons la sauvegarde classique en système de fichier, comme dans notre exemple sur le blog :&lt;/p&gt;&#xA;&lt;h5&gt;1) La sauvegarde sur volume persistant Kubernetes :&lt;/h5&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;- name: repo1&#xD;&#xA;  volume:&#xD;&#xA;    volumeClaimSpec:&#xD;&#xA;      accessModes:&#xD;&#xA;      - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;      resources:&#xD;&#xA;        requests:&#xD;&#xA;          storage: 1Gi&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Ce type de sauvegarde utilise un volume persistant de Kubernetes pour recueillir nos sauvegardes et les garder.&lt;br /&gt;&#xA;Une PersistentVolumeClaim (PVC) est une demande de stockage faite par un utilisateur. Elle est similaire à un Pod. Les Pods consomment des ressources de nœud et les PVC consomment des ressources de PV (PersistentVolume). Les Pods peuvent demander des niveaux spécifiques de ressources (CPU et mémoire). Les revendications peuvent demander une taille spécifique et des modes d&amp;#8217;accès spécifiques (par exemple, elles peuvent être montées en ReadWriteOnce, ReadOnlyMany, ReadWriteMany, ou ReadWriteOncePod, voir AccessModes).&lt;/p&gt;&#xA;&lt;h5&gt;2) Le stockage pour S3 :&lt;/h5&gt;&#xA;&lt;p&gt;Pour pouvoir faire du stockage dans S3, il faut rajouter un fichier de configuration dans notre dossier de déploiement. Le fichier doit s’appeler s3.conf. Ce fichier contient les crédential de connexion à un AWS S3 :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;repo1-s3-key=$YOUR_AWS_S3_KEY&#xD;&#xA;repo1-s3-key-secret=$YOUR_AWS_S3_KEY_SECRET&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Une fois que c’est configuré dans votre fichier, il ne reste plus qu’à modifier le postgresql.yaml, et configurer dans la partie backup :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      configuration:&#xD;&#xA;      - secret:&#xD;&#xA;          name: pgo-s3-creds&#xD;&#xA;      global:&#xD;&#xA;        repo1-path: /pgbackrest/postgres-operator/pgcluster1/repo1&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        s3:&#xD;&#xA;          bucket: &amp;quot;&amp;lt;YOUR_AWS_S3_BUCKET_NAME&amp;gt;&amp;quot;&#xD;&#xA;          endpoint: &amp;quot;&amp;lt;YOUR_AWS_S3_ENDPOINT&amp;gt;&amp;quot;&#xD;&#xA;          region: &amp;quot;&amp;lt;YOUR_AWS_S3_REGION&amp;gt;&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Une fois configuré, et le job mis dans le cron, vous devriez voir apparaitre les sauvegardes sur le volume S3.&lt;/p&gt;&#xA;&lt;h5&gt;3) Le stockage GCS :&lt;/h5&gt;&#xA;&lt;p&gt;Comme pour Amazon S3 on peut sauvegarder nos backups dans Google Cloud Storage. Pour pouvoir le faire fonctionner il vous faut copier votre GCS key secret (qui est un fichier JSON) dans un gcs.conf que vous allez placer dans votre dossier Kustomize.&lt;br /&gt;&#xA;Il vous suffit ensuite de modifier votre fichier postgres.yaml pour ajouter dans la partie backup la configuration pour une sauvegarde gcs :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      configuration:&#xD;&#xA;      - secret:&#xD;&#xA;          name: pgo-gcs-creds&#xD;&#xA;      global:&#xD;&#xA;        repo1-path: /pgbackrest/postgres-operator/pgcluster1/repo1&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        gcs:&#xD;&#xA;          bucket: &amp;quot;&amp;lt;YOUR_GCS_BUCKET_NAME&amp;gt;&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il ne vous reste plus qu’à regénérer vos pods, et votre sauvegarde arrivera directement dans votre Google Cloud Service.&lt;/p&gt;&#xA;&lt;h5&gt;4) Le stockage Azur Blob Storage :&lt;/h5&gt;&#xA;&lt;p&gt;Comme pour les deux points précédents, vous pouvez également stocker vos sauvegardes sur le blob storage d’Azure. Pour cela il vous faut créer un fichier dans votre kustomize, avec à l’intérieur la configuration pour votre point de sauvegarde Azure. Il vous faut l’appeler azure.conf et il devra contenir les lignes suivantes :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;repo1-azure-account=$YOUR_AZURE_ACCOUNT&#xD;&#xA;repo1-azure-key=$YOUR_AZURE_KEY&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il faut ensuite intégrer ces modifications dans votre fichier postgres.yaml :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      configuration:&#xD;&#xA;      - secret:&#xD;&#xA;          name: pgo-azure-creds&#xD;&#xA;      global:&#xD;&#xA;        repo1-path: /pgbackrest/postgres-operator/pgcluster/repo1&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        azure:&#xD;&#xA;          container: &amp;quot;&amp;lt;YOUR_AZURE_CONTAINER&amp;gt;&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Bien sur rien ne vous interdit, et c’est même conseillé, de joindre plusieurs moyens de sauvegarde. Cela permet notamment de s’assurer une plus grande fiabilité du système de sauvegarde, en s’assurant qu’elles sont disponibles à plusieurs endroits.&lt;br /&gt;&#xA;Une fois que vous avez décidé d’où vous allez stocker vos sauvegardes, et que vous l’avez configuré, il faut maintenant décider des différents paramètres de ces sauvegardes : la programmation, la rétention…&lt;/p&gt;&#xA;&lt;h5&gt;5) La programmation des sauvegardes :&lt;/h5&gt;&#xA;&lt;p&gt;Il faut savoir que par défaut, PGO sauvegarde automatiquement les WAL dans la méthode de sauvegarde que vous lui avez configuré. C’est donc une forme de sauvegarde en soit.&lt;br /&gt;&#xA;Mais dans le cadre d’une récupération après incident majeur, il peut aussi être utilise d’avoir des sauvegardes full programmées. Pgbackrest, qui est l’outil utilisé par PGO permet de mettre en place trois types de sauvegarde : les incrémentales, les différentielles et les fulls.&lt;br /&gt;&#xA;Chaque type de sauvegarde peut être programmée en suivant une notation identique à celle des crontab. Par exemple :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        schedules:&#xD;&#xA;          full: &amp;quot;0 1 * * 0&amp;quot;&#xD;&#xA;          differential: &amp;quot;0 1 * * 1-6&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Le fait d’implémenter ces planifications créera des CronJobs dans Kubernetes.&lt;/p&gt;&#xA;&lt;h5&gt;6) La rétention des backups :&lt;/h5&gt;&#xA;&lt;p&gt;Vous pouvez définir une rétention maximum pour vos backups sur le support de backup de votre choix. Une fois que cette rétention sera atteinte, pgbackrest fera le ménage tout seul des sauvegardes et des WAL qui lui sont reliées.&lt;br /&gt;&#xA;Il y a deux types de rétentions que l’on peut définir : les rétentions « count » basées sur le nombre de backup que l’on souhaite garder et les rétentions « time » basées sur le nombre de jours ou vous souhaitez garder votre sauvegarde.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      global:&#xD;&#xA;        repo1-retention-full: &amp;quot;14&amp;quot;&#xD;&#xA;        repo1-retention-full-type: time&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h5&gt;7) La sauvegarde unique :&lt;/h5&gt;&#xA;&lt;p&gt;Si dans le cadre d’un besoin particuliers, une grosse modification ou une migration par exemple, vous avez besoin de prendre une sauvegarde immédiate sans forcément attendre que le cron n’arrive, vous pouvez le faire.&lt;br /&gt;&#xA;Pour la configuration de cette sauvegarde, il faudra l’annoter comme « manuelle » :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      manual:&#xD;&#xA;        repoName: repo1&#xD;&#xA;        options:&#xD;&#xA;         - --type=full&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il vous faudra ensuite déclencher cette sauvegarde avec une commande manuelle. Dans le cadre de notre cluster exemple pgcluster1 :&lt;br /&gt;&#xA;kubectl annotate -n postgres-operator postgrescluster pgcluster1 \ postgres-operator.crunchydata.com/pgbackrest-backup=&amp;#8221;$(date)&amp;#8221;&lt;/p&gt;&#xA;&lt;h5&gt;8) Faire un clone à partir d’un repo :&lt;/h5&gt;&#xA;&lt;p&gt;Quand on a configuré un repo sur notre instance primaire, on peut facilement créer un clone de notre instance à l’aide de notre sauvegarde. Ainsi, on créer un tout nouveau Pods à partir des informations stockées à propos du pod que l’on possède déjà. Ici, nous allons créer un nouveau pod à partir de notre pod pgcluster1 :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;apiVersion: postgres-operator.crunchydata.com/v1beta1&#xD;&#xA;kind: PostgresCluster&#xD;&#xA;metadata:&#xD;&#xA;  name: pgcluster2&#xD;&#xA;spec:&#xD;&#xA;  dataSource:&#xD;&#xA;    postgresCluster:&#xD;&#xA;      clusterName: pgcluster1&#xD;&#xA;      repoName: repo1&#xD;&#xA;  image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres:ubi8-16.2-0&#xD;&#xA;  postgresVersion: 16&#xD;&#xA;  instances:&#xD;&#xA;    - dataVolumeClaimSpec:&#xD;&#xA;        accessModes:&#xD;&#xA;        - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;        resources:&#xD;&#xA;          requests:&#xD;&#xA;            storage: 1Gi&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        volume:&#xD;&#xA;          volumeClaimSpec:&#xD;&#xA;            accessModes:&#xD;&#xA;            - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;            resources:&#xD;&#xA;              requests:&#xD;&#xA;                storage: 1Gi&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Ici on peut noter entre autres la partie spec de la configuration, qui est le morceau de yaml nous permettant de dire qu’on s’appuie sur le cluster existant pour créer un clone indépendant :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;spec:&#xD;&#xA;  dataSource:&#xD;&#xA;    postgresCluster:&#xD;&#xA;      clusterName: pgcluster1&#xD;&#xA;      repoName: repo1&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h5&gt;9) Point in Time Recovery :&lt;/h5&gt;&#xA;&lt;p&gt;De la même façon, si l’on veut faire une restauration PITR, nous allons remplir la balise spec de notre yaml. Attention cependant, pour faire une restauration PITR, nous avons besoin de posséder encore la sauvegarde. On ne peut pas faire une restauration PITR sur une sauvegarde lointaine qu’on ne possèderait plus. Imaginons que je souhaite repartir d’une sauvegarde datant d’hier soir à 20h30 de mon instance pgcluster1 sur mon instance pgcluster2, la configuration serait la suivante :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;apiVersion: postgres-operator.crunchydata.com/v1beta1&#xD;&#xA;kind: PostgresCluster&#xD;&#xA;metadata:&#xD;&#xA;  name: pgcluster2&#xD;&#xA;spec:&#xD;&#xA;  dataSource:&#xD;&#xA;    postgresCluster:&#xD;&#xA;      clusterName: pgcluster1&#xD;&#xA;      repoName: repo1&#xD;&#xA;      options:&#xD;&#xA;      - --type=time&#xD;&#xA;      - --target=&amp;quot;2024-04-09 20:30:00-00&amp;quot;&#xD;&#xA;  image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres:ubi8-16.2-0&#xD;&#xA;  postgresVersion: 16&#xD;&#xA;  instances:&#xD;&#xA;    - dataVolumeClaimSpec:&#xD;&#xA;        accessModes:&#xD;&#xA;        - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;        resources:&#xD;&#xA;          requests:&#xD;&#xA;            storage: 1Gi&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        volume:&#xD;&#xA;          volumeClaimSpec:&#xD;&#xA;            accessModes:&#xD;&#xA;            - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;            resources:&#xD;&#xA;              requests:&#xD;&#xA;                storage: 1Gi&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;La partie qui nous intéresse ici est la partie spec, ou nous avons rajouter un type de restauration (ici time) et une heure target. Cela indique à pgbackrest qu’il doit aller chercher tous les fichiers de sauvegarde et WAL sur notre point de sauvegarde repo1 venant de l’instance pgcluster1 pour les réappliquer sur notre nouveau cluster pgcluster2.&lt;br /&gt;&#xA;Vous pouvez également vouloir réaliser une restauration In Place, c’est-à-dire écraser l’instance présente pour la remplacer par la restauration. Auquel cas, plutôt que de préciser comment s’appellera notre nouveau cluster, il faut alors passer par la balise restore :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;spec:&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      restore:&#xD;&#xA;        enabled: true&#xD;&#xA;        repoName: repo1&#xD;&#xA;        options:&#xD;&#xA;        - --type=time&#xD;&#xA;        - --target=&amp;quot;2024-04-09 20:30:00-00&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Ici, comme précédemment, nous restaurons à l’heure de 20 :30 hier soir, et cela sur notre propre instance. Ne reste plus qu’à lancer la restauration :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;kubectl annotate -n postgres-operator postgrescluster pgcluster1 --overwrite \ postgres-operator.crunchydata.com/pgbackrest-restore=&amp;quot;$(date)&amp;quot;&lt;/pre&gt;&#xA;&lt;p&gt;A noter qu’il ne faut pas oublier de désactiver ensuite le restore en le passant à false si vous ne souhaitez pas qu’il soit de nouveau écrasé au prochain changement de configuration.&lt;/p&gt;&#xA;&lt;h5&gt;10) Restaurer une base de données spécifique :&lt;/h5&gt;&#xA;&lt;p&gt;Si votre besoin est de restaurer une base de données spécifique plutôt que l’intégralité de l’instance, vous pouvez le préciser dans les paramètres de votre restauration.&lt;br /&gt;&#xA;Attention cependant, ce n’est pas une restauration comme le serais un pg_dump. Ici si vous restaurez simplement une seule base de données et pas le reste du cluster, les autres bases que vous n’avez pas choisit de restaurer deviendront inaccessibles.&lt;br /&gt;&#xA;Si nous voulons restaurer une base de données, et uniquement elle, voici la procédure :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;spec:&#xD;&#xA;backups:&#xD;&#xA;  pgbackrest:&#xD;&#xA;    restore:&#xD;&#xA;      enabled: true&#xD;&#xA;      repoName: repo1&#xD;&#xA;      options:&#xD;&#xA;        - --db-include=capdata&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Ici, on ne restaurera que la base de données capdata, et aucunes autres bases à partir de notre repo1.&lt;/p&gt;&#xA;&lt;h3&gt;PgBouncer :&lt;/h3&gt;&#xA;&lt;h4&gt;Utilité :&lt;/h4&gt;&#xA;&lt;p&gt;PgBouncer est un pooler de connexion pour PostgreSQL. Un pooler de connexion permet de maintenir ouvertes des sessions entre lui-même et le serveur, ce qui rend plus rapide l&amp;#8217;ouverture de sessions depuis les clients, une application Web par exemple.&lt;br /&gt;&#xA;PgBouncer permet aussi de mutualiser les sessions dans le serveur, économisant ainsi des ressources. PgBouncer propose plusieurs modes de partage : par requête (default), par transaction ou par session.&lt;/p&gt;&#xA;&lt;h4&gt;Mise en place :&lt;/h4&gt;&#xA;&lt;p&gt;Pour ajouter un bouncer à notre configuration c’est une réalité très simple. Il suffit d’ajouter dans notre fichier postgres.yaml la rubrique proxy :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;proxy:&#xD;&#xA;  pgBouncer:&#xD;&#xA;    image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbouncer:ubi8-1.21-3&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Une fois que vous avez rajouté cela dans la configuration, il n’y a plus qu’à appliquer celle-ci :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; kubectl apply -k kustomize/keycloak &lt;/pre&gt;&#xA;&lt;p&gt;Quand PGO créé un nouveau connexion pooler sur notre instance déployée, il modifier le fichier secrets de l’utilisateur.&lt;br /&gt;&#xA;On voit que plusieurs champs qui concerne pg_bouncer sont apparus. Ils constituent les informations qui vont vous permettre de vous connecter sur votre bouncer nouvellement créé :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;{&#xD;&#xA;    &amp;quot;apiVersion&amp;quot;: &amp;quot;v1&amp;quot;,&#xD;&#xA;    &amp;quot;data&amp;quot;: {&#xD;&#xA;        &amp;quot;dbname&amp;quot;: &amp;quot;cGdjbHVzdGVyMQ==&amp;quot;,&#xD;&#xA;        &amp;quot;host&amp;quot;: &amp;quot;cGdjbHVzdGVyMS1wcmltYXJ5LnBvc3RncmVzLW9wZXJhdG9yLnN2Yw==&amp;quot;,&#xD;&#xA;        &amp;quot;jdbc-uri&amp;quot;: &amp;quot;amRiYzpwb3N0Z3Jlc3FsOi8vcGdjbHVzdGVyMS1wcmltYXJ5LnBvc3RncmVzLW9wZXJhdG9yLnN2Yzo1NDMyL3BnY2x1c3RlcjE/cGFzc3dvcmQ9NXNSaSUzRCU1QmZZbSUzQ2lSSGslMkElNUIlM0VuWGhqaiU3Q1EmdXNlcj1wZ2NsdXN0ZXIx&amp;quot;,&#xD;&#xA;        &amp;quot;password&amp;quot;: &amp;quot;NXNSaT1bZlltPGlSSGsqWz5uWGhqanxR&amp;quot;,&#xD;&#xA;        &amp;quot;pgbouncer-host&amp;quot;: &amp;quot;cGdjbHVzdGVyMS1wZ2JvdW5jZXIucG9zdGdyZXMtb3BlcmF0b3Iuc3Zj&amp;quot;,&#xD;&#xA;        &amp;quot;pgbouncer-jdbc-uri&amp;quot;: &amp;quot;amRiYzpwb3N0Z3Jlc3FsOi8vcGdjbHVzdGVyMS1wZ2JvdW5jZXIucG9zdGdyZXMtb3BlcmF0b3Iuc3ZjOjU0MzIvcGdjbHVzdGVyMT9wYXNzd29yZD01c1JpJTNEJTVCZlltJTNDaVJIayUyQSU1QiUzRW5YaGpqJTdDUSZwcmVwYXJlVGhyZXNob2xkPTAmdXNlcj1wZ2NsdXN0ZXIx&amp;quot;,&#xD;&#xA;        &amp;quot;pgbouncer-port&amp;quot;: &amp;quot;NTQzMg==&amp;quot;,&#xD;&#xA;        &amp;quot;pgbouncer-uri&amp;quot;: &amp;quot;cG9zdGdyZXNxbDovL3BnY2x1c3RlcjE6NXNSaT0lNUJmWW0lM0NpUkhrJTJBJTVCJTNFblhoamolN0NRQHBnY2x1c3RlcjEtcGdib3VuY2VyLnBvc3RncmVzLW9wZXJhdG9yLnN2Yzo1NDMyL3BnY2x1c3RlcjE=&amp;quot;,&#xD;&#xA;        &amp;quot;port&amp;quot;: &amp;quot;NTQzMg==&amp;quot;,&#xD;&#xA;        &amp;quot;uri&amp;quot;: &amp;quot;cG9zdGdyZXNxbDovL3BnY2x1c3RlcjE6NXNSaT0lNUJmWW0lM0NpUkhrJTJBJTVCJTNFblhoamolN0NRQHBnY2x1c3RlcjEtcHJpbWFyeS5wb3N0Z3Jlcy1vcGVyYXRvci5zdmM6NTQzMi9wZ2NsdXN0ZXIx&amp;quot;,&#xD;&#xA;        &amp;quot;user&amp;quot;: &amp;quot;cGdjbHVzdGVyMQ==&amp;quot;,&#xD;&#xA;        &amp;quot;verifier&amp;quot;: &amp;quot;U0NSQU0tU0hBLTI1NiQ0MDk2OlgyQ3NQRU1FZjh3QkVlc05McDFJTkE9PSRKcDhKakl5Q0o1ZEpFRVhia1ptUERTNE5rR3d0V00rczdrMElsQmx0YkpvPTpEaHg3VzNCOE5vNDRYSHJ1Qm1RdENMQW9jNEtnSUZQa2dIeStUMkVWUUowPQ==&amp;quot;&#xD;&#xA;    },&#xD;&#xA;    &amp;quot;kind&amp;quot;: &amp;quot;Secret&amp;quot;,&#xD;&#xA;    &amp;quot;metadata&amp;quot;: {&#xD;&#xA;        &amp;quot;creationTimestamp&amp;quot;: &amp;quot;2024-04-09T16:37:36Z&amp;quot;,&#xD;&#xA;        &amp;quot;labels&amp;quot;: {&#xD;&#xA;            &amp;quot;postgres-operator.crunchydata.com/cluster&amp;quot;: &amp;quot;pgcluster1&amp;quot;,&#xD;&#xA;            &amp;quot;postgres-operator.crunchydata.com/pguser&amp;quot;: &amp;quot;pgcluster1&amp;quot;,&#xD;&#xA;            &amp;quot;postgres-operator.crunchydata.com/role&amp;quot;: &amp;quot;pguser&amp;quot;&#xD;&#xA;        },&#xD;&#xA;        &amp;quot;name&amp;quot;: &amp;quot;pgcluster1-pguser-pgcluster1&amp;quot;,&#xD;&#xA;        &amp;quot;namespace&amp;quot;: &amp;quot;postgres-operator&amp;quot;,&#xD;&#xA;        &amp;quot;ownerReferences&amp;quot;: [&#xD;&#xA;            {&#xD;&#xA;                &amp;quot;apiVersion&amp;quot;: &amp;quot;postgres-operator.crunchydata.com/v1beta1&amp;quot;,&#xD;&#xA;                &amp;quot;blockOwnerDeletion&amp;quot;: true,&#xD;&#xA;                &amp;quot;controller&amp;quot;: true,&#xD;&#xA;                &amp;quot;kind&amp;quot;: &amp;quot;PostgresCluster&amp;quot;,&#xD;&#xA;                &amp;quot;name&amp;quot;: &amp;quot;pgcluster1&amp;quot;,&#xD;&#xA;                &amp;quot;uid&amp;quot;: &amp;quot;7260b882-116f-4b02-b51a-18d4fe3a8038&amp;quot;&#xD;&#xA;            }&#xD;&#xA;        ],&#xD;&#xA;        &amp;quot;resourceVersion&amp;quot;: &amp;quot;9495&amp;quot;,&#xD;&#xA;        &amp;quot;uid&amp;quot;: &amp;quot;1fbdf1d2-48ea-4a45-b7d6-01248317dbee&amp;quot;&#xD;&#xA;    },&#xD;&#xA;    &amp;quot;type&amp;quot;: &amp;quot;Opaque&amp;quot;&#xD;&#xA;}&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Pour se connecter à notre pgbouncer, il suffit d’utiliser les informations fournies par le fichier de secret à la place de nos infos de connexion habituelles, et cela nous permet d’accéder directement au bouncer et non plus à l’instance elle-même.&lt;/p&gt;&#xA;&lt;p&gt;Cette connexion peut être facilement modifiée en utilisant la documentation de pgbouncer afin de pouvoir configurer à notre guise notre pgbouncer. Un exemple de configuration qu’on pourrais rencontrer serait :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;  proxy:&#xD;&#xA;    pgBouncer:&#xD;&#xA;      image: {{.Values.image.pgBouncer }}&#xD;&#xA;      config:&#xD;&#xA;        global:&#xD;&#xA;          default_pool_size: &amp;quot;100&amp;quot;&#xD;&#xA;          max_client_conn: &amp;quot;10000&amp;quot;&#xD;&#xA;          pool_mode: transaction&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Pour cet exemple on voit qu’on a définit un nombre de client maximum, la taille du pool à 100 et un mode transaction pour notre pool.&lt;/p&gt;&#xA;&lt;h3&gt;PGO et Prometheus&lt;/h3&gt;&#xA;&lt;h4&gt;Utilité :&lt;/h4&gt;&#xA;&lt;p&gt;Prometheus est une trousse à outils de surveillance et d&amp;#8217;alerte des systèmes en open source.&lt;br /&gt;&#xA;Prometheus collecte et stocke ses métriques sous forme de données de séries temporelles, c&amp;#8217;est-à-dire que les informations de métriques sont stockées avec le timestamp auquel elles ont été enregistrées, aux côtés de paires clé-valeur optionnelles appelées labels.&lt;br /&gt;&#xA;&amp;#8211; Un modèle de données multidimensionnel avec des données de séries temporelles identifiées par le nom de la métrique et des paires clé-valeur&lt;br /&gt;&#xA;&amp;#8211; PromQL, un langage de requête flexible pour exploiter cette dimensionnalité&lt;br /&gt;&#xA;&amp;#8211; Aucune dépendance sur le stockage distribué ; les nœuds de serveur individuels sont autonomes&lt;br /&gt;&#xA;&amp;#8211; La collecte de séries temporelles se fait via un modèle de tirage sur HTTP&lt;br /&gt;&#xA;&amp;#8211; La poussée de séries temporelles est prise en charge via une passerelle intermédiaire&lt;br /&gt;&#xA;&amp;#8211; Les cibles sont découvertes via la découverte de service ou la configuration statique&lt;br /&gt;&#xA;&amp;#8211; Prise en charge de plusieurs modes de graphiques et de tableaux de bord&lt;/p&gt;&#xA;&lt;h4&gt;Mise en place :&lt;/h4&gt;&#xA;&lt;p&gt;Pour pouvoir mettre en place une surveillance pour notre cluster, il est plus simple de télécharger et compléter le modèle fournit dans les exemples de pgo.&lt;br /&gt;&#xA;Ainsi, on peut récupérer les exemples à l’aide de git :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;YOUR_GITHUB_UN=&amp;quot;$YOUR_GITHUB_USERNAME&amp;quot;&#xD;&#xA;git clone --depth 1 &amp;quot;git@github.com:${YOUR_GITHUB_UN}/postgres-operator-examples.git&amp;quot;&#xD;&#xA;cd postgres-operator-examples&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Les différentes configurations se trouvent dans le dossier kustomize/monitoring.&lt;br /&gt;&#xA;Pour activer le monitoring de notre instance, il faut ajouter la balise monitoring à notre fichier postgres.yaml :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;monitoring:&#xD;&#xA;  pgmonitor:&#xD;&#xA;    exporter:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres-exporter:ubi8-5.5.1-0&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Une fois notre configuration modifiée, on l’applique afin que PGO détecte les changements et configure tout seul l’exporter pour qu’il puisse se connecter à nos bases de données et récupérer les métriques.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;kubectl apply -k kustomize/postgres&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il faut ensuite appliquer la configuration de base de pgmonitor pour qu’il créé lui-même les fichiers de configuration pour prometheus (il le fera en même temps pour Grafana et Alertmanager qui sont deux autres outils de surveillance). Pour cela on applique le kustomize présent dans le dossier monitoring :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$kubectl apply -k kustomize\postgres&#xD;&#xA;postgrescluster.postgres-operator.crunchydata.com/pgcluster1 configured&#xD;&#xA;$kubectl apply -k kustomize\monitoring&#xD;&#xA;serviceaccount/alertmanager created&#xD;&#xA;serviceaccount/grafana created&#xD;&#xA;serviceaccount/prometheus created&#xD;&#xA;clusterrole.rbac.authorization.k8s.io/prometheus created&#xD;&#xA;clusterrolebinding.rbac.authorization.k8s.io/prometheus created&#xD;&#xA;configmap/alert-rules-config created&#xD;&#xA;configmap/alertmanager-config created&#xD;&#xA;configmap/crunchy-prometheus created&#xD;&#xA;configmap/grafana-dashboards created&#xD;&#xA;configmap/grafana-datasources created&#xD;&#xA;secret/grafana-admin created&#xD;&#xA;service/crunchy-alertmanager created&#xD;&#xA;service/crunchy-grafana created&#xD;&#xA;service/crunchy-prometheus created&#xD;&#xA;persistentvolumeclaim/alertmanagerdata created&#xD;&#xA;persistentvolumeclaim/grafanadata created&#xD;&#xA;persistentvolumeclaim/prometheusdata created&#xD;&#xA;deployment.apps/crunchy-alertmanager created&#xD;&#xA;deployment.apps/crunchy-grafana created&#xD;&#xA;deployment.apps/crunchy-prometheus created&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Nos services ont été correctement déployés, il ne nous reste plus qu’à utiliser celui qui nous intéresse, ici service/crunchy-prometheus et lui indiquer de commencer à envoyer les informations sur notre prometheus :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$kubectl -n postgres-operator port-forward service/crunchy-prometheus 9090:9090&#xD;&#xA;Forwarding from 127.0.0.1:9090 -&amp;gt; 9090&#xD;&#xA;Forwarding from [::1]:9090 -&amp;gt; 9090&#xD;&#xA;Handling connection for 9090&#xD;&#xA;Handling connection for 9090&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Afin d’accéder à notre service prometheus, il ne nous reste plus qu’à se connecter avec l’adresse de notre machine, sur le port 9090 préalablement ouvert, pour voir apparaitre le dashboard de prometheus :&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image2.jpg&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-medium wp-image-10567&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image2-300x66.jpg&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;66&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image2-300x66.jpg 300w, https://blog.capdata.fr/wp-content/uploads/2024/05/Image2-1024x226.jpg 1024w, https://blog.capdata.fr/wp-content/uploads/2024/05/Image2-768x170.jpg 768w, https://blog.capdata.fr/wp-content/uploads/2024/05/Image2.jpg 1386w&#34; sizes=&#34;auto, (max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3&gt;PGO Client :&lt;/h3&gt;&#xA;&lt;h4&gt;Utilité :&lt;/h4&gt;&#xA;&lt;p&gt;Pour pouvoir gérer plus facilement le cluster créé par PGO, CrunchyData à développé une surcouche à kubectl qui permet de faciliter les commandes que nous pouvons réaliser sur le cluster.&lt;br /&gt;&#xA;Cela permet de ne pas avoir à taper les longues lignes de commandes qui permettent par exemple de démarrer les sauvegardes unitaires.&lt;/p&gt;&#xA;&lt;h4&gt;Mise en place :&lt;/h4&gt;&#xA;&lt;p&gt;Pour pouvoir installer cette surcouche, il faut télécharger la version qui correspond au système d’exploitation à partir du GIT de pgo client :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;# wget https://github.com/CrunchyData/postgres-operator-client/releases/download/v0.4.1/kubectl-pgo-linux-arm64&#xD;&#xA;--2024-04-11 12:07:45--  https://github.com/CrunchyData/postgres-operator-client/releases/download/v0.4.1/kubectl-pgo-linux-arm64&#xD;&#xA;Resolving github.com (github.com)... 140.82.121.4&#xD;&#xA;Connecting to github.com (github.com)|140.82.121.4|:443... connected.&#xD;&#xA;HTTP request sent, awaiting response... 302 Found&#xD;&#xA;Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...&#xD;&#xA;Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.&#xD;&#xA;HTTP request sent, awaiting response... 200 OK&#xD;&#xA;Length: 47895849 (46M) [application/octet-stream]&#xD;&#xA;Saving to: ‘kubectl-pgo-linux-arm64’&#xD;&#xA;&#xD;&#xA;kubectl-pgo-linux-arm64                                     100%[========================================================================================================================================&amp;gt;]  45.68M  --.-KB/s    in 0.1s&#xD;&#xA;&#xD;&#xA;2024-04-11 12:07:45 (373 MB/s) - ‘kubectl-pgo-linux-arm64’ saved [47895849/47895849]&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;On renome le fichier téléchargé en kubectl-pgo et on le déplace dans nos bin pour pouvoir les utiliser :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;# mv kubectl-pgo-linux-arm64 kubectl-pgo&#xD;&#xA;# sudo mv kubectl-pgo /usr/local/bin/kubectl-pgo&#xD;&#xA;# sudo chmod +x /usr/local/bin/kubectl-pgo&#xD;&#xA;Une fois que ces actions sont réalisées, on peut tester le fonctionnement :&#xD;&#xA;# kubectl pgo version&#xD;&#xA;Client Version: v0.4.1&#xD;&#xA;Operator Version: v5.5.1&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Les commandes disponibles avec cette extension sont les suivantes :&lt;br /&gt;&#xA;&amp;#8211; backup : Backup cluster&lt;br /&gt;&#xA;&amp;#8211; create : Create a resource&lt;br /&gt;&#xA;&amp;#8211; delete : Delete a resource&lt;br /&gt;&#xA;&amp;#8211; help : Help about any command&lt;br /&gt;&#xA;&amp;#8211; restore : Restore cluster&lt;br /&gt;&#xA;&amp;#8211; show Show : PostgresCluster details&lt;br /&gt;&#xA;&amp;#8211; start : Start cluster&lt;br /&gt;&#xA;&amp;#8211; stop : Stop cluster&lt;br /&gt;&#xA;&amp;#8211; support : Crunchy Support commands for PGO&lt;br /&gt;&#xA;&amp;#8211; version : PGO client&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pgo-operateurs-kubernetes-pour-postgresql-la-suite/&#34; rel=&#34;bookmark&#34; title=&#34;6 juin 2023&#34;&gt;PGO : opérateurs kubernetes pour PostgreSQL, la suite !&lt;/a&gt; (David Baffaleuf) [ContainerDevopsPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;26 avril 2023&#34;&gt;Kubegres : l&amp;#8217;opérateur Kubernetes clé en main pour PostgreSQL&lt;/a&gt; (David Baffaleuf) [ContainerDevopsPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/&#34; rel=&#34;bookmark&#34; title=&#34;29 mars 2023&#34;&gt;PostgreSQL sur la solution Kubernetes locale Minikube&lt;/a&gt; (Emmanuel RAMI) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-comparatif-entre-barman-et-pgbackrest/&#34; rel=&#34;bookmark&#34; title=&#34;4 février 2020&#34;&gt;PostgreSQL : Comparatif entre Barman et pgBackRest&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/sauvegardes-sql-server-dans-un-azure-blob-storage/&#34; rel=&#34;bookmark&#34; title=&#34;21 août 2018&#34;&gt;Sauvegardes SQL Server dans un Azure Blob Storage&lt;/a&gt; (Capdata team) [AzureSQL Server]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 3.377 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&amp;#038;title=PGO%20%3A%20la%20suite&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PGO%20%3A%20la%20suite&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pgo-la-suite/&#34;&gt;PGO : la suite&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/pgo-la-suite/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;La gestion efficace des clusters PostgreSQL dans un environnement Kubernetes est un défi complexe auquel sont confrontées de nombreuses entreprises aujourd&amp;#8217;hui. PGO offre une solution déclarative qui automatise la gestion des clusters PostgreSQL, simplifiant ainsi le déploiement, la mise à&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/pgo-la-suite/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pgo-la-suite/&#34;&gt;PGO : la suite&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>pg_recursively_delete : Simplifier les suppressions récursives</title>
    <updated>2024-04-03T13:11:08Z</updated>
    <id>tag:blog.capdata.fr,2024-04-03:/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&amp;#038;title=pg_recursively_delete%20%3A%20Simplifier%20les%20suppressions%20r%C3%A9cursives&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=pg_recursively_delete%20%3A%20Simplifier%20les%20suppressions%20r%C3%A9cursives&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;Si vous avez été amené au fil de votre carrière à manipuler de gros volumes de données contenus dans plusieurs tables possédant des références croisées entre elles, dépendantes d&amp;#8217;autres tables, qui elles-mêmes dépendent d&amp;#8217;autres tables, vous savez à quel point il peut être compliqué de remonter l&amp;#8217;intégralité de l&amp;#8217;arbre de dépendance pour supprimer la moindre ligne. Cela peut être long et fastidieux.&lt;/p&gt;&#xA;&lt;p&gt;Vous ne savez pas vraiment ce que vous supprimez, dans quelles tables, et quels impacts cela peut avoir sur votre base de données. Si les dépendances sont nombreuses, il est d&amp;#8217;autant plus compliqué de tout retracer et d&amp;#8217;être sûr à 100 % de ce que votre DELETE va entraîner.&lt;/p&gt;&#xA;&lt;p&gt;Dans cet article, je vais vous présenter rapidement un petit outil sous la forme d&amp;#8217;une extension que je trouve pratique à utiliser dans ce cas de figure. L&amp;#8217;outil s&amp;#8217;appelle pg_recursively_delete, et il permet de tracer avant d&amp;#8217;exécuter l&amp;#8217;ordre de suppression de votre ligne, et d&amp;#8217;avoir une arborescence des différentes données que vous allez impacter.&lt;/p&gt;&#xA;&lt;h2&gt;Installation d&amp;#8217;un moteur et de l&amp;#8217;extension :&lt;/h2&gt;&#xA;&lt;p&gt;Pour cet article, j&amp;#8217;ai choisi d&amp;#8217;utiliser PostgreSQL en version 16 pour tester si l&amp;#8217;extension fonctionnait toujours.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;root:~#sudo apt update &amp;amp;amp;&amp;amp;amp; sudo apt upgrade&#xD;&#xA;root:~#sudo sh -c &#39;echo &amp;quot;deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main&amp;quot; &amp;amp;gt; /etc/apt/sources.list.d/pgdg.list&#39;&#xD;&#xA;root:~#wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -&#xD;&#xA;root:~#sudo apt -y update&#xD;&#xA;root:~#sudo apt -y install postgresql-16&lt;/pre&gt;&#xA;&lt;p&gt;Notre moteur de base de données est installé, à présent il nous faut télécharger les sources de l&amp;#8217;extension, et l&amp;#8217;installer.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;root:~# git clone https://github.com/trlorenz/PG-recursively_delete.git&#xD;&#xA;Cloning into &#39;PG-recursively_delete&#39;...&#xD;&#xA;remote: Enumerating objects: 155, done.&#xD;&#xA;remote: Counting objects: 100% (95/95), done.&#xD;&#xA;remote: Compressing objects: 100% (62/62), done.&#xD;&#xA;remote: Total 155 (delta 41), reused 74 (delta 29), pack-reused 60&#xD;&#xA;Receiving objects: 100% (155/155), 38.55 KiB | 3.21 MiB/s, done.&#xD;&#xA;Resolving deltas: 100% (70/70), done.&#xD;&#xA;root:~# cd PG-recursively_delete/&#xD;&#xA;root:~/PG-recursively_delete# make&#xD;&#xA;cp sql/recursively_delete.sql sql/recursively_delete--0.1.5.sql&#xD;&#xA;root:~/PG-recursively_delete# sudo make install&#xD;&#xA;/bin/mkdir -p &#39;/usr/share/postgresql/16/extension&#39;&#xD;&#xA;/bin/mkdir -p &#39;/usr/share/postgresql/16/extension&#39;&#xD;&#xA;/bin/mkdir -p &#39;/usr/share/doc/postgresql-doc-16/extension&#39;&#xD;&#xA;/usr/bin/install -c -m 644 .//recursively_delete.control &#39;/usr/share/postgresql/16/extension/&#39;&#xD;&#xA;/usr/bin/install -c -m 644 .//sql/recursively_delete--0.1.5.sql  &#39;/usr/share/postgresql/16/extension/&#39;&#xD;&#xA;/usr/bin/install -c -m 644 .//doc/changelog.md &#39;/usr/share/doc/postgresql-doc-16/extension/&#39;&lt;/pre&gt;&#xA;&lt;h2&gt;Mise en place de l&amp;#8217;environnement&lt;/h2&gt;&#xA;&lt;p&gt;Pour illustrer le fonctionnement de l&amp;#8217;extension, je vais utiliser la base de données de démonstration dvdrental. Nous allons donc la télécharger et la charger dans une toute nouvelle base de données que nous aurons créée sur notre instance fraîchement créée :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; postgres:~$ wget https://www.postgresqltutorial.com/wp-content/uploads/2019/05/dvdrental.zip&#xD;&#xA;--2024-03-11 08:34:54--  https://www.postgresqltutorial.com/wp-content/uploads/2019/05/dvdrental.zip&#xD;&#xA;Resolving www.postgresqltutorial.com (www.postgresqltutorial.com)... 104.21.2.174, 172.67.129.129, 2606:4700:3037::6815:2ae, ...&#xD;&#xA;Connecting to www.postgresqltutorial.com (www.postgresqltutorial.com)|104.21.2.174|:443... connected.&#xD;&#xA;HTTP request sent, awaiting response... 200 OK&#xD;&#xA;Length: 550906 (538K) [application/zip]&#xD;&#xA;Saving to: ‘dvdrental.zip’&#xD;&#xA;&#xD;&#xA;dvdrental.zip                                               100%[========================================================================================================================================&amp;gt;] 537.99K  --.-KB/s    in 0.01s&#xD;&#xA;&#xD;&#xA;2024-03-11 08:34:54 (46.0 MB/s) - ‘dvdrental.zip’ saved [550906/550906]  &lt;/pre&gt;&#xA;&lt;p&gt;Une fois téléchargée, on la dezippe :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;postgres:~$ ls -l&#xD;&#xA;total 544&#xD;&#xA;drwxr-xr-x 3 postgres postgres   4096 Mar 11 08:30 16&#xD;&#xA;-rw-rw-r-- 1 postgres postgres 550906 May 12  2019 dvdrental.zip&#xD;&#xA;postgres:~$ unzip dvdrental.zip&#xD;&#xA;Archive:  dvdrental.zip&#xD;&#xA;  inflating: dvdrental.tar&#xD;&#xA;postgres:~$ ls -l&#xD;&#xA;total 3316&#xD;&#xA;drwxr-xr-x 3 postgres postgres    4096 Mar 11 08:30 16&#xD;&#xA;-rw-rw-r-- 1 postgres postgres 2835456 May 12  2019 dvdrental.tar&#xD;&#xA;-rw-rw-r-- 1 postgres postgres  550906 May 12  2019 dvdrental.zip&lt;/pre&gt;&#xA;&lt;p&gt;On créé la base de données pour accueillir nos données, et on charge le fichier de sauvegarde :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;postgres:~$ psql&#xD;&#xA;psql (16.2 (Ubuntu 16.2-1.pgdg22.04+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help. &lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;postgres=# create database dvdrental;&#xD;&#xA;CREATE DATABASE&#xD;&#xA;postgres=# \l&#xD;&#xA;                                                   List of databases&#xD;&#xA;   Name    |  Owner   | Encoding | Locale Provider | Collate |  Ctype  | ICU Locale | ICU Rules |   Access privileges&#xD;&#xA;-----------+----------+----------+-----------------+---------+---------+------------+-----------+-----------------------&#xD;&#xA; dvdrental | postgres | UTF8     | libc            | C.UTF-8 | C.UTF-8 |            |           |&#xD;&#xA; postgres  | postgres | UTF8     | libc            | C.UTF-8 | C.UTF-8 |            |           |&#xD;&#xA; template0 | postgres | UTF8     | libc            | C.UTF-8 | C.UTF-8 |            |           | =c/postgres          +&#xD;&#xA;           |          |          |                 |         |         |            |           | postgres=CTc/postgres&#xD;&#xA; template1 | postgres | UTF8     | libc            | C.UTF-8 | C.UTF-8 |            |           | =c/postgres          +&#xD;&#xA;           |          |          |                 |         |         |            |           | postgres=CTc/postgres&#xD;&#xA;(4 rows)&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;postgres:~$ pg_restore -U postgres -d dvdrental dvdrental.tar&lt;/pre&gt;&#xA;&lt;p&gt;Une fois que c&amp;#8217;est fait, on peut se connecter pour vérifier que tout a bien été chargé :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;postgres:~$ psql&#xD;&#xA;psql (16.2 (Ubuntu 16.2-1.pgdg22.04+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;postgres=# \c dvdrental&#xD;&#xA;You are now connected to database &amp;quot;dvdrental&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;dvdrental=# \dt&#xD;&#xA;             List of relations&#xD;&#xA; Schema |     Name      | Type  |  Owner&#xD;&#xA;--------+---------------+-------+----------&#xD;&#xA; public | actor         | table | postgres&#xD;&#xA; public | address       | table | postgres&#xD;&#xA; public | category      | table | postgres&#xD;&#xA; public | city          | table | postgres&#xD;&#xA; public | country       | table | postgres&#xD;&#xA; public | customer      | table | postgres&#xD;&#xA; public | film          | table | postgres&#xD;&#xA; public | film_actor    | table | postgres&#xD;&#xA; public | film_category | table | postgres&#xD;&#xA; public | inventory     | table | postgres&#xD;&#xA; public | language      | table | postgres&#xD;&#xA; public | payment       | table | postgres&#xD;&#xA; public | rental        | table | postgres&#xD;&#xA; public | staff         | table | postgres&#xD;&#xA; public | store         | table | postgres&#xD;&#xA;(15 rows)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h2&gt;L&amp;#8217;extension :&lt;/h2&gt;&#xA;&lt;p&gt;Pour tester l&amp;#8217;extension, nous allons essayer de supprimer un client de la liste des clients.&lt;br /&gt;&#xA;Le schéma de la base de données dvdrental est le suivant :&lt;br /&gt;&#xA;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2024/03/dvd-rental-sample-database-diagram.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone wp-image-10507&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2024/03/dvd-rental-sample-database-diagram-238x300.png&#34; alt=&#34;&#34; width=&#34;336&#34; height=&#34;424&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2024/03/dvd-rental-sample-database-diagram-238x300.png 238w, https://blog.capdata.fr/wp-content/uploads/2024/03/dvd-rental-sample-database-diagram.png 730w&#34; sizes=&#34;auto, (max-width: 336px) 100vw, 336px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Si l&amp;#8217;on observe attentivement le schéma ci-dessus, en voulant supprimer une donnée de la table customer, cela devrait avoir un impact sur les tables rental et payment qui sont directement liées à la table customer. De plus, ces deux tables sont également liées entre elles, ce qui signifie que supprimer une donnée dans la table rental modifiera nécessairement la table payment.&lt;/p&gt;&#xA;&lt;p&gt;Prenons l&amp;#8217;exemple de la suppression du client numéro 1. Si nous recherchons les dépendances de ce client dans la table rental, nous obtenons 32 lignes associées au customer_id 1 :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt; dvdrental=# select count(*) from rental where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;    32&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Et si nous allons maintenant chercher toutes les occurrences de ce même client dans la table des paiements, nous obtenons :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;dvdrental=# select count(*) from payment where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;    30&#xD;&#xA;(1 row) &lt;/pre&gt;&#xA;&lt;p&gt;À présent, avec l&amp;#8217;extension recursive_delete, nous allons chercher à obtenir le schéma de suppression pour vérifier si les résultats que nous avons trouvés sont corrects :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;dvdrental=# create extension recursively_delete;&#xD;&#xA;CREATE EXTENSION&#xD;&#xA;dvdrental=# \set VERBOSITY terse&#xD;&#xA;dvdrental=# select recursively_delete(&#39;customer&#39;, 1);&#xD;&#xA;INFO:  DAMAGE PREVIEW (recursively_delete v0.1.5)&#xD;&#xA;INFO:&#xD;&#xA;INFO:          1     customer&#xD;&#xA;INFO:         30 r   | payment.[&amp;quot;customer_id&amp;quot;]&#xD;&#xA;INFO:         32 r   | rental.[&amp;quot;customer_id&amp;quot;]&#xD;&#xA;INFO:          ~ n   | | payment.[&amp;quot;rental_id&amp;quot;]&#xD;&#xA;INFO:&#xD;&#xA; recursively_delete&#xD;&#xA;--------------------&#xD;&#xA;                  0&#xD;&#xA;(1 row) &lt;/pre&gt;&#xA;&lt;p&gt;La fonction de suppression de l&amp;#8217;extension fonctionne avec les paramètres suivants :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Le nom de la table en premier paramètre&lt;/li&gt;&#xA;&lt;li&gt;La clause WHERE du DELETE en second paramètre, qui peut être de multiples types (des entiers, des chaînes de caractères, des listes, des UUID&amp;#8230;)&lt;/li&gt;&#xA;&lt;li&gt;Le mode de fonctionnement de l&amp;#8217;extension, par défaut à false, qui indique au programme de ne pas effectuer les suppressions, mais simplement de dresser le schéma. Le passer à true entraînerait les suppressions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Pour interpréter le schéma, voici la composition de chaque nœud :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;La première colonne correspond au nombre de lignes&lt;/li&gt;&#xA;&lt;li&gt;Le type de contraintes qui expliquent l&amp;#8217;implication de la table dans le schéma : &amp;#8216;a&amp;#8217;, &amp;#8216;r&amp;#8217;, &amp;#8216;c&amp;#8217;, &amp;#8216;n&amp;#8217;, ou &amp;#8216;d&amp;#8217; (&amp;#8216;no action&amp;#8217;, &amp;#8216;restrict&amp;#8217;, &amp;#8216;cascade&amp;#8217;, &amp;#8216;set null&amp;#8217;, ou &amp;#8216;set default&amp;#8217;)&lt;/li&gt;&#xA;&lt;li&gt;Un indicateur de si oui ou non le champ en question participe à une référence circulaire.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;En examinant le résultat renvoyé par notre extension, nous constatons que nous obtenons les mêmes résultats : 30 lignes pour payment et 32 lignes pour rental. Nous obtenons également une dernière ligne qui nous indique que payment possède une référence à rental dans sa structure, et qu&amp;#8217;il va lui aussi procéder à des suppressions en fonction du rental_id. Cela pourrait être par exemple le cas où une location effectuée par un client serait payée par un autre.&lt;/p&gt;&#xA;&lt;p&gt;Pour effectuer la suppression, il suffit simplement de préciser true en troisième paramètre.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;dvdrental=# select recursively_delete(&#39;customer&#39;, 1, true);&#xD;&#xA; recursively_delete&#xD;&#xA;--------------------&#xD;&#xA;                  1&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Et à présent, si nous consultons notre table customer, la ligne 1 a disparu, ainsi que toutes les lignes qui la concernent dans d&amp;#8217;autres tables également.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;dvdrental=# select count(*) from customer where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;     0&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA;dvdrental=# select count(*) from rental where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;     0&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA;dvdrental=# select count(*) from payment where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;     0&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Nos lignes ont bel et bien disparu.&lt;/p&gt;&#xA;&lt;p&gt;Cette extension fonctionne également avec les clés primaires composites. Il suffit de préciser entre crochets les deux valeurs de notre clé primaire, et le tour est joué.&lt;/p&gt;&#xA;&lt;p&gt;Pour illustrer davantage le fonctionnement, je vais réaliser une suppression sur la table film. Cette table possède quelques dépendances.&lt;br /&gt;&#xA;Disons que nous souhaitons supprimer les 10 premiers films de notre liste, car ils ne sont plus loués étant trop anciens (plus personne n&amp;#8217;a de magnétoscope pour regarder de bonnes vieilles cassettes !).&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;dvdrental=# select recursively_delete(&#39;film&#39;, (SELECT array_agg(film_id) FROM film  WHERE film_id between 1 and 10));&#xD;&#xA;INFO:  DAMAGE PREVIEW (recursively_delete v0.1.5)&#xD;&#xA;INFO:&#xD;&#xA;INFO:         10     film&#xD;&#xA;INFO:         62 r   | film_actor.[&amp;quot;film_id&amp;quot;]&#xD;&#xA;INFO:         10 r   | film_category.[&amp;quot;film_id&amp;quot;]&#xD;&#xA;INFO:         52 r   | inventory.[&amp;quot;film_id&amp;quot;]&#xD;&#xA;INFO:        165 r   | | rental.[&amp;quot;inventory_id&amp;quot;]&#xD;&#xA;INFO:          ~ n   | | | payment.[&amp;quot;rental_id&amp;quot;]&#xD;&#xA;INFO:&#xD;&#xA; recursively_delete&#xD;&#xA;--------------------&#xD;&#xA;                  0&#xD;&#xA;(1 row)&lt;/pre&gt;&#xA;&lt;p&gt;Nous observons donc que notre suppression de 10 films (dans un array) entraîne la suppression d&amp;#8217;acteurs, de catégories, d&amp;#8217;inventaires, et par extension, de locations et de paiements&lt;/p&gt;&#xA;&lt;h2&gt;Conclusion :&lt;/h2&gt;&#xA;&lt;p&gt;En conclusion, l&amp;#8217;extension pg_recursively_delete offre une solution pratique pour supprimer récursivement des données dans PostgreSQL, simplifiant ainsi les tâches de maintenance et de nettoyage des bases de données. Cependant, malgré ses avantages, cette extension présente certaines limites en termes de performances.&lt;/p&gt;&#xA;&lt;p&gt;L&amp;#8217;une des principales limitations réside dans le fait que la suppression récursive peut entraîner des opérations coûteuses en termes de temps d&amp;#8217;exécution, surtout lorsque les données concernées sont fortement imbriquées ou que la base de données est volumineuse. Les performances peuvent également être affectées lorsque les tables impliquées dans la suppression ont des index complexes ou des contraintes de clés étrangères.&lt;/p&gt;&#xA;&lt;p&gt;De plus, il est crucial de reconnaître les risques associés à la suppression de données ayant de nombreuses dépendances dans une base de données. La suppression inconsidérée de telles données peut entraîner des incohérences dans la base de données, des erreurs d&amp;#8217;intégrité référentielle et même des pertes de données importantes. Il est donc essentiel de procéder avec prudence et de prendre en compte toutes les implications potentielles avant d&amp;#8217;utiliser cette extension.&lt;/p&gt;&#xA;&lt;p&gt;En résumé, bien que l&amp;#8217;extension pg_recursively_delete offre une fonctionnalité utile pour gérer les opérations de suppression récursive dans PostgreSQL, il est essentiel pour les utilisateurs de comprendre ses limites en termes de performances et les risques potentiels associés à la suppression de données avec de nombreuses dépendances. Une utilisation judicieuse et une évaluation minutieuse des scénarios d&amp;#8217;utilisation sont indispensables pour garantir l&amp;#8217;intégrité et la performance de la base de données.&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pg_dirtyread-ou-comment-reparer-facilement-un-delete-sauvage/&#34; rel=&#34;bookmark&#34; title=&#34;27 mars 2024&#34;&gt;pg_dirtyread où comment réparer facilement un delete sauvage&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pyrseas-et-postgresql-comparer-facilement-des-schema-de-base-de-donnees/&#34; rel=&#34;bookmark&#34; title=&#34;3 janvier 2023&#34;&gt;Pyrseas et Postgresql : Comparer facilement des schémas de base de données&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-planifier-une-tache-avec-pg_cron/&#34; rel=&#34;bookmark&#34; title=&#34;24 septembre 2019&#34;&gt;PostgreSQL : planifier une tâche avec pg_cron&lt;/a&gt; (Emmanuel RAMI) [Non classéPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-anonymizer/&#34; rel=&#34;bookmark&#34; title=&#34;7 juillet 2022&#34;&gt;PostgreSQL Anonymizer&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/&#34; rel=&#34;bookmark&#34; title=&#34;19 décembre 2024&#34;&gt;La montée de version en zero-downtime : merci la réplication !&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 2.821 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&amp;#038;title=pg_recursively_delete%20%3A%20Simplifier%20les%20suppressions%20r%C3%A9cursives&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=pg_recursively_delete%20%3A%20Simplifier%20les%20suppressions%20r%C3%A9cursives&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/&#34;&gt;pg_recursively_delete : Simplifier les suppressions récursives&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Si vous avez été amené au fil de votre carrière à manipuler de gros volumes de données contenus dans plusieurs tables possédant des références croisées entre elles, dépendantes d&amp;#8217;autres tables, qui elles-mêmes dépendent d&amp;#8217;autres tables, vous savez à quel point&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/&#34;&gt;pg_recursively_delete : Simplifier les suppressions récursives&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #120</title>
    <updated>2025-02-21T15:20:00Z</updated>
    <id>tag:sebastien.lardiere.net,2025-02-21:/blog/index.php/post/2025/02/21/PostgreSQL-Hebdo-120</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2025/02/21/PostgreSQL-Hebdo-120" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.octo.com/7-things-a-developer-should-know-about-databases&#34;&gt;7 things a developer should know about databases&lt;/a&gt; : de précieux conseils, à lire attentivement et à faire circuler auprès de vos équipes !&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.dalibo.com//2025/02/10/patchs_parallelisations_2.html&#34;&gt;La suite des patchs sur la parallélisation &lt;/a&gt; : Au-delà du fond, qui est intéressant, c’est le point de vue sur le développement de PostgreSQL est mis en évidence, et cela permet de mieux comprendre cet aspect de la communauté PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.loxodata.com/post/pgwatch3/&#34;&gt;pgwatch3&lt;/a&gt; : quelques explications sur la nouvelle version de l&#39;outil de supervision pgwatch ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.twilio.com/en-us/blog/sqlite-postgresql-complicated&#34;&gt;SQLite or PostgreSQL? It&#39;s Complicated!&lt;/a&gt; : comparatif de performances sur de vraies données !&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-174-168-1512-1417-and-1320-released-3018/&#34;&gt;PostgreSQL 17.4, 16.8, 15.12, 14.17, and 13.20 Released!&lt;/a&gt; et &lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-173-167-1511-1416-and-1319-released-3015/&#34;&gt;PostgreSQL 17.3, 16.7, 15.11, 14.16, and 13.19 Released!&lt;/a&gt; : mettez à jour !&#xA;&lt;ul&gt;&#xA;&lt;li&gt;en français : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-4/&#34;&gt;PostgreSQL 17.4 et autres correctifs&lt;/a&gt; et  &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-3/&#34;&gt;PostgreSQL 17.3 et autres correctifs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/end-of-the-road-for-postgresql-streaming-replication/&#34;&gt;End of the road for PostgreSQL streaming replication?&lt;/a&gt; : pourquoi il est difficile de paralléliser le rejeu de la réplication dans une instance Standby ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.crunchydata.com/blog/enhanced-postgres-release-notes&#34;&gt;Enhanced Postgres Release Notes&lt;/a&gt; : très bonne idée, et gros travail : on trouve maintenant un lien vers le commit pour chacune des entrées des notes de publication ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #119</title>
    <updated>2025-01-31T16:16:00Z</updated>
    <id>tag:sebastien.lardiere.net,2025-01-31:/blog/index.php/post/2025/01/31/PostgreSQL-Hebdo-119</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2025/01/31/PostgreSQL-Hebdo-119" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.depesz.com/2024/12/01/sql-best-practices-dont-compare-count-with-0/&#34;&gt;SQL best practices – don’t compare count(*) with 0&lt;/a&gt; : il n&#39;est pas utile de compter quelque chose alors qu&#39;on juste savoir s&#39;il existe ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://raymondtukpe.com/sql-nulls-are-weird.html&#34;&gt;SQL NULLs are Weird!&lt;/a&gt; : maîtriser cet aspect du SQL n&#39;est pas si évident, et pourtant fondamental ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://notso.boringsql.com/posts/deletes-are-difficult/&#34;&gt;DELETEs are difficult&lt;/a&gt;: tout savoir sur l&#39;opération DELETE ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.pgedge.com/blog/understanding-and-reducing-postgresql-replication-lag&#34;&gt;Understanding and Reducing PostgreSQL Replication Lag&lt;/a&gt; : le retard de réplication peut avoir de nombreux impacts, le mesurer et le maitriser est important ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://thebuild.com/blog/2025/01/28/vacuum-index_cleanup-off-considered-harmful/&#34;&gt;VACUUM (INDEX_CLEANUP OFF) Considered Harmful&lt;/a&gt; : attention aux options de commandes qui pourraient paraître intéressantes au premier abord ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.binwang.me/2024-12-02-PostgreSQL-High-Availability-Solutions-Part-1.html&#34;&gt;Jepsen Test on Patroni: A PostgreSQL High Availability Solution&lt;/a&gt; : test très complet de Patroni ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rodoq.medium.com/are-all-your-update-useful-6b8d548085bf&#34;&gt;Are all your UPDATE useful ?&lt;/a&gt; : Vos UPDATE sont-ils toujours utiles ?&lt;/li&gt;&#xA;&lt;li&gt;Le projet PostgreSQL Ecosystem est maintenant public : &lt;a href=&#34;https://www.loxodata.com/post/pg-ecosystem/&#34; title=&#34;https://www.loxodata.com/post/pg-ecosystem/&#34;&gt;https://www.loxodata.com/post/pg-ec...&lt;/a&gt; et &lt;a href=&#34;https://pg-ecosystem.gitlab.io/pg-ecosystem/&#34; title=&#34;https://pg-ecosystem.gitlab.io/pg-ecosystem/&#34;&gt;https://pg-ecosystem.gitlab.io/pg-e...&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #118</title>
    <updated>2024-11-22T16:09:00Z</updated>
    <id>tag:sebastien.lardiere.net,2024-11-22:/blog/index.php/post/2024/11/22/PostgreSQL-Hebdo-118</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2024/11/22/PostgreSQL-Hebdo-118" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pgversions.com/&#34; title=&#34;https://pgversions.com/&#34;&gt;https://pgversions.com/&lt;/a&gt; : outil permettant de connaitre les différences entre une version mineure et l&#39;état actuel de PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pgpedia.info/blog/index.html&#34; title=&#34;https://pgpedia.info/blog/index.html&#34;&gt;https://pgpedia.info/blog/index.htm...&lt;/a&gt; : blog résumant l&#39;activité de développement de PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rhaas.blogspot.com/2024/11/why-pgdump-is-amazing.html&#34;&gt;Why pg_dump Is Amazing&lt;/a&gt; : oui, pg_dump est un bon outil, très utile, qu&#39;il faut maitriser ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://databaserookies.wordpress.com/2024/11/02/plpgsql-how-conditional-expressions-are-evaluated/&#34;&gt;PL/pgSQL Secrets: How Conditional Expressions Are Parsed and Evaluated Under the Hood.&lt;/a&gt; : ou on comprend qu&#39;un IF est en fait un SELECT ;&lt;/li&gt;&#xA;&lt;li&gt;Publication de PostgreSQL 17.2 : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-2/&#34; title=&#34;https://www.loxodata.com/post/postgresql-17-2/&#34;&gt;https://www.loxodata.com/post/postg...&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.crunchydata.com/blog/a-change-to-relresultinfo-a-near-miss-with-postgres-17-1&#34;&gt;A change to ResultRelInfo - A Near Miss with Postgres 17.1&lt;/a&gt; : retour sur un petit couac&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://challahscript.com/what_i_wish_someone_told_me_about_postgres&#34;&gt;What I Wish Someone Told Me About Postgres&lt;/a&gt; : le plein de bonnes idées à retenir ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stormatics.tech/blogs/scenarios-that-trigger-autovacuum-in-postgresql&#34;&gt;Scenarios That Trigger Autovacuum in PostgreSQL&lt;/a&gt; : article assez complet sur le fonctionnement d&#39;autovacuum.&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #117</title>
    <updated>2024-10-31T16:00:00Z</updated>
    <id>tag:sebastien.lardiere.net,2024-10-31:/blog/index.php/post/2024/31/10/PostgreSQL-Hebdo-117</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2024/31/10/PostgreSQL-Hebdo-117" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rhaas.blogspot.com/2024/10/is-pgdump-backup-tool.html&#34;&gt;Is pg_dump a Backup Tool?&lt;/a&gt; : la sauvegarde, et la restauration des données, et en réalité un processus, et non pas juste un problème d&#39;outil. pg_dump est un outil qui peut faire partie du processus de sauvegarde/restauration, et ça peut-être utile pour BACK UP, c&#39;est-à-dire revenir dans un état normal ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-17-released-2936/&#34;&gt;PostgreSQL 17 Released!&lt;/a&gt; : Publication de PostgreSQL 17.0 ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/whats-so-great-about-postgresql-v17/&#34;&gt;What&#39;s so great about PostgreSQL v17?&lt;/a&gt; : aperçu de quelques fonctionnalités de PostgreSQL 17 ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dev.to/lifen/as-rails-developers-why-we-are-excited-about-postgresql-17-27nj&#34;&gt;As Rails developers, why we are excited about PostgreSQL 17 &lt;/a&gt; : PostgreSQL 17 du point de vue d&#39;un développeur Rails ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://notso.boringsql.com/posts/custom-postgresql-extensions-with-rust/&#34;&gt;Custom PostgreSQL extensions with Rust&lt;/a&gt; : comment faire une extension PostgreSQL en Rust ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://danolivo.substack.com/p/7456653e-9716-4e91-ad09-83737784c665&#34;&gt;PostgreSQL &#39;VALUES -&amp;gt; ANY&#39; transformation&lt;/a&gt; : à propos de l&#39;adaptation du Planner aux requêtes des utilisateurs ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://amitkapila16.blogspot.com/2024/09/online-upgrading-logical-and-physical.html?m=1&#34;&gt;Online Upgrading Logical and Physical Replication Nodes&lt;/a&gt; : à propos de la réplication logique lors d&#39;une mise à jour majeure ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.depesz.com/2024/10/29/new-way-to-search-postgresql-documentation/&#34;&gt;New way to search PostgreSQL documentation&lt;/a&gt; : un prompt simple pour rechercher dans la documentation de PostgreSQL, à mettre dans ses bookmarks ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #116</title>
    <updated>2024-09-09T14:06:00Z</updated>
    <id>tag:sebastien.lardiere.net,2024-09-09:/blog/index.php/post/2024/09/09/PostgreSQL-Hebdo-116</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2024/09/09/PostgreSQL-Hebdo-116" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://begriffs.com/posts/2018-03-20-user-defined-order.html&#34;&gt;User-defined Order in SQL&lt;/a&gt; : Ordonner les informations, c&#39;est souvent adopter un certain point de vue, et cette démarche fait partie de la modélisation des données ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mccue.dev/pages/8-16-24-just-use-postgres&#34;&gt;Just use Postgres&lt;/a&gt; : passage en revue des alternatives à PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/do-you-still-need-pgbadger-youre-using-grafana-alicja-kucharczyk-cgfmf&#34;&gt;Do you still need pgBadger if you’re using Grafana?&lt;/a&gt; : Grafana ne remplace pas complètement un rapport pgBadger, dans lequel on trouve de nombreuses informations utiles à la compréhension du fonctionnement d&#39;une instance PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/not-so-good-idea-pipe-syntax-sql-franck-pachot-dx6he/&#34;&gt;&lt;/a&gt; : De la façon dont le language SQL s&#39;écrit, ou pourquoi on manipule des ensembles et non pas des flux ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34; title=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;https://github.com/cybertec-postgre...&lt;/a&gt; la prochaine version de PgWatch poursuit son développement avec la version 3.0 beta4&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dataegret.com/2024/08/handling_cancellation_request/&#34;&gt;Handling Cancellation Request&lt;/a&gt; : Comment annuler correctement une requête, depuis l&#39;application client, vers un cluster PostgreSQL avec le gestionnaire de connexions PgBouncer ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.shayon.dev/post/2024/225/stop-relying-on-if-not-exists-for-concurrent-index-creation-in-postgresql/&#34;&gt;Stop Relying on IF NOT EXISTS for Concurrent Index Creation in PostgreSQL&lt;/a&gt; : à propos d&#39;index invalide et de création conditionelle ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://anyblockers.com/posts/postgres-as-a-search-engine&#34;&gt;Postgres as a search engine&lt;/a&gt; : Peut-on utiliser PostgreSQL comme moteur de recherche ?&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://okbob.blogspot.com/2024/09/how-to-get-info-about-relations-between.html?m=1&#34;&gt;How to get info about relations between system tables?&lt;/a&gt; : à propos des liens internes du catalogue ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-17-rc1-released-2926/&#34;&gt;PostgreSQL 17 RC1 Released!&lt;/a&gt;  (et en français : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-rc1/&#34; title=&#34;https://www.loxodata.com/post/postgresql-17-rc1/&#34;&gt;https://www.loxodata.com/post/postg...&lt;/a&gt;) : la date prévue pour PostgreSQL 17.0 est le 26 septembre !&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/patroni/patroni/blob/master/docs/releases.rst#version-401&#34;&gt;Patroni 4.0&lt;/a&gt; : nouvelle version de l&#39;outil de gestion de la haute disponibilité, avec quelques ruptures de compatibilité ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #115</title>
    <updated>2024-08-09T14:39:00Z</updated>
    <id>tag:sebastien.lardiere.net,2024-08-09:/blog/index.php/post/2024/08/09/PostgreSQL-Hebdo-115</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2024/08/09/PostgreSQL-Hebdo-115" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://swizec.com/blog/why-sql-is-forever/&#34;&gt;Why SQL is Forever&lt;/a&gt; : billet sur la pertinence du SQL et des transactions face aux bases de données « NoSQL », et sur le point de vue de Stonebraker (le créateur de PostgreSQL) à ce sujet ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ubicloud.com/blog/difference-between-running-postgres-for-yourself-and-for-others&#34;&gt;Difference between running Postgres for yourself and for others&lt;/a&gt; : comparaison des modes d&#39;hébergement d&#39;une instance PostgreSQL (du point de vue d&#39;un clouder) ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://proopensource.it/blog/postgresql-connection-poolers&#34;&gt;PostgreSQL Connection Poolers&lt;/a&gt; : court billet sur les gestionnaires de connexions à PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://danolivo.substack.com/p/designing-a-prototype-postgres-plan&#34;&gt;Designing a Prototype: Postgres Plan Freezing&lt;/a&gt; : intéressante démarche à propos de la mise en cache de plan d&#39;exécution de requêtes ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://drew.silcock.dev/blog/how-postgres-stores-data-on-disk/&#34;&gt;How Postgres stores data on disk – this one&#39;s a page turner&lt;/a&gt; : article complet sur la technique de stockage des donnés de PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-164-158-1413-1316-1220-and-17-beta-3-released-2910/&#34;&gt;PostgreSQL 16.4, 15.8, 14.13, 13.16, 12.20, and 17 Beta 3 Released!&lt;/a&gt; (en français : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-16-4/&#34;&gt;PostgreSQL 16.4 et autres correctifs&lt;/a&gt;) : Troisième Bêta pour PostgreSQL 17 ! À vos tests !&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&lt;p&gt;À venir :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Le programme de PgConf Europe 2024, qui a lieu à Athènes, est publié : &lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/&#34; title=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/&#34;&gt;https://www.postgresql.eu/events/pg...&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>Substituer une variable dans un script SQL</title>
    <updated>2024-11-25T08:00:00Z</updated>
    <id>tag:fljd.in,2024-11-25:/2024/11/25/substituer-une-variable-dans-un-script-sql/</id>
    <link href="https://fljd.in/2024/11/25/substituer-une-variable-dans-un-script-sql/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Il est fréquent de vouloir automatiser une tâche répétitive en la scriptant&#xA;rapidement, puis à force d&amp;rsquo;itérations, de l&amp;rsquo;enrichir, voire de l&amp;rsquo;intégrer dans&#xA;la base de code d&amp;rsquo;un projet. À ce jeu, les outils comme SQL*Plus et psql peuvent&#xA;être de puissants alliés et des interpréteurs aussi pertinents que Bash ou&#xA;Python.&lt;/p&gt;&#xA;&lt;p&gt;Dans le cadre des projets de migration que je mène régulièrement, il m&amp;rsquo;arrive de&#xA;tomber sur ces scripts, en grand nombre. Certains ont la particularité de&#xA;proposer des paramètres d&amp;rsquo;entrée, traités par SQL*Plus avec le mécanisme très&#xA;confortable de substitution de variables. Dans cet article, je partage quelques&#xA;astuces pour convertir certains aspects de ces scripts grâce aux fonctionnalités&#xA;équivalentes que l&amp;rsquo;on retrouve sur l&amp;rsquo;outil psql de PostgreSQL.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Poissons et coquillages</title>
    <updated>2024-10-14T08:30:00Z</updated>
    <id>tag:fljd.in,2024-10-14:/2024/10/14/poissons-et-coquillages/</id>
    <link href="https://fljd.in/2024/10/14/poissons-et-coquillages/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;En tant que pur produit académique des années 2010, mon langage de script de prédilection a&#xA;toujours été le Bash (&lt;em&gt;Bourne Again Shell&lt;/em&gt;). Non sans ignorer qu&amp;rsquo;il ait pu en exister d&amp;rsquo;autres, je&#xA;ne me suis jamais vraiment tourné vers d&amp;rsquo;autres shells pour automatiser les tâches du quotidien&#xA;dans mon métier de DBA.&lt;/p&gt;&#xA;&lt;p&gt;Et pour cause, j&amp;rsquo;ai administré des centaines de serveurs de distributions très variées et il&#xA;n&amp;rsquo;était pas bien vu d&amp;rsquo;installer des dépendances systèmes lourdes pour enrichir des scripts Python&#xA;ou Perl. Nous apprenions donc à écrire des scripts portables et universels, compatibles partout&#xA;où nous déposions nos valises.&lt;/p&gt;&#xA;&lt;p&gt;Me suis-je enfermé dans un dogme conservateur, en m&amp;rsquo;interdisant &lt;em&gt;de facto&lt;/em&gt; à me tourner vers des&#xA;shells modernes et bien plus aisés à appréhender ?&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Les types hiérarchiques</title>
    <updated>2024-09-19T11:20:00Z</updated>
    <id>tag:fljd.in,2024-09-19:/2024/09/19/les-types-hierarchiques/</id>
    <link href="https://fljd.in/2024/09/19/les-types-hierarchiques/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bien que la norme SQL définisse un ensemble de règles pour que les systèmes de bases&#xA;de données puissent être interchangeables, il existe de petites singularités dans la&#xA;nature. À ce titre, le type de données &lt;code&gt;hierarchyid&lt;/code&gt; fourni par SQL Server est un&#xA;exemple flagrant. Si vous êtes amené à basculer vers PostgreSQL, deux solutions s&amp;rsquo;offrent&#xA;à vous.&lt;/p&gt;&#xA;&lt;p&gt;Une première et plus simple consiste à lier chaque nœud à son parent à l&amp;rsquo;aide d&amp;rsquo;une nouvelle&#xA;colonne &lt;code&gt;parentid&lt;/code&gt; et d&amp;rsquo;y appliquer une contrainte de clé étrangère. Une autre approche,&#xA;plus complète, consiste à utiliser l&amp;rsquo;extension &lt;code&gt;ltree&lt;/code&gt;. Cet article traite de ce dernier&#xA;cas.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Faire vivre une communauté</title>
    <updated>2024-07-30T09:30:00Z</updated>
    <id>tag:fljd.in,2024-07-30:/2024/07/30/faire-vivre-une-communaute/</id>
    <link href="https://fljd.in/2024/07/30/faire-vivre-une-communaute/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le &lt;a href=&#34;https://pgday.fr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PG Day France&lt;/a&gt; s&amp;rsquo;est tenu les 11 et 12 juin derniers à Lille, ma ville natale.&#xA;Il s&amp;rsquo;agit de l&amp;rsquo;événement de la communauté française de PostgreSQL qui pose ses valises dans une&#xA;ville différente chaque année. L&amp;rsquo;occasion était trop belle pour moi et j&amp;rsquo;y ai rencontré de nombreuses&#xA;personnes venant de toute la France et de ses alentours, pour discuter de PostgreSQL au cours&#xA;de deux jours d&amp;rsquo;ateliers et de conférences.&lt;/p&gt;&#xA;&lt;p&gt;Pour cette édition, j&amp;rsquo;ai eu le plaisir de prendre la parole et de faire un retour d&amp;rsquo;expérience&#xA;sur l&amp;rsquo;animation du groupe Meetup local dont j&amp;rsquo;ai repris les rennes il y a maintenant quatre ans.&#xA;Dans cet article, je souhaite retranscrire les principaux points abordés lors de cette présentation,&#xA;en attendant que la vidéo de la conférence soit mise en ligne.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Un assistant pour copier les données distantes</title>
    <updated>2024-05-28T00:00:00Z</updated>
    <id>tag:fljd.in,2024-05-28:/2024/05/28/un-assistant-pour-copier-les-donnees-distantes/</id>
    <link href="https://fljd.in/2024/05/28/un-assistant-pour-copier-les-donnees-distantes/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lors de la dernière &lt;a href=&#34;https://blog.dalibo.com/2023/12/08/pgsession16_programme.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PGSession 16&lt;/a&gt;, j&amp;rsquo;ai rédigé et animé un &lt;a href=&#34;https://dali.bo/wsfdw_html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;atelier&lt;/a&gt; de&#xA;trois heures au sujet de la migration vers PostgreSQL à l&amp;rsquo;aide des Foreign Data&#xA;Wrappers, ou FDW. Ce fut notamment l&amp;rsquo;occasion de présenter au grand public,&#xA;l&amp;rsquo;extension &lt;a href=&#34;https://github.com/cybertec-postgresql/db_migrator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;db_migrator&lt;/code&gt;&lt;/a&gt; pour laquelle j&amp;rsquo;ai dédié un &lt;a href=&#34;https://fljd.in/2023/07/28/en-route-vers-la-liberte-avec-db_migrator/&#34;&gt;article&lt;/a&gt; sur ce&#xA;blog.&lt;/p&gt;&#xA;&lt;p&gt;Au cours de cet atelier, nous pouvons constater que la copie des données avec&#xA;l&amp;rsquo;extension &lt;code&gt;db_migrator&lt;/code&gt; n&amp;rsquo;est pas parfaitement prise en charge. En effet, bien&#xA;qu&amp;rsquo;il existe une fonction de bas niveau pour répartir sur plusieurs processus le&#xA;transfert table à table, de nombreuses situations devront exiger de rédiger un&#xA;grand nombre de requêtes SQL pour se tirer d&amp;rsquo;affaire. Au cours des mois qui&#xA;suivirent, je me suis attelé à la conception d&amp;rsquo;un &lt;a href=&#34;https://github.com/fljdin/fdw-assistant&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;assistant&lt;/a&gt; écrit en&#xA;PL/pgSQL dont le but est de simplifier la génération de ces requêtes.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>On analyse la nouvelle collation de PostgreSQL 17</title>
    <updated>2024-06-07T11:40:12Z</updated>
    <id>tag:blog-postgresql.verite.pro,2024-06-07:/2024/06/07/pg17-utf8-collation.html</id>
    <link href="https://blog-postgresql.verite.pro/2024/06/07/pg17-utf8-collation.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PostgreSQL 17 est sorti en version bêta le 23 mai dernier, et dans ce billet on&#xA;va détailler une de ses nouveautés: une collation interne gérant l’UTF-8 avec des&#xA;comparaisons de texte en binaire.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Les rapports de bugs de Postgres en 2023</title>
    <updated>2024-01-24T10:23:10Z</updated>
    <id>tag:blog-postgresql.verite.pro,2024-01-24:/2024/01/24/pgsql-bugs-annee-2023.html</id>
    <link href="https://blog-postgresql.verite.pro/2024/01/24/pgsql-bugs-annee-2023.html" rel="alternate"></link>
    <summary type="html">Une revue quantitative des rapports de bugs de Postgres en 2023</summary>
  </entry>
  <entry>
    <title>Classification des caractères avec ICU</title>
    <updated>2023-06-11T14:32:00Z</updated>
    <id>tag:blog-postgresql.verite.pro,2023-06-11:/2023/06/11/caracteres-icu.html</id>
    <link href="https://blog-postgresql.verite.pro/2023/06/11/caracteres-icu.html" rel="alternate"></link>
    <summary type="html">Avec PostgreSQL 16 où ICU devient le fournisseur de collations par défaut, il y a quelques différences sémantiques à anticiper dans la classification des caractères. Cet article en détaille quelques-unes.</summary>
  </entry>
  <entry>
    <title>Isolation Repeatable Read avec PostgreSQL versus MySQL</title>
    <updated>2020-02-10T17:50:00Z</updated>
    <id>tag:blog-postgresql.verite.pro,2020-02-10:/2020/02/10/isolation-postgresql-vs-mysql.html</id>
    <link href="https://blog-postgresql.verite.pro/2020/02/10/isolation-postgresql-vs-mysql.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Les moteurs SQL permettent aux transactions concurrentes d’être&#xA;isolées les unes des autres pour éviter les interférences.&#xA;Cette propriété d’isolation correspond à la lettre I de l’acronyme&#xA;bien connu &lt;a href=&#34;https://fr.wikipedia.org/wiki/Propri%C3%A9t%C3%A9s_ACID&#34;&gt;“ACID”&lt;/a&gt;,&#xA;les autres propriétés étant Atomicité, Cohérence&#xA;(&lt;em&gt;Consistency&lt;/em&gt; en anglais) et Durabilité.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Recherche et remplacement multiple avec plperl</title>
    <updated>2020-01-22T09:05:14Z</updated>
    <id>tag:blog-postgresql.verite.pro,2020-01-22:/2020/01/22/multi-replace.html</id>
    <link href="https://blog-postgresql.verite.pro/2020/01/22/multi-replace.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Remplacer une chaîne par une autre dans une chaîne plus large est simple&#xA;en SQL, avec la fonction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;replace&lt;/code&gt;:&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Les collations non déterministes</title>
    <updated>2019-10-16T16:32:15Z</updated>
    <id>tag:blog-postgresql.verite.pro,2019-10-16:/2019/10/16/collations-non-deterministes.html</id>
    <link href="https://blog-postgresql.verite.pro/2019/10/16/collations-non-deterministes.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Depuis la version 12, les collations de PostgreSQL peuvent être créées&#xA;avec un paramètre nommé &lt;strong&gt;deterministic&lt;/strong&gt;, qui peut être vrai&#xA;ou faux, si bien que les collations  sont maintenant&#xA;soit &lt;strong&gt;déterministes&lt;/strong&gt; (ce qu’elles sont par défaut), soit&#xA;&lt;strong&gt;non déterministes&lt;/strong&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Mesurer facilement la latence I/O avec PostgreSQL 16</title>
    <updated>2023-09-02T16:30:00Z</updated>
    <id>tag:pgphil.ovh,2023-09-02:/traqueur_16_01.php</id>
    <link href="http://pgphil.ovh/traqueur_16_01.php" rel="alternate"></link>
    <summary type="html">Démonstration avec le traqueur d&#39;une nouvelle fonctionnalité PostgreSQL 16 facilitant le suivi des performances et le diagnostic des ralentissements</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>Mettre à jour PostgreSQL pour améliorer les performances</title>
    <updated>2023-05-21T09:00:00Z</updated>
    <id>tag:pgphil.ovh,2023-05-21:/migration_performance_14_15_01.php</id>
    <link href="http://pgphil.ovh/migration_performance_14_15_01.php" rel="alternate"></link>
    <summary type="html">Pagination, ex aequo...obtenez vos résultats triés bien plus rapidement avec PostgreSQL 15</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL inspire les autres SGBD ?</title>
    <updated>2023-04-12T09:00:00Z</updated>
    <id>tag:pgphil.ovh,2023-04-12:/oracle23c_ou_oracle23p_comme_postgresql.php</id>
    <link href="http://pgphil.ovh/oracle23c_ou_oracle23p_comme_postgresql.php" rel="alternate"></link>
    <summary type="html">Oracle 23c ou 23p comme PostgreSQL ?</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>CYCLE</title>
    <updated>2022-12-03T15:00:00Z</updated>
    <id>tag:pgphil.ovh,2022-12-03:/nocycle_15_01.php</id>
    <link href="http://pgphil.ovh/nocycle_15_01.php" rel="alternate"></link>
    <summary type="html">Nouveautés autour des requêtes hiérarchiques avec PostgreSQL 14 et versions supérieures</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>MERGE</title>
    <updated>2022-03-29T17:30:00Z</updated>
    <id>tag:pgphil.ovh,2022-03-29:/upsert_15_devel_01.php</id>
    <link href="http://pgphil.ovh/upsert_15_devel_01.php" rel="alternate"></link>
    <summary type="html">Introduction de la commande MERGE par PostgreSQL 15</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>Limitations du planner (optimiseur) de PostgreSQL</title>
    <updated>2022-03-06T18:45:00Z</updated>
    <id>tag:pgphil.ovh,2022-03-06:/limitations_planner_13_01.php</id>
    <link href="http://pgphil.ovh/limitations_planner_13_01.php" rel="alternate"></link>
    <summary type="html">Est-il toujours possible en 2022 de faire trébucher l&#39;optimiseur statistique de PostgreSQL ? Comment y remédier ?</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>[Infographie] PostgreSQL</title>
    <updated>2021-02-11T11:23:13Z</updated>
    <id>tag:blog.atolcd.com,2021-02-11:/infographie-postgresql/</id>
    <content type="html">&#xA;&lt;p&gt;PostgreSQL est un SGBD que nous affectionnons particulièrement chez Atol CD ! Retrouvez dans cette infographie quelques caractéristiques techniques, des chiffres-clé, son histoire mais aussi pourquoi nous l&amp;rsquo;aimons et notre Top5 des fonctionnalités côté développement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-gallery columns-1 is-cropped wp-block-gallery-1 is-layout-flex wp-block-gallery-is-layout-flex&#34;&gt;&lt;ul class=&#34;blocks-gallery-grid&#34;&gt;&lt;li class=&#34;blocks-gallery-item&#34;&gt;&lt;figure&gt;&lt;img fetchpriority=&#34;high&#34; decoding=&#34;async&#34; width=&#34;866&#34; height=&#34;2560&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-scaled.jpg&#34; alt=&#34;&#34; data-id=&#34;4477&#34; data-full-url=&#34;https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-scaled.jpg&#34; data-link=&#34;https://blog.atolcd.com/infographie-postgresql/infographie_postgresql/&#34; class=&#34;wp-image-4477&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-scaled.jpg 866w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-101x300.jpg 101w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-346x1024.jpg 346w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-768x2271.jpg 768w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-520x1536.jpg 520w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-693x2048.jpg 693w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-600x1774.jpg 600w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-945x2794.jpg 945w&#34; sizes=&#34;(max-width: 866px) 100vw, 866px&#34; /&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/infographie-postgresql/&#34;&gt;[Infographie] PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/infographie-postgresql/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=infographie-postgresql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PostgreSQL est un SGBD que nous affectionnons particulièrement chez Atol CD ! Retrouvez dans cette infographie quelques caractéristiques techniques, des chiffres-clé, son histoire mais aussi pourquoi nous l&amp;#8217;aimons et notre Top5 des fonctionnalités côté développement.&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/infographie-postgresql/&#34;&gt;[Infographie] PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Sortie de PostgreSQL 13</title>
    <updated>2020-09-24T05:54:57Z</updated>
    <id>tag:blog.atolcd.com,2020-09-24:/sortie-de-postgresql-13/</id>
    <content type="html">&#xA;&lt;p&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;&lt;img decoding=&#34;async&#34; class=&#34;alignnone size-full wp-image-4130&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2020/09/pg13.jpg&#34; alt=&#34;&#34; width=&#34;960&#34; height=&#34;540&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2020/09/pg13.jpg 960w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-300x169.jpg 300w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-768x432.jpg 768w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-600x338.jpg 600w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-945x532.jpg 945w&#34; sizes=&#34;(max-width: 960px) 100vw, 960px&#34; /&gt;Malgré des actualités plutôt moroses au Botswana concernant nos chers éléphants, il y en a un qui se porte bien et est encore plus fort à savoir PostgreSQL qui sort en version 13 stable ce jeudi 24 septembre 2020. &lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;Après seulement 3 versions Bêta et une RC le voilà dans les starting blocks pour débarquer sur vos serveurs ! Et comme à chaque nouvelle version son&lt;/span&gt; &lt;span style=&#34;font-weight: 400;&#34;&gt;lot de nouveautés&lt;/span&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;Un petit rappel qui peut parfois éviter bien des catastrophes, si vous avez prévu de migrer vers PostgreSQL 13, vous devriez jeter un oeil sur &lt;a href=&#34;https://www.postgresql.org/docs/13/release-13.html#id-1.11.6.5.4&#34;&gt;les potentielles incompatibilités avec les précédentes versions&lt;/a&gt;  (et aussi sur les versions intermédiaires si vous faite un gap de plusieurs versions d&amp;rsquo;un coup), il est toujours préférable d&amp;rsquo;identifier ces légers changements en amont plutôt qu&amp;rsquo;une fois en production. Mais rassurez-vous, dans cette version pas de quoi freiner significativement une migration.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;h1&gt;Partitionnement&lt;/h1&gt;&#xA;&lt;p&gt;Des améliorations sont ajoutées sur le partitionnement de tables, tant au niveau performance avec l&amp;rsquo;ajout de cas où une jointure directe entre partition peut être utilisée dans une requête, mais aussi de fonctionnalités telles que  la gestion des triggers avec le support de la clause BEFORE ou bien encore la réplication logique sans avoir besoin de publier chaque partition.&lt;/p&gt;&#xA;&lt;h1&gt;Index&lt;/h1&gt;&#xA;&lt;p&gt;Là aussi des améliorations de performances mais aussi des gains d&amp;rsquo;espace disque sur les index B-tree surtout pour ceux contenant des doublons, mais si vous passez par un pg_upgrade il voudra passer par un reindex pour bénéficier de ces changements.&lt;/p&gt;&#xA;&lt;h1&gt;Planificateur&lt;/h1&gt;&#xA;&lt;p&gt;Le planificateur de requête PostgreSQL a lui aussi eu le droit à quelques améliorations notamment au niveau des statistiques ce qui peut améliorer les plans d&amp;rsquo;exécution et donc les performances.&lt;/p&gt;&#xA;&lt;h1&gt;Performance générale&lt;/h1&gt;&#xA;&lt;p&gt;Les performances ne sont pas en reste dans cette nouvelle version, avec l&amp;rsquo;ajout du &lt;span style=&#34;font-weight: 400;&#34;&gt;tri incrémentiel ce qui accélère le tri des données dans certains cas,  sur les agrégations de hachage qui peuvent désormais utiliser le stockage sur disque dans le cadre de grands ensembles d&amp;rsquo;agrégation, sur la conversion de type entier vers texte.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;h1&gt;Vues système&lt;/h1&gt;&#xA;&lt;p&gt;De nouvelles vues système font leur apparition :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/progress-reporting.html#BASEBACKUP-PROGRESS-REPORTING&#34;&gt;pg_stat_progress_basebackup &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/progress-reporting.html#ANALYZE-PROGRESS-REPORTING&#34;&gt;pg_stat_progress_analyze &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/view-pg-shmem-allocations.html&#34;&gt;pg_shmem_allocations &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/monitoring-stats.html#MONITORING-PG-STAT-SLRU-VIEW&#34;&gt;pg_stat_slru&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;la vue &lt;a href=&#34;https://www.postgresql.org/docs/13/monitoring-stats.html#PG-STAT-ACTIVITY-VIEW&#34;&gt;pg_stat_activity&lt;/a&gt; se voit elle ajoutée une colonne leader_pid ce qui permet de retrouver rapidement tous les processus impliqués dans une requête parallèle.&lt;/p&gt;&#xA;&lt;h1&gt;Fonctionnalités&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ajout de la fonctionnalité &lt;a href=&#34;https://www.postgresql.org/docs/13/sql-select.html#SQL-LIMIT&#34;&gt;FETCH FIRST WITH TIES&lt;/a&gt; (vous trouverez &lt;a href=&#34;http://pgphil.ovh/topn_13_beta_01.php&#34;&gt;ici&lt;/a&gt; un exemple)&lt;/li&gt;&#xA;&lt;li&gt;Ajout de la fonction gen_random_uuid() utilisable sans activer d’extensions&lt;/li&gt;&#xA;&lt;li&gt;Ajout de la possibilité de renommer une colonne d&amp;rsquo;une vue :&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;ALTER VIEW [ IF EXISTS ] name RENAME [ COLUMN ] column_name TO new_column_name&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de la fonction .datetime() dans les jsonpath pour convertir automatique une chaîne en date ou horodatage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1&gt;Client psql&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de nouvelles commandes pour afficher la description de classe d&amp;rsquo;opérateur et famille d&amp;rsquo;opérateur&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a class=&#34;link&#34; title=&#34;Meta-Commands&#34; href=&#34;https://www.postgresql.org/docs/13/app-psql.html#APP-PSQL-META-COMMANDS&#34;&gt;&lt;code class=&#34;literal&#34;&gt;\dAc&lt;/code&gt;&lt;/a&gt;, &lt;code class=&#34;literal&#34;&gt;\dAf&lt;/code&gt;, &lt;code class=&#34;literal&#34;&gt;\dAo&lt;/code&gt;, et &lt;code class=&#34;literal&#34;&gt;\dAp&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Ajout du statut de la transaction dans le prompt &lt;br /&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;* dans une transaction&lt;/li&gt;&#xA;&lt;li&gt;! dans un échec de transaction&lt;/li&gt;&#xA;&lt;li&gt;? pour un état indéterminé de la transaction&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1&gt;Administration&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de la capacité de la commande VACUUM à traiter des index en parallèle&lt;/li&gt;&#xA;&lt;li&gt;la commande reindexdb peut aussi paralléliser les tâches&lt;/li&gt;&#xA;&lt;li&gt;introduction de la notion de « trusted extension » qui permet à un super utilisateur de définir les extensions qu’un utilisateur a le droit d&amp;rsquo;installer dans sa base de données en ayant le droit CREATE.&lt;/li&gt;&#xA;&lt;li&gt;Ajout pour pg_dump de l&amp;rsquo;option &amp;#8211;include-foreign-data pour inclure dans la sauvegarde les données de serveurs distants&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La liste des nouveautés dans cette version est grande, toutes les nouveautés n&amp;rsquo;ont pas été abordées mais vous pouvez bien sur les retrouver dans la &lt;a href=&#34;https://www.postgresql.org/docs/13/release-13.html&#34;&gt;note de version&lt;/a&gt;. Le focus a surtout été fait sur le côté utilisateur plutôt qu&amp;rsquo;administrateur de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-13/&#34;&gt;Sortie de PostgreSQL 13&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/sortie-de-postgresql-13/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sortie-de-postgresql-13" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Malgré des actualités plutôt moroses au Botswana concernant nos chers éléphants, il y en a un qui se porte bien et est encore plus fort à savoir PostgreSQL qui sort en version 13 stable ce jeudi 24 septembre 2020.  Après... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-13/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-13/&#34;&gt;Sortie de PostgreSQL 13&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Sortie de PostgreSQL 11</title>
    <updated>2018-10-19T13:12:39Z</updated>
    <id>tag:blog.atolcd.com,2018-10-19:/sortie-de-postgresql-11/</id>
    <content type="html">&lt;p&gt;Après seulement une release candidate (mais auparavant 4 version bêta), PostgreSQL 11 vient de sortir!!!! Et comme à chaque nouvelle version son lot de nouveautés que nous allons essayer de passer rapidement en revue.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-3169&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11.jpg&#34; alt=&#34;&#34; width=&#34;826&#34; height=&#34;540&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11.jpg 826w, https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11-300x196.jpg 300w, https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11-768x502.jpg 768w, https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11-600x392.jpg 600w&#34; sizes=&#34;(max-width: 826px) 100vw, 826px&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Amélioration de la parallélisation&lt;/h2&gt;&#xA;&lt;p&gt;Quoi de mieux que de commencer le tour des nouveautés par un sujet que l&amp;rsquo;on a abordé lors du &lt;a href=&#34;https://blog.atolcd.com/conference-la-parallelisation-au-service-de-loptimisation/&#34;&gt;PG Day France 2018&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 11 va encore plus loin dans la parallélisation avec :&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Création d&amp;rsquo;index B-tree en parallèle&lt;/li&gt;&#xA;&lt;li&gt;Parallélisation des UNION ALL&lt;/li&gt;&#xA;&lt;li&gt;Amélioration du Parallel hash join (paralléliser le remplissage d’une seule table de hachage, partagée) et parallelized sequential scans&lt;/li&gt;&#xA;&lt;li&gt;Parallélisation sur la création de vue matérialisée et table à partir des résultats d&amp;rsquo;une requête&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE .. AS, SELECT INTO et CREATE MATERIALIZED VIEW.&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout d&amp;rsquo;un paramètre de configuration du serveur « parallel_leader_participation » qui permet de contrôler si le processus leader participe à l&amp;rsquo;exécution des sous plans d&amp;rsquo;exécution&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Amélioration du partitionnement&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;La possibilité de partitionner une table par hashage de clé (en plus des autres)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE hash1 (col1 NUMERIC, col2 VARCHAR(10)) PARTITION BY HASH(col1);&#xD;&#xA;CREATE TABLE hash1a PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 0) ;&#xD;&#xA;CREATE TABLE hash1b PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 1) ;&#xD;&#xA;CREATE TABLE hash1c PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 2) ;&#xD;&#xA;CREATE TABLE hash1d PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 3) ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout possible d&amp;rsquo;une partition par défaut pour les données ne correspondant à aucune partition&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE table1d PARTITION OF table1 DEFAULT;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;La possibilité de créer des clés primaires, clés étrangères, index et triggers qui seront automatiquement applicables sur l&amp;rsquo;ensemble des partitions&lt;/li&gt;&#xA;&lt;li&gt;Support du changement automatique de partition en cas de mise à jour de la clé de partitionnement&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances lors des SELECT sur la lecture des partitions&lt;/li&gt;&#xA;&lt;li&gt;Support des upsert sur les tables partitionnées&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;INSERT  INTO  tablep1 (col1, col2) &#xD;&#xA;VALUES  (100,  &#39;update&#39;) &#xD;&#xA;ON  CONFLICT ON CONSTRAINT tablep1_pkey &#xD;&#xA;DO UPDATE SET col2=&#39;update&#39; ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Gestion des transactions dans les procédures stockées&lt;/h2&gt;&#xA;&lt;p&gt;PostgreSQL 11 introduit la possibilité de créer des procédures (en PL/pgSQL, PL/Perl, PL/Python, et PL/Tcl). Depuis de nombreuses années, il est possible dans PostgreSQL de créer des fonctions et bien ici ça y ressemble fortement, sauf que l&amp;rsquo;on ne retourne pas de résultats et que l&amp;rsquo;on peut gérer les transactions !&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE PROCEDURE transaction_test1()&#xD;&#xA;LANGUAGE plpgsql&#xD;&#xA;AS $$&#xD;&#xA;BEGIN&#xD;&#xA;  FOR i IN 0..9 LOOP&#xD;&#xA;    INSERT INTO table1 (col1) VALUES (i) ;&#xD;&#xA;    IF i % 2 = 0 THEN&#xD;&#xA;      COMMIT;&#xD;&#xA;    ELSE&#xD;&#xA;      ROLLBACK;&#xD;&#xA;    END IF;&#xD;&#xA;  END LOOP;&#xD;&#xA;END;&#xD;&#xA;$$;&lt;/pre&gt;&lt;p&gt;L&amp;rsquo;exécution de ces procédures se fait en utilisant la commande CALL&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CALL transaction_test1();&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Compilation JIT&lt;/h2&gt;&#xA;&lt;p&gt;PostgreSQL 11 introduit le support de la compilation Just-in-Time (JIT) pour optimiser l’exécution de code et d’autres opérations. Utilisant des composants du projet LLVM, l’introduction de JIT dans PostgreSQL accélère les requêtes utilisant des expressions, listes, agrégats, projections, ainsi que certaines opérations internes.&lt;/p&gt;&#xA;&lt;p&gt;Pour pouvoir utiliser la compilation JIT, vous devrez installer la dépendance LLVM puis activer la compilation JIT soit dans le fichier de configuration (jit = on), soit durant votre session en exécutant SET jit = on.&lt;/p&gt;&#xA;&lt;p&gt;La compilation JIT bénéficie surtout aux requêtes de longue durée et limitées par le processeur. Ce seront souvent des requêtes analytiques (OLAP). Pour les requêtes courtes, le surcoût apporté par la compilation JIT sera souvent supérieur au temps qu&amp;rsquo;elle permet de gagner.&lt;/p&gt;&#xA;&lt;h2&gt;Améliorations générales SQL&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Support de toutes les clauses (SQL:2011) dans les fonctions de fenêtrage ce qui permet maintenant l’utilisation de RANGE dans des clauses PRECEDING/FOLLOWING, GROUPS ou d’exclusion&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;WINDOW window_name AS ( &#xD;&#xA;  [ PARTITION BY expression [, ...] ]&#xD;&#xA;  [ ORDER BY expression [ ASC | DESC | USING operator ] [ NULLS { FIRST | LAST } ] [, ...] ]&#xD;&#xA;  [ frame_clause ]&#xD;&#xA;)&#xD;&#xA;&#xD;&#xA;frame_clause :&#xD;&#xA;{ RANGE | ROWS | GROUPS } frame_start [ frame_exclusion ]&#xD;&#xA;{ RANGE | ROWS | GROUPS } BETWEEN frame_start AND frame_end [ frame_exclusion ]&#xD;&#xA;&#xD;&#xA;frame_start / frame_end :&#xD;&#xA;&#xD;&#xA;UNBOUNDED PRECEDING&#xD;&#xA;offset PRECEDING&#xD;&#xA;CURRENT ROW&#xD;&#xA;offset FOLLOWING&#xD;&#xA;UNBOUNDED FOLLOWING&#xD;&#xA;&#xD;&#xA;frame_exclusion :&#xD;&#xA;&#xD;&#xA;EXCLUDE CURRENT ROW&#xD;&#xA;EXCLUDE GROUP&#xD;&#xA;EXCLUDE TIES&#xD;&#xA;EXCLUDE NO OTHERS&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de fonctions de hash sha-2 : sha224(), sha256(), sha384() et sha512()&lt;/li&gt;&#xA;&lt;li&gt;Ajout de fonctions de recherche plein texte : json(b)_to_tsvector() et websearch_to_tsquery()&lt;/li&gt;&#xA;&lt;li&gt;Ajout de l&amp;rsquo;opérateur ^@ identique à LIKE &amp;lsquo;mot%&amp;rsquo; mais plus efficace sur un index b-tree&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;text ^@ text&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Amélioration des index avec l&amp;rsquo;ajout du mot clef INCLUDE, qui permet d&amp;rsquo;indiquer une liste de colonnes qui seront incluses dans l&amp;rsquo;index comme des colonnes non clés. L&amp;rsquo;ajout de colonnes dans la création d&amp;rsquo;index permet alors l&amp;rsquo;utilisation de parcours d&amp;rsquo;index couvrants.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] nom ] ON [ ONLY ] nom_table [ USING méthode ]&#xD;&#xA;    ( { nom_colonne | ( expression ) } [ COLLATE collation ] [ classeop ] [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, ...] )&#xD;&#xA;    [ INCLUDE ( nom_colonne [, ...] ) ]&#xD;&#xA;    [ WITH ( parametre_stockage = valeur [, ... ] ) ]&#xD;&#xA;    [ TABLESPACE nom_espacelogique ]&#xD;&#xA;    [ WHERE prédicat ]&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Amélioration de l’ordre ALTER TABLE .. ADD COLUMN .. DEFAULT .. avec une valeur par défaut non NULL n’a plus besoin de réécrire entièrement la table lors de son exécution, ce qui entraîne une grosse amélioration des performances.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Authentification&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de l&amp;rsquo;authentification LDAP, mais celle ci n&amp;rsquo;est utilisée que pour valider les paires nom d&amp;rsquo;utilisateur/mot de passe. De ce fait, pour pouvoir utiliser LDAP comme méthode d&amp;rsquo;authentification, l&amp;rsquo;utilisateur doit préalablement exister dans la base.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;psql&lt;/h2&gt;&#xA;&lt;p&gt;Le client psql évolue lui aussi :&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout des commandes « quit » et « exit » dans le client psql&amp;#8230; (fini les personnes prisent de panique pour sortir de leur terminal ??? )&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://media.giphy.com/media/xTk9ZBWrma4PIC9y4E/giphy.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de la commande \gdesc pour afficher les noms et types de colonnes du résultat de la requête&lt;/li&gt;&#xA;&lt;li&gt;Ajout de variables pour les erreurs et activités des requêtes ERROR, SQLSTATE, ROW_COUNT, LAST_ERROR_MESSAGE, and LAST_ERROR_SQLSTATE.&lt;/li&gt;&#xA;&lt;li&gt;Ajout de la possibilité de tester l&amp;rsquo;existence d&amp;rsquo;une variable par exemple dans un if&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;\if :{?variable_name}&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Amélioration de la complétion dans l&amp;rsquo;écriture de requêtes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;En dehors de ces nouveautés en terme d&amp;rsquo;utilisation, cette nouvelle version apporte aussi des améliorations de performance et d&amp;rsquo;utilisation de mémoire.&lt;/p&gt;&#xA;&lt;p&gt;Et voilà, nous avons fini notre petit tour rapide des nouveautés de postgreSQL 11, mais ne vous inquiétez pas une version 12 est déjà en préparation pour le troisième trimestre 2019.&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-11/&#34;&gt;Sortie de PostgreSQL 11&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/sortie-de-postgresql-11/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sortie-de-postgresql-11" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Après seulement une release candidate (mais auparavant 4 version bêta), PostgreSQL 11 vient de sortir!!!! Et comme à chaque nouvelle version son lot de nouveautés que nous allons essayer de passer rapidement en revue. Amélioration de la parallélisation Quoi de... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-11/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-11/&#34;&gt;Sortie de PostgreSQL 11&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Pimp My PostgreSQL</title>
    <updated>2018-01-26T11:07:23Z</updated>
    <id>tag:blog.atolcd.com,2018-01-26:/pimp-my-postgresql/</id>
    <content type="html">&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignright wp-image-2934&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2018/01/pimp-my-postgresql.png&#34; alt=&#34;&#34; width=&#34;491&#34; height=&#34;290&#34; /&gt;Une question qui se pose souvent après l&amp;rsquo;installation d&amp;rsquo;une instance postgreSQL, c&amp;rsquo;est comment configurer ce fichier postgresql.conf. Dans le doute souvent, beaucoup de personnes conservent la configuration par défaut, ce qui ne va pas poser vraiment de problème pour une utilisation légère. Mais si on a une instance postgreSQL avec postGIS et des millions d&amp;rsquo;enregistrements, cela va rapidement se trouver problématique si on laisse les valeurs par défaut&amp;#8230;&lt;/p&gt;&#xA;&lt;p&gt;Pour les initiés qui installent régulièrement de nouvelles instances postgreSQL, se plonger dans les plus de 600 lignes du fichier de configuration par défaut ne les effraie pas. Mais on n&amp;rsquo;installe pas forcément tous les jours un nouveau serveur avec des caractéristiques différentes. Il faut donc soit se replonger pour une centième fois dans la documentation de postgres pour se rappeler à notre bonne mémoire les différents paramètres et les valeurs à adapter en fonction de la ram, disque, cpu&amp;#8230;&lt;/p&gt;&#xA;&lt;p&gt;En plus de devoir se rappeler les &lt;strong&gt;paramètres à modifier,&lt;/strong&gt; il faut aussi connaître les &lt;strong&gt;règles de calcul &lt;/strong&gt;pour les valeurs comme par exemple le « effective_cache_size » qui est préconisé à 75% de la ram total du serveur si celui-ci est dédié à postgres.&lt;/p&gt;&#xA;&lt;p&gt;Le but de cet article n&amp;rsquo;est pas de voir ni de détailler tous les paramètres de configuration possibles et inimaginables, mais de voir cela comme un mémo pour les initiés ou de s’interroger sur les &lt;strong&gt;paramètres qui seraient potentiellement à modifier en fonction du serveur&lt;/strong&gt; (et des applications qui l&amp;rsquo;utilisent) si l&amp;rsquo;on ne connait pas l&amp;rsquo;utilisation des paramètres de ce fichier postgresql.conf.&lt;/p&gt;&#xA;&lt;p&gt;Pour cela un petit outil a été conçu par Cybertec, qui permet de renseigner quelques caractéristiques et de voir évoluer en conséquence le fichier postgresql.conf notamment en fonction de la ram du serveur, du nombre de cpu, de la taille de la base&amp;#8230; etc.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-full wp-image-2925&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator.png&#34; alt=&#34;&#34; width=&#34;1005&#34; height=&#34;993&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator.png 1005w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-300x296.png 300w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-768x759.png 768w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-945x934.png 945w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-600x593.png 600w&#34; sizes=&#34;auto, (max-width: 1005px) 100vw, 1005px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cela ne remplace pas une connaissance aguerrie de postgreSQL et de sa configuration mais ça permet de se faire une idée des paramètres à adapter en fonction de son serveur et de ses besoins.&lt;/p&gt;&#xA;&lt;p&gt;Cet outil est disponible en ligne à cette adresse : &lt;a href=&#34;http://pgconfigurator.cybertec.at/&#34;&gt;http://pgconfigurator.cybertec.at/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/pimp-my-postgresql/&#34;&gt;Pimp My PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/pimp-my-postgresql/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pimp-my-postgresql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Une question qui se pose souvent après l&amp;#8217;installation d&amp;#8217;une instance postgreSQL, c&amp;#8217;est comment configurer ce fichier postgresql.conf. Dans le doute souvent, beaucoup de personnes conservent la configuration par défaut, ce qui ne va pas poser vraiment de problème pour une... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/pimp-my-postgresql/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/pimp-my-postgresql/&#34;&gt;Pimp My PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Sortie de PostgreSQL 10</title>
    <updated>2017-10-05T13:28:32Z</updated>
    <id>tag:blog.atolcd.com,2017-10-05:/sortie-de-postgresql-10/</id>
    <content type="html">&lt;p&gt;Aujourd&amp;rsquo;hui, c&amp;rsquo;est la sortie de &lt;strong&gt;PostgreSQL 10&lt;/strong&gt;!!!! Première révolution, la numérotation des versions : on passe de 9.4&amp;#8230;9.6 pour les versions majeures à 10, 11, 12&amp;#8230; Ce point est important car un changement de version majeure implique une migration des données. Une opération beaucoup plus lourde que la seule mise à jour des exécutables !&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-2788&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/10/postgresql-10.jpg&#34; alt=&#34;&#34; width=&#34;558&#34; height=&#34;337&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/10/postgresql-10.jpg 558w, https://blog.atolcd.com/wp-content/uploads/2017/10/postgresql-10-300x181.jpg 300w&#34; sizes=&#34;auto, (max-width: 558px) 100vw, 558px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Voici quelques détails sur cette&lt;strong&gt; nouvelle version 10&lt;/strong&gt; et ce qu&amp;rsquo;elle apporte :&lt;/p&gt;&#xA;&lt;h2&gt;Performance et partitionnement&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Le partitionnement de table est maintenant un attribut de la table :&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE table_name ( ... )&#xD;&#xA;[ PARTITION BY { RANGE | LIST } ( { column_name | ( expression ) }&#xD;&#xA;&#xD;&#xA;CREATE TABLE table_name&#xD;&#xA;PARTITION OF parent_table [ (&#xD;&#xA;) ] FOR VALUES partition_bound_spec&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;PostgreSQL 10 va plus loin dans la parallélisation avec le parallélisme des Index-Only Scan, Index Scan, Bitmap Heap Scan, Merge Join / Gather Merge, Subplan-Related Improvements&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances pour les agrégats et jointures avec &lt;code&gt;postgres_fdw&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances de l&amp;rsquo;analyseur de requête&lt;/li&gt;&#xA;&lt;li&gt;Apparition des statistiques multi-colonnes&lt;/li&gt;&#xA;&lt;li&gt;Amélioration du plan d’exécution des requêtes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Réplication et scalabilité&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Réplication logique : légère et basée sur les WAL, répliquant les objets individuellement via les commandes PUBLICATION (primaire) et SUBSCRIPTION (secondaire)&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE PUBLICATION financials FOR TABLE ONLY loans, ONLY fines;&lt;/pre&gt;&lt;br /&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE SUBSCRIPTION financials&#xD;&#xA;CONNECTION &#39;dbname=libdata user=postgres host=172.17.0.2&#39;&#xD;&#xA;PUBLICATION financials;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;QUORUM replication : avec ANY et FIRST pour synchronous_standby_names;&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;synchronous_standby_names = ANY 2(node1,node2,node3);&#xD;&#xA;synchronous_standby_names = FIRST 2(node1,node2);&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Suppression automatique à la fin de la session des slots de réplication temporaires&lt;/li&gt;&#xA;&lt;li&gt;Amélioration de libpq permettant des connexions a de multiples systèmes&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances de la réplication physique&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Administration&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Support de la compression pour pg_receivewal&lt;/li&gt;&#xA;&lt;li&gt;Ajout d&amp;rsquo;informations sur les Background processes et Wait Events dans pg_stat_activity&lt;/li&gt;&#xA;&lt;li&gt;Ajout de fonctions qui remontent à l&amp;rsquo;utilisateur des informations sur le status de transaction. L&amp;rsquo;usage principal de ces fonctions est de déterminer les transactions commitées entre deux snapshots.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;txid_status(bigint)&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Fonctionnalités SQL et développeurs&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Gestion de colonne Identity qui vise à remplacer l&amp;rsquo;utilisation du type serial et qui est conforme au standard SQL&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE test_new (&#xD;&#xA;    id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,&#xD;&#xA;    payload text&#xD;&#xA;);&lt;/pre&gt;&lt;p&gt;plus d&amp;rsquo;informations sur ce sujet &lt;a href=&#34;https://blog.2ndquadrant.com/postgresql-10-identity-columns/&#34;&gt;ici par exemple&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Possibilité de renommer la valeur d&amp;rsquo;une énumération&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TYPE langage AS ENUM (&#39;SQL&#39;, &#39;JAVA&#39;, &#39;HTML&#39;) ;&#xD;&#xA;ALTER TYPE langage RENAME VALUE &#39;HTML&#39; TO &#39;HTML5&#39; ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout des triggers AFTER STATEMENT qui peuvent avoir accès à l’ensemble des lignes modifiées, avant et après changement, à travers une pseudo-variable de type table&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TRIGGER nom_trigger AFTER DELETE ON nom_table&#xD;&#xA;REFERENCING OLD TABLE AS OLD&#xD;&#xA;FOR EACH STATEMENT&#xD;&#xA;EXECUTE PROCEDURE nom_procedure();&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de la fonction xmltable qui produit une table basée sur la valeur XML donnée.&lt;/li&gt;&#xA;&lt;li&gt;Supprimer des éléments d&amp;rsquo;un JSONB&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;SELECT &#39;{&#34;a&#34;:1 , &#34;b&#34;:2, &#34;c&#34;:3}&#39;::jsonb - &#39;{a,c}&#39;::text[] ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Il est possible de créer des indexes full text sur une colonne JSON ou JSONB&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE INDEX bookdata_fts ON bookdata&#xD;&#xA;USING gin (( to_tsvector(&#39;english&#39;,bookdata) ));&#xD;&#xA;&#xD;&#xA;SELECT bookdata -&amp;gt; &#39;title&#39;&#xD;&#xA;FROM bookdata&#xD;&#xA;WHERE to_tsvector(&#39;english&#39;,bookdata) @@ to_tsquery(&#39;duke&#39;);&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Sécurité&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Authentification SCRAM plus sécurisée que md5&lt;/li&gt;&#xA;&lt;li&gt;Création de nouveau rôle pour le monitoring évitant ainsi d&amp;rsquo;être super utilisateur&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;pg_read_all_settings : Lit toutes les variables de configuration, y compris celles normalement visibles des seuls super-utilisateurs.&#xD;&#xA;pg_read_all_stats : Lit toutes les vues pg_stat_* et utilise plusieurs extensions relatives aux statistiques, y compris celles normalement visibles des seuls super-utilisateurs.&#xD;&#xA;pg_stat_scan_tables : Exécute des fonctions de monitoring pouvant prendre des verrous verrous ACCESS SHARE sur les tables, potentiellement pour une longue durée.&#xD;&#xA;pg_monitor : Lit et exécute plusieurs vues et fonctions de monitoring. Ce rôle est membre de pg_read_all_settings, pg_read_all_stats et pg_stat_scan_tables.&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de politiques restrictive dans les politiques de sécurité pour l&amp;rsquo;accès aux lignes et plus seulement de politiques permissives&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE POLICY admin_local_only ON passwd AS RESTRICTIVE TO admin&#xD;&#xA;    USING (pg_catalog.inet_client_addr() IS NULL);&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Autres fonctionnalités&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;file_fdw peut maintenant utiliser les programmes&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE FOREIGN TABLE&#xD;&#xA;   test(a int, b text)&#xD;&#xA;   SERVER csv&#xD;&#xA;   OPTIONS (program &#39;gunzip -c /tmp/data.czv.gz&#39;);&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;support des collations ICU&lt;/li&gt;&#xA;&lt;li&gt;Ajout d&amp;rsquo;un module amcheck permettant de vérifier cohérence / corruption d&amp;rsquo;un index B-Tree&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE EXTENSION amcheck ;&#xD;&#xA;   SELECT bt_index_check(&#39;idx1_check1&#39;) ;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Modifications entrainant une incompatibilité ascendante&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;“xlog” et “clog” qui deviennent respectivement “wal” et “xact”.&lt;/li&gt;&#xA;&lt;li&gt;fin du support du protocole client/serveur 1.0 (clients datant d’avant la version 6.3)&lt;/li&gt;&#xA;&lt;li&gt;changement de valeurs par défaut pour pg_basebackup&lt;/li&gt;&#xA;&lt;li&gt;fin du support des TIMESTAMP avec floating point.&lt;/li&gt;&#xA;&lt;li&gt;Le module contrib/tsearch2 a été supprimé qui permettait une comptabilité avec les fonction de recherche full text avant la version 8.3&lt;/li&gt;&#xA;&lt;li&gt;fin du support de la commande pg_dump pour les bases de données plus anciennes que la version 8.0&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Et voilà, nous avons fini notre petit tour rapide des nouveautés de postgreSQL 10 mais une version 11 est déjà prévue pour dans 12 mois !&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-10/&#34;&gt;Sortie de PostgreSQL 10&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/sortie-de-postgresql-10/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sortie-de-postgresql-10" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Aujourd&amp;#8217;hui, c&amp;#8217;est la sortie de PostgreSQL 10!!!! Première révolution, la numérotation des versions : on passe de 9.4&amp;#8230;9.6 pour les versions majeures à 10, 11, 12&amp;#8230; Ce point est important car un changement de version majeure implique une migration des... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-10/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-10/&#34;&gt;Sortie de PostgreSQL 10&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Nouveau module d’export de données pour REMOcRA</title>
    <updated>2017-05-12T13:52:26Z</updated>
    <id>tag:blog.atolcd.com,2017-05-12:/nouveau-module-dexport-de-donnees-remocra/</id>
    <content type="html">&lt;h1&gt;Objectif du module&lt;/h1&gt;&#xA;&lt;p&gt;Le SDIS du Var ne disposait pas jusqu&amp;rsquo;à ce jour, à travers la plate-forme collaborative &lt;a href=&#34;http://sdis.atolcd.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;REMOcRA&lt;/a&gt;, d&amp;rsquo;une méthode simple pour exporter le contenu de la base de données auprès de ses partenaires. Les demandes étant de plus en plus récurrentes, le SDIS du Var a décidé &lt;strong&gt;de faire évoluer l&amp;rsquo;application pour l&amp;rsquo;enrichir d&amp;rsquo;un module dédié aux exports&lt;/strong&gt; et a confié à Atol Conseils et Développements sa réalisation en veillant à respecter les besoins suivants :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;En tant qu&amp;rsquo;administrateur de l&amp;rsquo;extranet, être en mesure de réaliser facilement des exports de données en se basant sur des modèles administrables. Ce module devait être en mesure de produire des fichiers tabulaires ou des fichiers géographiques.&lt;/li&gt;&#xA;&lt;li&gt;En tant que partenaire, être en mesure d&amp;rsquo;exporter soit même les données mises à disposition par le SDIS sur un territoire autorisé.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1&gt;Comment ça marche ?&lt;/h1&gt;&#xA;&lt;h2&gt;Un fonctionnement basé sur des modèles d&amp;rsquo;exports&lt;/h2&gt;&#xA;&lt;p&gt;Le mécanisme d&amp;rsquo;export repose sur des modèles. Ces derniers peuvent être référencés directement par les administrateurs de la plate-forme REMOcRA grâce à des fichiers de définition de modèle (format XML) déposés fia FTP dans un sous-dossier de REMOcRA.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-large wp-image-2626&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-1024x220.png&#34; alt=&#34;&#34; width=&#34;676&#34; height=&#34;145&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-1024x220.png 1024w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-300x64.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-768x165.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-945x203.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-600x129.png 600w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1.png 1067w&#34; sizes=&#34;auto, (max-width: 676px) 100vw, 676px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Le fichier XML précise principalement la requête SQL à utiliser pour filtrer et formater les données à la bonne structure. L&amp;rsquo;attribut spatial du nœud racine permet de préciser si l&amp;rsquo;export est de type tabulaire (CSV) ou géographique (Esri Shapefile). Dans le cas d&amp;rsquo;un export géographique, la colonne « wkt » contenant la géométrie encodée en WKT est exploitée.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-2627&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2.png&#34; alt=&#34;&#34; width=&#34;822&#34; height=&#34;341&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2.png 822w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2-300x124.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2-768x319.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2-600x249.png 600w&#34; sizes=&#34;auto, (max-width: 822px) 100vw, 822px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Le référencement des modèles est réalisé directement depuis l&amp;rsquo;interface en exécutant depuis REMOcRA le traitement « Référencer les modèles d&amp;rsquo;export de données » disponible dans la catégorie d&amp;rsquo;applications « Divers »&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-2628&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3.png&#34; alt=&#34;&#34; width=&#34;968&#34; height=&#34;288&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3.png 968w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-300x89.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-768x228.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-945x281.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-600x179.png 600w&#34; sizes=&#34;auto, (max-width: 968px) 100vw, 968px&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Un traitement spécifique intégrant le filtrage spatial des données&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-large wp-image-2629&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-1024x525.png&#34; alt=&#34;&#34; width=&#34;676&#34; height=&#34;347&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-1024x525.png 1024w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-300x154.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-768x394.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-945x484.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-600x307.png 600w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4.png 1167w&#34; sizes=&#34;auto, (max-width: 676px) 100vw, 676px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;La réalisation d&amp;rsquo;un export de données depuis le système REMOcRA se base sur le mécanisme suivant :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;L&amp;rsquo;utilisateur de profil « administrateur » dispose d&amp;rsquo;un nouveau traitement intitulé « Exporter les données à partir d&amp;rsquo;un modèle ». Ce dernier permet de réaliser des exports de données en s&amp;rsquo;appuyant sur la liste de modèles.&lt;/li&gt;&#xA;&lt;li&gt;Après avoir choisi son modèle, la demande d&amp;rsquo;export formulée par l&amp;rsquo;utilisateur est stockée en file d&amp;rsquo;attente. Une tâche planifiée vérifie régulièrement la présence de demandes en attente&lt;/li&gt;&#xA;&lt;li&gt;Lors de l’exécution de la tâche planifiée, le moteur ETL exécute les demandes d&amp;rsquo;export en attente en s&amp;rsquo;appuyant sur les informations contenues dans le modèle pour générer un fichier CSV (dans le cas de données non géographiques) ou des fichiers de formes (fichiers ESRI Shapefile).&lt;/li&gt;&#xA;&lt;li&gt;A l&amp;rsquo;issu du traitement, les fichiers produits sont compressés au format ZIP et un lien de téléchargement est fourni dans un mél envoyé au demandeur du traitement.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-2630&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5.png&#34; alt=&#34;&#34; width=&#34;962&#34; height=&#34;367&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5.png 962w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-300x114.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-768x293.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-945x361.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-600x229.png 600w&#34; sizes=&#34;auto, (max-width: 962px) 100vw, 962px&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Une mutualisation des connaissances !&lt;/h2&gt;&#xA;&lt;p&gt;Le SDIS du Var (83), à l&amp;rsquo;initiative de la plate-forme collaborative métier REMOcRA, a décidé de faire bénéficier ses confrères de sa démarche en redistribuant gratuitement l&amp;rsquo;outil et ce module sous licence Creative Commons.&lt;br /&gt;&#xA;Dans cette démarche open source, la solution et le nouveau module sont disponibles sur Github pour installation et test à tous les SDIS sur &lt;a href=&#34;https://github.com/atolcd/sdis-remocra&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/atolcd/sdis-remocra&lt;/a&gt;. Pour plus d&amp;rsquo;information sur la solution REMOcRA, consulter &lt;a href=&#34;http://sdis.atolcd.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;http://sdis.atolcd.com&lt;/a&gt;&lt;br /&gt;&#xA;&lt;em&gt;REMOcRA est cofinancé par l’Union européenne. L’Europe s’engage avec le Fonds européen de développement régional.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/&#34;&gt;Nouveau module d&amp;rsquo;export de données pour REMOcRA&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=nouveau-module-dexport-de-donnees-remocra" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Objectif du module Le SDIS du Var ne disposait pas jusqu&amp;#8217;à ce jour, à travers la plate-forme collaborative REMOcRA, d&amp;#8217;une méthode simple pour exporter le contenu de la base de données auprès de ses partenaires. Les demandes étant de plus... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/&#34;&gt;Nouveau module d&amp;rsquo;export de données pour REMOcRA&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Nouveau dans pg13: Colonne leader_pid dans pg_stat_activity</title>
    <updated>2020-03-08T05:33:26Z</updated>
    <id>tag:rjuju.github.io,2020-03-08:/postgresqlfr/2020/03/08/nouveau-dans-pg13-leader_pid.html</id>
    <content type="html">&lt;h3 id=&#34;nouvelle-colonne-leader_pid-dans-la-vue-pg_stat_activity&#34;&gt;Nouvelle colonne leader_pid dans la vue pg_stat_activity&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Étonnamment, depuis que les requêtes parallèles ont été ajoutées dans&#xA;PostgreSQL 9.6, il était impossible de savoir à quel processus client était lié&#xA;un worker parallèle.  Ainsi, comme &lt;a href=&#34;https://twitter.com/g_lelarge/status/1209486212190343168&#34;&gt;Guillaume l’a fait&#xA;remarquer&lt;/a&gt;, it makes&#xA;il est assez difficile de construire des outils simples permettant&#xA;d’échantillonner les événements d’attente liés à tous les processus impliqués&#xA;dans une requête.  Une solution simple à ce problème est d’exporter&#xA;l’information de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;lock group leader&lt;/code&gt; disponible dans le processus client au&#xA;niveau SQL :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit b025f32e0b5d7668daec9bfa957edf3599f4baa8&#xA;Author: Michael Paquier &amp;lt;michael@paquier.xyz&amp;gt;&#xA;Date:   Thu Feb 6 09:18:06 2020 +0900&#xA;&#xA;Add leader_pid to pg_stat_activity&#xA;&#xA;This new field tracks the PID of the group leader used with parallel&#xA;query.  For parallel workers and the leader, the value is set to the&#xA;PID of the group leader.  So, for the group leader, the value is the&#xA;same as its own PID.  Note that this reflects what PGPROC stores in&#xA;shared memory, so as leader_pid is NULL if a backend has never been&#xA;involved in parallel query.  If the backend is using parallel query or&#xA;has used it at least once, the value is set until the backend exits.&#xA;&#xA;Author: Julien Rouhaud&#xA;Reviewed-by: Sergei Kornilov, Guillaume Lelarge, Michael Paquier, Tomas&#xA;Vondra&#xA;Discussion: https://postgr.es/m/CAOBaU_Yy5bt0vTPZ2_LUM6cUcGeqmYNoJ8-Rgto+c2+w3defYA@mail.gmail.com&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Avec cette modification, il est maintenant très simple de trouver tous les&#xA;processus impliqués dans une requête parallèle.  Par exemple :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;=#&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;  &lt;span class=&#34;n&#34;&gt;array_agg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;members&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_stat_activity&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;IS&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;GROUP&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;       &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;members&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-------------------+------------+---------------&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;      &lt;span class=&#34;mi&#34;&gt;31630&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32269&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32268&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Attention toutefois, comme indiqué dans le message de commit, si la colonne&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;leader_pid&lt;/code&gt; à la même valeur que la colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pid&lt;/code&gt;, cela ne veut pas forcément&#xA;dire que le processus client est actuellement en train d’effectuer une requête&#xA;parallèle, car une fois que le champ est positionné il n’est jamais&#xA;réinitialisé.  De plus, pour éviter tout surcoût, aucun verrou supplémentaire&#xA;n’est maintenu lors de l’affichage de ces données.  Cela veut dire que chaque&#xA;ligne est traitée indépendamment.  Ainsi, bien que cela soit fort peu probable,&#xA;vous pouvez obtenir des données incohérentes dans certaines circonstances,&#xA;comme par exemple un worker paralèlle pointant vers un pid qui est déjà&#xA;déconnecté.&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2020/03/08/nouveau-dans-pg13-leader_pid.html&#34;&gt;Nouveau dans pg13: Colonne leader_pid dans pg_stat_activity&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on March 08, 2020.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2020/03/08/nouveau-dans-pg13-leader_pid.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>pg qualstats 2: Suggestion d&#39;index globale</title>
    <updated>2020-01-06T12:23:29Z</updated>
    <id>tag:rjuju.github.io,2020-01-06:/postgresqlfr/2020/01/06/pg_qualstats-2-suggestion-index-globale.html</id>
    <content type="html">&lt;p&gt;Parvenir à une suggestion d’index de qualité peut être une tâche complexe.&#xA;Cela nécessite à la fois une connaissance des requêtes applicatives et des&#xA;spécificités de la base de données.  Avec le temps de nombreux projets ont&#xA;essayé de résoudre ce problème, l’un d’entre eux étant &lt;a href=&#34;https://powa.readthedocs.io/&#34;&gt;PoWA version&#xA;3&lt;/a&gt;, avec l’aide de &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/pg_qualstats.html&#34;&gt;pg_qualstats&#xA;extension&lt;/a&gt;.&#xA;Cet outil donne de plutôt bonnes suggestions d’index, mais il est nécessaire&#xA;d’installer et configurer PoWA, alors que certains utilisateurs aimeraient&#xA;n’avoir que la suggestion d’index globale.  Pour répondre à ce besoin de&#xA;simplicité, l’algorithme utilisé dans PoWA est maintenant disponible dans&#xA;pg_qualstats version 2, sans avoir besoin d’utiliser des composants&#xA;additionnels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: La fonction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_qualstats_index\_advisor()&lt;/code&gt; a été changée pour retourner&#xA;du &lt;strong&gt;json&lt;/strong&gt; plutôt que du &lt;strong&gt;jsonb&lt;/strong&gt;, afin de conserver la compatibilité avec PostgreSQL&#xA;9.3.  Les requêtes d’exemples sont donc également modifiées pour utiliser&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;json_array_elements()&lt;/code&gt; plutôt que &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;jsonb_array_elements()&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;quest-ce-que-pg_qualstats&#34;&gt;Qu’est-ce que pg_qualstats&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Une manière simple d’expliquer ce qu’est pg_qualstats serait de dire qu’il&#xA;s’agit d’une extension similaire à&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/pgstatstatements.html&#34;&gt;pg_stat_statements&lt;/a&gt;&#xA;mais travaillant au niveaux des prédicats.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cette extension sauvegarde des statistiques utiles pour les clauses &lt;strong&gt;WHERE&lt;/strong&gt;&#xA;et &lt;strong&gt;JOIN&lt;/strong&gt; : à quelle table et quelle colonne un prédicat fait référénce, le&#xA;nombre de fois qu’un prédicat a été utilisé, le nombre d’exécutions de&#xA;l’opérateur sous-jacent, si le prédicat provient d’un parcours d’index ou non,&#xA;la sélectivité, la valeur des constantes et bien plus encore.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il est possible de déduire beaucoup de choses depuis ces informations.  Par&#xA;exemple, si vous examinez les prédicats qui contiennent des références à des&#xA;tables différentes, vous pouvez trouver quelles tables sont jointes ensembles,&#xA;et à quel point les conditions de jointures sont sélectives.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;suggestion-globale-&#34;&gt;Suggestion Globale ?&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Comment je l’ai mentionné, la suggestion d’index globale ajoutée dans&#xA;pg_qualstats 2 utilise la même approche que celle de PoWA, ainsi cet article&#xA;peut servir à décrire le fonctionnement des deux outils.  La seule différence&#xA;est que vous obtiendrez probablement une suggestion de meilleure qualité avec&#xA;PoWA, puisque plus de prédicats seront disponibles, et que vous pourrez&#xA;également choisir sur quel intervalle de temps vous souhaitez effectuer une&#xA;suggestion d’index manquants.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La chose importante à retenir ici est qu’il s’agit d’une suggestion effectuée&#xA;de manière &lt;strong&gt;globale&lt;/strong&gt;, c’est-à-dire en prenant en compte tous les prédicats&#xA;intéressant en même temps.  Cette approche est différente de toutes les autres&#xA;dont j’ai connaissance, qui ne prennent en compte qu’une seule requête à la&#xA;fois.  Selon moi, une approche globale est meilleure, car il est possible de&#xA;réduire le nombre total d’index, en maximisant l’efficacité des index&#xA;multi-colonnes.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;comment-marche-la-suggestion-globale&#34;&gt;Comment marche la suggestion globale&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;La première étape consiste à récupérer tous les prédicats qui pourraient&#xA;bénéficier de nouveaux index.  C’est particulièrement facile à obtenir avec&#xA;pg_qualstats.  En filtrant les prédicats venant d’un parcours séquentiel,&#xA;exécutés de nombreuses fois et qui filtrent de nombreuses lignes (à la fois en&#xA;nombre et en pourcentage), vous obtenez une liste parfaite de prédicats qui&#xA;auraient très probablement besoin d’un index (ou alors dans certains cas une&#xA;liste des requêtes mal écrites).  Voyons regardons par exemple le cas d’une&#xA;applications qui utiliserait ces 4 prédicats:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/global_advisor_1_quals.png&#34;&gt;&lt;img src=&#34;/images/global_advisor_1_quals.png&#34; alt=&#34;Liste de tous les prédicats&#xA;trouvés&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ensuite, il faut construire l’ensemble entier des chemins de toutes les&#xA;prédicats joints par un AND logique, qui contiennent d’autres prédicats, qui&#xA;peuvent être eux-meme également joints par des AND logiques.  En utilisants les&#xA;même 4 prédicats vus précédemments, nous obtenons ces chemins :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/global_advisor_2_graphs.png&#34;&gt;&lt;img src=&#34;/images/global_advisor_2_graphs.png&#34; alt=&#34;Construction de tous les chemins de prédicats&#xA;possibles&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois tous les chemins construits, il suffit d’obtenir le meilleur chemin&#xA;pour trouver le meilleur index à suggérer.  Le classement de ces chemins est&#xA;pour le moment fait en donnant un poids à chaque nœud de chaque chemin qui&#xA;correspond au nombre de prédicats simple qu’il contient, et en additionnant le&#xA;poids pour chaque chemin.  C’est une approche très simple, et qui permet de&#xA;favoriser un nombre minimal d’index qui optimisent le plus de requêtes&#xA;possible.  Avec nos exemple, nous obtenons :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/global_advisor_3_weighted.png&#34;&gt;&lt;img src=&#34;/images/global_advisor_3_weighted.png&#34; alt=&#34;Ajout d&#39;un poids à tous les chemins et choix du score le plus&#xA;haut&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bien évidemment, d’autres approches de classement pourraient être utilisée pour&#xA;prendre en compte d’autres paramètres, et potentiellement obtenir une meilleur&#xA;suggestion.  Par exemple, en prenant en compte également le nombre d’exécution&#xA;ou la sélectivité des prédicats.  Si le ratio de lecture/écriture pour chaque&#xA;table est connu (ce qui est disponible avec l’extension&#xA;&lt;a href=&#34;https://github.com/powa-team/powa-archivist&#34;&gt;powa-archivist&lt;/a&gt;), il serait&#xA;également possible d’adapter le classement pour limiter la suggestion d’index&#xA;pour les tables qui ne sont accédées presque exclusivement en écriture.  Avec&#xA;cet algorithme, ces ajustements seraient relativement simples à faire.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois que le meilleur chemin est trouvé, on peut générer l’ordre de création&#xA;de l’index !  Comme l’ordre des colonnes peut être important, l’ordre est&#xA;généré en récupérant les colonnes de chaque nœud par poids croissant.  Avec&#xA;notre exemple, l’index suivant est généré :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Une fois que l’index est trouvé, on supprime simplement les prédicats contenus&#xA;de la liste globale de prédicats et on reprendre de zéro jusqu’à ce qu’il n’y&#xA;ait plus de prédicats.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;un-peu-plus-de-détails-et-mise-en-garde&#34;&gt;Un peu plus de détails et mise en garde&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Bien évidemment, il s’agit ici d’une version simplifiée de l’algorithme de&#xA;suggestion, car d’autres informations sont nécessaires.  Par exemple, la liste&#xA;des prédicats est en réalité ajustée avec les &lt;a href=&#34;https://www.postgresql.org/docs/current/indexes-opclass.html&#34;&gt;classes d’opérateurs et méthode&#xA;d’acces&lt;/a&gt; en&#xA;fonction du type de la colonne et de sont opérateur, afin de s’assurer&#xA;d’obtenir des index valides.  Si plusieurs méthodes d’accès aux index sont&#xA;trouvées pour un même meilleur chemin, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;btree&lt;/code&gt; sera choisi en priorité.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cela nous amène à un autre détail : cette approche est principalement pensée&#xA;pour les index &lt;strong&gt;btree&lt;/strong&gt;, pour lesqules l’ordre des colonnes est critiques.&#xA;D’autres méthodes d’accès ne requièrent pas un ordre spécifique pour les&#xA;colonnes, et pour ces méthodes d’accès il est possible qu’une suggestion plus&#xA;optimale soit possible si l’ordre des colonnes n’était pas pris en compte.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Un autre point important est que les classes d’opérateurs et méthodes d’accès&#xA;ne sont pas gérés en dur mais récupérés à l’exécution en utilisant les&#xA;catalogues locaux.  Par conséquent, vous pouvez obtenir des résultats&#xA;différents (et potentiellement meilleurs) si vous faites en sorte d’avoir&#xA;toutes les classes d’opérateur additionelles disponibles quand vous utilisez la&#xA;suggestion d’index globale.  Cela pourrait être les extensions &lt;strong&gt;btree_gist&lt;/strong&gt;&#xA;et &lt;strong&gt;btree_gist&lt;/strong&gt;, mais également d’autres méthodes d’accès aux index.  Il est&#xA;également possible que certain types / opérateurs n’aient pas de méthode&#xA;d’accès associée dans les catalogues.  Dans ce cas, ces prédicats sont&#xA;retournées séparément dans une liste de prédicats non optimisables&#xA;automatiquement, et pour lequel une analyse manuelle est nécessaire.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Enfin, comme pg_qualstats ne traite pas les prédicats composés d’expressions,&#xA;l’outil ne peut pas suggérer d’index sur des expressions, par exemple en cas&#xA;d’utilisateur de recherche plein texte.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;exemple-dutilisation&#34;&gt;Exemple d’utilisation&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Une simple fonction est fournie, avec des paramètres facultatifs, qui retourne&#xA;une valeur de type json :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;OR&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;REPLACE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FUNCTION&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_qualstats_index_advisor&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;min_filter&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;min_selectivity&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;forbidden_am&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;{}&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;RETURNS&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Les noms de paramètres sont parlants :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;min_filter&lt;/code&gt;: combien de lignes le prédicat doit-il filtrer en moyenne pour&#xA;être pris en compte par la suggestion globale, par défaut &lt;strong&gt;1000&lt;/strong&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;min_selectivity&lt;/code&gt;: quelle doit être la sélectivité moyenne d’un prédicat&#xA;pour qu’il soit pris en compte par la suggestion globale, par défaut&#xA;&lt;strong&gt;30%&lt;/strong&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;forbidden_am&lt;/code&gt;: liste des méthodes d’accès aux index à ignorer.  Aucune par&#xA;défaut, bien que pour les version 9.6 et inférieures &lt;strong&gt;les index hash sont&#xA;ignoré en interne&lt;/strong&gt;, puisque ceux-ci ne sont sur que depuis la version 10.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple simple, tirés des tests de non régression de pg_qualstats :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pgqs&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;a&#39;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generate_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id2&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id3&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;INSERT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;INTO&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;line &#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generate_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_qualstats_reset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ILIKE&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;moh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;COUNT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pgqs&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Et voici ce que la fonction retourne :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json_array_elements&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;pg_qualstats_index_advisor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min_filter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&#39;indexes&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;ORDER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;COLLATE&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;C&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;                               &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;---------------------------------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;CREATE INDEX ON public.adv USING btree (id1)&#34;&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;CREATE INDEX ON public.adv USING btree (val, id1, id2, id3)&#34;&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;CREATE INDEX ON public.pgqs USING btree (id)&#34;&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json_array_elements&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;pg_qualstats_index_advisor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min_filter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&#39;unoptimised&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;ORDER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;COLLATE&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;C&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;        &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-----------------&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;adv.val ~~* ?&#34;&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;La &lt;a href=&#34;https://github.com/powa-team/pg_qualstats/&#34;&gt;version 2 de pg_qualstats&lt;/a&gt;&#xA;n’est pas encore disponible en version stable, mais n’hésitez pas à la tester&#xA;et &lt;a href=&#34;https://github.com/powa-team/pg_qualstats/issues&#34;&gt;rapporter tout problème que vous pourriez&#xA;rencontrer&lt;/a&gt; !&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2020/01/06/pg_qualstats-2-suggestion-index-globale.html&#34;&gt;pg qualstats 2: Suggestion d&#39;index globale&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on January 06, 2020.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2020/01/06/pg_qualstats-2-suggestion-index-globale.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>PoWA 4: Nouveau daemon powa-collector</title>
    <updated>2019-12-10T18:54:17Z</updated>
    <id>tag:rjuju.github.io,2019-12-10:/postgresqlfr/2019/12/10/powa-4-nouveau-powa-collector.html</id>
    <content type="html">&lt;p&gt;Cet article fait partie d’une série d’article sur &lt;a href=&#34;http://powa.readthedocs.io/&#34;&gt;la beta de PoWA&#xA;4&lt;/a&gt;, et décrit le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon&#xA;powa-collector&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;nouveau-daemon-powa-collector&#34;&gt;Nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon powa-collector&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Ce daemon remplace le précédent &lt;em&gt;background worker&lt;/em&gt; lorsque le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html&#34;&gt;mode&#xA;remote&lt;/a&gt; est utilisé.&#xA;Il s’agit d’un simple daemon écrit en python, qui s’occupera de toutes les&#xA;étapes nécessaires pour effectuer des &lt;em&gt;snapshots distants&lt;/em&gt;.  Il est &lt;a href=&#34;https://pypi.org/project/powa-collector/&#34;&gt;disponible&#xA;sur pypi&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Comme je l’ai expliqué dans mon &lt;a href=&#34;/postgresql/2019/05/17/powa-4-with-remote-mode-beta-is-available.html&#34;&gt;précédent article introduistant PoWA 4&lt;/a&gt;, ce&#xA;daemon est nécessaire  pour la configuration d’un mode remote, en gardant cette&#xA;architecture à l’esprit :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_remote.svg&#34;&gt;&lt;img src=&#34;/images/powa_4_remote.svg&#34; alt=&#34;Architecture de PoWA 4 en mode distant&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sa configuration est très simple.  Il vous suffit tout simplement de renommer&#xA;le fichier &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa-collector.conf.sample&lt;/code&gt; fourni, et d’adapter &lt;a href=&#34;https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING&#34;&gt;l’URI de&#xA;connexion&lt;/a&gt;&#xA;pour décrire comment se connecter sur votre &lt;em&gt;serveur repository&lt;/em&gt; dédié, et&#xA;c’est fini.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une configuration typique devrait ressembler à :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-conf&#34; data-lang=&#34;conf&#34;&gt;{&#xA;    &lt;span class=&#34;s2&#34;&gt;&#34;repository&#34;&lt;/span&gt;: {&#xA;        &lt;span class=&#34;s2&#34;&gt;&#34;dsn&#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&#34;postgresql://powa_user@server_dns:5432/powa&#34;&lt;/span&gt;,&#xA;    },&#xA;    &lt;span class=&#34;s2&#34;&gt;&#34;debug&#34;&lt;/span&gt;: &lt;span class=&#34;n&#34;&gt;true&lt;/span&gt;&#xA;}&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;La liste des &lt;em&gt;serveur distants&lt;/em&gt;, leur configuration ainsi que tout le reste qui&#xA;est nécessaire pour le bon fonctionnement sera automatiquement récupéré depuis&#xA;le &lt;em&gt;serveur repository&lt;/em&gt; que vous ave déjà configuré.  Une fois démarré, il&#xA;démarrera un thread dédié par &lt;em&gt;serveur distant&lt;/em&gt; déclaré, et maintiendra une&#xA;&lt;strong&gt;connexion persistente&lt;/strong&gt; sur ce &lt;em&gt;serveur distant&lt;/em&gt;.  Chaque thread effectuera&#xA;un &lt;em&gt;snapshot distant&lt;/em&gt;, exportant les données sur le &lt;em&gt;serveur repository&lt;/em&gt; en&#xA;utilisant les nouvelles &lt;em&gt;fonctions sources&lt;/em&gt;.  Chaque thread ouvrira et fermera&#xA;une connexion sur le &lt;em&gt;serveur repository&lt;/em&gt; lors de l’exécution du &lt;em&gt;snapshot&#xA;distant&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bien évidemment, ce daemon a besoin de pouvoir se connecter sur tous les&#xA;&lt;em&gt;serveurs distants&lt;/em&gt; déclarés ainsi que le &lt;em&gt;serveur repository&lt;/em&gt;.  La table&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_servers&lt;/code&gt;, qui stocke la liste des &lt;em&gt;serveurs distants&lt;/em&gt;, a un champ pour&#xA;stocker les nom d’utilisateur et mot de passe pour se connecter aux &lt;em&gt;serveur&#xA;distants&lt;/em&gt;.  Stocker un mot de passe en clair dans cette table est une hérésie,&#xA;si l’on considère l’aspect sécurité.  Ainsi, comme indiqué dans la&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/security.html#connection-on-remote-servers&#34;&gt;section sécurité de&#xA;PoWA&lt;/a&gt;,&#xA;vous pouve stocker un mot de passe NULL et &lt;a href=&#34;https://www.postgresql.org/docs/current/auth-methods.html&#34;&gt;utiliser à la place n’importe&#xA;laquelle des autres méthodes d’authentification supportées par la&#xA;libpq&lt;/a&gt; (fichier&#xA;.pgpass, certificat…).  C’est très fortement recommandé pour toute&#xA;installation sérieuse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La connexion persistente sur le &lt;em&gt;serveur repository&lt;/em&gt; est utilisée pour&#xA;superviser la daemon :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;pour vérifier  que le daemon est bien démarré&lt;/li&gt;&#xA;  &lt;li&gt;pour communiquer au travers de l’UI en utilisant un &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/protocol.html&#34;&gt;protocole simple&lt;/a&gt;&#xA;afin d’effectuer des actions diverses (recharger la configuration, vérifier&#xA;le status d’un thread dédié à un &lt;em&gt;serveur distant&lt;/em&gt;…)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Il est à noter que vous pouvez également demander au daemon de recharger sa&#xA;configuration en envoyant un SIGHUP au processus du daemon.  Un rechargement&#xA;est nécessaire pour toute modification effectuée sur la liste des serveurs&#xA;distants (ajout ou suppression d’un &lt;em&gt;serveur distant&lt;/em&gt;, ou mise à jour d’un&#xA;existant).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez également noter que, par choix,&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;powa-collector&lt;/a&gt;&#xA;n’effectuera pas de &lt;em&gt;snapshot local&lt;/em&gt;.  Si vous voulez utiliser PoWA pour le&#xA;&lt;em&gt;serveur repository&lt;/em&gt;, il vous faudra activer le &lt;em&gt;background worker&lt;/em&gt; original.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;nouvelle-page-de-configuration&#34;&gt;Nouvelle page de configuration&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;La page de configuration est maintenant modifiée pour donner toutes les&#xA;informations nécessaires sur le status du background worker, le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;powa-collector&#xA;daemon&lt;/a&gt;&#xA;(incluant tous ses threads dédiés) ainsi que la liste des &lt;em&gt;serveurs distants&lt;/em&gt;&#xA;déclarés.  Voici un exemple de cette nouvelle page racine de configuration :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_configuration_page.png&#34;&gt;&lt;img src=&#34;/images/powa_4_configuration_page.png&#34; alt=&#34;Nouvelle page de&#xA;configuration&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon&#xA;powa-collector&lt;/a&gt;&#xA;est utilisé, le status de chaque serveur distant sera récupéré en utilisant le&#xA;protocole de communication.  Si le collecteur rencontre des erreurs (lors de la&#xA;connexion à un &lt;em&gt;serveur distant&lt;/em&gt;, durant un &lt;em&gt;snapshot&lt;/em&gt; par exemple), celles-ci&#xA;seront également affichées ici.  À noter également que ces erreurs seront&#xA;également affichées en haut de chaque page de toutes les pages de l’UI, afin&#xA;d’être sûr de ne pas les rater.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;De plus, la section configuration a maintenant une hiérarchie, et vous pourrez&#xA;voir la liste des extensions ainsi que la configuration actuelle de PostgreSQL&#xA;pour le serveur &lt;strong&gt;local&lt;/strong&gt; ou &lt;strong&gt;distant&lt;/strong&gt; en cliquant sur le serveur de votre&#xA;choix!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il y a également un nouveau bouton &lt;strong&gt;Reload collector&lt;/strong&gt; sur le bandeau&#xA;d’en-tête qui, comme on pourrait s’y attendre, demandera au collecteur de&#xA;recharger sa configuration.  Cela peut être utile si vous avez déclarés de&#xA;nouveaux serveurs mais n’ave pas d’accès au serveur sur lequel le collecteur&#xA;s’exécute.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette article est le dernier de la séurie concernant la nouvelle version de&#xA;PoWA.  Il est toujours en beta, n’hésitez donc pas à le tester, &lt;a href=&#34;https://powa.readthedocs.io/en/latest/support.html#support&#34;&gt;rapporter&#xA;tout bug rencontré&lt;/a&gt;&#xA;ou donner tout autre retour!&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/12/10/powa-4-nouveau-powa-collector.html&#34;&gt;PoWA 4: Nouveau daemon powa-collector&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on December 10, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/12/10/powa-4-nouveau-powa-collector.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>PoWA 4: nouveautés dans powa-archivist !</title>
    <updated>2019-06-05T14:26:17Z</updated>
    <id>tag:rjuju.github.io,2019-06-05:/postgresqlfr/2019/06/05/powa-4-nouveaute-dans-powa-archivist.html</id>
    <content type="html">&lt;p&gt;Cet article fait partie d’une série d’article sur &lt;a href=&#34;http://powa.readthedocs.io/&#34;&gt;la beta de PoWA&#xA;4&lt;/a&gt;, et décrit les changements présents dans&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/index.html&#34;&gt;powa-archivist&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour plus d’information sur cette version 4, vous pouvez consulter &lt;a href=&#34;/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html&#34;&gt;l’article&#xA;de présentation général&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;aperçu-rapide&#34;&gt;Aperçu rapide&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Tout d’abord, il faut savoir qu’il n’y a pas d’upgrade possible depuis la v3&#xA;vers la v4, il est donc nécessaire d’effectuer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;DROP EXTENSION powa&lt;/code&gt; si vous&#xA;utilisiez déjà PoWA sur vos serveurs.  Cela est du au fait que la v4 apporte&#xA;&lt;strong&gt;de très nombreux&lt;/strong&gt; changements dans la partie SQL de l’extension, ce qui en&#xA;fait le changement le plus significatif dans la suite PoWA pour cette nouvelle&#xA;version.  Au moment où j’écris cet article, la quantité de changements apportés&#xA;dans cette extension est :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-diff&#34; data-lang=&#34;diff&#34;&gt; CHANGELOG.md       |   14 +&#xA; powa--4.0.0dev.sql | 2075 +++++++++++++++++++++-------&#xA; powa.c             |   44 +-&#xA; 3 files changed, 1629 insertions(+), 504 deletions(-)&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;L’absence d’upgrade ne devrait pas être un problème en pratique.  PoWA est un&#xA;outil pour analyser les performances, il est fait pour avoir des données avec&#xA;une grande précision mais un historique très limité.  Si vous cherchez une&#xA;solution de supervision généraliste pour conserver des mois de données, PoWA&#xA;n’est définitivement pas l’outil qu’il vous faut.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;configurer-la-liste-des-serveurs-distants&#34;&gt;Configurer la liste des &lt;em&gt;serveurs distants&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;En ce qui concerne les changements à proprement parler, le premier petit&#xA;changement est que le &lt;a href=&#34;https://www.postgresql.org/docs/current/bgworker.html&#34;&gt;background&#xA;worker&lt;/a&gt; n’est plus&#xA;nécessaire pour le fonctionnement de powa-archivist, car il n’est pas utilisé&#xA;pour le mode distant.  Cela signifie qu’un redémarrage de PostgreSQL n’est plus&#xA;nécessaire pour installer PoWA.  Bien évidemment, un redémarrage est toujours&#xA;nécessaire si vous souhaitez utiliser le mode local, en utilisant le background&#xA;worker, or si vous voulez installer des extensions additionelles qui&#xA;nécessitent elles-même un redémarrage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ensuite, comme PoWA requiert un peu de configuration (fréquence des snapshot,&#xA;rétention des données et ainsi de suite), certaines nouvelles tables sont&#xA;ajouter pour permettre de configurer tout ça.  La nouvelle table &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_servers&lt;/code&gt;&#xA;stocke la configuration de toutes les instances distantes dont les données&#xA;doivent être stockées sur cette instance.  Cette &lt;em&gt;instance PoWA locale&lt;/em&gt; est&#xA;appelée un &lt;strong&gt;serveur repository&lt;/strong&gt; (qui devrait typiquement être dédiée à&#xA;stocker des données PoWA), en opposition aux &lt;strong&gt;instances distantes&lt;/strong&gt; qui sont&#xA;les instances que vous voulez monitorer.  Le contenu de cette table est tout ce&#xA;qu’il y a de plus simple :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powa_servers&lt;/span&gt;&#xA;                              &lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_servers&#34;&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;   &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;                 &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-----------+----------+-----------+----------+------------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;            &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nextval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&#39;powa_servers_id_seq&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;regclass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;hostname&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;alias&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;port&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;username&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;password&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;dbname&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;frequency&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;300&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;powa_coalesce&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;retention&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interval&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;1 day&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;interval&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Si vous avez déjà utilisé PoWA, vous devriez reconnaître la plupart des options&#xA;de configuration qui sont maintenant stockées ici.  Les nouvelles options sont&#xA;utilisées pour décrire comment se connecter aux &lt;em&gt;instances distances&lt;/em&gt;, et&#xA;peuvent fournir un alias à afficher sur l’UI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Vous avez également probablement remarqué une colonne &lt;strong&gt;password&lt;/strong&gt;.  Stocker un&#xA;mot de passe en clair dans cette table est une hérésie pour n’importe qui&#xA;désirant un minimum de sécurité.  Ainsi, comme mentionné dans la &lt;a href=&#34;https://powa.readthedocs.io/en/latest/security.html#connection-on-remote-servers&#34;&gt;section&#xA;sécurité de la documentation de PoWA&#xA;&lt;/a&gt;,&#xA;vous pouvez stocker NULL pour le champ password et à la place utiliser&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/auth-methods.html&#34;&gt;n’importe laquelle des autres méthodes d’authentification supportée par la&#xA;libpq&lt;/a&gt;&#xA;(fichier .pgpass, certificat…).  Une authentification plus sécurisée est&#xA;chaudement recommandée pour toute installation sérieuse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une autre table, la table &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_snapshot_metas&lt;/code&gt;, est également ajoutée pour&#xA;stocker quelques métadonnées concernant les informations de snapshot pour&#xA;chaque &lt;em&gt;serveur distant&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;                                   &lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_snapshot_metas&#34;&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;                &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;--------------+--------------------------+-----------+----------+---------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;                  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;coalesce_seq&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;bigint&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;snapts&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;-infinity&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;aggts&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;-infinity&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;purgets&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;-infinity&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;errors&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Il s’agit tout simplement d’un compteur pour compter le nombre de snapshots&#xA;effectués, un timestamp pour chaque type d’événement survenu (snapshot,&#xA;aggrégation et purge) et un tableau de chaîne de caractères pour stocker toute&#xA;erreur survenant durant le snapshot, afin que l’UI pour l’afficher.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;api-sql-pour-configurer-les-serveurs-distants&#34;&gt;API SQL pour configurer les &lt;em&gt;serveurs distants&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Bien que ces tables soient très simples, une &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html#configure-powa-and-stats-extensions-on-each-remote-server&#34;&gt;API SQL basique est disponible&#xA;pour déclarer de nouveaux serveurs et les&#xA;configurer&lt;/a&gt;.&#xA;6 fonctions de bases sont disponibles :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_register_server()&lt;/code&gt;, pour déclarer un nouveau &lt;em&gt;servuer distant&lt;/em&gt;, ainsi&#xA;que la liste des extensions qui y sont disponibles&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_configure_server()&lt;/code&gt; pour mettre à jour un des paramètres pour le&#xA;&lt;em&gt;serveur distant&lt;/em&gt; spécifié (en utilisant un paramètre JSON, où la clé est&#xA;le nom du paramètre à changer et la valeur la nouvelle valeur à utiliser)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_deactivate_server()&lt;/code&gt; pour désactiver les snapshots pour le &lt;em&gt;serveur&#xA;distant&lt;/em&gt; spécifiqué (ce qui concrètement positionnera le paramètre&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;frequency&lt;/code&gt; à &lt;strong&gt;-1&lt;/strong&gt;)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_delete_and_purge_server()&lt;/code&gt; pour supprimer le &lt;em&gt;serveur distant&lt;/em&gt;&#xA;spécifié de la liste des serveurs et supprimer toutes les données associées&#xA;aux snapshots&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_activate_extension()&lt;/code&gt;, pour déclarer qu’une nouvelle extension est&#xA;disponible sur le &lt;em&gt;serveur distant&lt;/em&gt; spécifié&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_deactivate_extension()&lt;/code&gt;, pour spécifier qu’une extension n’est plus&#xA;disponible sur le &lt;em&gt;serveur distant&lt;/em&gt; spécifié&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Toute action plus compliquée que ça devra être effectuée en utilisant des&#xA;requêtes SQL.  Heureusement, il ne devrait pas y avoir beaucoup d’autres&#xA;besoins, et les tables sont vraiment très simple donc cela ne devrait pas poser&#xA;de soucis.  &lt;a href=&#34;https://github.com/powa-team/powa-archivist/issues&#34;&gt;N’hésitez cependant pas à demander de nouvelles&#xA;fonctions&lt;/a&gt; si vous aviez&#xA;d’autres besoins.  Veuillez également noter que l’UI ne vous permet pas&#xA;d’appeler ces fonctions, puisque celle-ci est pour le moment &lt;strong&gt;entièrement en&#xA;lecture seule&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;effectuer-des-snapshots-distants&#34;&gt;Effectuer des &lt;em&gt;snapshots distants&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Puisque les métriques sont maintenant stockées sur une instance PostgreSQL&#xA;différente, nous avons énormément changé la façon dont les &lt;em&gt;snapshots&lt;/em&gt;&#xA;(récupérer les données fournies par une &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/index.html&#34;&gt;extensions&#xA;statistique&lt;/a&gt;&#xA;et les stockées dans le catalogue PoWA &lt;a href=&#34;/postgresqlfr/2019/04/06/minimiser-le-surcout-de-stockage-par-ligne.html&#34;&gt;de manière à optimiser le stockage&lt;/a&gt;) sont&#xA;effectués.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La liste de toutes les extensions statistiques, ou &lt;em&gt;sources de données&lt;/em&gt;, qui&#xA;sont disponibles sur un &lt;strong&gt;serveur&lt;/strong&gt; (soit &lt;em&gt;distant&lt;/em&gt; soit &lt;em&gt;local&lt;/em&gt;) et pour&#xA;lesquelles un &lt;em&gt;snapshot&lt;/em&gt; devrait être effectué est stockée dans une table&#xA;appelée &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_functions&lt;/code&gt;:&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;               &lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_functions&#34;&lt;/span&gt;&#xA;     &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;----------------+---------+-----------+----------+---------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;module&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;operation&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;function_name&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;query_source&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;added_manually&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;boolean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;true&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;enabled&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;boolean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;true&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;priority&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;numeric&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Un nouveau champ &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;query_source&lt;/code&gt; a été rajouté.  Celui-ci fournit le nom de la&#xA;&lt;em&gt;fonction source&lt;/em&gt;, nécessaire pour la compatibilité d’une &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/index.html&#34;&gt;extension&#xA;statistique&lt;/a&gt;&#xA;avec les snapshots distants.  Cette fonction est utilisée pour exporter les&#xA;compteurs fournis par cette extension sur un serveur différent, dans une &lt;em&gt;table&#xA;transitoire&lt;/em&gt; dédiée.  La fonction de &lt;em&gt;snapshot&lt;/em&gt; effectuera alors le &lt;em&gt;snapshot&lt;/em&gt;&#xA;en utilisant automatiquement ces données exportées plutôt que celles fournies&#xA;par l’extension statististique locale quand le mode distant est utilisé.  Il&#xA;est à noter que l’export de ces compteurs ainsi que le snapshot distant est&#xA;effectué automatiquement par le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon&#xA;powa-collector&lt;/a&gt;&#xA;que je présenterai dans un autre article.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple montant comment PoWA effectue un &lt;em&gt;snapshot distant&lt;/em&gt; d’une&#xA;liste de base données.  Comme vous allez le voir, c’est très simple ce qui&#xA;signifie qu’il est également très simple d’ajouter cette même compatibilité&#xA;pour une nouvelle extension statistique.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La &lt;em&gt;table transitoire&lt;/em&gt;:&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;   &lt;span class=&#34;n&#34;&gt;Unlogged&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_databases_src_tmp&#34;&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;---------+---------+-----------+----------+---------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Pour de meilleurs performances, toutes les &lt;em&gt;tables transitoires&lt;/em&gt; sont &lt;strong&gt;non&#xA;journalisées (unlogged)&lt;/strong&gt;, puisque leur contenu n’est nécessaire que durant un&#xA;&lt;em&gt;snapshot&lt;/em&gt; et sont supprimées juste après.  Dans cet examlple, la &lt;em&gt;table&#xA;transitoire&lt;/em&gt; ne stocke que l’identifiant du serveur distant correspondant à ces&#xA;données, l’oid ainsi que le nom de chacune des bases de données présentes sur&#xA;le &lt;em&gt;serveur distant&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Et la &lt;em&gt;fonction source&lt;/em&gt; :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;OR&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;REPLACE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FUNCTION&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;powa_databases_src&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_srvid&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;OUT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;OUT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;RETURNS&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SETOF&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;record&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;LANGUAGE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plpgsql&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;BEGIN&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;IF&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_srvid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;THEN&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;RETURN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_database&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;ELSE&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;RETURN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powa_databases_src_tmp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;_srvid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;END&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IF&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;END&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Cette fonction retourne simplement le contenu de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_database&lt;/code&gt; si les données&#xA;locales sont demandées (l’identifiant de serveur &lt;strong&gt;0&lt;/strong&gt; est toujours le serveur&#xA;local), ou alors le contenu de la &lt;em&gt;table transitoire&lt;/em&gt; pour le serveur distant&#xA;spécifié.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La &lt;em&gt;fonction de snapshot&lt;/em&gt; peut alors facilement effectuer n’importe quel&#xA;traitement avec ces données pour le &lt;em&gt;serveur distant&lt;/em&gt; voulu.  Dans le cas de la&#xA;fonction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_databases_snapshot()&lt;/code&gt;, il s’agit simplement de synchroniser la&#xA;liste des bases de données, et de stocker le timestamp de suppression si une&#xA;base de données qui existait précédemment n’est plus listée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour plus de détails, vous pouvez consulter la documentation concernant&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/development.html&#34;&gt;l’ajout d’une source de données dans&#xA;PoWA&lt;/a&gt;,&#xA;qui a été mise à jour pour les spécificités de la version 4.&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/06/05/powa-4-nouveaute-dans-powa-archivist.html&#34;&gt;PoWA 4: nouveautés dans powa-archivist !&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on June 05, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/06/05/powa-4-nouveaute-dans-powa-archivist.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>PoWA 4 apporte un mode remote, disponible en beta !</title>
    <updated>2019-05-17T11:04:17Z</updated>
    <id>tag:rjuju.github.io,2019-05-17:/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html</id>
    <content type="html">&lt;p&gt;&lt;a href=&#34;http://powa.readthedocs.io/&#34;&gt;PoWA 4&lt;/a&gt; est disponible en beta.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;nouveau-mode-remote-&#34;&gt;Nouveau mode remote !&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html&#34;&gt;nouveau mode remote&lt;/a&gt;&#xA;est la plus grosse fonctionnalité ajoutée dans PoWA 4, bien qu’il y ait eu&#xA;d’autres améliorations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Je vais décrire ici ce que ce nouveau mode implique ainsi que ce qui a changé&#xA;sur l’&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-web/index.html&#34;&gt;UI&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si de plus amples détails sur le reste des changements apportés dans PoWA 4&#xA;vous intéresse, je publierai bientôt d’autres articles sur le sujet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour les plus pressés, n’hésitez pas à aller directement sur la &lt;a href=&#34;https://dev-powa.anayrat.info/&#34;&gt;démo v4 de&#xA;PoWA&lt;/a&gt;, très gentiment hébergée par &lt;a href=&#34;http://blog.anayrat.info/&#34;&gt;Adrien&#xA;Nayrat&lt;/a&gt;.  Aucun authentification n’est requise,&#xA;cliquez simplement sur “Login”.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;pourquoi-un-mode-remote-est-il-important&#34;&gt;Pourquoi un mode remote est-il important&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette fonctionnalité a probablement été la plus fréquemment demandée depuis que&#xA;PoWA a été publié, en 2014.  Et c’est pour de bonnes raisons, car un mode local&#xA;a quelques inconvénients.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tout d’abord, voyons comment se présentait l’architecture avec les versions 3&#xA;et antérieures.  Imaginons une instance contenant 2 bases de données (db1 et&#xA;db2), ainsi qu’&lt;strong&gt;une base de données dédiée à PoWA&lt;/strong&gt;.  Cette base de données&#xA;dédiée contient à la fois les &lt;em&gt;extensions statistiques&lt;/em&gt; nécessaires pour&#xA;récupérer compteurs de performances actuels ainsi que pour &lt;strong&gt;les stocker&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_local.svg&#34;&gt;&lt;img src=&#34;/images/powa_4_local.svg&#34; alt=&#34;Architecture en mode local&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Un &lt;em&gt;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/configuration.html#background-worker-configuration&#34;&gt;background&#xA;worker&lt;/a&gt;&lt;/em&gt;&#xA;est démarré par PoWA, qui est responsable d’effectuer des &lt;em&gt;snapshots&lt;/em&gt; et de les&#xA;stocker dans la base powa dédiée à intervalle réguliers.  Ensuite, en utilisant&#xA;powa-web, vous pouvez consulter l’activité de n’importe laquelle des bases de&#xA;données &lt;strong&gt;locales&lt;/strong&gt; en effectuant des requêtes sur les données stockées dans la&#xA;base dédié, et potentiellement en se connectant sur l’une des autres bases de&#xA;données locales lorsque les données complètes sont nécessaires, par exemple&#xA;lorsque l’outil de suggestion d’index est utilisé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Avec la version 4, l’architecture avec une configuration distante change de&#xA;manière significative:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_remote.svg&#34;&gt;&lt;img src=&#34;/images/powa_4_remote.svg&#34; alt=&#34;Architecture en mode distant&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Vous pouvez voir qu’une base de donnée powa dédiée est toujours nécessaire,&#xA;mais &lt;strong&gt;uniquement pour les extensions statistiques&lt;/strong&gt;.  Les données sont&#xA;maintenant stockées sur une instance différente.  Ensuite, le &lt;em&gt;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/configuration.html#background-worker-configuration&#34;&gt;background&#xA;worker&lt;/a&gt;&lt;/em&gt;&#xA;est remplacé par un &lt;strong&gt;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;nouveau daemon&#xA;collecteur&lt;/a&gt;&lt;/strong&gt;,&#xA;qui lit les métriques de performance depuis les &lt;em&gt;serveurs distants&lt;/em&gt;, et les&#xA;stocke sur le &lt;em&gt;serveur repository&lt;/em&gt; dédié.  Powa-web pourra présenter les&#xA;données en se connectant sur le &lt;em&gt;serveur repository&lt;/em&gt;, ainsi que sur les&#xA;&lt;strong&gt;serveurs distants&lt;/strong&gt; lorsque des données complètes sont nécessaires.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En résumé, avec le nouveau mode distant ajouté dans cette version 4&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;un redémarrage de PostgreSQL n’est plus nécessaire pour installer&#xA;powa-archivist&lt;/li&gt;&#xA;  &lt;li&gt;il n’y a plus de surcoût du au fait de stocker et requêter les données sur&#xA;le même serveur PostgreSQL que vos serveurs de productions (il y a toujours&#xA;certaines partie de l’UI qui nécessitent d’effectuer des requêtes sur le&#xA;serveur d’origine, par exemple pour montrer des plans avec EXPLAIN, mais le&#xA;surcoût est négligeable)&lt;/li&gt;&#xA;  &lt;li&gt;il est maintenant possible d’utiliser PoWA sur un &lt;strong&gt;serveur en&#xA;hot-standby&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;L’UI vous accueillera donc maintenant avec une page initiale afin de choisir&#xA;lequel des serveurs stockés sur la base de données cible vous voulez&#xA;travailler :&#xA;&lt;a href=&#34;/images/powa_4_all_servers.png&#34;&gt;&lt;img src=&#34;/images/powa_4_all_servers.png&#34; alt=&#34;Choix des serveurs&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La principale raison pour laquelle il a fallu tellement de temps pour apporter&#xA;ce mode distant est parce que cela apporte beaucoup de complexité, nécessitant&#xA;une réécriture majeure de PoWA.  Nous voulions également ajouter d’abord&#xA;d’autres fonctionnalités, comme la &lt;strong&gt;suggestion globale d’index&lt;/strong&gt;, avec une&#xA;&lt;strong&gt;validation grâce à &lt;a href=&#34;http://hypopg.readthedocs.io/&#34;&gt;hypopg&lt;/a&gt;&lt;/strong&gt; introduit avec&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/releases/v3.0.0.html&#34;&gt;PoWA 3&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;changements-dans-powa-web&#34;&gt;Changements dans &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-web/index.html&#34;&gt;powa-web&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;L’&lt;em&gt;interface graphique&lt;/em&gt; est le composant qui a le plus de changements visibles&#xA;dans cette version 4.  Voici les plus changements les plus importants.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;compatibilité-avec-le-mode-distant&#34;&gt;Compatibilité avec le mode distant&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Le changement le plus important est bien évidemment le support pour le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html&#34;&gt;nouveau&#xA;mode remote&lt;/a&gt;.  En&#xA;conséquence, la première page affichée est maintenant une page de &lt;strong&gt;sélection&#xA;de serveur&lt;/strong&gt;, affichant tous les &lt;em&gt;serveurs distants&lt;/em&gt; enregistrés.  Après avoir&#xA;choisi le &lt;em&gt;serveur distant&lt;/em&gt; voulu (ou le &lt;em&gt;serveur local&lt;/em&gt; si vous n’utilisez pas&#xA;le mode distant), toutes les autres pages seront similaires à celles&#xA;disponibles jusqu’à la version 3, mais afficheront les données pour un &lt;em&gt;serveur&#xA;distant&lt;/em&gt; spécifique uniquement, et bien entendu en récupérant les données&#xA;depuis la &lt;strong&gt;base de données repository&lt;/strong&gt;, avec en plus de nouvelles&#xA;informations décrites ci-dessous.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez notez que puisque les données sont maintenant stockées sur un &lt;em&gt;serveur&#xA;repository&lt;/em&gt; dédié quand le mode remote est utilisé, la majorité de l’UI est&#xA;utilisable sans se connecter au &lt;em&gt;serveur distant&lt;/em&gt; sélectionné.  Toutefois,&#xA;powa-web nécessite toujours de pouvoir se connecter sur le &lt;em&gt;serveur distant&lt;/em&gt;&#xA;quand les données originales sont nécessaires (par exemple, pour la suggestion&#xA;d’index ou pour montrer des plans avec &lt;strong&gt;EXPLAIN&lt;/strong&gt;).  Les &lt;a href=&#34;https://powa.readthedocs.io/en/latest/security.html#connection-on-remote-servers&#34;&gt;mêmes considérations&#xA;et possibilités concernant&#xA;l’authentification&lt;/a&gt;&#xA;que pour le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon powa-collector&#xA;&lt;/a&gt;&#xA;(qui sera décrit dans un prochain article) s’appliquent ici.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;pg_track_settings-support&#34;&gt;&lt;a href=&#34;https://github.com/rjuju/pg_track_settings/&#34;&gt;pg_track_settings&lt;/a&gt; support&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Quand cette extension est correctement configurée, un nouveau widget timeline&#xA;apparaîtra, placé entre chaque graph et son aperçu, affichant différents types&#xA;de changements enregistrés si ceux-ci ont été détectés sur l’intervalle de&#xA;temps sélectionné.  Sur les pages par base de données et par requête, la liste&#xA;sera également filtrée en fonction de la base de données sélectionnée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La même timeline sera affichée sur chacun des graphs de chacune des pages, afin&#xA;de facilement vérifier si ces changements ont eu un impact visible en utilisant&#xA;les différents graphs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez noter que les détails des changements sont affichés au survol de la&#xA;souris.  Vous pouvez également cliquer sur n’importe lequel des événements de&#xA;la timeline pour figer l’affichage, et tracer une ligne verticale sur le graph&#xA;associé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple d’un tel changement de configuration en action :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/pg_track_settings_powa4.png&#34;&gt;&lt;img src=&#34;/images/pg_track_settings_powa4.png&#34; alt=&#34;Changements de configuration détectés&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez également noter qu’il est nécessaire d’avoir au minimum la version&#xA;2.0.0 de &lt;a href=&#34;https://github.com/rjuju/pg_track_settings/&#34;&gt;pg_track_settings&lt;/a&gt;, et&#xA;que l’extension doit être installée &lt;strong&gt;à la fois sur les &lt;em&gt;serveurs distants&lt;/em&gt;&#xA;ainsi que sur le &lt;em&gt;serveur repository&lt;/em&gt;.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;nouveaux-graphs-disponibles&#34;&gt;Nouveaux graphs disponibles&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Quand&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/pg_stat_kcache.html&#34;&gt;pg_stat_kcache&lt;/a&gt;&#xA;est configuré, ses informations n’étaient auparavant affichées que sur la page&#xA;par requête.  Les informations sont maintenant également affichées sur les&#xA;pages par serveur et par base, dans deux nouveaux graphs :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;dans le graph &lt;strong&gt;Block Access&lt;/strong&gt;, où les métriques &lt;strong&gt;OS cache&lt;/strong&gt; et &lt;strong&gt;disk&#xA;read&lt;/strong&gt; remplaceront la métrique &lt;strong&gt;read&lt;/strong&gt;&lt;/li&gt;&#xA;  &lt;li&gt;dans un nouveau graph &lt;strong&gt;System Resources&lt;/strong&gt; (qui est également ajouté dans&#xA;la page &lt;em&gt;par requête&lt;/em&gt;), montrant les &lt;a href=&#34;/postgresql/2018/07/17/pg_stat_kcache-2-1-is-out.html&#34;&gt;metrics ajoutées dans pg_stat_kcache&#xA;2.1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Voici un example de ce nouveau graph &lt;strong&gt;System Resources&lt;/strong&gt; :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/pg_stat_kcache_system_resources_powa4.png&#34;&gt;&lt;img src=&#34;/images/pg_stat_kcache_system_resources_powa4.png&#34; alt=&#34;Ressources système&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il y avait également un graph &lt;strong&gt;Wait Events&lt;/strong&gt; (disponible quand &lt;a href=&#34;https://powa.readthedocs.io/en/v4/components/stats_extensions/pg_wait_sampling.html&#34;&gt;l’extension&#xA;pg_wait_sampling&lt;/a&gt;&#xA;est configuée) disponible uniquement sur la page par requête.  Ce graph est&#xA;maintenant disponible sur les pages par serveur et par base également.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;documentation-des-métriques-et-liens-vers-la-documentation&#34;&gt;Documentation des métriques et liens vers la documentation&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Certaines métriques affichées sur l’interface sont assez parlante, mais&#xA;certaines autres peuvent être un peu obscures.  Jusqu’à maintenant, il n’y&#xA;avait malheureusement aucune documentation pour les métriques.  Le problème est&#xA;maintenant réglé, et tous les graphs ont une &lt;em&gt;icône d’information&lt;/em&gt;, qui&#xA;affichent une description des métriques utilisée dans le graph au survol de la&#xA;souris.  Certains graphs incluent également un lien vers la &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/index.html&#34;&gt;documentation PoWA&#xA;de extension&#xA;statistiques&lt;/a&gt;&#xA;pour les utilisateurs qui désirent en apprendre plus à leur sujet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_metrics_doc.png&#34;&gt;&lt;img src=&#34;/images/powa_4_metrics_doc.png&#34; alt=&#34;Documentation des métriques&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;et-des-correctifs-de-bugs-divers&#34;&gt;Et des correctifs de bugs divers&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Certains problèmes de longues dates ont également été rapportés :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;la boîte affichée au survol d’un graph montant les valeurs des métriques&#xA;avait une position verticale incorrecte&lt;/li&gt;&#xA;  &lt;li&gt;la sélection temporelle en utilisant l’aperçu des graphs ne montrait pas un&#xA;aperçu correct après avoir appliqué la sélection&lt;/li&gt;&#xA;  &lt;li&gt;les erreurs lors de la création d’index hypothétiques ou dans certains cas&#xA;leur affichage n’était pas correctement gérés sur plusieurs pages&lt;/li&gt;&#xA;  &lt;li&gt;les filtres des tableaux n’était pas réappliqués quand l’intervalle de&#xA;temps sélectionné était changé&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Si un de ces problèmes vous a un jour posé problème, vous serez ravi&#xA;d’apprendre qu’ils sont maintenant tous corrigés !&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette 4ème version de PoWA représente un temps de développement très important,&#xA;de nombreuses améliorations sur la documentation et beaucoup de tests.  Nous&#xA;somme maintenant assez satisfaits, mais il est possible que nous ayons ratés&#xA;certains bugs.  Si vous vous intéressez à ce projet, j’espère que vous&#xA;essaierez de tester cette beta, et si besoin n’hésitez pas à &lt;a href=&#34;https://powa.readthedocs.io/en/latest/support.html#support&#34;&gt;nous remonter un&#xA;bug&lt;/a&gt;!&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html&#34;&gt;PoWA 4 apporte un mode remote, disponible en beta !&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on May 17, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>Nouveauté pg12: Statistiques sur les erreurs de checkums</title>
    <updated>2019-04-18T11:02:26Z</updated>
    <id>tag:rjuju.github.io,2019-04-18:/postgresqlfr/2019/04/18/nouveau-dans-pg12-statistiques-erreurs-checksums.html</id>
    <content type="html">&lt;h3 id=&#34;data-checksums&#34;&gt;Data checksums&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Ajoutés dans &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=96ef3b8ff1c&#34;&gt;PostgreSQL&#xA;9.3&lt;/a&gt;,&#xA;les &lt;a href=&#34;https://www.postgresql.org/docs/current/app-initdb.html#APP-INITDB-DATA-CHECKSUMS&#34;&gt;data&#xA;checksums&lt;/a&gt;&#xA;peuvent aider à détecter les corruptions de données survenant sur votre&#xA;stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les checksums sont activés si l’instance a été initialisée en utilisant &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;initdb&#xA;--data-checksums&lt;/code&gt; (ce qui n’est pas le comportement par défaut), ou s’ils ont&#xA;été activés après en utilisant la nouvelle utilitaire&#xA;activated afterwards with the new&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/devel/app-pgchecksums.html&#34;&gt;pg_checksums&lt;/a&gt;&#xA;également &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=ed308d783790&#34;&gt;ajouté dans PostgreSQL&#xA;12&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Quand les checksums sont ativés, ceux-ci sont écrits à chaque fois qu’un bloc&#xA;de données est écrit sur disque, et vérifiés à chaque fois qu’un bloc est lu&#xA;depuis le disque (ou depuis le cache du système d’exploitation).  Si la&#xA;vérification échoue, une erreur est remontée dans les logs.  Si le bloc était&#xA;lu par un processus client, la requête associée échouera bien évidemment, mais&#xA;si le bloc était lu par une opération&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/protocol-replication.html#id-1.10.5.9.7.1.8.1.12&#34;&gt;BASE_BACKUP&lt;/a&gt;&#xA;(tel que pg_basebackup), la commande continuera à s’exécuter.  Bien que les&#xA;data checksums ne détecteront qu’un sous ensemble des problèmes possibles, ils&#xA;ont tout de même une certaine utilisé, surtout si vous ne faites pas confiance&#xA;à votre stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Jusqu’à PostgreSQL 11, les erreurs de validation de checksum ne pouvaient être&#xA;trouvées qu’en cherchant dans les logs, ce qui n’est clairement pas pratique si&#xA;vous voulez monitorer de telles erreurs.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;nouveaux-compteurs-disponibles-dans-pg_stat_database&#34;&gt;Nouveaux compteurs disponibles dans pg_stat_database&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Pour rendre la supervision des erreurs de checksum plus simple, et pour aider&#xA;les utilisateurs à réagir dès qu’un tel problème survient, PostgreSQL 12 ajoute&#xA;de nouveaux compteurs dans la vue &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_database&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit 6b9e875f7286d8535bff7955e5aa3602e188e436&#xA;Author: Magnus Hagander &amp;lt;magnus@hagander.net&amp;gt;&#xA;Date:   Sat Mar 9 10:45:17 2019 -0800&#xA;&#xA;Track block level checksum failures in pg_stat_database&#xA;&#xA;This adds a column that counts how many checksum failures have occurred&#xA;on files belonging to a specific database. Both checksum failures&#xA;during normal backend processing and those created when a base backup&#xA;detects a checksum failure are counted.&#xA;&#xA;Author: Magnus Hagander&#xA;Reviewed by: Julien Rouhaud&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit 77bd49adba4711b4497e7e39a5ec3a9812cbd52a&#xA;Author: Magnus Hagander &amp;lt;magnus@hagander.net&amp;gt;&#xA;Date:   Fri Apr 12 14:04:50 2019 +0200&#xA;&#xA;    Show shared object statistics in pg_stat_database&#xA;&#xA;    This adds a row to the pg_stat_database view with datoid 0 and datname&#xA;    NULL for those objects that are not in a database. This was added&#xA;    particularly for checksums, but we were already tracking more satistics&#xA;    for these objects, just not returning it.&#xA;&#xA;    Also add a checksum_last_failure column that holds the timestamptz of&#xA;    the last checksum failure that occurred in a database (or in a&#xA;    non-dataabase file), if any.&#xA;&#xA;    Author: Julien Rouhaud &amp;lt;rjuju123@gmail.com&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit 252b707bc41cc9bf6c55c18d8cb302a6176b7e48&#xA;Author: Magnus Hagander &amp;lt;magnus@hagander.net&amp;gt;&#xA;Date:   Wed Apr 17 13:51:48 2019 +0200&#xA;&#xA;    Return NULL for checksum failures if checksums are not enabled&#xA;&#xA;    Returning 0 could falsely indicate that there is no problem. NULL&#xA;    correctly indicates that there is no information about potential&#xA;    problems.&#xA;&#xA;    Also return 0 as numbackends instead of NULL for shared objects (as no&#xA;    connection can be made to a shared object only).&#xA;&#xA;    Author: Julien Rouhaud &amp;lt;rjuju123@gmail.com&amp;gt;&#xA;    Reviewed-by: Robert Treat &amp;lt;rob@xzilla.net&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Ces compteurs reflèteront les erreurs de validation de checksum à la fois pour&#xA;les processus clients et pour l’activité&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/protocol-replication.html#id-1.10.5.9.7.1.8.1.12&#34;&gt;BASE_BACKUP&lt;/a&gt;,&#xA;par base de données.&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;n&#34;&gt;rjuju&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_stat_database&lt;/span&gt;&#xA;                        &lt;span class=&#34;k&#34;&gt;View&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;pg_catalog.pg_stat_database&#34;&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-----------------------+--------------------------+-----------+----------+---------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;datid&lt;/span&gt;                 &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;                      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt;               &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;                     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;p&#34;&gt;[...]&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;checksum_failures&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;bigint&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;checksum_last_failure&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;p&#34;&gt;[...]&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;stats_reset&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;La colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;checksum_failures&lt;/code&gt; montrera un nombre cumulé d’erreurs, et la&#xA;colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;checksum_last_failure&lt;/code&gt; montrera l’horodatage de la dernière erreur de&#xA;validation sur la base de données (NULL si aucune erreur n’est jamais&#xA;survenue).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour éviter toute confusion (merci à Robert Treat pour l’avoir signalé), ces&#xA;deux colonnes retourneront toujours NULL si les data checkums ne sont pas&#xA;activés, afin qu’on ne puisse pas croire que les checksums sont toujours&#xA;vérifiés avec succès.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Comme effet de bord, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_database&lt;/code&gt;  montrera maintenant également les&#xA;statistiques disponibles pour les objets partagés (tels que la table&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_database&lt;/code&gt; par exemple), dans une nouvelle ligne pour laquelle &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;datid&lt;/code&gt; vaut&#xA;&lt;strong&gt;0&lt;/strong&gt;, et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;datname&lt;/code&gt; vaut &lt;strong&gt;NULL&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;del&gt;Une sonde dédiée est également &lt;a href=&#34;https://github.com/OPMDG/check_pgactivity/issues/226&#34;&gt;déjà&#xA;planifiée&lt;/a&gt; dans&#xA;&lt;a href=&#34;https://opm.readthedocs.io/probes/check_pgactivity.html&#34;&gt;check_pgactivity&lt;/a&gt; !&lt;/del&gt;&#xA;Une sonde dédiée est également &lt;a href=&#34;https://github.com/OPMDG/check_pgactivity/commit/0e8b516e95e4364470d4e205aebc9fe68bbcfd23&#34;&gt;déjà&#xA;disponible&lt;/a&gt;&#xA;dans &lt;a href=&#34;https://opm.readthedocs.io/probes/check_pgactivity.html&#34;&gt;check_pgactivity&lt;/a&gt; !&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/04/18/nouveau-dans-pg12-statistiques-erreurs-checksums.html&#34;&gt;Nouveauté pg12: Statistiques sur les erreurs de checkums&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on April 18, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/04/18/nouveau-dans-pg12-statistiques-erreurs-checksums.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>Mettre en place une streaming replication avec PostgreSQL 10</title>
    <updated>2018-03-13T06:28:00Z</updated>
    <id>tag:blog.raveland.tech,2018-03-13:/post/postgresql_sr_fr/</id>
    <link href="https://blog.raveland.tech/post/postgresql_sr_fr/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Dans ce post, je vais vous expliquer comment mettre en place une &lt;em&gt;streaming replication&lt;/em&gt; avec PostgreSQL 10. Par contre, je n&amp;rsquo;expliquerais pas comment installer PostgreSQL donc je suppose que cela est déjà le cas.&lt;/p&gt;</summary>
    <author>
      <name>blog.raveland.tech</name>
    </author>
  </entry>
  <entry>
    <title>OpenBSD / PostgreSQL / Authentification</title>
    <updated>2017-11-29T11:31:53Z</updated>
    <id>tag:blog.raveland.tech,2017-11-29:/post/openbsd_pg/</id>
    <link href="https://blog.raveland.tech/post/openbsd_pg/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Si vous êtes un utilisateur d&amp;rsquo;OpenBSD et de PostgreSQL, vous pouvez utiliser l&amp;rsquo;authentification BSD pour vous authentifier sur vos bases.&#xA;Nous allons voir comment faire cela.&lt;/p&gt;</summary>
    <author>
      <name>blog.raveland.tech</name>
    </author>
  </entry>
  <entry>
    <title>Postgresql et la réplication logique</title>
    <updated>2017-11-27T08:32:06Z</updated>
    <id>tag:blog.raveland.tech,2017-11-27:/post/postgresql_lr/</id>
    <link href="https://blog.raveland.tech/post/postgresql_lr/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cet article va tester la nouvelle fonctionnalité disponible depuis PostgreSQL 10.0 : la réplication logique.&lt;/p&gt;&#xA;&lt;p&gt;Pour en savoir plus, l&amp;rsquo;excellente &lt;a href=&#34;https://docs.postgresql.fr/10/logical-replication.html&#34;&gt;documentation de PostgreSQL&lt;/a&gt;&lt;/p&gt;</summary>
    <author>
      <name>blog.raveland.tech</name>
    </author>
  </entry>
</feed>