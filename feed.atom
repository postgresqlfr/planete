<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>Planète PostgreSQL</title>
  <id>https://planete.postgresql.fr/</id>
  <updated>2025-03-13T16:43:34Z</updated>
  <subtitle>L&#39;actualité de PostgreSQL de français</subtitle>
  <link href="https://planete.postgresql.fr/"></link>
  <author>
    <name>PostgreSQL.fr</name>
    <email>contact@postgresql.fr</email>
  </author>
  <entry>
    <title>L&#39;extension pg_trgm</title>
    <updated>2025-03-07T08:20:00Z</updated>
    <id>tag:www.loxodata.com,2025-03-07:/post/pg_trgm/</id>
    <link href="http://www.loxodata.com/post/pg_trgm/" rel="alternate"></link>
    <summary type="html">&lt;h1 id=&#34;lextension-pg_trgm&#34;&gt;L&amp;rsquo;extension pg_trgm&lt;/h1&gt;&#xA;&lt;h2 id=&#34;présentation&#34;&gt;Présentation&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;rsquo;extension &lt;code&gt;pg_trgm&lt;/code&gt; (trigrammes) est fournie dans la distribution standard de PostgreSQL. Elle est présente dans &lt;code&gt;/contrib&lt;/code&gt; et s&amp;rsquo;installe simplement dans une base de données :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# CREATE EXTENSION IF NOT EXISTS pg_trgm;&#xA;CREATE EXTENSION&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cette extension permet de décomposer une chaîne de caractères en succession de sous-chaînes de 3 caractères (trigrammes), afin de permettre des recherches sur une sous-chaîne, ou bien des recherches de similarité entre chaînes de caractères.&lt;/p&gt;&#xA;&lt;h2 id=&#34;fonctionnement&#34;&gt;Fonctionnement&lt;/h2&gt;&#xA;&lt;h3 id=&#34;jeu-dessai&#34;&gt;Jeu d&amp;rsquo;essai&lt;/h3&gt;&#xA;&lt;p&gt;Dans le cadre de cette présentation, je me suis constitué une table d&amp;rsquo;un million de lignes, laquelle contient un champ &lt;code&gt;family&lt;/code&gt; contenant un nom de famille parmi les 1000 plus fréquent en France, et dont la fréquence dans la table est semblable à celle de la population française :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# \dS my_datas&#xA;                              Table &amp;#34;public.my_datas&amp;#34;&#xA;   Column    |  Type  | Collation | Nullable |               Default&#xA;-------------+--------+-----------+----------+--------------------------------------&#xA; id          | bigint |           | not null | nextval(&amp;#39;my_datas_id_seq&amp;#39;::regclass)&#xA; random_text | text   |           |          |&#xA; family      | text   |           |          |&#xA;Indexes:&#xA;    &amp;#34;idx_test_id&amp;#34; btree (id)&#xA;&#xA;loxodata_text=# SELECT count(1) FROM my_datas;&#xA;  count&#xA;---------&#xA; 1000204&#xA;(1 row)&#xA;&#xA;loxodata_text=# SELECT * FROM my_datas LIMIT 5;&#xA;   id   |             random_text              | family&#xA;--------+--------------------------------------+---------&#xA; 211685 | 94376bb6-3655-4a65-b61a-8dbec927c5e5 | GRANGER&#xA; 211686 | 7f9f8a34-13f2-4459-bd2c-e4b90a7eca9b | LE ROUX&#xA; 211687 | 526549b3-13fe-4aae-87c1-4a5480cf6898 | FUCHS&#xA; 211688 | 1acbdde8-b4cd-4bf8-957c-84adf1c6cf1c | BRUNET&#xA; 211689 | 77cd8645-bfe8-471c-a118-3dbe507d8e8f | LAMBERT&#xA;(5 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;décomposition&#34;&gt;Décomposition&lt;/h3&gt;&#xA;&lt;p&gt;On peut visualiser la décomposition en trigrammes avec la fonction &lt;code&gt;show_trgm()&lt;/code&gt; :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# SELECT show_trgm(&amp;#39;GRANGER&amp;#39;);&#xA;                show_trgm&#xA;-----------------------------------------&#xA; {&amp;#34;  g&amp;#34;,&amp;#34; gr&amp;#34;,ang,&amp;#34;er &amp;#34;,ger,gra,nge,ran}&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;similarité&#34;&gt;Similarité&lt;/h3&gt;&#xA;&lt;p&gt;La fonction &lt;code&gt;similarity()&lt;/code&gt; permet de tester la similarité entre deux chaînes de caractères. Le résultat est un score entre 0 et 1. Zéro indique qu&amp;rsquo;il n&amp;rsquo;y a aucun trigramme en commun entre les deux chaînes, tandis que 1 indique que les deux chaînes sont identiques. On peut ainsi tester la similarité entre deux noms de famille :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# select similarity(&amp;#39;GRANGER&amp;#39;,&amp;#39;BRUNET&amp;#39;);&#xA; similarity&#xA;------------&#xA;          0&#xA;(1 row)&#xA;&#xA;loxodata_text=# select similarity(&amp;#39;GRANGER&amp;#39;,&amp;#39;GRANGE&amp;#39;);&#xA; similarity&#xA;------------&#xA;  0.6666667&#xA;(1 row)&#xA;&#xA;loxodata_text=# select similarity(&amp;#39;GRANGER&amp;#39;,&amp;#39;GRANIER&amp;#39;);&#xA; similarity&#xA;------------&#xA; 0.45454547&#xA;(1 row)&#xA;&#xA;loxodata_text=# select similarity(&amp;#39;GRANGER&amp;#39;,&amp;#39;LEGRAND&amp;#39;);&#xA; similarity&#xA;------------&#xA; 0.14285715&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;L&amp;rsquo;opérateur booléen de similarité entre deux chaînes est &lt;code&gt;%&lt;/code&gt; :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# select &amp;#39;GRANGER&amp;#39; % &amp;#39;GRANIER&amp;#39;;&#xA; ?column?&#xA;----------&#xA; t&#xA;(1 row)&#xA;&#xA;loxodata_text=# select &amp;#39;GRANGER&amp;#39; % &amp;#39;LEGRAND&amp;#39;;&#xA; ?column?&#xA;----------&#xA; f&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;L&amp;rsquo;opérateur booléen retourne &lt;code&gt;True&lt;/code&gt; si le score de similarité excède une limite fixée par défaut à &lt;code&gt;0.3&lt;/code&gt;. La limite courante peut être consultée avec la fonction &lt;code&gt;show_limit()&lt;/code&gt; :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# select show_limit();&#xA; show_limit&#xA;------------&#xA;        0.3&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Et cette limite peut être modifiée au niveau de la session avec la fonction &lt;code&gt;set_limit()&lt;/code&gt;. Ainsi, si on passe le seuil à &lt;code&gt;0.1&lt;/code&gt;, &amp;lsquo;GRANGER&amp;rsquo; et &amp;lsquo;LEGRAND&amp;rsquo; sont désormais considérés comme similaires :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# select set_limit(0.1);&#xA; set_limit&#xA;-----------&#xA;       0.1&#xA;(1 row)&#xA;&#xA;loxodata_text=# select &amp;#39;GRANGER&amp;#39; % &amp;#39;LEGRAND&amp;#39;;&#xA; ?column?&#xA;----------&#xA; t&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cette limite peut être configurée au niveau du cluster avec le paramètre &lt;code&gt;pg_trgm.similarity_threshold&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;indexation-et-performances&#34;&gt;Indexation et performances&lt;/h2&gt;&#xA;&lt;h3 id=&#34;lindexation-btree-classique&#34;&gt;L&amp;rsquo;indexation BTREE classique&lt;/h3&gt;&#xA;&lt;p&gt;Les champs TEXT peuvent être indexés classiquement avec un index BTREE :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# CREATE INDEX idx_test ON my_datas(family text_pattern_ops);&#xA;CREATE INDEX&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cela permet de trouver rapidement des chaînes de caractères ou des débuts de chaînes de caractères :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT id FROM my_datas WHERE family = &amp;#39;GRANGER&amp;#39;;&#xA;                                                     QUERY PLAN&#xA;---------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=10.09..2289.04 rows=731 width=8) (actual time=0.101..0.584 rows=658 loops=1)&#xA;   Recheck Cond: (family = &amp;#39;GRANGER&amp;#39;::text)&#xA;   Heap Blocks: exact=637&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test  (cost=0.00..9.91 rows=731 width=0) (actual time=0.047..0.047 rows=658 loops=1)&#xA;         Index Cond: (family = &amp;#39;GRANGER&amp;#39;::text)&#xA; Planning Time: 0.120 ms&#xA; Execution Time: 0.612 ms&#xA;(7 rows)&#xA;&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT id FROM my_datas WHERE family like  &amp;#39;GRAN%&amp;#39;;&#xA;                                                      QUERY PLAN&#xA;-----------------------------------------------------------------------------------------------------------------------&#xA; Index Scan using idx_test on my_datas  (cost=0.42..8.45 rows=66 width=8) (actual time=0.024..2.121 rows=3692 loops=1)&#xA;   Index Cond: ((family ~&amp;gt;=~ &amp;#39;GRAN&amp;#39;::text) AND (family ~&amp;lt;~ &amp;#39;GRAO&amp;#39;::text))&#xA;   Filter: (family ~~ &amp;#39;GRAN%&amp;#39;::text)&#xA; Planning Time: 0.137 ms&#xA; Execution Time: 2.234 ms&#xA;(5 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cependant un tel index se révèle inutile lorsqu&amp;rsquo;on ne connaît pas le début de la chaîne recherchée. Dans ce cas on bascule sur un Seq Scan malgré la présence de l&amp;rsquo;index :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT id FROM my_datas WHERE family like  &amp;#39;%ANGER&amp;#39;;&#xA;                                                        QUERY PLAN&#xA;---------------------------------------------------------------------------------------------------------------------------&#xA; Gather  (cost=1000.00..17185.70 rows=6643 width=8) (actual time=0.196..36.796 rows=2585 loops=1)&#xA;   Workers Planned: 2&#xA;   Workers Launched: 2&#xA;   -&amp;gt;  Parallel Seq Scan on my_datas  (cost=0.00..15521.40 rows=2768 width=8) (actual time=0.027..33.117 rows=862 loops=3)&#xA;         Filter: (family ~~ &amp;#39;%ANGER&amp;#39;::text)&#xA;         Rows Removed by Filter: 332540&#xA; Planning Time: 0.071 ms&#xA; Execution Time: 36.894 ms&#xA;(8 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;indexation-des-trigrammes&#34;&gt;Indexation des trigrammes&lt;/h3&gt;&#xA;&lt;p&gt;Il est possible d&amp;rsquo;indexer les vecteurs de trigrammes avec un index GIN :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# CREATE INDEX idx_test_trgm ON my_datas USING GIN(family gin_trgm_ops);&#xA;CREATE INDEX&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;La recherche sur la fin de chaîne de caractères se fait maintenant en utilisant l&amp;rsquo;index nouvellement créé :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT id FROM my_datas WHERE family like  &amp;#39;%ANGER&amp;#39;;&#xA;                                                         QUERY PLAN&#xA;-----------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=94.35..9754.04 rows=6643 width=8) (actual time=1.422..3.197 rows=2585 loops=1)&#xA;   Recheck Cond: (family ~~ &amp;#39;%ANGER&amp;#39;::text)&#xA;   Heap Blocks: exact=2292&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..92.69 rows=6643 width=0) (actual time=1.193..1.194 rows=2585 loops=1)&#xA;         Index Cond: (family ~~ &amp;#39;%ANGER&amp;#39;::text)&#xA; Planning Time: 0.085 ms&#xA; Execution Time: 3.282 ms&#xA;(7 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nous pouvons maintenant effectuer une recherche de similarité :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT DISTINCT family FROM my_datas WHERE family %  &amp;#39;GRANGER&amp;#39;;&#xA;                                                               QUERY PLAN&#xA;----------------------------------------------------------------------------------------------------------------------------------------&#xA; Unique  (cost=370.28..370.61 rows=64 width=7) (actual time=19.476..19.867 rows=6 loops=1)&#xA;   -&amp;gt;  Sort  (cost=370.28..370.45 rows=66 width=7) (actual time=19.474..19.632 rows=4284 loops=1)&#xA;         Sort Key: family&#xA;         Sort Method: quicksort  Memory: 264kB&#xA;         -&amp;gt;  Bitmap Heap Scan on my_datas  (cost=119.31..368.29 rows=66 width=7) (actual time=7.737..18.771 rows=4284 loops=1)&#xA;               Recheck Cond: (family % &amp;#39;GRANGER&amp;#39;::text)&#xA;               Rows Removed by Index Recheck: 3468&#xA;               Heap Blocks: exact=5458&#xA;               -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..119.29 rows=66 width=0) (actual time=7.173..7.173 rows=7752 loops=1)&#xA;                     Index Cond: (family % &amp;#39;GRANGER&amp;#39;::text)&#xA; Planning Time: 0.297 ms&#xA; Execution Time: 19.887 ms&#xA;(12 rows)&#xA;&#xA;loxodata_text=# SELECT DISTINCT family FROM my_datas WHERE family %  &amp;#39;GRANGER&amp;#39;;&#xA;  family&#xA;----------&#xA; GRAND&#xA; GRANGE&#xA; GRANGER&#xA; GRANIER&#xA; GRAS&#xA; LAGRANGE&#xA;(6 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cette recherche par similarité peut être utile, votre serviteur en sait quelque chose avec son patronyme qui comporte un &amp;lsquo;B&amp;rsquo; muet et qui entraîne souvent moultes confusions lorsque je dois épeler mon nom, et qui est donc écrit souvent approximativement :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# SELECT DISTINCT family FROM my_datas WHERE family % &amp;#39;LEFEBVRE&amp;#39;;&#xA;  family&#xA;----------&#xA; LEFEBVRE&#xA; LEFEVRE&#xA; LEFEUVRE&#xA;(3 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;performances&#34;&gt;Performances&lt;/h3&gt;&#xA;&lt;p&gt;On peut voir que sur une recherche d&amp;rsquo;égalité, ou bien sur une recherche de début de chaîne, c&amp;rsquo;est l&amp;rsquo;index B-Tree qui est préféré par le planner :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family =  &amp;#39;LEFEBVRE&amp;#39;;&#xA;                                                           QUERY PLAN&#xA;---------------------------------------------------------------------------------------------------------------------------------&#xA; Index Only Scan using idx_test on my_datas  (cost=0.42..1370.94 rows=3801 width=7) (actual time=0.018..0.488 rows=4312 loops=1)&#xA;   Index Cond: (family = &amp;#39;LEFEBVRE&amp;#39;::text)&#xA;   Heap Fetches: 399&#xA; Planning Time: 0.340 ms&#xA; Execution Time: 0.615 ms&#xA;(5 rows)&#xA;&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family like  &amp;#39;LEFEBVRE%&amp;#39;;&#xA;                                                           QUERY PLAN&#xA;---------------------------------------------------------------------------------------------------------------------------------&#xA; Index Only Scan using idx_test on my_datas  (cost=0.42..1389.95 rows=3867 width=7) (actual time=0.010..0.729 rows=4312 loops=1)&#xA;   Index Cond: ((family ~&amp;gt;=~ &amp;#39;LEFEBVRE&amp;#39;::text) AND (family ~&amp;lt;~ &amp;#39;LEFEBVRF&amp;#39;::text))&#xA;   Filter: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA;   Heap Fetches: 399&#xA; Planning Time: 0.165 ms&#xA; Execution Time: 0.877 ms&#xA;(6 rows)&#xA;&#xA;loxodata_text=# drop index idx_test;&#xA;DROP INDEX&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Il est cependant important de noter que si l&amp;rsquo;index B-Tree est préféré sur la recherche en début de chaîne ( &lt;code&gt;LIKE &#39;xxxx%&#39;&lt;/code&gt; ) c&amp;rsquo;est parce que la classe d&amp;rsquo;opérateurs &lt;code&gt;text_pattern_ops&lt;/code&gt; a été utilisée lors de la création de l&amp;rsquo;index. Si nous créons un index B-Tree sans cette classe d&amp;rsquo;opérateurs, il sera préféré pour une recherche d&amp;rsquo;égalité, mais pas pour une recherche de début de chaîne du fait des problèmes complexes liés aux &lt;code&gt;LOCALES&lt;/code&gt; des différentes langues :&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# CREATE INDEX idx_test ON my_datas(family);&#xA;CREATE INDEX&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family like  &amp;#39;LEFEBVRE%&amp;#39;;&#xA;                                                          QUERY PLAN&#xA;------------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=139.26..7724.28 rows=3867 width=7) (actual time=2.370..5.048 rows=4312 loops=1)&#xA;   Recheck Cond: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA;   Heap Blocks: exact=3544&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..138.29 rows=3867 width=0) (actual time=2.000..2.000 rows=4312 loops=1)&#xA;         Index Cond: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA; Planning Time: 0.162 ms&#xA; Execution Time: 5.179 ms&#xA;(7 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Si nous supprimons définitivement l&amp;rsquo;index B-Tree, on voit que l&amp;rsquo;index sur les trigrammes est utilisé efficacement pour une recherche d&amp;rsquo;égalité (seulement après PG v13) mais pas aussi efficacement qu&amp;rsquo;avec l&amp;rsquo;index B-Tree (coût estimé 7666 vs 1370). Cependant ce coût est remarquablement constant que la recherche se fasse sur une égalité, un début de chaîne (&lt;code&gt;LIKE &#39;xxx%&#39;&lt;/code&gt;) ou une recherche sur une sous-chaîne (&lt;code&gt;LIKE &#39;%xxx%&#39;&lt;/code&gt;).&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family =  &amp;#39;LEFEBVRE&amp;#39;;&#xA;                                                          QUERY PLAN&#xA;------------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=151.72..7666.35 rows=3801 width=7) (actual time=3.331..6.085 rows=4312 loops=1)&#xA;   Recheck Cond: (family = &amp;#39;LEFEBVRE&amp;#39;::text)&#xA;   Heap Blocks: exact=3544&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..150.77 rows=3801 width=0) (actual time=2.961..2.962 rows=4312 loops=1)&#xA;         Index Cond: (family = &amp;#39;LEFEBVRE&amp;#39;::text)&#xA; Planning Time: 0.095 ms&#xA; Execution Time: 6.298 ms&#xA;(7 rows)&#xA;&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family like  &amp;#39;LEFEBVRE%&amp;#39;;&#xA;                                                          QUERY PLAN&#xA;------------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=139.26..7724.28 rows=3867 width=7) (actual time=2.632..5.366 rows=4312 loops=1)&#xA;   Recheck Cond: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA;   Heap Blocks: exact=3544&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..138.29 rows=3867 width=0) (actual time=2.263..2.263 rows=4312 loops=1)&#xA;         Index Cond: (family ~~ &amp;#39;LEFEBVRE%&amp;#39;::text)&#xA; Planning Time: 0.075 ms&#xA; Execution Time: 5.584 ms&#xA;(7 rows)&#xA;&#xA;loxodata_text=# EXPLAIN ANALYZE SELECT family FROM my_datas WHERE family like  &amp;#39;%LEFEBVRE%&amp;#39;;&#xA;                                                          QUERY PLAN&#xA;------------------------------------------------------------------------------------------------------------------------------&#xA; Bitmap Heap Scan on my_datas  (cost=109.52..7694.54 rows=3867 width=7) (actual time=1.628..4.402 rows=4312 loops=1)&#xA;   Recheck Cond: (family ~~ &amp;#39;%LEFEBVRE%&amp;#39;::text)&#xA;   Heap Blocks: exact=3544&#xA;   -&amp;gt;  Bitmap Index Scan on idx_test_trgm  (cost=0.00..108.55 rows=3867 width=0) (actual time=1.260..1.260 rows=4312 loops=1)&#xA;         Index Cond: (family ~~ &amp;#39;%LEFEBVRE%&amp;#39;::text)&#xA; Planning Time: 0.078 ms&#xA; Execution Time: 4.603 ms&#xA;(7 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Si un champ texte fait l&amp;rsquo;objet d&amp;rsquo;une recherche d&amp;rsquo;égalité dans une clause &lt;code&gt;WHERE&lt;/code&gt;, un index B-Tree est parfaitement adéquat.&lt;/li&gt;&#xA;&lt;li&gt;Si un champ texte fait l&amp;rsquo;objet d&amp;rsquo;une recherche sur un début de chaîne de type &lt;code&gt;WHERE champ LIKE &#39;ABC%&#39;&lt;/code&gt; , un index B-Tree est là encore adéquat, à condition de lui spécifier la classe d&amp;rsquo;opérateurs &lt;code&gt;text_pattern_ops&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Si un champ texte fait l&amp;rsquo;objet d&amp;rsquo;une recherche sur une sous-chaîne de type &lt;code&gt;WHERE champ LIKE &#39;%ABC%&#39;&lt;/code&gt; , seul un index GIN ou GiST sur les trigrammes sera utile.&lt;/li&gt;&#xA;&lt;li&gt;Lorsqu&amp;rsquo;un index sur les trigrammes a été créé, dans la plupart des cas l&amp;rsquo;index B-Tree peut être supprimé. Cependant, du fait de la meilleure efficacité du B-Tree, il peut être pertinent dans de rares occasions de conserver également l&amp;rsquo;index B-Tree.&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>Retour sur la PG Conf Europe 2024</title>
    <updated>2025-02-24T14:10:00Z</updated>
    <id>tag:www.loxodata.com,2025-02-24:/post/pgconf-eu-2024-report/</id>
    <link href="http://www.loxodata.com/post/pgconf-eu-2024-report/" rel="alternate"></link>
    <summary type="html">&lt;h2 id=&#34;retour-sur-la-pg-conf-europe-2024&#34;&gt;Retour sur la PG Conf Europe 2024&lt;/h2&gt;&#xA;&lt;p&gt;Cette année, la PostgreSQL Conference Europe 2024 s&amp;rsquo;est déroulée à&#xA;Athènes, en Grèce, à quelques hectomètres de l&amp;rsquo;acropole. À nouveau, un&#xA;record d&amp;rsquo;affluence est battu cette année avec 779 participants, ce qui&#xA;en fait l&amp;rsquo;évènement PostgreSQL le plus important au monde.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://www.loxodata.com/images/post/pgconf-eu-2024/athena-noctua.jpg&#34; alt=&#34;La chouette d&amp;rsquo;Athéna&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;La liste des conférences est disponible sur le site de&#xA;l&amp;rsquo;évènement : &lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/&#34;&gt;https://2024.pgconf.eu/&lt;/a&gt;.&#xA;Les supports de présentations, ainsi que les enregistrements vidéos sont&#xA;également mis à disposition.&lt;/p&gt;&#xA;&lt;p&gt;La &lt;a href=&#34;https://buff.ly/4b483Ff&#34;&gt;conférence d&amp;rsquo;ouverture&lt;/a&gt; est donnée par Stacey Haysler. Le sujet&#xA;abordé est celui du coût de la licence PostgreSQL. Cette dernière&#xA;étant gratuite, elle demande une implication des différents acteurs&#xA;pour que le projet puisse fonctionner et demeurer robuste et pérenne.&lt;/p&gt;&#xA;&lt;p&gt;Les conférences sont ensuite réparties dans différentes salles, avec 4&#xA;conférences simultanées, dont une réservée aux sponsors. Nous résumons&#xA;ici nos notes à propos des présentations auxquelles nous avons&#xA;assisté.&lt;/p&gt;&#xA;&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://anarazel.de/talks/2024-10-23-pgconf-eu-numa-vs-postgresql/numa-vs-postgresql.pdf&#34;&gt;NUMA vs PostgreSQL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Andres Freund nous explique les particularités de NUMA, qui est une&#xA;architecture d&amp;rsquo;accès à la mémoire, ce qui a des conséquences pour les&#xA;processeurs, et donc les logiciels qui s&amp;rsquo;en servent. Quels sont les&#xA;problèmes rencontrés dans le contexte de l&amp;rsquo;utilisation de PostgreSQL ?&#xA;Cette présentation est complexe, mais détaillée et permet à l&amp;rsquo;auditoire&#xA;de mieux comprendre le comportement global des systèmes, tout en&#xA;ouvrant vers des optimisations possibles de PostgreSQL.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5720/slides/608/Streaming%20I_O.pdf&#34;&gt;Streaming I/O and vectored I/O&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Les orateurs Thomas Munro &amp;amp; Nazir Bilal Yavuz détaillent un point&#xA;important concernant les performances des lectures et écritures de&#xA;données (I/O) : après un historique des solutions, ils expliquent ce&#xA;que sont les solutions modernes telles que les Streaming I/O et que peut&#xA;apporter le patch AIO qui est en cours de développement.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/5689-debugging-active-queries-with-mid-flight-instrumented-explain-plans/&#34;&gt;Debugging active queries with mid-flight instrumented explain plans&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Rafael Thofehrn Castro nous présente des extensions et patchs pour&#xA;suivre les plans d&amp;rsquo;exécutions à la volée dans une instance&#xA;PostgreSQL. C&amp;rsquo;est bluffant, malheureusement rien n&amp;rsquo;est disponible&#xA;publiquement.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5747/slides/559/postgres_statistics_presentation.pdf&#34;&gt;A Deep Dive into Postgres Statistics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Louise Leinweber détaille de façon claire et précise ce que sont les&#xA;statistiques sur les données dans PostgreSQL, comment elles sont&#xA;utilisées dans PostgreSQL et quels leviers nous avons pour agir.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/6035-porting-on-prem-performance-troubleshooting-skills-to-the-cloud/&#34;&gt;Porting on-prem performance troubleshooting skills to the cloud&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Denzil Ribeiro évoque l&amp;rsquo;outillage nécessaire à la supervision d&amp;rsquo;une&#xA;instance PostgreSQL dans le cloud, en particulier tout ce qui est&#xA;spécifique aux environnements clouds, très utile lorsqu&amp;rsquo;on vient&#xA;d&amp;rsquo;environnements dits &amp;ldquo;on-premise&amp;rdquo;.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5870/slides/572/PostgreSQL%20Observed%E2%80%94%20and%20Explained.pdf&#34;&gt;PostgreSQL Observed—and Explained&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Stacey Haysler et Karen Jex utilisent quelques points emblématiques&#xA;des problèmes souvent rencontrés par les utilisateurs de PostgreSQL&#xA;pour évoquer les bonnes ou mauvaises pratiques et certains&#xA;anti-patterns connus.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/5812-vacuuming-large-tables-how-recent-postgres-changes-further-enable-mission-critical-workloads/&#34;&gt;Vacuuming Large Tables: How Recent Postgres Changes Further Enable Mission Critical Workloads&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Robert Treat évoque avec humour ses mésaventures avec les vacuums et&#xA;les ID de transactions, et les améliorations apportées depuis dans&#xA;PostgreSQL 17.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5768/slides/619/Postgres%20Partitioning%20-%20Slicing%20and%20Dicing.pdf&#34;&gt;Mastering PostgreSQL Partitioning: Supercharge Performance and Simplify Maintenance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Ryan Booz évoque un outil très utile en ce qui concerne la gestion de&#xA;la performance : le partitionnement des tables, ses différentes&#xA;possibilités et cas d&amp;rsquo;usage, jusqu&amp;rsquo;aux extensions que sont TimescaleDB&#xA;et Citus.&lt;/p&gt;&#xA;&lt;h2 id=&#34;high-availibility&#34;&gt;High availibility&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5916/slides/578/bmejias_Sparta_Dual_Kings_PG_Active_Active.pdf&#34;&gt;Sparta&amp;rsquo;s Dual Kingship and PostgreSQL Active-Active&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Boriss Mejías détaille le fonctionnement d&amp;rsquo;une réplication&#xA;active-active, avec toutes les notions, plus ou moins complexes, qui&#xA;permettent de bien comprendre les contraintes qu&amp;rsquo;imposent ce type de&#xA;réplication.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5892/slides/544/patroni-deployment-patterns.pdf&#34;&gt;Patroni Deployment Patterns&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Michael Banck expose de façon pratique et claire le fonctionnement de&#xA;Patroni, avec quelques éléments pertinents à retenir, correspondant à son&#xA;expérience.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5846/slides/547/comparing_poolers.pdf&#34;&gt;Comparing Connection Poolers for PostgreSQL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Julian Markwort compare les différents gestionnaires de connexions&#xA;entre eux. Quelles sont les différentes questions qui se posent pour&#xA;adopter un tel outil, et pourquoi faut-il choisir pgBouncer ?&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5853/slides/567/Speeding%20up%20logical%20replication%20setup.pdf&#34;&gt;Speeding up logical replication setup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Euler Taveira présente le développement qu&amp;rsquo;il a mené dans PostgreSQL&#xA;pour intégré l&amp;rsquo;outil &lt;code&gt;pg_createsubscriber&lt;/code&gt; qui permet de convertir une&#xA;réplication physique en réplication logique, accélérant ainsi la&#xA;création d&amp;rsquo;un réplica logique.&lt;/p&gt;&#xA;&lt;h3 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/6038/slides/552/CPK%20Your%20Virtual%20DBA.pdf&#34;&gt;Crunchy Postgres for Kubernetes: Your virtual DBA&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Karen Jex explique le fonctionnement de Kubernetes et l&amp;rsquo;utilisation de&#xA;l&amp;rsquo;opérateur Crunchy Postgres, et comment son fonctionnement s&amp;rsquo;articule&#xA;avec le rôle et les responsabilités d&amp;rsquo;un administrateur de bases de&#xA;données.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5584/slides/576/PGConf.EU%20-%20Demystifying%20Kubernetes%20for%20Postgres%20DBAs.pdf&#34;&gt;Demystifying Kubernetes for Postgres DBAs: A Guide to Operators&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Adam Wright évoque le lien entre Kubernetes et PostgreSQL : les&#xA;opérateurs ! Différents opérateurs pour PostgreSQL existent et ne sont&#xA;pas strictement équivalents, ce qui nécessite une compréhension de&#xA;chacun d&amp;rsquo;entre eux de la part de l&amp;rsquo;administrateur de bases de données&#xA;pour les adopter : sécurité, réseau, sauvegarde, stockage, extension.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5829/slides/554/202410-pgconf-From%20VMs%20to%20Cloud-Native%20PostgreSQL%20in%20Kubernetes.pdf&#34;&gt;From VMs to Cloud-Native PostgreSQL in Kubernetes: A Case Study of Migrating a Medium-Sized Application&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;David Pech fait le retour d&amp;rsquo;expérience d&amp;rsquo;une migration d&amp;rsquo;instance&#xA;PostgreSQL depuis des machines virtuelles vers un cluster&#xA;Kubernetes. Le choix de l&amp;rsquo;opérateur Kubernetes est un point important&#xA;de la démarche. Après avoir fait tomber quelques mythes autour de&#xA;Kubernetes, l&amp;rsquo;orateur détaille de plan de travail pour adopter la&#xA;solution.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/5654-fun-with-postgres-high-availability-poker/&#34;&gt;Fun with Postgres High Availability Poker&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Dave Pitts et Derk Van Veen introduisent les concepts de haute&#xA;disponibilité de PostgreSQL par le jeu, ce qui est toujours une bonne&#xA;manière d&amp;rsquo;apprendre.&lt;/p&gt;&#xA;&lt;h2 id=&#34;intelligence-artificielle&#34;&gt;Intelligence artificielle&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5830/slides/609/pgconfeu-2024-vectors-internal.pdf&#34;&gt;Dissimilarity search: implementing in-memory vector search algorithms to PostgreSQL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Jonathan Katz parle de l&amp;rsquo;extension pgvector, qui est une possibilité&#xA;offerte aux utilisateurs de PostgreSQL de vectoriser des données et de&#xA;faire des recherches par approximation.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5579/slides/575/AIfortheDBA_pgconfeu.pdf&#34;&gt;Leveraging AI as a PostgreSQL DBA, Grant Fritchey&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Grant Fritchey se demande si les prompts d&amp;rsquo;IA sont de bons outils pour&#xA;les DBA ? Quelles sont les différentes tâches du DBA qui pourraient&#xA;bénéficier de l&amp;rsquo;aide d&amp;rsquo;un assistant conversationnel ?&lt;/p&gt;&#xA;&lt;h2 id=&#34;sécurité&#34;&gt;Sécurité&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://l_avrot.gitlab.io/slides/permissions_20241023.html#/&#34;&gt;Untangling the Web of PostgreSQL Permissions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Lætitia Avrot évoque l&amp;rsquo;ensemble des fonctionnalités liées aux&#xA;permissions dans PostgreSQL : rôle, groupe, privilèges, Row Level&#xA;Security, privilèges par défaut.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5554/slides/555/PostgreSQL_Security_PgConf2024_Export.pdf&#34;&gt;PostgreSQL security: defending against external Attacks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Taras Kloba détaille un sujet très important, quoique parfois trop&#xA;négligé : comment protéger PostgreSQL contre les attaques. Des mises à&#xA;jour de sécurité à la gestion de l&amp;rsquo;authentification en passant par la&#xA;protection des données, cette présentation fait la liste des points à&#xA;retenir en termes de sécurité.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/session/5645-column-encryption-solutions-and-ideas/&#34;&gt;Column encryption (solutions and ideas)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Peter Eisentraut fait le tour des besoins et solutions de chiffrement&#xA;de données disponibles avec PostgreSQL.&lt;/p&gt;&#xA;&lt;h2 id=&#34;autres&#34;&gt;Autres&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5710/slides/549/csn-snapshots.pdf&#34;&gt;High-concurrency distributed snapshots, Ants Aasma&lt;/a&gt; :&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Le modèle actuel de snapshot, qui autorise la visibilité des&#xA;enregistrements, est maintenant vieux de plus de vingt ans : quel&#xA;modèle peut-il le remplacer, en prenant en compte la croissance de la&#xA;concurrence d&amp;rsquo;accès. L&amp;rsquo;orateur évoque alors les notions de Commit&#xA;Sequence Number ou d&amp;rsquo;un modèle hybride.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5630/slides/562/undelete_from_table.pdf&#34;&gt;UNDELETE data FROM table;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Christoph Berg explique en détail le fonctionnement de PostgreSQL&#xA;lorsqu&amp;rsquo;on lui demande de supprimer un enregistrement, et ce qu&amp;rsquo;il est&#xA;possible de faire pour retrouver cet enregistrement avec l&amp;rsquo;extension&#xA;&lt;code&gt;pg_dirtyread&lt;/code&gt; ou la commande &lt;code&gt;pg_waldump&lt;/code&gt;. Dans tous les cas, faites&#xA;des sauvegardes !&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/sessions/session/5748/slides/588/PGConf.EU.2024_pg_ivm.pdf&#34;&gt;pg_ivm : extension for rapid incremental view&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Yugo Nagata présente l&amp;rsquo;extension &lt;code&gt;pg_ivm&lt;/code&gt; qui permet de créer des vues&#xA;matérialisées incrémentales, qui sont donc mises à jour rapidement,&#xA;contrairement aux vues matérialisées existantes dans PostgreSQL qui&#xA;nécessitent une régénération entière.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 17.4 et autres correctifs</title>
    <updated>2025-02-20T14:30:00Z</updated>
    <id>tag:www.loxodata.com,2025-02-20:/post/postgresql-17-4/</id>
    <link href="http://www.loxodata.com/post/postgresql-17-4/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le PGDG (PostgreSQL Global Development Group) a publié une mise à jour&#xA;de toutes les versions supportées de PostgreSQL, incluant 17.4, 16.8, 15.12,&#xA;14.17 et 13.20.&lt;/p&gt;&#xA;&lt;p&gt;Pour la liste complète des changements, se référer à la &lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;note de publication de versions&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;corrections-de-bogues-et-améliorations&#34;&gt;Corrections de bogues et améliorations&lt;/h2&gt;&#xA;&lt;p&gt;Les problèmes ci-dessous concernent PostgreSQL 17. Certains de ces problèmes&#xA;peuvent aussi concerner d&amp;rsquo;autres versions de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Les correctifs sont :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Amélioration du comportement des fonctions d&amp;rsquo;échappement de la bibliothèque &lt;a href=&#34;https://www.postgresql.org/docs/current/libpq.html&#34;&gt;&lt;code&gt;libpq&lt;/code&gt;&lt;/a&gt;.&#xA;Le correctif de la vulnérabilité &lt;a href=&#34;https://www.postgresql.org/support/security/CVE-2025-1094/&#34;&gt;CVE-2025-1094&lt;/a&gt;&#xA;a introduit une régression amenant les fonctions d&amp;rsquo;échappement à ne pas respecter&#xA;les tailles des chaînes de caractères fournies en paramètres, entraînant dans&#xA;certains cas des plantages. Ce problème peut impacter une bibliothèque cliente de&#xA;PostgreSQL en fonction de son intégration à la bibliothèque &lt;code&gt;libpq&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;Correction de fuites mémoire dans la commande &lt;a href=&#34;https://www.postgresql.org/docs/current/app-pgcreatesubscriber.html&#34;&gt;pg_createsubscriber&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;mise-à-jour&#34;&gt;Mise à jour&lt;/h2&gt;&#xA;&lt;p&gt;Toutes les publications de mises à jour de PostgreSQL sont&#xA;cumulatives. Comme pour les autres mises à jour mineures, il n&amp;rsquo;est pas&#xA;nécessaire d&amp;rsquo;extraire et de recharger les bases de données ni&#xA;d&amp;rsquo;utiliser &lt;code&gt;pg_upgrade&lt;/code&gt; pour appliquer cette mise à jour ;&#xA;il suffit simplement d&amp;rsquo;arrêter PostgreSQL et de mettre à jour les binaires.&lt;/p&gt;&#xA;&lt;p&gt;Les utilisateurs ayant sauté une ou plusieurs mises à jour peuvent&#xA;avoir besoin d&amp;rsquo;étapes additionnelles après la mise à jour.&#xA;Les notes de publication des versions précédentes fournissent les détails.&lt;/p&gt;&#xA;&lt;p&gt;Pour plus de détails, se référer à la &lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;note de publication de versions&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;liens&#34;&gt;Liens&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;Téléchargements&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;Notes de version&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/security/&#34;&gt;Page sur la sécurité&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/versioning/&#34;&gt;Politique de version&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/donate/&#34;&gt;Faire un don&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Si vous avez des corrections ou suggestions sur cette annonce de publication, merci de les envoyer à la mailing liste publique &lt;a href=&#34;https://www.postgresql.org/list/&#34;&gt;&lt;em&gt;pgsql-www@lists.postgresql.org&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 17.3 et autres correctifs</title>
    <updated>2025-02-14T15:00:00Z</updated>
    <id>tag:www.loxodata.com,2025-02-14:/post/postgresql-17-3/</id>
    <link href="http://www.loxodata.com/post/postgresql-17-3/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le PGDG (PostgreSQL Global Development Group) a publié une mise à jour&#xA;de toutes les versions supportées de PostgreSQL, incluant 17.3, 16.7,&#xA;15.11, 14.16, 13.19.&lt;/p&gt;&#xA;&lt;p&gt;Cette publication corrige également une vulnérabilité de sécurité et plus de 70 bogues&#xA;reportés dans les mois précédents.&lt;/p&gt;&#xA;&lt;p&gt;Cependant, le PGDG a annoncé mettre à disposition le &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-4-ooc-release/&#34;&gt;20 février&lt;/a&gt;&#xA;prochain un correctif suite à l&amp;rsquo;introduction d&amp;rsquo;une régression sur cette mise à jour.&#xA;Il est recommandé de ne pas procéder à cette mise à jour, mais d&amp;rsquo;attendre la&#xA;version 17.4.&lt;/p&gt;&#xA;&lt;h2 id=&#34;problèmes-de-sécurité&#34;&gt;Problèmes de sécurité&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/support/security/CVE-2025-1094/&#34;&gt;CVE-2025-1094&lt;/a&gt; :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;CVSS v3.1 Base Score: &lt;a href=&#34;https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?version=3.1&amp;amp;vector=AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H&#34;&gt;8.1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Supported, Vulnerable Versions: 13 - 17.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Une neutralisation inadéquate d&amp;rsquo;une syntaxe avec guillemets dans les fonctions de &lt;a href=&#34;https://www.postgresql.org/docs/current/libpq.html&#34;&gt;&lt;code&gt;libpq&lt;/code&gt;&lt;/a&gt; &lt;code&gt;PQescapeLiteral()&lt;/code&gt;, &lt;code&gt;PQescapeIdentifier()&lt;/code&gt;, &lt;code&gt;PQescapeString()&lt;/code&gt; et &lt;code&gt;PQescapeStringConn()&lt;/code&gt; permet de faire de l&amp;rsquo;injection SQL dans certains cas d&amp;rsquo;usage. Spécifiquement, l&amp;rsquo;injection SQL requiert à l&amp;rsquo;application d&amp;rsquo;utiliser le résultat de fonction pour construite l&amp;rsquo;entrée de &lt;code&gt;psql&lt;/code&gt;,&#xA;le terminal interactif de PostgreSQL. De même, une neutralisation inadéquate d&amp;rsquo;une syntaxe avec guillemets dans les programmes utilitaires de PostgreSQL en ligne de commande permet à une source d&amp;rsquo;arguments à ces commandes en ligne d&amp;rsquo;effectuer de l&amp;rsquo;injection SQL lorsque le paramètre &lt;a href=&#34;https://www.postgresql.org/docs/current/runtime-config-client.html#GUC-CLIENT-ENCODING&#34;&gt;&lt;code&gt;client_encoding&lt;/code&gt;&lt;/a&gt; est &lt;code&gt;BIG5&lt;/code&gt; et &lt;a href=&#34;https://www.postgresql.org/docs/current/runtime-config-preset.html#GUC-SERVER-ENCODING&#34;&gt;&lt;code&gt;server_encoding&lt;/code&gt;&lt;/a&gt; est soit &lt;code&gt;EUC_TW&lt;/code&gt; soit &lt;code&gt;MULE_INTERNAL&lt;/code&gt;. Les versions antérieures à PostgreSQL 17.3, 16.7, 15.11, 14.16 et 13.19 sont affectées.&lt;/p&gt;&#xA;&lt;p&gt;Le projet PostgreSQL remercie Stephen Fewer, Principal Security Researcher, Rapid7 pour avoir signalé ce problème.&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h2 id=&#34;corrections-de-bogues-et-améliorations&#34;&gt;Corrections de bogues et améliorations&lt;/h2&gt;&#xA;&lt;p&gt;Cette mise à jour corrige plus de 70 bogues ayant été reportés durant les mois précédents. Les problèmes ci-dessous concernent PostgreSQL 17. Certains de ces problèmes peuvent aussi concerner d&amp;rsquo;autres versions de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Les correctifs sont :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;restauration du comportement d&amp;rsquo;avant la version 17 concernant la troncature des noms&#xA;de bases de données de plus de 63 octets et les noms d&amp;rsquo;utilisateurs dans les&#xA;requêtes de connexion ;&lt;/li&gt;&#xA;&lt;li&gt;ne pas vérifier des privilèges de connexions et limites sur les processus&#xA;parallèles, mais les hériter du processus principal ;&lt;/li&gt;&#xA;&lt;li&gt;suppression du suffixe &lt;code&gt;Lock&lt;/code&gt; des noms d&amp;rsquo;évènements d&amp;rsquo;attente &lt;code&gt;LWLock&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;correction de la réutilisation de résultats obsolètes dans les agrégats de&#xA;fenêtrage qui peuvent conduire à des résultats incorrects ;&lt;/li&gt;&#xA;&lt;li&gt;correction de plusieurs conditions de concurrence pour &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-vacuum.html&#34;&gt;&lt;code&gt;vacuum&lt;/code&gt;&lt;/a&gt;&#xA;qui dans le pire des cas peut conduire à une corruption du catalogue système ;&lt;/li&gt;&#xA;&lt;li&gt;corrections sur la &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-truncate.html&#34;&gt;&lt;code&gt;TRUNCATE&lt;/code&gt;&lt;/a&gt;&#xA;de tables et d&amp;rsquo;index pour prévenir une éventuelle corruption ;&lt;/li&gt;&#xA;&lt;li&gt;correction sur le détachement d&amp;rsquo;une partition lorsque sa propre contrainte de&#xA;clé étrangère fait référence à une table partitionnée ;&lt;/li&gt;&#xA;&lt;li&gt;correction pour les codes de format &lt;code&gt;FFn&lt;/code&gt; (par exemple &lt;code&gt;FF1&lt;/code&gt;) pour &lt;code&gt;to_timestamp&lt;/code&gt;,&#xA;où un code de format entier avant le &lt;code&gt;FFn&lt;/code&gt; consommait tous les chiffres disponibles ;&lt;/li&gt;&#xA;&lt;li&gt;corrections pour &lt;code&gt;SQL/JSON&lt;/code&gt; et &lt;code&gt;XMLTABLE()&lt;/code&gt; pour mettre des entrées spécifiques&#xA;entre guillemets lorsque cela est nécessaire ;&lt;/li&gt;&#xA;&lt;li&gt;inclusion de l&amp;rsquo;option &lt;code&gt;ldapscheme&lt;/code&gt; dans la vue &lt;a href=&#34;https://www.postgresql.org/docs/current/view-pg-hba-file-rules.html&#34;&gt;&lt;code&gt;pg_hba_file_rules()&lt;/code&gt;&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;corrections pour &lt;a href=&#34;https://www.postgresql.org/docs/current/queries-union.html&#34;&gt;&lt;code&gt;UNION&lt;/code&gt;&lt;/a&gt;,&#xA;y compris le fait de ne pas fusionner des colonnes avec des collations non&#xA;compatibles ;&lt;/li&gt;&#xA;&lt;li&gt;corrections pouvant avoir un impact sur la disponibilité ou la vitesse de démarrage&#xA;d&amp;rsquo;une connexion à PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;correction de plusieurs fuites mémoire dans la sortie du décodage logique ;&lt;/li&gt;&#xA;&lt;li&gt;correction de plusieurs fuites mémoire avec le langage &lt;a href=&#34;https://www.postgresql.org/docs/current/plpython.html&#34;&gt;&lt;code&gt;PL/Python&lt;/code&gt;&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;ajout de l&amp;rsquo;autocomplétion pour la commande &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-copy.html&#34;&gt;&lt;code&gt;COPY&lt;/code&gt; (&lt;code&gt;MERGE INTO&lt;/code&gt;)&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;rendre &lt;a href=&#34;https://www.postgresql.org/docs/current/app-pgcontroldata.html&#34;&gt;&lt;code&gt;pg_controldata&lt;/code&gt;&lt;/a&gt;&#xA;plus résilient lors de l&amp;rsquo;affichage d&amp;rsquo;informations provenant de fichiers &lt;a href=&#34;https://www.postgresql.org/docs/current/wal-internals.html&#34;&gt;&lt;code&gt;pg_control&lt;/code&gt;&lt;/a&gt;&#xA;corrompus ;&lt;/li&gt;&#xA;&lt;li&gt;correction d&amp;rsquo;une fuite mémoire sur la commande &lt;a href=&#34;https://www.postgresql.org/docs/current/app-pgrestore.html&#34;&gt;&lt;code&gt;pg_restore&lt;/code&gt;&lt;/a&gt;&#xA;avec des données compressées via &lt;code&gt;zstd&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;correction de &lt;a href=&#34;https://www.postgresql.org/docs/current/app-pgbasebackup.html&#34;&gt;&lt;code&gt;pg_basebackup&lt;/code&gt;&lt;/a&gt;&#xA;pour gérer correctement les fichiers &lt;code&gt;pg_wal.tar&lt;/code&gt; de plus de 2GB sur Windows ;&lt;/li&gt;&#xA;&lt;li&gt;modification sur le module &lt;a href=&#34;https://www.postgresql.org/docs/current/earthdistance.html&#34;&gt;&lt;code&gt;earthdistance&lt;/code&gt;&lt;/a&gt;&#xA;pour utiliser le canevas des fonctions standards SQL pour corriger des problèmes&#xA;sur des mises à jour majeures vers la version 17 quand l&amp;rsquo;extension &lt;a href=&#34;https://www.postgresql.org/docs/current/earthdistance.html&#34;&gt;&lt;code&gt;earthdistance&lt;/code&gt;&lt;/a&gt;&#xA;est utilisée ;&lt;/li&gt;&#xA;&lt;li&gt;corrige des erreurs avec &lt;a href=&#34;https://www.postgresql.org/docs/current/pageinspect.html&#34;&gt;&lt;code&gt;pageinspect&lt;/code&gt;&lt;/a&gt;&#xA;dans des instances où la définition de la fonction &lt;code&gt;brin_page_items()&lt;/code&gt; n&amp;rsquo;est pas&#xA;à jour de la dernière version ;&lt;/li&gt;&#xA;&lt;li&gt;corrige des conditions de concurrence lors de tentative d&amp;rsquo;annulation d&amp;rsquo;une&#xA;requête distante avec &lt;a href=&#34;https://www.postgresql.org/docs/current/postgres-fdw.html&#34;&gt;&lt;code&gt;postgres_fdw&lt;/code&gt;&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Cette publication met aussi à jour les fichiers de fuseaux horaires avec la&#xA;publication de &lt;code&gt;tzdata&lt;/code&gt; 2025a pour les changements de lois DST au Paraguay, plus&#xA;des corrections historiques pour les Philippines.&lt;/p&gt;&#xA;&lt;h2 id=&#34;mise-à-jour&#34;&gt;Mise à jour&lt;/h2&gt;&#xA;&lt;p&gt;Toutes les publications de mises à jour de PostgreSQL sont&#xA;cumulatives. Comme pour les autres mises à jour mineures, il n&amp;rsquo;est pas&#xA;nécessaire d&amp;rsquo;extraire et de recharger les bases de données ni&#xA;d&amp;rsquo;utiliser &lt;code&gt;pg_upgrade&lt;/code&gt; pour appliquer cette mise à jour ;&#xA;il suffit simplement d&amp;rsquo;arrêter PostgreSQL et de mettre à jour les binaires.&lt;/p&gt;&#xA;&lt;p&gt;Les utilisateurs ayant sauté une ou plusieurs mises à jour peuvent&#xA;avoir besoin d&amp;rsquo;étapes additionnelles après la mise à jour.&#xA;Les notes de publication des versions précédentes fournissent les détails.&lt;/p&gt;&#xA;&lt;p&gt;Pour plus de détails, se référer à la &lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;note de publication de versions&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;liens&#34;&gt;Liens&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;Téléchargements&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;Notes de version&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/security/&#34;&gt;Page sur la sécurité&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/versioning/&#34;&gt;Politique de version&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/donate/&#34;&gt;Faire un don&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Si vous avez des corrections ou suggestions sur cette annonce de publication, merci de les envoyer à la mailing liste publique &lt;a href=&#34;https://www.postgresql.org/list/&#34;&gt;&lt;em&gt;pgsql-www@lists.postgresql.org&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>Correctif hors cycle pour PostgreSQL</title>
    <updated>2025-02-14T08:00:00Z</updated>
    <id>tag:www.loxodata.com,2025-02-14:/post/postgresql-17-4-ooc-release/</id>
    <link href="http://www.loxodata.com/post/postgresql-17-4-ooc-release/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le &lt;a href=&#34;https://www.postgresql.org/&#34;&gt;PGDG&lt;/a&gt; prévoit une livraison hors cycle pour le 20 février 2025 afin de corriger une régression introduite sur la &lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-173-167-1511-1416-and-1319-released-3015/&#34;&gt;mise à jour du 13 février 2025&lt;/a&gt; portant sur les versions mineures : 17.3, 16.7, 15.11, 14.16 et 13.19.&#xA;Dans cette mise à jour, vous retrouverez des correctifs pour les versions supportées (17.4, 16.8, 15.12, 14.17, 13.20). Bien que ces correctifs puissent ne pas impacter tous les utilisateurs de PostgreSQL, le PGDG&#xA;a préféré adresser le problème au plus tôt et ne pas attendre la prochaine échéance prévue le &lt;a href=&#34;https://www.postgresql.org/developer/roadmap/&#34;&gt;8 mai 2025&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Le correctif de sécurité &lt;a href=&#34;https://www.postgresql.org/support/security/CVE-2025-1094/&#34;&gt;CVE-2025-1094&lt;/a&gt;, traitant d&amp;rsquo;une vulnérabilité dans la librairie &lt;a href=&#34;https://www.postgresql.org/docs/current/libpq.html&#34;&gt;&lt;code&gt;libpq&lt;/code&gt;&lt;/a&gt; de PostgreSQL, a introduit une régression portant sur la gestion des chaînes de caractères (&amp;ldquo;C string&amp;rdquo;) terminée par un&#xA;caractère non nul. L&amp;rsquo;erreur pourrait être visible en fonction de comment un client PostgreSQL a implémenté ce comportement, et peut ne pas impacter tous les drivers PostgreSQL. Par précaution, le PGDG a avancé le cycle de mise à jour.&lt;/p&gt;&#xA;&lt;p&gt;Si vous êtes impacté par ce problème, il est recommandé d&amp;rsquo;attendre la sortie des versions 17.4, 16.8, 15.12, 14.17 et 13.29 avant de mettre à jour PostgreSQL.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>pgwatch 3</title>
    <updated>2025-02-03T14:30:00Z</updated>
    <id>tag:www.loxodata.com,2025-02-03:/post/pgwatch3/</id>
    <link href="http://www.loxodata.com/post/pgwatch3/" rel="alternate"></link>
    <summary type="html">&lt;h2 id=&#34;supervision&#34;&gt;Supervision&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;rsquo;outil &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt; est l&amp;rsquo;un des outils les plus populaires pour la supervision des instances&#xA;PostgreSQL. Le projet a été initié par la société &lt;a href=&#34;https://www.cybertec-postgresql.com/&#34;&gt;Cybertec&lt;/a&gt; pour ses propres besoins. Initialement en version 2,&#xA;&lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch2&#34;&gt;pgwatch2&lt;/a&gt; a été réécrit récemment en &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch/releases/tag/3.0.0&#34;&gt;version 3&lt;/a&gt;.&#xA;Pavlo Golub est en charge du projet chez Cybertec.&lt;/p&gt;&#xA;&lt;p&gt;Cette version 3 propose les mêmes fonctionnalités éprouvées de la version 2 avec quelques nouveautés, notamment le stockage en parallèle vers plusieurs stockages,&#xA;l&amp;rsquo;utilisation de l&amp;rsquo;API v3 de Etcd, la factorisation du code et la dépréciation de certains types de stockage (InfluxDB par exemple), la mise à jour des versions de certains&#xA;composants tels que &lt;a href=&#34;http://grafana.org/&#34;&gt;Grafana&lt;/a&gt; ou les images Docker mises à disposition.&lt;/p&gt;&#xA;&lt;p&gt;Pour rappel, &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt; se base sur un collecteur écrit en &lt;code&gt;go&lt;/code&gt; qui vient récupérer une liste de métriques prédéfinies,&#xA;mais extensibles à souhait afin de récupérer des statistiques sur vos instances PostgreSQL et le système (moyennant l&amp;rsquo;utilisation de l&amp;rsquo;extension &lt;code&gt;PL/Python&lt;/code&gt;) quelque&#xA;soit leur nombre avec le minimum d&amp;rsquo;impact. Le stockage des métriques s&amp;rsquo;effectue sur PostgreSQL, mais il est aussi possible de choisir TimescaleDB, Prometheus ou des fichiers JSON.&lt;/p&gt;&#xA;&lt;p&gt;Les tableaux de bord fournis sont utilisables dans l&amp;rsquo;outil &lt;a href=&#34;http://grafana.org/&#34;&gt;Grafana&lt;/a&gt;, ce qui permet de les personnaliser finement, de créer des alertes, et de gérer finement les accès aux différents tableaux et données collectées.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt; permet aussi de récupérer les statistiques des outils tels que &lt;code&gt;PgBouncer&lt;/code&gt;, &lt;code&gt;Patroni&lt;/code&gt;, &lt;code&gt;Pgpool-II&lt;/code&gt;, &lt;code&gt;Prometheus&lt;/code&gt;, de parser les logs de PostgreSQL, ou de récupérer des statistiques depuis des services managés de PostreSQL chez divers fournisseurs de solution cloud (AWS, Azure, GCP).&lt;/p&gt;&#xA;&lt;p&gt;L&amp;rsquo;architecture de &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt; est très modulaire et permet de s&amp;rsquo;adapter à votre infrastructure et à tous vos cas d&amp;rsquo;usage ou presque.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://www.loxodata.com/images/post/pgwatch/pgwatch_architecture.jpg&#34; alt=&#34;Architecture pgwatch3 © Cybertec&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;quelques-nouveautés&#34;&gt;Quelques nouveautés&lt;/h2&gt;&#xA;&lt;h3 id=&#34;remote-sinks&#34;&gt;Remote Sinks&lt;/h3&gt;&#xA;&lt;p&gt;Une des nouveautés de la version 3 de &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt; est le découplage de la partie stockage. L&amp;rsquo;introduction des &lt;code&gt;remote sinks&lt;/code&gt; avec la possibilité d&amp;rsquo;utiliser l&amp;rsquo;interface (basée sur RPC) mise à disposition pour implémenter un type de stockage particulier pour y pousser les métriques de &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Mais aussi, la possibilité de disposer en parallèle de plusieurs stockages des métriques, par exemple vers une base de données et un fichier JSON.&lt;/p&gt;&#xA;&lt;h3 id=&#34;etcd&#34;&gt;Etcd&lt;/h3&gt;&#xA;&lt;p&gt;Autre grosse nouveauté, c&amp;rsquo;est le passage à la version 3 de l&amp;rsquo;API de &lt;code&gt;etcd&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;En effet, jusqu&amp;rsquo;à la version &lt;a href=&#34;https://etcd.io/docs/v3.3/&#34;&gt;3.3&lt;/a&gt; de &lt;code&gt;etcd&lt;/code&gt;, l&amp;rsquo;API par défaut était la version 2. Le protocole de la version 2 n&amp;rsquo;étant pas compatible avec la version 3 de ce dernier. Lors de l&amp;rsquo;utilisation d&amp;rsquo;un cluster Patroni et de la découverte automatique des noeuds, &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt; se base sur le protocole d&amp;rsquo;&lt;code&gt;etcd&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Pour cette raison, &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt; en version 3 utilise la version 3.5 de &lt;code&gt;etcd&lt;/code&gt; afin d&amp;rsquo;utiliser le protocole version 3 de l&amp;rsquo;API &lt;code&gt;etcd&lt;/code&gt;. Le protocole version 2 n&amp;rsquo;étant pas compatible avec le protocole en version 3, les clés/valeurs de la version 2 ne pourront être lues avec la version 3. Il faudra migrer en utilisant la procédure de migration donnée par &lt;code&gt;etcd&lt;/code&gt; &lt;a href=&#34;https://etcd.io/docs/v3.3/upgrades/upgrading-etcd/&#34;&gt;ici&lt;/a&gt;. Côté &lt;code&gt;patroni&lt;/code&gt;, la migration repose sur le changement dans le fichier de configuration de la version de &lt;code&gt;etcd&lt;/code&gt; en indiquant &lt;code&gt;etcd3&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;La documentation de &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt; est disponible &lt;a href=&#34;https://pgwat.ch/v3.0/&#34;&gt;ici&lt;/a&gt; pour la version 3.&lt;/p&gt;&#xA;&lt;h2 id=&#34;migration-vers-pgwatch3&#34;&gt;Migration vers pgwatch3&lt;/h2&gt;&#xA;&lt;p&gt;La question de la migration de pgwatch2 vers pgwatch3 se pose. Dans la documentation actuelle, rien n&amp;rsquo;y fait référence. Mais après discussion avec Pavlo Golub, il existe un &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch/tree/master/cmd/convert_metrics&#34;&gt;utilitaire de conversion&lt;/a&gt; pour convertir des métriques personnalisées au format utilisé par &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch2&#34;&gt;pgwatch2&lt;/a&gt; vers celui de &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch3&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Il est ainsi possible de récupérer vos anciennes métriques personnalisées pour les convertir dans le format utilisé par &lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;pgwatch&lt;/a&gt; avec un unique fichier &lt;code&gt;.yaml&lt;/code&gt; :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;go run convert_metrics.go --src /home/projects/pgwatch2/pgwatch2/metrics/ --dst /tmp/metrics.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;références&#34;&gt;Références&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch/releases/tag/3.0.0&#34;&gt;Release notes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pgwat.ch/v3.0/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://etcd.io/docs/v3.5/&#34;&gt;etcd&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 18 - Suppression de jointures inutiles</title>
    <updated>2025-03-07T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-03-07://2025/03/07/postgresql-18-self_join_elimination.html</id>
    <link href="https://blog.dalibo.com//2025/03/07/postgresql-18-self_join_elimination.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Reviers, le 7 mars 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fonctionnalité m’avait beaucoup impressionné en version 9.0, bien qu’elle&#xA;ait été éclipsée par la grande nouveauté, la réplication en natif. Cette&#xA;fonctionnalité avait pour but de supprimer les jointures inutiles. En fait, seul&#xA;un cas de jointure inutile dans un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;LEFT JOIN&lt;/code&gt; était traité. Depuis, beaucoup de&#xA;patchs ont circulé pour détecter d’autres cas, mais aucun n’a passé la sélection&#xA;jusqu’à la semaine dernière. La nouveauté concerne les jointures d’une table sur&#xA;elle-même. C’est ce que je vais détailler dans cet article.&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/portrait_guillaume.png&#34; alt=&#34;Guillaume Lelarge&#34; style=&#34;float: right; padding:10px; width:120px;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Prenons cette requête de jointure d’une table avec elle-même :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-sql highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;JOIN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1bis&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1bis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Sans contrainte particulière sur &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;c1&lt;/code&gt;, cette jointure ne peut être éludée. Cependant, si les&#xA;valeurs de la colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;c1&lt;/code&gt; sont uniques, le moteur n’a pas besoin de réaliser la jointure&#xA;pour obtenir le résultat.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nous allons prendre ce jeu de test :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-sql highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;INSERT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;INTO&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generate_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_000_000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;ALTER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ADD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;PRIMARY&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;KEY&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;VACUUM&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ANALYZE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Voici le plan d’exécution de la première requête en version 17 :&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-file&#34;&gt;Hash Join  (cost=30832.00..59603.01 rows=1000000 width=8)&#xA;  Hash Cond: (t1.c1 = t1bis.c1)&#xA;  -&amp;gt;  Seq Scan on t1  (cost=0.00..14425.00 rows=1000000 width=4)&#xA;  -&amp;gt;  Hash  (cost=14425.00..14425.00 rows=1000000 width=4)&#xA;        -&amp;gt;  Seq Scan on t1 t1bis  (cost=0.00..14425.00 rows=1000000 width=4)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;La jointure est bien réalisée. Et voici maintenant le plan d’exécution en version 18 :&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-file&#34;&gt;Seq Scan on t1 t1bis  (cost=0.00..14425.00 rows=1000000 width=8)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Il n’y a plus trace de la jointure. Le coût est de ce fait inférieur et la durée d’exécution l’est aussi : 530 ms en&#xA;version 17, contre 185 ms en version 18. De plus, la durée&#xA;d’optimisation/planification de la requête est elle aussi inférieure avec cette&#xA;optimisation : 0,20 ms contre 0,06 ms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans le cas où la contrainte n’est plus une clé primaire, mais une simple&#xA;contrainte d’unicité, le plan en sera un peu impacté :&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-file&#34;&gt;Seq Scan on t1 t1bis  (cost=0.00..14425.00 rows=1000000 width=8)&#xA;  Filter: (c1 IS NOT NULL)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;En effet, le filtre est nécessaire pour respecter la requête d’origine. Ce&#xA;filtre supplémentaire a un petit impact sur la durée d’exécution de la requête,&#xA;étant donné qu’elle passe à 220 ms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il est à noter que cette optimisation fonctionne aussi avec d’autres formes de&#xA;cette requête, par exemple :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-sql highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;EXISTS&lt;/span&gt;&#xA;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1bis&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1bis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&#xA;  &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Enfin, il faut savoir que cette optimisation est débrayable en configurant le&#xA;paramètre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;enable_self_join_elimination&lt;/code&gt; à &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;off&lt;/code&gt; en sachant qu’il est à &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;on&lt;/code&gt; par&#xA;défaut.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour terminer, il est évident qu’il est préférable de bien écrire les requêtes&#xA;mais quand l’application qui exécute la requête est propriétaire, il n’est pas&#xA;possible de modifier les requêtes exécutées. Quand un développeur utilise un&#xA;ORM, il n’a pas toujours la possibilité de changer la requête exécutée par&#xA;l’ORM. Et enfin, ce genre de requête peut aussi provenir de plusieurs vues&#xA;imbriquées qui finissent par en arriver à ce genre d’aberration.&#xA;Cette optimisation qui semble si évidente n’est pas du tout triviale : le&#xA;&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=fc069a3a6319b5bf40d2f0f1efceae1c9b7a68a8&#34;&gt;commit&lt;/a&gt;&#xA;a vingt-trois contributeurs, dont les plus aguerris des développeurs de PostgreSQL,&#xA;et &lt;a href=&#34;https://www.postgresql.org/message-id/flat/64486b0b-0404-e39e-322d-0801154901f3%40postgrespro.ru&#34;&gt;la discussion avait démarré en 2018&lt;/a&gt; !&#xA;&lt;!--&#xA;   vim: spelllang=fr spell&#xA;--&gt;&lt;/p&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>Linux Pratique - Maintenance d’une instance PostgreSQL</title>
    <updated>2025-03-03T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-03-03://2025/03/03/lp6.html</id>
    <link href="https://blog.dalibo.com//2025/03/03/lp6.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Reviers, 3 mars 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois un &lt;a href=&#34;https://blog.dalibo.com/2024/06/07/lp1.html&#34;&gt;serveur PostgreSQL&#xA;installé&lt;/a&gt;, plusieurs thématiques&#xA;sont à prendre en considération : la&#xA;&lt;a href=&#34;https://blog.dalibo.com/2024/09/09/lp3.html&#34;&gt;sauvegarde&lt;/a&gt;, la&#xA;&lt;a href=&#34;https://blog.dalibo.com/2024/11/18/lp4.html&#34;&gt;supervision&lt;/a&gt; et la maintenance.&#xA;C’est ce dernier point que nous allons voir dans cet article.&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/lp144.jpg&#34; alt=&#34;Linux Pratique 144&#34; style=&#34;float: right; padding: 10px; width: 300px;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il existe principalement deux types de maintenance à réaliser sur un serveur&#xA;PostgreSQL. Ils visent uniquement à préserver de bonnes performances du système&#xA;de bases de données. Il est question de lutter contre une fragmentation trop&#xA;importante des tables et des index (pour éviter une surconsommation des accès&#xA;disques et mémoires), et il est question de s’assurer d’avoir de bonnes&#xA;statistiques sur les données (pour avoir de bons plans d’exécution, et ainsi de&#xA;bonnes performances des requêtes). Cet article commence par expliquer ces types&#xA;de maintenance, puis aborde la question de sa mise en place et de son&#xA;automatisation.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;mise-à-jour-des-statistiques-sur-les-données&#34;&gt;Mise à jour des statistiques sur les données&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;C’est certainement le point le moins problématique et le plus compréhensible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour créer un plan d’exécution, l’optimiseur de requêtes de PostgreSQL se base&#xA;notamment sur des statistiques sur les données. Par exemple, pour choisir entre&#xA;un parcours de table et un parcours d’index, le ratio de valeurs filtrées est&#xA;une information importante. Plus ce ratio sera faible (c.-à-d. grand nombre de&#xA;lignes filtrées, peu de lignes renvoyées), plus un index sera intéressant pour&#xA;les performances. Mais pour avoir cette information du ratio, il faut avoir une&#xA;idée ou un résumé des données contenues dans chaque colonne. Pour cela,&#xA;PostgreSQL peut calculer, enregistrer et utiliser des statistiques sur ces&#xA;données. La commande &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; a pour responsabilité de générer ces&#xA;statistiques.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour le calcul des statistiques, un échantillon des lignes de la table est pris&#xA;en compte. Cet échantillon (en nombre de lignes) correspond au résultat de la&#xA;multiplication de la valeur du paramètre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;default_statistics_target&lt;/code&gt; avec une&#xA;valeur en dur (300). Ce paramètre vaut 100 par défaut, l’échantillon par défaut&#xA;est donc de 30000 lignes. Ces lignes sont prises au hasard, chacune dans un&#xA;bloc différent. Donc &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; lit par défaut 30000 blocs pour chaque table&#xA;(tout du moins pour les tables qui ont au moins 30000 blocs).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour chacune de ces lignes, la commande calcule les statistiques de chaque&#xA;colonne de la table, et les enregistre dans le catalogue système&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_statistic&lt;/code&gt;. Depuis la version 10, il peut aussi calculer des statistiques&#xA;sur le contenu de plusieurs colonnes. Nous parlons alors de statistiques&#xA;étendues, enregistrées dans les catalogues systèmes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_statistic_ext&lt;/code&gt; et&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_statistic_ext_data&lt;/code&gt;. Il est possible de regarder le contenu de ces&#xA;catalogues, mais c’est difficilement compréhensible pour un humain. Il est&#xA;préférable de passer par les vues &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stats&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stats_ext&lt;/code&gt;, qui ont été&#xA;spécialement créées pour être plus facilement appréhendables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Revenons à l’échantillon. Plus il est grand, plus les statistiques seront&#xA;précises. Cependant, plus il est grand, plus l’opération d’&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; sera&#xA;longue. Et cela peut paraître contre-intuitif, mais avoir plus de statistiques&#xA;va demander plus de travail à l’optimiseur qui mettra donc plus de temps à&#xA;proposer un plan d’exécution. Donc un échantillon plus grand n’est pas&#xA;automatiquement une bonne chose. Il faut faire la balance entre les gains sur&#xA;les plans générés et les pertes dues au calcul et à l’optimisation plus longue.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Même si la configuration basique est globale sur toutes les tables,&#xA;l’échantillon n’a en fait aucun intérêt d’être le même pour toutes les tables.&#xA;Chaque colonne de chaque table peut avoir une distribution spécifique des&#xA;données, et il pourrait donc être préférable de spécifier cette configuration&#xA;par colonne, voire par table. Même s’il n’est actuellement pas possible de la&#xA;spécifier par table, il est possible de le faire par colonne avec la commande&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ALTER TABLE&lt;/code&gt;. Par exemple :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;ALTER TABLE t1 ALTER COLUMN c1 SET STATISTICS 200;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Les statistiques sont calculées à l’exécution de la commande &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt;. Au fur&#xA;et à mesure des écritures dans la base, les statistiques vont devenir obsolètes&#xA;et il sera nécessaire de les calculer à nouveau. Autrement dit, il est&#xA;essentiel d’exécuter périodiquement cette commande. La fréquence de son&#xA;exécution dépend principalement de la fréquence des requêtes d’écriture de&#xA;données (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;INSERT&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;COPY&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;UPDATE&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;DELETE&lt;/code&gt;) ou plus exactement du nombre de&#xA;lignes impactées par ces requêtes.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;lutte-contre-la-fragmentation&#34;&gt;Lutte contre la fragmentation&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Au fil de l’utilisation d’une base de données de PostgreSQL, les tables&#xA;deviennent de plus en plus volumineuses si aucune opération de maintenance&#xA;n’est réalisée. En effet, lors d’opérations de mise à jour ou de suppression de&#xA;lignes dans une table, les lignes concernées ne sont pas supprimées directement&#xA;du fichier correspondant à cette table. Cela ralentirait beaucoup les écritures&#xA;si la suppression physique était immédiate. De plus, les lignes sont conservées&#xA;pour la session qui les a supprimées au cas où celle-ci devrait annuler la&#xA;suppression. Elles sont aussi conservées pour le cas où d’autres sessions&#xA;exécuteraient des lectures de la même table tant que la session qui supprime&#xA;ces lignes n’a pas validé sa transaction. Même si cette transaction est&#xA;validée, les lignes sont conservées au cas où les autres sessions utilisent un&#xA;niveau transactionnel qui leur permet toujours de voir ces anciennes lignes.&#xA;Bref, il existe plein de cas où ces lignes mises à jour ou supprimées doivent&#xA;rester accessibles à certaines sessions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Entrons un peu plus dans le détail des différentes opérations d’écriture. En&#xA;cas d’insertion (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;INSERT&lt;/code&gt; ou &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;COPY&lt;/code&gt;), soit il existe un emplacement de libre&#xA;dans un bloc de fichier, auquel cas la nouvelle ligne est enregistrée à cet&#xA;emplacement, soit il n’en existe pas de libre, ce qui cause l’ajout d’un&#xA;nouveau bloc, et l’enregistrement de la nouvelle ligne dans ce nouveau bloc.&#xA;L’index est modifié pour référencer la nouvelle ligne.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En cas de suppression (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;DELETE&lt;/code&gt;), la ligne ciblée est indiquée comme supprimée&#xA;dans le fichier de la table. L’index n’est pas touché et référence donc&#xA;toujours l’ancienne ligne.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En cas de mise à jour (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;UPDATE&lt;/code&gt;), PostgreSQL ne met pas à jour la ligne ciblée.&#xA;Il fait l’équivalent d’un Copy-On-Write, autrement dit une copie de la ligne&#xA;est effectuée dans le fichier de la table, la copie contient la nouvelle&#xA;(version de cette) ligne avec les données modifiées, l’ancienne (version de&#xA;cette) ligne est toujours présente avec les anciennes données. Comme indiqué&#xA;entre parenthèses, nous parlons plutôt de version de ligne, l’ancienne étant la&#xA;version originale, la nouvelle étant la version modifiée. Cette nouvelle&#xA;version est enregistrée comme toute nouvelle ligne. Donc, avec PostgreSQL, un&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;UPDATE&lt;/code&gt; est l’exact équivalent d’un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;DELETE&lt;/code&gt; de la ligne actuelle, suivi d’un&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;INSERT&lt;/code&gt; de la ligne avec les données modifiées. De ce fait, l’index se voit&#xA;ajouter (généralement) une nouvelle référence à cette ligne, mais avec un&#xA;pointeur indiquant l’emplacement de la nouvelle ligne, tout en conservant le&#xA;pointeur vers l’ancienne ligne.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;J’ai indiqué « l’index ». C’est évidemment à condition qu’il y ait un index sur cette table, et s’il y en a plusieurs, tous sont pris en compte, à quelques subtilités près (index partiel, mise à jour HOT).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nous nous retrouvons donc avec des lignes déclarées comme supprimées dans le&#xA;fichier, mais bien physiquement présentes dans le fichier. Pendant un moment,&#xA;elles restent visibles par certaines transactions. Cependant, au bout d’un&#xA;moment, toutes les transactions qui voyaient encore ces lignes se terminent. À&#xA;ce moment-là, aucune transaction ne peut voir ces lignes supprimées. Elles sont&#xA;pourtant toujours présentes dans le fichier de la table et il existe toujours&#xA;des références dans l’index qui pointent vers ces lignes. Pour ne pas perdre du&#xA;temps à chaque opération d’écriture dans la table, les développeurs de&#xA;PostgreSQL ont décidé qu’il faudrait exécuter une opération spécifique pour&#xA;trouver les lignes supprimées visibles par aucune session et les marquer d’une&#xA;façon particulière indiquant qu’il est possible de réutiliser l’espace qu’elles&#xA;occupent. Cette opération s’exécute en utilisant l’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cette opération réalise trois étapes :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;récupération de la liste des lignes actuellement invisibles par toutes les&#xA;transactions en cours ;&lt;/li&gt;&#xA;  &lt;li&gt;suppression des références de ces lignes dans les index de la table ;&lt;/li&gt;&#xA;  &lt;li&gt;mise à jour du fichier FSM indiquant les espaces libres réutilisables.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Ces trois étapes peuvent être exécutées plusieurs fois s’il n’est pas possible&#xA;de conserver en mémoire l’ensemble des lignes invisibles. La mémoire utilisée&#xA;pour cela dépend de la valeur du paramètre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;maintenance_work_mem&lt;/code&gt;, sachant que&#xA;l’opération &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ne pourra pas utiliser plus de 1 Go (ce qui représente&#xA;quand même 178 millions de lignes mortes).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois cette opération effectuée, un fichier FSM est présent sur disque. Tout&#xA;nouvel ajout de ligne (suite à un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;INSERT&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;COPY&lt;/code&gt; ou &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;UPDATE&lt;/code&gt;) lira ce fichier&#xA;pour trouver où placer la nouvelle ligne. Ceci permet d’utiliser les espaces&#xA;rendus disponibles et évite de faire grossir le fichier de la table.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans la majorité des cas, le nettoyage de la table et des index ne permet pas&#xA;aux fichiers de ces objets de perdre en volumétrie. Il permet principalement de&#xA;renseigner la structure FSM pour savoir où écrire sans faire grossir le&#xA;fichier. Cependant, si un ou plusieurs blocs en toute fin de fichier sont&#xA;complètement libérés de leurs lignes et qu’il est possible d’obtenir rapidement&#xA;un verrou exclusif sur la table, l’opération &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; pourra tronquer le&#xA;fichier pour rendre ces blocs au système de fichiers. De mon expérience, cela&#xA;est suffisamment peu fréquent pour être visible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour ce qui est de l’utilisation de l’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;, celle-ci peut viser&#xA;spécifiquement une table si son nom est indiqué. Par exemple, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM t1&lt;/code&gt;&#xA;permettra de traiter la table &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;t1&lt;/code&gt;. Si aucune table n’est indiquée, toutes les&#xA;tables de la base seront traitées.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; accepte plusieurs options. Vu le nombre (14 !), nous&#xA;n’allons pas les citer toutes ici. La plus fréquemment utilisée est l’option&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt;, qui permet de profiter des lectures de la table pour en plus mettre&#xA;à jour les statistiques sur les données, à l’image de l’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;PARALLEL&lt;/code&gt; permet de paralléliser le traitement des index d’une table&#xA;sur plusieurs CPU, avec un CPU par index. C’est particulièrement intéressant&#xA;pour les tables volumineuses dotées de nombreux index.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mais l’option la plus fréquemment évoquée est l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;FULL&lt;/code&gt;. Cette option&#xA;change complètement le travail de la commande &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;, et on peut se&#xA;questionner sur le bien-fondé de ne pas avoir créé une instruction spécifique&#xA;pour cette opération. En utilisant l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;FULL&lt;/code&gt;, nous forçons la réécriture&#xA;complète de la table et de ses index, ce qui aura pour conséquence une&#xA;diminution sur disque de la volumétrie des fichiers associés à ces objets.&#xA;Cette opération a cependant deux gros inconvénients : les objets sont&#xA;totalement verrouillés pendant cette opération (donc l’écriture et la lecture&#xA;par d’autres processus sont bloqués le temps du traitement), et il est&#xA;essentiel d’avoir la place nécessaire pour les nouveaux fichiers le temps du&#xA;traitement (l’estimation de la place nécessaire est très basique : comptez&#xA;exactement la même volumétrie que la table et ses index occupent avant&#xA;l’opération).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une autre opération fait à peu près la même chose : &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CLUSTER&lt;/code&gt;. La seule&#xA;différence avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM FULL&lt;/code&gt; est que &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CLUSTER&lt;/code&gt; trie en plus les données avant&#xA;de les stocker dans le nouveau fichier de table. Le tri se fait par rapport au&#xA;tri d’un index. Il faut donc indiquer à l’instruction la table à traiter et&#xA;l’index à suivre.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voilà pour ce qui est des tables, mais les index peuvent aussi se fragmenter.&#xA;Ils sont toujours correctement balancés, mais les blocs du fichier de l’index&#xA;peuvent ne pas être remplis. Dans ce cas, il convient de les réindexer.&#xA;L’opération est aussi lente que leur création, elle est aussi bloquante (pas de&#xA;lecture de l’index, pas d’écriture dans la table associée). Cette opération&#xA;utilise l’instruction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX&lt;/code&gt;. Il est possible de réindexer un seul index&#xA;(&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX INDEX i1;&lt;/code&gt;), tous les index d’une table (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX TABLE t1;&lt;/code&gt;), tous&#xA;les index d’un schéma (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX SCHEMA s1;&lt;/code&gt;), tous les index d’une base&#xA;(&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX;&lt;/code&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cette instruction accepte deux options : &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CONCURRENTLY&lt;/code&gt; (pour éviter le verrou&#xA;sur les écritures dans la table, ce qui a pour conséquence une opération plus&#xA;longue et le risque d’obtenir au final un index invalide) et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;TABLESPACE&lt;/code&gt; (pour&#xA;placer le nouveau fichier de l’index dans un autre tablespace).&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;comment-savoir-quun-objet-est-fragmenté&#34;&gt;Comment savoir qu’un objet est fragmenté&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Il existe deux moyens. Les deux sont à utiliser.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Le premier est une estimation. Il permet d’avoir rapidement une idée de la&#xA;fragmentation. Cette estimation se base notamment sur les statistiques sur les&#xA;données et elle sera d’autant plus fiable que ces statistiques sont récentes.&#xA;Deux groupes de requêtes sont disponibles, le premier pour les tables, le&#xA;second pour les index Btree. Les autres méthodes d’indexation ne sont donc pas&#xA;couvertes, cependant le Btree est la méthode par défaut et la plus couramment&#xA;utilisée. Ces requêtes sont disponibles dans le &lt;a href=&#34;https://github.com/ioguix/pgsql-bloat-estimation/&#34;&gt;dépôt GitHub&#xA;pgsql-bloat-estimation&lt;/a&gt;.&#xA;Généralement, je place ces requêtes dans des vues pour une utilisation&#xA;facilitée. Cela me donnerait par exemple cette requête pour trouver les 20&#xA;tables les plus fragmentées :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT quote_ident(schemaname)||&#39;.&#39;||quote_ident(tblname) AS table,&#xA;       real_size AS taille,&#xA;       bloat_size AS taille_fragmentation,&#xA;       round(bloat_pct::numeric, 2) AS ratio_fragmentation&#xA;FROM v_table_bloat&#xA;ORDER BY bloat_size DESC&#xA;LIMIT 20;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Le second est une extension (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgstattuple&lt;/code&gt;) qui donnera une information exacte.&#xA;Cependant, pour donner une information exacte, les fonctions qu’elle propose&#xA;doivent parcourir les objets entiers, ce qui se révèle très lent par rapport&#xA;aux requêtes citées précédemment. L’extension a été mise à jour récemment pour&#xA;proposer une fonction d’approximation qui se base, elle, sur le contenu de la&#xA;Visibility Map et sur le contenu de la Free Space Map. Voici un exemple de&#xA;requête utilisant la fonction exacte pour récupérer là aussi les 20 tables les&#xA;plus fragmentées :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT quote_ident(n.nspname)||&#39;.&#39;||quote_ident(c.relname) AS table,&#xA;       s.table_len AS taille,&#xA;       s.dead_tuple_len AS taille_invisibles,&#xA;       s.free_space AS taille_libre&#xA;FROM pg_class c&#xA;  JOIN pg_namespace n ON n.oid=c.relnamespace,&#xA;  LATERAL pgstattuple(c.oid) s&#xA;WHERE c.relkind=&#39;r&#39;&#xA;ORDER BY s.dead_tuple_len DESC&#xA;LIMIT 20;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;et celle utilisant la fonction d’approximation :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT quote_ident(n.nspname)||&#39;.&#39;||quote_ident(c.relname) AS table,&#xA;       s.table_len AS taille,&#xA;       s.dead_tuple_len AS taille_invisibles,&#xA;       s.approx_free_space AS taille_libre&#xA;FROM pg_class c&#xA;  JOIN pg_namespace n ON n.oid=c.relnamespace,&#xA;  LATERAL pgstattuple_approx(c.oid) s&#xA;WHERE c.relkind=&#39;r&#39;&#xA;ORDER BY s.dead_tuple_len DESC&#xA;LIMIT 20;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Cette extension dispose aussi de fonctions pour tester les index des méthodes&#xA;d’accès Btree, GIN et Hash.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour revenir au début de ce chapitre, je disais qu’il fallait utiliser les&#xA;deux, sans expliquer pourquoi. Les fonctions exactes sont trop longues si vous&#xA;voulez les exécuter fréquemment sur des bases de grosse volumétrie. Une&#xA;stratégie intéressante est d’utiliser les vues ou fonctions d’estimation pour&#xA;avoir une idée des objets les plus fragmentés et d’utiliser les fonctions&#xA;exactes uniquement sur les tables suffisamment fragmentées pour valider ou non&#xA;les informations des estimations. Cela permet de connaître les tables à traiter&#xA;réellement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En ce qui concerne la supervision, il peut être intéressant de suivre la&#xA;volumétrie de la base et sa fragmentation. Cela peut se faire avec la requête&#xA;suivante :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT &#39;volumétrie de la base&#39; AS &#34;Type&#34;, pg_size_pretty(pg_database_size(current_database())) AS &#34;Size&#34;&#xA;UNION&#xA;SELECT &#39;volumétrie de la fragmentation des tables&#39;, pg_size_pretty(sum(bloat_size)::numeric) FROM v_table_bloat&#xA;UNION&#xA;SELECT &#39;volumétrie de la fragmentation des index&#39;, pg_size_pretty(sum(bloat_size)::numeric) FROM v_index_bloat;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Ceci n’est qu’un exemple, qui sera facile à adapter le cas échéant.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;comment-exécuter-les-opérations-de-maintenance&#34;&gt;Comment exécuter les opérations de maintenance&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Une exécution manuelle est possible, mais ne convient qu’en de rares cas.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il est préférable d’automatiser ces opérations. Les développeurs de PostgreSQL&#xA;en ont automatisé certaines en développant un sous-processus appelé autovacuum.&#xA;Ce sous-processus va traiter chacune des bases de l’instance et déclenchera si&#xA;besoin des opérations &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt;. Ce besoin est détecté en se basant&#xA;sur le nombre de lignes insérées, modifiées et supprimées pour l’&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; et&#xA;sur le nombre de lignes mortes pour le VACUUM. Ces informations font partie des&#xA;statistiques d’activité récupérées en temps réel par PostgreSQL. Une&#xA;configuration permet d’indiquer à partir de quel ratio de lignes nous&#xA;souhaitons voir ces opérations déclenchées. Ces ratios sont par défaut très&#xA;haut, ce qui fait que peu d’opérations sont déclenchées, mais il est possible&#xA;de les diminuer globalement ou table par table si vos bases subissent beaucoup&#xA;d’écriture.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les paramètres les plus importants de ce sous-processus sont :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_analyze_scale_factor&lt;/code&gt;, ratio de lignes écrites avant de lancer&#xA;un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_analyze_threshold&lt;/code&gt;, nombre minimum de lignes écrites avant de&#xA;lancer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ANALYZE&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_vacuum_scale_factor&lt;/code&gt;, ratio de lignes mortes avant de lancer un&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_vacuum_threshold&lt;/code&gt;, nombre minimum de lignes mortes avant de&#xA;lancer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_vacuum_insert_scale_factor&lt;/code&gt;, ratio de lignes insérées avant de&#xA;lancer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_vacuum_insert_threshold&lt;/code&gt;, ratio de lignes insérées avant de&#xA;lancer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Le sous-processus autovacuum calcule donc la valeur cible en additionnant le&#xA;nombre minimum et le ratio multiplié par le nombre de lignes, et compare cette&#xA;valeur cible au nombre de lignes mortes pour le cas d’un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;. Si le nombre&#xA;de lignes mortes dépasse la valeur cible, l’autovacuum lance un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; sur la&#xA;table concernée. Par défaut, le ratio est de 20 %. Sur une petite table, ce&#xA;n’est pas énorme. Sur une table volumineuse par contre, le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; ne sera&#xA;lancé que très peu fréquemment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour le dire autrement, pour une table de 100 Go, il faudra attendre 20 Go de&#xA;fragmentation pour exécuter un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;. Ce n’est pas bon, il aurait fallu le&#xA;lancer bien avant. C’est pour cela qu’il est généralement conseillé de&#xA;descendre ce ratio et de le faire table par table pour prendre en compte leur&#xA;utilisation, leur fragmentation actuelle. Il est même parfois intéressant de&#xA;placer à zéro le ratio et de ne prendre en compte que le nombre minimum de&#xA;lignes, pour se baser sur un volume fixe de fragmentation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cependant, une configuration aussi détaillée demande du temps et des&#xA;connaissances. Le plus simple, dans un premier temps, est certainement de&#xA;diminuer les valeurs par défaut de manière globale. Il est fréquemment&#xA;conseillé de diviser les ratios pour 10.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il est à noter que l’autovacuum ne fait ni &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM FULL&lt;/code&gt;, ni &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;REINDEX&lt;/code&gt;. La&#xA;raison en est que ces opérations nécessitent un verrou exclusif qui est&#xA;bloquant pour les autres sessions en cours d’exécution. Cela va donc générer de&#xA;fortes contentions à des moments généralement très actifs. Ces deux opérations&#xA;sont plutôt à lancer manuellement, quand le besoin s’en fait sentir ou quand il&#xA;est prévu une fenêtre de maintenance où il n’y aura pas d’autres accès à la&#xA;base.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans les autres paramètres intéressants, notons &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum_work_mem&lt;/code&gt;. Ce&#xA;dernier a le même but que le paramètre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;maintenance_work_mem&lt;/code&gt;, mais ne concerne&#xA;que le processus autovacuum. Ainsi, il est possible d’avoir une configuration&#xA;pour ce sous-processus et une configuration pour les &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; manuels.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;en-conclusion&#34;&gt;En conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;autovacuum est votre (meilleur) ami. Certains le désactivent parce qu’il&#xA;consommerait beaucoup de ressources. Sans nier qu’il consomme effectivement des&#xA;ressources, il permet surtout d’en sauver grâce à des statistiques à jour et en&#xA;luttant contre le grossissement sans fin des tables. Dans la très grande&#xA;majorité des cas, le désactiver est une erreur.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si vous préférez passer par une exécution via cron, pourquoi pas, mais il faut&#xA;bien comprendre ce que l’on fait et pourquoi.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans tous les cas, comme l’a dit Robert Haas, un des principaux développeurs de&#xA;PostgreSQL, lors d’une conférence à Prague au PGConf.EU 2024 : “Vacuuming is&#xA;like exercising. If it hurts, you’re not doing it enough!” (« Le VACUUM, c’est&#xA;comme faire du sport. Si cela fait mal, c’est que vous n’en faites pas&#xA;assez ! »).&lt;/p&gt;&#xA;&#xA;&lt;hr /&gt;&#xA;&#xA;&lt;p&gt;Depuis quelques années, Guillaume Lelarge publie des articles dans le magazine&#xA;« Linux Pratique » édité par les Éditions Diamond. Avec leur accord, il reprend&#xA;ici une série destinée à guider l’installation, la maintenance et l’utilisation&#xA;de PostgreSQL.&lt;/p&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>La PGSession 17 en replay</title>
    <updated>2025-02-28T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-02-28://2025/02/28/replay_pgsession17.html</id>
    <link href="https://blog.dalibo.com//2025/02/28/replay_pgsession17.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Saint-Étienne, le 28 février 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La journée Conférences de la &lt;strong&gt;PGSession 17&lt;/strong&gt; s’est tenue le 15 janvier à Paris. Voici les liens vers les supports de présentation et les vidéos en replay !&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/pgsession17_speakers.png&#34; alt=&#34;Les conférenciers de la PGSession 17&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Un grand merci aux conférenciers pour leurs contributions : Matt, Julien, Pierre G., Clément, Guillaume A., Guillaume L., Loïc, Cédric, Pierre T. et Yann&lt;/strong&gt; (absent sur la photo).&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;les-conférences-en-replay&#34;&gt;Les conférences en replay&lt;/h3&gt;&#xA;&#xA;&lt;ol&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_pg17&#34;&gt;Les nouveautés de PostgreSQL 17&lt;/a&gt;&lt;/strong&gt;, par Cédric Martin et Guillaume Armède  (Dalibo)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_powa&#34;&gt;PoWA v.5 : quoi de neuf ?&lt;/a&gt;&lt;/strong&gt;, par Julien Rouhaud (Nile) et Pierre Giraud (Dalibo)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_rex-maif&#34;&gt;Retour d’expérience Client : le Socle Dalibo&lt;/a&gt;&lt;/strong&gt;, par Clément Paillier (MAIF)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_i3g&#34;&gt;2014-2024 : les 10 ans de l’Infrastructure Interne d’Information Géographique&lt;/a&gt;&lt;/strong&gt;, par Yann Convers (DRÉAL AuRA)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_azimutt&#34;&gt;Explorer, documenter et faire évoluer ses bases de données avec Azimutt&lt;/a&gt;&lt;/strong&gt;, par Loïc Knuchel (Azimutt)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_usual-suspects&#34;&gt;Usual Suspects : mais qui a mis la production dans cet état ?&lt;/a&gt;&lt;/strong&gt;, par Pierre Top (Octo Technology)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_dev-pg&#34;&gt;Développement d’une fonctionnalité pour PostgreSQL, du besoin au commit…&lt;/a&gt;&lt;/strong&gt;, par Guillaume Lelarge (Dalibo)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://dali.bo/pgsession17_conf_recherche-hybride&#34;&gt;Observer les oiseaux autrement : la recherche hybride au service de nos amis ailés&lt;/a&gt;&lt;/strong&gt;, par Matt Cornillon (Google Cloud)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;figure style=&#34;float: right;padding: 10px;width: 250px;&#34;&gt;&#xA;  &lt;img style=&#34;padding: 0;&#34; src=&#34;/img/2023_chapeau_rouge.png&#34; alt=&#34;Chapeau rouge&#34; /&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;Les autres liens utiles :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;a href=&#34;https://dali.bo/pgsession17_playlist&#34;&gt;la playlist PGSession 17&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;a href=&#34;https://dali.bo/pgsessions_archives&#34;&gt;les supports de présentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Enfin, nous remercions chaleureusement notre prestataire &lt;strong&gt;Chapeau rouge&lt;/strong&gt; pour son accompagnement vidéo, toujours efficace et sympathique.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bon visionnage !&lt;/p&gt;&#xA;&#xA;&lt;hr /&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Des questions, des commentaires, des suggestions ?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Écrivez-nous à &lt;a href=&#34;mailto:contact@pgsessions.com&#34;&gt;contact@pgsessions.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>Plongez dans le monde de CloudNativePG #4 - Les sauvegardes !</title>
    <updated>2025-02-27T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-02-27://2025/02/27/cnpg-3.html</id>
    <link href="https://blog.dalibo.com//2025/02/27/cnpg-3.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Lyon, le 27 février 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;CloudNativePG&lt;/strong&gt; ou comment embarquer un éléphant sur un porte-conteneurs !&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les deux premiers articles étaient l’occasion de découvrir l’opérateur et comment&#xA;il nous aide à embarquer notre éléphant favori sur un porte-conteneurs 🐘.&#xA;Embarquer un éléphant est une chose, le repêcher s’il tombe à l’eau en est une&#xA;autre… Attaquons-nous à un sujet très important, les sauvegardes des instances&#xA;PostgreSQL 🛟 !&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/cnpg-header.png&#34; alt=&#34;moteur&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;un-peu-de-données&#34;&gt;Un peu de données&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Pour le moment nos instances ne contiennent pas grand-chose. Il est temps&#xA;d’insérer quelques données, notamment avec l’outil &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;. C’est l’occasion&#xA;pour moi de présenter l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; du plugin &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;cnpg&lt;/code&gt;. &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; est un&#xA;outil très connu dans le monde PostgreSQL. Il permet notamment de générer des&#xA;jeux de tests et d’effectuer des tests de charge (à ce sujet, avez-vous lu notre&#xA;&lt;a href=&#34;https://blog.dalibo.com/2025/02/13/cnpg-3.html&#34;&gt;dernier article&lt;/a&gt; de blog ?).&#xA;Les mainteneurs CloudNativePG ont intégré cet outil du projet cœur PostgreSQL,&#xA;dans leurs images, nous permettant ainsi de l’utiliser.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg pgbench postgresql &lt;span class=&#34;nt&#34;&gt;--&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--initialize&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--scale&lt;/span&gt; 10 &#xA;&lt;span class=&#34;go&#34;&gt;job/postgresql-pgbench-446336 created&#xA;&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl logs job/postgresql-pgbench-446336&#xA;&lt;span class=&#34;go&#34;&gt;dropping old tables...&#xA;creating tables...&#xA;generating data (client-side)...&#xA;100000 of 1000000 tuples (10%) of pgbench_accounts done (elapsed 0.02 s, remaining 0.21 s)&#xA;200000 of 1000000 tuples (20%) of pgbench_accounts done (elapsed 0.08 s, remaining 0.30 s)&#xA;300000 of 1000000 tuples (30%) of pgbench_accounts done (elapsed 0.14 s, remaining 0.33 s)&#xA;400000 of 1000000 tuples (40%) of pgbench_accounts done (elapsed 0.20 s, remaining 0.30 s)&#xA;500000 of 1000000 tuples (50%) of pgbench_accounts done (elapsed 0.25 s, remaining 0.25 s)&#xA;600000 of 1000000 tuples (60%) of pgbench_accounts done (elapsed 0.30 s, remaining 0.20 s)&#xA;700000 of 1000000 tuples (70%) of pgbench_accounts done (elapsed 0.36 s, remaining 0.15 s)&#xA;800000 of 1000000 tuples (80%) of pgbench_accounts done (elapsed 0.44 s, remaining 0.11 s)&#xA;900000 of 1000000 tuples (90%) of pgbench_accounts done (elapsed 0.52 s, remaining 0.06 s)&#xA;1000000 of 1000000 tuples (100%) of pgbench_accounts done (elapsed 0.57 s, remaining 0.00 s)&#xA;vacuuming...&#xA;creating primary keys...&#xA;done in 0.96 s (drop tables 0.09 s, create tables 0.00 s, client-side generate 0.61 s, vacuum 0.11 s, primary keys 0.15 s).&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;La commande a généré 157 Mo de données dans la base &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;app&lt;/code&gt; (qui pour rappel, est&#xA;créée automatiquement par l’opérateur)… Oui je sais ! C’est une toute petite&#xA;base, mais c’est pour de la démo ! Les sujets liés à de la volumétrie importante&#xA;arriveront plus tard 😇.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;sauvegarde-logique&#34;&gt;Sauvegarde logique&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;À l’heure actuelle l’opérateur ne permet pas de déclencher une sauvegarde&#xA;logique de manière déclarative. Pour autant, dès lors que l’instance est&#xA;accessible, il est tout à fait possible de créer une sauvegarde avec l’outil&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_dump&lt;/code&gt; (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ou pg_dumpall&lt;/code&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Par exemple, si je rends mon instance accessible avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl port-forward&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;go&#34;&gt;kubectl port-forward --address 0.0.0.0 postgresql-2 5432:5432&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;Forwarding from 0.0.0.0:5432 -&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;5432&#xA;&lt;span class=&#34;go&#34;&gt;Handling connection for 5432&#xA;[...]&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Je peux appeler la commande &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_dump&lt;/code&gt;, renseigner le mot de passe et obtenir mon&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;dump&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;pg_dump &lt;span class=&#34;nt&#34;&gt;-h&lt;/span&gt; localhost &lt;span class=&#34;nt&#34;&gt;-U&lt;/span&gt; app &lt;span class=&#34;nt&#34;&gt;-Fc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; sauvegarde.dump&#xA;&lt;span class=&#34;go&#34;&gt;Password:&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;ls&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;-lh&lt;/span&gt; sauvegarde.dump&#xA;&lt;span class=&#34;go&#34;&gt;-rw-rw-r-- 1 pierrick pierrick 2,7M janv. 22 17:36 sauvegarde.dump&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;L’exposition du port 5432 de l’instance est grandement facilitée par la commande&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl port-forward&lt;/code&gt;. Dans un environnement de production, la mise en œuvre&#xA;demandera un peu plus de travail 🙃.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En bref, il vous sera toujours possible d’effectuer des sauvegardes logiques&#xA;d’une instance déployée par CloudNativePG.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;sauvegarde-par-volume-snapshot&#34;&gt;Sauvegarde par &lt;em&gt;Volume Snapshot&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;L’opérateur supporte aussi la méthode de sauvegarde par &lt;em&gt;Volume Snapshot&lt;/em&gt;. C’est&#xA;une fonctionnalité Kubernetes que ne supporte pas encore tous les&#xA;&lt;em&gt;Containers Storage Interface&lt;/em&gt; (CSI). Ce ne sera pas l’objet de l’article&#xA;aujourd’hui, mais jetez tout de même un œil à cette fonctionnalité&#xA;(&lt;a href=&#34;https://cloudnative-pg.io/documentation/current/backup_volumesnapshot/&#34;&gt;Backup on Volume Snapshot&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;sauvegarde-physique-pitr&#34;&gt;Sauvegarde physique &lt;em&gt;PITR&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;À l’inverse d’une sauvegarde logique, qui se limite à une base de données&#xA;spécifique, une sauvegarde physique permet de sauvegarder l’instance dans sa&#xA;globalité. Le principe est de sauvegarder toute l’arborescence PostgreSQL, que&#xA;ce soit les fichiers de données, le contenu des index, les fichiers de configuration ou les éléments&#xA;propres au fonctionnement de PostgreSQL.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si en plus de cette sauvegarde, vous archivez régulièrement les journaux de&#xA;transactions (&lt;em&gt;WAL&lt;/em&gt;) alors vous avez mis en place une sauvegarde &lt;em&gt;PITR&lt;/em&gt; (&lt;em&gt;Point In&#xA;Time Recovery&lt;/em&gt;) qui vous permettra, en rejouant ces fichiers là, de restaurer&#xA;votre instance soit complètement, soit jusqu’à un certain point dans le passé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Notre formation&#xA;&lt;a href=&#34;https://public.dalibo.com/exports/formation/manuels/formations/dba3/dba3.handout.html#sauvegarde-physique-%C3%A0-chaud-et-pitr&#34;&gt;DBA3&lt;/a&gt;&#xA;traite de ce sujet de manière plus détaillée&lt;/em&gt; 😎.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ce petit rappel étant fait, passons au vif du sujet !&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Stockage objets&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’opérateur CloudNativePG repose sur l’outil &lt;a href=&#34;https://docs.pgbarman.org/release/3.13.0/user_guide/barman_cloud.html&#34;&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Barman&#xA;Cloud&lt;/code&gt;&lt;/a&gt;&#xA;pour les sauvegardes physiques et l’archivage continu. Il est embarqué dans&#xA;l’image qui est utilisée lors de la création d’une instance. Le stockage des&#xA;journaux et des sauvegardes se fera obligatoirement sur un système de stockage&#xA;objets. Cette &lt;a href=&#34;https://cloudnative-pg.io/documentation/current/appendixes/object_stores/&#34;&gt;page de&#xA;documentation&lt;/a&gt;&#xA;indique les principales solutions supportées.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour cette série d’articles, je vais utiliser la solution &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Object Storage&lt;/code&gt; de&#xA;Scaleway, compatible &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;S3&lt;/code&gt;. Les informations qui me seront nécessaires sont :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;Le nom du &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt; à utiliser : ce sera &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;backup-postgresql&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;Une clé d’accès API : &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;jenevaispasvousladonner&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;Le secret lié à cette clé &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;encoremoinslesecret&lt;/code&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;La région de stockage : &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fr-par&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Ces informations là sont à ajouter dans un objet &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Secret&lt;/code&gt; qui sera par la&#xA;suite renseigné dans la configuration de notre instance. Les informations&#xA;doivent être encodées en &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;BASE64&lt;/code&gt; dans le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;YAML&lt;/code&gt;. Voici un exemple de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Secret&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Secret&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Opaque&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;ACCESS_KEY_ID&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;amVuZXZhaXNwYXN2b3VzbGFkb25uZXLCoA==&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;ACCESS_REGION&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ZnItcGFy&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;ACCESS_SECRET_KEY&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ZW5jb3JlbW9pbnNsZXNlY3JldMKg&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;N’oubliez pas de créer cet objet avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl apply&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Configuration&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Maintenant que nous avons un espace de stockage, voyons la configuration de&#xA;notre instance pour la mise en place de cette sauvegarde &lt;em&gt;PITR&lt;/em&gt;. Elle se fait&#xA;dans la section &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;backup.barmanObjectStore&lt;/code&gt; de notre objet &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Cluster&lt;/code&gt;.&#xA;Voilà à quoi ressemblerait notre définition :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql.cnpg.io/v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Cluster&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;imageName&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ghcr.io/cloudnative-pg/postgresql:17.0&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;instances&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;storage&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;20Gi&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;backup&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;barmanObjectStore&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;destinationPath&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;s3://backup-postgresql/&#34;&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;endpointURL&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;https://s3.fr-par.scw.cloud&#34;&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;s3Credentials&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;accessKeyId&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_KEY_ID&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;secretAccessKey&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_SECRET_KEY&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;region&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_REGION&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;destinationPath&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;endpointURL&lt;/code&gt; sont propres à la solution de stockage&#xA;choisie. Des exemples existent pour vous aider à configurer cela&#xA;(voir la page &lt;a href=&#34;https://cloudnative-pg.io/documentation/current/samples/&#34;&gt;Samples&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Lors de la création du &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Cluster&lt;/code&gt; PostgreSQL, les informations du &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Secret&lt;/code&gt;&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;s3-scaleway&lt;/code&gt; sont récupérées et l’archivage des journaux se fait&#xA;automatiquement sur le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt; S3.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Archivage des journaux&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dans les traces de notre instance, nous voyons désormais que les journaux sont&#xA;bien archivés. Voici l’exemple d’une trace &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;JSON&lt;/code&gt; mise en forme avec l’outil&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;jq&lt;/code&gt; où nous pouvons voir, dans le champ &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;msg&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;endTime&lt;/code&gt; par exemple, que le&#xA;journal a bien été archivé.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-json highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;level&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;info&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;ts&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;2025-01-23T09:57:03.786672436Z&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;logger&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;wal-archive&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;msg&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;Archived WAL file&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;logging_pod&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;postgresql-1&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;walName&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;/var/lib/postgresql/data/pgdata/pg_wal/000000010000000000000005&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;startTime&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;2025-01-23T09:57:00.327727678Z&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;endTime&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;2025-01-23T09:57:03.786579567Z&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;elapsedWalTime&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;3.458851895&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Côté Scaleway, toute une arborescence a été créée dans le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt;&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;backup-postgresql&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;go&#34;&gt;backup-postgresql&#xA;└── postgresql&#xA;    └── wals&#xA;        └── 0000000100000000&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;postgresql&lt;/code&gt;, qui correspond au &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;name&lt;/code&gt; de notre cluster PostgreSQL ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;wals&lt;/code&gt;, qui contient les dossiers correspondant aux différentes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;timelines&lt;/code&gt; de&#xA;l’instance ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;0000000100000000&lt;/code&gt;, qui contient les journaux.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Sauvegarde&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’opérateur CloudNativePG étend l’API Kubernetes avec une nouvelle ressource&#xA;appelée &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Backup&lt;/code&gt;. En créant une ressource de ce type, une sauvegarde physique&#xA;sera déclenchée et stockée dans le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt; associé à notre &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Cluster&lt;/code&gt;. Le nom du&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Cluster&lt;/code&gt; doit évidemment être mentionné dans la ressource pour que les&#xA;informations du stockage S3 soient récupérées.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Créons le fichier &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;sauvegarde.yaml&lt;/code&gt; avec le contenu suivant :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql.cnpg.io/v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Backup&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;premiere-sauvegarde&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;cluster&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Et créons cette ressource avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl apply -f sauvegarde.yaml&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl apply &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; sauvegarde.yaml&#xA;&lt;span class=&#34;go&#34;&gt;backup.postgresql.cnpg.io/premiere-sauvegarde created&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt; contient désormais le dossier &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;base&lt;/code&gt; qui contiendra les différentes&#xA;sauvegardes effectuées. Celle qui vient d’être faite est bien présente dans le&#xA;dossier.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;go&#34;&gt;backup-postgresql&#xA;└── postgresql&#xA;    ├── base&#xA;    │   └── 20250123T105602&#xA;    │      ├── backup.info&#xA;    │      └── data.tar&#xA;    └── wals&#xA;        └── 0000000100000000&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Pour information, l’opérateur CloudNativePG est configuré pour effectuer la&#xA;sauvegarde à partir d’un secondaire pour ne pas charger l’instance&#xA;primaire. C’est ce que l’on peut voir dans les traces de l’opérateur. Le champ&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pod&lt;/code&gt; indique bien que c’est le secondaire qui a été choisi.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-json highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;level&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;info&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;ts&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;2025-01-23T10:56:02.112865913Z&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;msg&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;Starting backup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;controller&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;backup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;controllerGroup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;postgresql.cnpg.io&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;controllerKind&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;Backup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;Backup&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;    &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;name&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;premiere-sauvegarde&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;    &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;namespace&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;default&#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;namespace&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;default&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;name&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;premiere-sauvegarde&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;reconcileID&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;a91635aa-0c72-4c88-98c8-f7de4c2da83a&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;cluster&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;postgresql&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;  &lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;&#34;pod&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&#34;postgresql-2&#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Cette configuration par défaut peut être surchargée avec l’option&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;target: &#34;primary&#34;&lt;/code&gt; de la ressource &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Backup&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;réutiliser-cette-sauvegarde&#34;&gt;Réutiliser cette sauvegarde&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;J’aurais pu titrer cette partie &lt;em&gt;Restauration de l’instance&lt;/em&gt;, mais je ne l’ai&#xA;volontairement pas fait pour proposer un autre angle pour aborder ce sujet.&#xA;Évidemment, dès lors qu’une sauvegarde existe, vous pouvez l’utiliser pour&#xA;restaurer une instance en panne. Ce sera très probablement un article de blog&#xA;(ça y est la liste d’articles s’allonge…😏).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les équipes de développement ont souvent besoin de données de production à jour&#xA;pour tester leur nouvelle version (je fais simple et ne pas rentrer dans&#xA;les problématiques d’&lt;a href=&#34;https://blog.dalibo.com/2024/11/15/postgresql_anonymizer_exports_anonymises.html&#34;&gt;anonymisation&lt;/a&gt; des données par exemple). L’idée ici est de&#xA;déployer une nouvelle instance sur un nouveau cluster Kubernetes à partir de&#xA;cette sauvegarde là.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sur un autre cluster Kubernetes, appelé &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;k8s-demo&lt;/code&gt;, j’installe l’opérateur &#xA;CloudNativePG et crée le cluster &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;postgresql-dev&lt;/code&gt; défini de cette manière :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql.cnpg.io/v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;Cluster&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql-dev&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;imageName&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ghcr.io/cloudnative-pg/postgresql:17.0&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;instances&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;storage&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;20Gi&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;bootstrap&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;na&#34;&gt;recovery&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;externalClusters&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;    &lt;span class=&#34;pi&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;postgresql&lt;/span&gt;&#xA;      &lt;span class=&#34;na&#34;&gt;barmanObjectStore&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;destinationPath&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;s3://backup-postgresql/&#34;&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;endpointURL&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;https://s3.fr-par.scw.cloud&#34;&lt;/span&gt;&#xA;        &lt;span class=&#34;na&#34;&gt;s3Credentials&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;accessKeyId&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_KEY_ID&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;secretAccessKey&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_SECRET_KEY&lt;/span&gt;&#xA;          &lt;span class=&#34;na&#34;&gt;region&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s3-scaleway&lt;/span&gt;&#xA;            &lt;span class=&#34;na&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ACCESS_REGION&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Les deux instructions intéressantes ici sont &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;bootstrap&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;externalClusters&lt;/code&gt;.&#xA;Elles permettent d’indiquer que la création de notre instance PostgreSQL, doit se&#xA;faire à partir de la sauvegarde qui se trouve sur le stockage S3 indiqué.&#xA;Si vous faites le test, n’oubliez pas de créer le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Secret&lt;/code&gt; &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;s3-scaleway&lt;/code&gt; dans le&#xA;cluster &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;k8s-dev&lt;/code&gt;. Il contient les informations de connexion au S3.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Pod&lt;/code&gt; spécifique va être déployé. Son nom est plutôt parlant :&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;postgresql-dev-1-full-recovery-xxxxx&lt;/code&gt;. Une restauration de type &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;full&lt;/code&gt; est en&#xA;train de se faire à partir de la sauvegarde S3. Lorsque celle-ci est terminée,&#xA;le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Pod&lt;/code&gt; est créé et votre instance est accessible, les données sont bien présentes sur l’instance du pod postgresql-dev.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;-it&lt;/span&gt; postgresql-dev-1 &lt;span class=&#34;nt&#34;&gt;--&lt;/span&gt; psql &lt;span class=&#34;nt&#34;&gt;-d&lt;/span&gt; app &lt;span class=&#34;nt&#34;&gt;-c&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\d&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;t&#34;&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;Defaulted container &#34;postgres&#34; out of: postgres, bootstrap-controller (init)&#xA;             List of relations&#xA; Schema |       Name       | Type  | Owner &#xA;--------+------------------+-------+-------&#xA; public | pgbench_accounts | table | app&#xA; public | pgbench_branches | table | app&#xA; public | pgbench_history  | table | app&#xA; public | pgbench_tellers  | table | app&#xA;(4 rows)&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Vous avez donc une nouvelle instance, créée à partir d’une sauvegarde de votre&#xA;instance de production.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Petit truc à savoir 💡 : l’opérateur utilise par défaut la sauvegarde la plus &#xA;récente disponible dans le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Bucket&lt;/code&gt;. Ce fonctionnement est ajustable selon votre&#xA;besoin.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Nous venons de voir comment sauvegarder notre instance avec CloudNativePG et&#xA;l’outil &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Barman&lt;/code&gt; sur une solution de stockage objets 🛟. La mise en place est&#xA;plutôt simple. J’ai volontairement fait une sauvegarde basique, sans rentrer&#xA;dans les détails. Sachez qu’il existe de nombreuses options, notamment pour ce&#xA;qui est de la compression ou de la rétention des sauvegardes. À vous de jouer !&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Des questions, des commentaires ? &lt;a href=&#34;mailto:pierrick.chovelon@dalibo.com?subject=[Commentaire-Blog] CloudNativePG&#34;&gt;Écrivez-nous !&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>Plongez dans le monde de CloudNativePG #3 - Stockage et performance</title>
    <updated>2025-02-13T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-02-13://2025/02/13/cnpg-3.html</id>
    <link href="https://blog.dalibo.com//2025/02/13/cnpg-3.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Vallée de Munster, 13 février 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Récemment, Dalibo a été sollicité par un client pour réaliser une étude&#xA;sur l’exploitation de PostgreSQL dans Kubernetes. Ce client avait&#xA;légitimement des questions concernant &lt;strong&gt;le stockage pour PostgreSQL&lt;/strong&gt;. Ce&#xA;dernier nous a explicitement demandé notre avis concernant Longhorn, une&#xA;solution de stockage répliqué et distribué pour Kubernetes.&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;Bien que nous ayons quelques hypothèses à ce sujet, la solution a&#xA;suscité notre intérêt. Nous avons donc voulu évaluer/explorer cette&#xA;solution de stockage de manière approfondie. Nous vous proposons dans&#xA;cet article une présentation de Longhorn, mais aussi d’une partie des&#xA;tests que nous avons réalisés pour PostgreSQL sur ce type&#xA;d’architecture. Ce sera l’occasion d’évoquer succinctement l’utilisation&#xA;du plugin &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl&lt;/code&gt; de l’opérateur &lt;strong&gt;CloudNativePG&lt;/strong&gt;, ce plugin sera utilisé&#xA;pour lancer &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; dans un environnement conteneurisé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/cnpg-header.png&#34; alt=&#34;moteur&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h1 id=&#34;présentation-longhorn&#34;&gt;Présentation Longhorn&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Longhorn est une solution de stockage (&lt;em&gt;block storage&lt;/em&gt;) persistant dite&#xA;hautement disponible et distribuée pour les Kubernetes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cette solution intègre des fonctionnalités de synchronisation des&#xA;données, de prise d’instantané et de sauvegarde incrémentielle des&#xA;volumes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Longhorn permet entre autre :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;La réplication du stockage entre plusieurs nœuds Kubernetes ;&lt;/li&gt;&#xA;  &lt;li&gt;La mise en place d’un stockage type “hyperconvergé”, le stockage se&#xA;fait par dessus Kubernetes. Il est par exemple possible de combiner&#xA;des nœuds de calcul et de stockage ;&lt;/li&gt;&#xA;  &lt;li&gt;De facilement exporter les données vers du stockage de type S3 ou&#xA;NFS. Pour par exemple stocker et planifier des sauvegardes ;&lt;/li&gt;&#xA;  &lt;li&gt;D’effectuer des instantanés (&lt;em&gt;snapshot&lt;/em&gt;) ;&lt;/li&gt;&#xA;  &lt;li&gt;D’avoir une interface web de gestion.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2 id=&#34;installation-de-longhorn&#34;&gt;Installation de Longhorn&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Nous avons réalisé une installation de base de Longhorn en utilisant la&#xA;procédure suivante:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Appliquer le &lt;em&gt;manifest&lt;/em&gt; distribué par le projet :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl apply &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; https://raw.githubusercontent.com/longhorn/longhorn/v1.8.0/deploy/longhorn.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Vérifier la présence des composants pour le fonctionnement de base&#xA;dans l’espace de nom &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;longhorn-system&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get pods &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt; longhorn-system&#xA;&lt;span class=&#34;go&#34;&gt;NAME                                                READY   STATUS    RESTARTS      AGE&#xA;csi-attacher-79866cdcf8-bs22m                       1/1     Running   1 (11m ago)   12m&#xA;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;...&#xA;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;longhorn-driver-deployer-64c9779f48-v4t55           1/1     Running   0             19m&#xA;longhorn-manager-xds9c                              2/2     Running   0             19m&#xA;longhorn-ui-5677d74dfd-c97p7                        1/1     Running   0             19m&#xA;longhorn-ui-5677d74dfd-dcckd                        1/1     Running   0             19m&#xA;&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get deployments &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt; longhorn-system&#xA;&lt;span class=&#34;go&#34;&gt;NAME                       READY   UP-TO-DATE   AVAILABLE   AGE&#xA;csi-attacher               3/3     3            3           19m&#xA;csi-provisioner            3/3     3            3           19m&#xA;csi-resizer                3/3     3            3           19m&#xA;csi-snapshotter            3/3     3            3           19m&#xA;longhorn-driver-deployer   1/1     1            1           25m&#xA;longhorn-ui                2/2     2            2           25&#xA;&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get services &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt; longhorn-system&#xA;&lt;span class=&#34;go&#34;&gt;NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;longhorn-admission-webhook    ClusterIP   10.96.9.151     &amp;lt;none&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;9502/TCP   31m&#xA;&lt;span class=&#34;c&#34;&gt;...&#xA;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;longhorn-recovery-backend     ClusterIP   10.96.235.98    &amp;lt;none&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;9503/TCP   31m&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Vérifier la présence des deux classes de stockage définies par le&#xA;&lt;em&gt;manifest&lt;/em&gt; de Longhorn&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get storageclasses.storage.k8s.io&#xA;&lt;span class=&#34;go&#34;&gt;NAME                 PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE&#xA;longhorn (default)   driver.longhorn.io      Delete          Immediate              true                   16m&#xA;longhorn-static      driver.longhorn.io      Delete          Immediate              true                   16m&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Et pour finir, consulter l’interface de gestion (nous utilisons ici,&#xA;une simple redirection de port) :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl port-forward services/longhorn-frontend &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; longhorn-system 8080:80&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;&#xA;    &lt;p&gt;Nous pouvons maintenant ouvrir l’interface de gestion dans notre&#xA;navigateur &lt;a href=&#34;http://127.0.0.1:8080&#34;&gt;http://127.0.0.1:8080&lt;/a&gt;&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Nous avons maintenant un cluster Kubernetes en mesure d’utiliser du&#xA;stockage distribué. L’utilisation de Longhorn permet potentiellement de&#xA;réduire le risque de perdre des données lors de la perte d’un nœud&#xA;Kubernetes. L’interface web de gestion donne un bref aperçu des&#xA;nombreuses options offertes par cette solution de stockage. Pour plus&#xA;des informations complémentaires concernant les fonctionnalités, le&#xA;fonctionnement interne de et la réplication inter nœud, nous vons&#xA;invitons à consulter la &lt;a href=&#34;https://longhorn.io/docs/1.8.0/concepts/&#34;&gt;documentation officielle du&#xA;projet&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Avant de continuer, il nous semble utile de rappeler que notre&#xA;installation (de Longhorn) est uniquement pour des tests. Pour un&#xA;système de production, il est strictement nécessaire de se questionner&#xA;concernant divers sujets que nous n’aborderons pas ici (par exemple:&#xA;CAP, fencing, sauvegarde…).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Après ces quelques vérifications et un rapide tour de l’interface de&#xA;gestion, nous pouvons démarrer nos tests.&lt;/p&gt;&#xA;&#xA;&lt;h2 id=&#34;tester-avec-du-stockage-répliqué&#34;&gt;Tester avec du stockage répliqué&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Dans ce paragraphe, nous allons mesurer la charge disque que Longhorn&#xA;est capable d’encaisser avec un volume composé de 3 réplicas&#xA;(configuration fournie par défaut). Nous lancerons aussi quelques tests&#xA;avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; sur une instance PostgreSQL. Comme annoncé dans&#xA;l’introduction, nous utiliserons pour cela le &lt;a href=&#34;https://cloudnative-pg.io/documentation/current/kubectl-plugin/#kubectl-plugin&#34;&gt;&lt;em&gt;plugin&#xA;CNPG&lt;/em&gt;&lt;/a&gt;&#xA;pour kubectl. Pour finir, l’opérateur CNPG sera aussi utilisé pour nous&#xA;faciliter la création de nos instances PostgreSQL de tests.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;lancer-fio&#34;&gt;Lancer &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Avant d’effectuer nos tests avec PostgreSQL, nous allons utiliser &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;&#xA;pour évaluer les performances brutes de notre stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour cela, nous pouvons lancer la commande suivante :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg fio fio-test-perf &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; default &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    --pvcSize 2Gi --storageClass longhorn --dry-run |\&#xA;    sed -e &#39;s/runtime=60/runtime=3600/g&#39;|kubectl apply -f -&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Cette commande va exécuter &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; pendant une heure avec un volume&#xA;dédié de 2 Gi. En fin d’exécution, les résultats sont récupérables via&#xA;une page web. Il est possible de consulter cette page en exposant le&#xA;service dédié :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl port-forward &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; fio deployment/fio-test-perf 8000&#xA;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;open http://127.0.0.1:8000&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;La page (consultable sur &lt;a href=&#34;http://127.0.0.1:8000&#34;&gt;http://127.0.0.1:8000&lt;/a&gt;) présente des&#xA;graphiques et les &lt;em&gt;logs&lt;/em&gt; de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;. Pour nos tests sur du stockage&#xA;répliqué la bande passante moyenne mesurée est de 2800 IOPs &lt;strong&gt;en&#xA;lecture&lt;/strong&gt; :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/read_iops_noreplica.1-2Dtrend.png&#34; alt=&#34;IOPs sur volume avec réplication&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour mesurer la capacité théorique en écriture, nous pouvons relancer&#xA;notre test en utilisant le scénario &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;write&lt;/code&gt; de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;. Pour modifier les&#xA;différents paramètres de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;, nous exportons le &lt;em&gt;manifest&lt;/em&gt; généré avec&#xA;le plugin CloudNativePG de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl&lt;/code&gt; pour ensuite le modifier :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg fio fio-test-perf-write &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; default &lt;span class=&#34;nt&#34;&gt;--pvcSize&lt;/span&gt; 2Gi &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;gp&#34;&gt;    --storageClass longhorn --dry-run &amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/tmp/scenario.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;On modifie la &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;ConfigMap&lt;/code&gt; pour &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; qui se trouve dans le fichier&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;/tmp/scenario.yaml&lt;/code&gt; (on change à minima l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;rw&lt;/code&gt; de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;read&lt;/code&gt; a&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;write&lt;/code&gt;) :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-yaml highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;na&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;v1&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;ConfigMap&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;fio-test-perf&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;default&lt;/span&gt;&#xA;&lt;span class=&#34;na&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt;&#xA;  &lt;span class=&#34;na&#34;&gt;job&lt;/span&gt;&lt;span class=&#34;pi&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;pi&#34;&gt;|-&lt;/span&gt;&#xA;    &lt;span class=&#34;s&#34;&gt;[write]&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;direct=1&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;bs=8k&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;size=1G&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;time_based=1&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;runtime=3600&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;ioengine=libaio&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;iodepth=32&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;end_fsync=1&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;log_avg_msec=1000&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;directory=/data&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;rw=write&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;write_bw_log=read&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;write_lat_log=read&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;write_iops_log=read&lt;/span&gt;&#xA;        &lt;span class=&#34;s&#34;&gt;...&lt;/span&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;L’exécution de ce scénario génère le graphique suivant :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/write_iops_withreplica.1-2Dtrend.png&#34; alt=&#34;IOPs en écriture sur volume avec réplication&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nous pouvons conclure que Longhorn avec 3 réplicas sur notre&#xA;infrastructure de test peut encaisser :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;2819 IOPs en lecture&lt;/li&gt;&#xA;  &lt;li&gt;1316 IOPs en écriture&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3 id=&#34;tester-avec-une-instance-postgresql&#34;&gt;Tester avec une instance PostgreSQL&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Nous allons maintenant utiliser &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; sur un cluster PostgreSQL. Ce&#xA;cluster sera composé d’une seule instance PostgreSQL. Les données de&#xA;notre instance se trouveront sur du stockage répliqué sur 3 nœuds&#xA;Kubernetes (configuration de base de la classe de stockage &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;longhorn&lt;/code&gt;).&#xA;Nous commençons par déclarer une instance avec la classe de stockage&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;longhorn&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl apply &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; - &lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;no&#34;&gt;EOF&lt;/span&gt;&lt;span class=&#34;sh&#34;&gt;&#xA;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;apiVersion: postgresql.cnpg.io/v1&#xA;kind: Cluster&#xA;metadata:&#xA;  name: cluster-longhorn&#xA;spec:&#xA;  instances: 1&#xA;  storage:&#xA;    storageClass: longhorn&#xA;    size: 10Gi&#xA;  resources:&#xA;    requests:&#xA;      memory: 1Gi&#xA;      cpu: &#39;1&#39;&#xA;    limits:&#xA;      memory: 2Gi&#xA;      cpu: &#39;2&#39;&#xA;  postgresql:&#xA;    parameters:&#xA;      shared_buffers: 256MB&#xA;      effective_io_concurrency: &#39;300&#39;&#xA;      random_page_cost: &#39;1.1&#39;&#xA;EOF&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Cette instance (après initialisation) est utilisable et testable en&#xA;suivant les étapes suivantes :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Garnir la base &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;app&lt;/code&gt; de notre instance avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;. Pour cette&#xA;opération, nous utilisons le plugin &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl&lt;/code&gt; de CloudNativePG pour&#xA;déployer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt; (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;job-instance-longhorn&lt;/code&gt; ici) dédié à &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;.&#xA;Les options &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--initialize&lt;/code&gt; &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--scale 250&lt;/code&gt; sont placées après un&#xA;double tiret. En fonction de nos besoins, il est possible d’ajouter&#xA;des options complémentaires pour &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg pgbench &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    --job-name job-instance-longhorn cluster-longhorn \&#xA;    -- --initialize --scale 250&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Surveiller le &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Pod&lt;/code&gt; correspondant à &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;&#xA;(&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;job-instance-longhorn-djgwb&lt;/code&gt;) :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get pods&#xA;&lt;span class=&#34;go&#34;&gt;NAME                              READY   STATUS      RESTARTS   AGE&#xA;cluster-longhorn-1                1/1     Running     0          8m34s&#xA;cluster-longhorn-1-initdb-6bgsb   0/1     Completed   0          9m&#xA;job-instance-longhorn-djgwb       1/1     Running     0          3m33s&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Récupérer les résultats de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; en affichant les journaux du&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl logs &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt; default job/job-instance-longhorn-client1&#xA;&lt;span class=&#34;go&#34;&gt;dropping old tables...&#xA;NOTICE:  table &#34;pgbench_accounts&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_branches&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_history&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_tellers&#34; does not exist, skipping&#xA;creating tables...&#xA;generating data (client-side)...&#xA;100000 of 25000000 tuples (0%) of pgbench_accounts done (elapsed 0.08 s, remaining 20.13 s) &#xA;200000 of 25000000 tuples (0%) of pgbench_accounts done (elapsed 0.14 s, remaining 17.49 s)&#xA;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;...&#xA;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;24900000 of 25000000 tuples (99%) of pgbench_accounts done (elapsed 200.00 s, remaining 0.80 s)&#xA;25000000 of 25000000 tuples (100%) of pgbench_accounts done (elapsed 201.36 s, remaining 0.00 s)&#xA;vacuuming...&#xA;creating primary keys...&#xA;done in 336.58 s (drop tables 0.01 s, create tables 0.14 s, client-side generate 203.41 s, vacuum 13.16 s, primary keys 119.86 s).&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Les informations utiles se trouvent à la fin :&lt;/p&gt;&#xA;&#xA;    &lt;ul&gt;&#xA;      &lt;li&gt;durée : 336.58 s&lt;/li&gt;&#xA;      &lt;li&gt;temps création des clés primaires : 119.86 s&lt;/li&gt;&#xA;      &lt;li&gt;client-side generate - principalement temps pour garnir les&#xA;tables : 203.41 s&lt;/li&gt;&#xA;    &lt;/ul&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Si nécessaire, nous pouvons aussi récupérer la taille (3746 MB) de&#xA;la base en utilisant cette commande :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--namespace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;default &lt;span class=&#34;nt&#34;&gt;--stdin&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;--tty&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    -ti cluster-longhorn-1  \&#xA;    -- psql -c &#34;SELECT pg_size_pretty(pg_database_size(&#39;app&#39;))&#34;&#xA;Defaulted container &#34;postgres&#34; out of: postgres, bootstrap-controller (init)&#xA; pg_size_pretty&#xA;----------------&#xA; 3746 MB&#xA;(1 row)&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;Maintenant que notre base de test est en place, nous lançons&#xA;successivement des tâches (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt;) pour &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; en augmentant&#xA;progressivement la valeur de l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--client&lt;/code&gt; (et ce afin&#xA;d’établir le tableau visible plus bas) :&lt;/p&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg pgbench &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    --job-name job-instance-longhorn-client1 cluster-longhorn \&#xA;    -- --time 300 --client 1 --jobs 1&#xA;job/job-instance-longhorn-client1 create&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;&#xA;    &lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl logs &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; job/job-instance-longhorn-client1&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;&#xA;&#xA;    &lt;p&gt;Cette dernière étape permet d’établir ce tableau (variation de&#xA;l’option &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--client&lt;/code&gt;) :&lt;/p&gt;&#xA;&#xA;    &lt;table&gt;&#xA;      &lt;thead&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--client&lt;/code&gt;&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;TPS&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;Latence moyenne&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;initial connection time&lt;/th&gt;&#xA;        &lt;/tr&gt;&#xA;      &lt;/thead&gt;&#xA;      &lt;tbody&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;1&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;52&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;18.906&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;28.819&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;2&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;109&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;18.260&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;22.341&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;4&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;201&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;19.850&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;24.132&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;8&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;313&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;24.256&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;108.819&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;        &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;16&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;409&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;39.026&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;57.023&lt;/td&gt;&#xA;        &lt;/tr&gt;&#xA;      &lt;/tbody&gt;&#xA;    &lt;/table&gt;&#xA;  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2 id=&#34;tester-avec-du-stockage-non-répliqué&#34;&gt;Tester avec du stockage non répliqué&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Dans cette section, nous allons réaliser notre batterie de tests (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt;&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; et plusieurs exécutions de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;) en utilisant du stockage non&#xA;répliqué.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On commence par ajouter une classe de stockage utilisant Longhorn en&#xA;positionnant le nombre de réplica à 1 (la partie importante est la ligne&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;numberOfReplicas: &#34;1&#34;&lt;/code&gt;) :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl apply &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; - &lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;no&#34;&gt;EOF&lt;/span&gt;&lt;span class=&#34;sh&#34;&gt;&#xA;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;---&#xA;allowVolumeExpansion: true&#xA;apiVersion: storage.k8s.io/v1&#xA;kind: StorageClass&#xA;metadata:&#xA;  name: longhorn-noreplica&#xA;parameters:&#xA;  dataEngine: v1&#xA;  dataLocality: disabled&#xA;  disableRevisionCounter: &#34;true&#34;&#xA;  fromBackup: &#34;&#34;&#xA;  fsType: ext4&#xA;  numberOfReplicas: &#34;1&#34;&#xA;  staleReplicaTimeout: &#34;30&#34;&#xA;  unmapMarkSnapChainRemoved: ignored&#xA;provisioner: driver.longhorn.io&#xA;reclaimPolicy: Delete&#xA;volumeBindingMode: Immediate&#xA;EOF&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Nous pouvons vérifier la présence de cette nouvelle classe et reprendre&#xA;nos tests en adaptant la classe de stockage :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl get storageclasses.storage.k8s.io longhorn-noreplica&#xA;&lt;span class=&#34;go&#34;&gt;NAME                 PROVISIONER          RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE&#xA;longhorn-noreplica   driver.longhorn.io   Delete          Immediate           true                   4d&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;h3 id=&#34;lancer-fio-1&#34;&gt;Lancer fio&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;On lance un nouveau &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Job&lt;/code&gt; pour &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt; en spécifiant notre nouvelle classe&#xA;de stockage :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl cnpg fio fio-test-perf-noreplica &lt;span class=&#34;nt&#34;&gt;-n&lt;/span&gt; default &lt;span class=&#34;se&#34;&gt;\&lt;/span&gt;&#xA;&lt;span class=&#34;go&#34;&gt;    --pvcSize 2Gi --storageClass longhorn-noreplica --dry-run |\&#xA;    sed -e &#39;s/runtime=60/runtime=3600/g&#39; | kubectl apply -f -&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Pour ensuite consulter les résultats, on expose le port 80 de notre&#xA;déploiement :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl port-forward deployment/fio-test-perf-noreplica 8000&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/read_iops_noreplica.1-2Dtrend.png&#34; alt=&#34;IOPs en lecture sur volume sans réplication&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Et exécuter le test en écriture et consulter les résultats :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/write_iops_noreplica.1-2Dtrend.png&#34; alt=&#34;IOPs en écriture sur volume sans réplication&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nous constatons que notre solution de stockage configurée sans&#xA;réplication est en mesure d’encaisser en moyenne :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;2493 IOPs en lecture&lt;/li&gt;&#xA;  &lt;li&gt;2289 IOPs en écriture&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Par rapport à une instance utilisant du stockage répliqué, on remarque&#xA;une différence importante pour les écritures (presque 1000 IOPS en&#xA;plus).&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;tester-avec-une-instance-postgresql-1&#34;&gt;Tester avec une instance PostgreSQL&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Après avoir testé avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;fio&lt;/code&gt;, nous allons réaliser la même batterie de&#xA;tests avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; que pour notre première instance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On commence par déclarer une nouvelle instance PostgreSQL en utilisant&#xA;notre nouvelle classe de stockage, pour ensuite :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;Garnir cette seconde instance avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; et les options&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--initialize&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--scale 250&lt;/code&gt;&lt;/li&gt;&#xA;  &lt;li&gt;Lancer plusieurs tâches pour simuler progressivement 1, 2, 4, 8 et&#xA;16 clients PostgreSQL.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Ce qui va nous permettre de comparer les deux configurations avec et&#xA;sans réplication synchrone au niveau stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Le résultat du garnissage d’une base indique ceci :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-console highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;kubectl logs &lt;span class=&#34;nt&#34;&gt;-f&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;jobs&lt;/span&gt;/job-instance-longhorn-noreplica&#xA;&lt;span class=&#34;go&#34;&gt;dropping old tables...&#xA;NOTICE:  table &#34;pgbench_accounts&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_branches&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_history&#34; does not exist, skipping&#xA;NOTICE:  table &#34;pgbench_tellers&#34; does not exist, skipping&#xA;creating tables...&#xA;generating data (client-side)...&#xA;100000 of 25000000 tuples (0%) of pgbench_accounts done (elapsed 0.06 s, remaining 15.69 s)&#xA;200000 of 25000000 tuples (0%) of pgbench_accounts done (elapsed 0.31 s, remaining 37.95 s)&#xA;300000 of 25000000 tuples (1%) of pgbench_accounts done (elapsed 0.39 s, remaining 31.78 s)&#xA;24900000 of 25000000 tuples (99%) of pgbench_accounts done (elapsed 100.51 s, remaining 0.48 s)&#xA;25000000 of 25000000 tuples (100%) of pgbench_accounts done (elapsed 100.58 s, remaining 0.00 s)&#xA;vacuuming...&#xA;creating primary keys...&#xA;done in 203.71 s (drop tables 0.01 s, create tables 0.09 s, client-side generate 102.00 s, vacuum 11.99 s, primary keys 89.62 s).&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Ces informations nous montrent que sans réplication le garnissage de&#xA;notre base prend approximativement 1/3 de temps en moins :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;durée : 203.71 s (336.58 s lors de notre première exécution)&lt;/li&gt;&#xA;  &lt;li&gt;temps création des clés primaires : 89.62 s, (cela représente 30 s&#xA;de moins que pour une instance avec du stockage répliqué)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;em&gt;client-side generate&lt;/em&gt; - (principalement du temps pour garnir les&#xA;tables) : 102.00 secondes, ce qui correspond à 101 secondes de moins&#xA;que notre première instance avec du stockage répliqué&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Et les résultats des différents jobs avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt;, nous permettent&#xA;d’établir le tableau suivant :&lt;/p&gt;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th style=&#34;text-align: center&#34;&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;--client&lt;/code&gt;&lt;/th&gt;&#xA;      &lt;th style=&#34;text-align: center&#34;&gt;TPS&lt;/th&gt;&#xA;      &lt;th style=&#34;text-align: center&#34;&gt;Latence moyenne&lt;/th&gt;&#xA;      &lt;th style=&#34;text-align: center&#34;&gt;initial connection time&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;1&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;63&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;13.953&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;19.090&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;2&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;144&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;13.864&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;43.447&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;4&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;242&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;19.433&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;25.395&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;8&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;329&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;24.300&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;138.927&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;16&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;412&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;38.839&lt;/td&gt;&#xA;      &lt;td style=&#34;text-align: center&#34;&gt;157.923&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;p&gt;Les lectures restent sensiblement identiques. Il pourrait être utile de&#xA;vérifier le comportement du cache ou des caches (PostgreSQL, système…)&#xA;pour en savoir plus concernant les lectures.&lt;/p&gt;&#xA;&#xA;&lt;h1 id=&#34;conclusion---stockage-distribué-avec-postgresql&#34;&gt;Conclusion - Stockage distribué avec PostgreSQL&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Intuitivement, sur la base de notre connaissance d’autres solutions de&#xA;stockage et du fonctionnement de PostgreSQL, on aurait tendance à&#xA;conseiller de désactiver la réplication au niveau du stockage pour&#xA;laisser PostgreSQL s’occuper de la réplication.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les résultats de nos tests (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pgbench&lt;/code&gt; lors des phases d’initialisations)&#xA;démontrent un impact (&lt;em&gt;Write amplification&lt;/em&gt;) notable sur les écritures.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;D’ailleurs, on retrouve dans la documentation de CloudNativePG un&#xA;paragraphe spécifique concernant ce type de solution.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Most block storage solutions in Kubernetes, such as Longhorn and Ceph,&#xA;recommend having multiple replicas of a volume to enhance resiliency.&#xA;This approach works well for workloads that lack built-in resiliency.&lt;/p&gt;&#xA;&#xA;  &lt;p&gt;However, CloudNativePG integrates this resiliency directly into the&#xA;Postgres Cluster through the number of instances and the persistent&#xA;volumes attached to them, as explained in “Synchronizing the state”.&lt;/p&gt;&#xA;&#xA;  &lt;p&gt;As a result, defining additional replicas at the storage level can&#xA;lead to write amplification, unnecessarily increasing disk I/O and&#xA;space usage.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://cloudnative-pg.io/documentation/1.25/storage/&#34;&gt;https://cloudnative-pg.io/documentation/1.25/storage/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nos tests et la documentation valident donc nos intuitions. Lors de&#xA;l’utilisation de PostgreSQL sur des technologies de stockage avancées,&#xA;il est souvent souhaitable de s’appuyer sur les mécanismes natifs (de&#xA;PostgreSQL) pour gérer la réplication. Dit plus simplement Longhorn,&#xA;dans sa configuration de base, ne nous semble pas adapté pour notre SGBD&#xA;favori et pourrait même avoir des effets indésirables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Concernant les lectures disque, on constate que Longhorn, de par son&#xA;architecture, n’apporte pas grand-chose pour PostgreSQL. Lors de nos&#xA;tests, c’est surtout le cache système et de PostgreSQL qui semblent être&#xA;bénéfiques. On aurait d’ailleurs pu présenter des tests spécifiques pour&#xA;démontrer cela (pourquoi pas dans un prochain article ?!).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cet article, nous a permis de présenter quelques fonctionnalités&#xA;fournies avec le plugin &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;kubectl&lt;/code&gt; de CloudNativePG. Nous avons aussi un&#xA;bref aperçu du fonctionnement de Longhorn. Dans le cadre de nos&#xA;recherches et tests, nous avons traité plus en profondeur cette&#xA;technologie. Nous avons retenu ici, la partie la plus pertinente pour&#xA;PostgreSQL. D’autres articles concernant PostgreSQL et Kubernetes&#xA;arriveront prochainement sur notre blog.&lt;/p&gt;&#xA;&#xA;&lt;!--&#xA;    vim: spelllang=fr spell&#xA;  --&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>La suite des patchs sur la parallélisation</title>
    <updated>2025-02-10T06:00:00Z</updated>
    <id>tag:blog.dalibo.com,2025-02-10://2025/02/10/patchs_parallelisations_2.html</id>
    <link href="https://blog.dalibo.com//2025/02/10/patchs_parallelisations_2.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;em&gt;Reviers, le 10 février 2025&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cela fait plusieurs mois maintenant que nous avons envoyé des patchs sur la&#xA;&lt;a href=&#34;https://www.postgresql.org/list/pgsql-hackers/&#34;&gt;liste de discussion des développeurs de PostgreSQL&lt;/a&gt; pour&#xA;améliorer la supervision de la parallélisation. J’avais promis de revenir&#xA;vers vous à ce sujet. Je l’ai fait lors d’une conférence à la &lt;a href=&#34;https://dali.bo/pgsession17_conf_dev-pg&#34;&gt;PGSession 17&lt;/a&gt;&#xA;et je vais revenir rapidement ici sur ce sujet pour ceux et celles qui n’ont&#xA;pas pu y assister.&lt;/p&gt;&#xA;&#xA;&lt;!--MORE--&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;/img/portrait_guillaume.png&#34; alt=&#34;Guillaume Lelarge&#34; style=&#34;float: right; padding:10px; width:120px;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En septembre 2024, Benoît et moi avons envoyé quatre patchs pour améliorer la supervision de la parallélisation d’une requête. Détaillons ces patchs et le retour qu’ils ont reçu.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;patch-1--traces-supplémentaires&#34;&gt;Patch #1 : traces supplémentaires&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;L’idée des quatre participants (Benoît, Franck, Jehan-Guillaume et moi) du&#xA;&lt;a href=&#34;https://blog.dalibo.com/2024/09/16/cowork_parallelisation.html&#34;&gt;cowork de Nantes&lt;/a&gt; est d’avoir une trace permettant de savoir quand la&#xA;parallélisation d’un nœud d’une requête a été demandée, le niveau de parallélisation demandé&#xA;(nombre de workers planifiés), et le niveau de parallélisation atteint&#xA;(nombre de workers réellement exécutés). Voici un exemple de la trace&#xA;proposée :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;LOG:  1 parallel nodes planned (1 obtained all their workers, 0 obtained none), 2 workers planned (2 workers launched)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Savoir qu’il n’y a aucune requête parallélisée ou, au contraire, savoir qu’il y&#xA;en a plein, peut aider à quantifier les ressources allouées à la machine&#xA;(ici, le nombre de CPU).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Savoir qu’il y a eu moins de workers exécutés que planifiés peut démontrer un&#xA;problème de configuration (notamment sur les paramètres&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;max_worker_processes&lt;/code&gt;, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;max_parallel_workers&lt;/code&gt; et&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;max_parallel_workers_per_gather&lt;/code&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;À Dalibo, on tient à conseiller nos clients en nous basant sur des constatations&#xA;et force est d’avouer que cette trace supplémentaire nous aiderait&#xA;grandement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ces traces ont donc un intérêt et le patch a logiquement suscité un intérêt de la part de la communauté. Suite aux réactions, le patch a été amélioré. Il en est aujourd’hui à sa version 6 et est divisé en plusieurs parties :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0001-Add-a-guc-for-parallel-worker-logging.patch&lt;/code&gt; ajoute un paramètre&#xA;de configuration (&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;log_parallel_workers&lt;/code&gt;) permettant de contrôler la trace sur&#xA;la parallélisation avec trois options : désactivé, activé pour toutes les&#xA;opérations, activé seulement quand des workers manquaient.&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0002-Implements-logging-for-parallel-worker-usage-in-inde.patch&lt;/code&gt; ajoute&#xA;la trace sur les requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CREATE INDEX&lt;/code&gt; (attention, seuls les index B-tree&#xA;et BRIN peuvent profiter de la parallélisation à leur création).&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0003-Setup-counters-for-parallel-vacuums.patch&lt;/code&gt; ajoute les compteurs de&#xA;parallélisation pour tracer la parallélisation des requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;.&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0004-Implements-logging-for-parallel-worker-usage-in-vacu.patch&lt;/code&gt; ajoute&#xA;les traces sur la parallélisation des requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;.&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;V6_0005-Implements-logging-for-parallel-worker-usage-in-quer.patch&lt;/code&gt; ajoute&#xA;les traces sur la parallélisation des requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;SELECT&lt;/code&gt; (les compteurs ont&#xA;été ajoutés par un autre patch dont nous parlerons après).&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;La trace est devenue plus simple :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;launched 3 parallel workers (planned: 4)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Le but de la division en plusieurs patchs est de mieux comprendre la&#xA;structure du patch global, de faciliter sa relecture, puis de permettre au&#xA;&lt;em&gt;commiter&lt;/em&gt; d’intégrer uniquement les parties qui lui semblent intéressantes et finalisées,&#xA;si le patch global nécessite encore des discussions. Cela donne ainsi plus de&#xA;chance au développeur de voir au moins une partie de son patch intégrée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Actuellement, ce patch n’a pas été intégré. Il &lt;a href=&#34;https://commitfest.postgresql.org/51/4291/&#34;&gt;fait partie du commit fest de&#xA;janvier&lt;/a&gt;, à l’état &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;Needs review&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;patch-2--pg_stat_database&#34;&gt;Patch #2 : pg_stat_database&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette vue nous intéresse pour cumuler par base le nombre de workers de&#xA;parallélisation planifiés et le nombre de ceux réellement exécutés. Le patch&#xA;initial proposait quatre nouvelles colonnes, deux pour les requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;SELECT&lt;/code&gt;&#xA;et deux pour les requêtes DDL (actuellement, seules les commandes DDL &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CREATE&#xA;INDEX&lt;/code&gt; et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; sont parallélisables).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Là aussi, une bonne discussion a eu lieu sur l’intérêt de ces différentes&#xA;colonnes. Autant la présence de colonnes pour les requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;SELECT&lt;/code&gt; ne&#xA;suscite pas trop d’objections, autant celle des colonnes pour les requêtes&#xA;DDL est fortement contestée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;L’argument principal contre ces colonnes est qu’un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;CREATE INDEX&lt;/code&gt; et un&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; sont des opérations manuelles et que l’opérateur peut voir lui-même&#xA;quand il lance l’opération si cette opération est parallélisée. Pour moi, cet&#xA;argument a du sens. Pour les « petits malins » qui objecteront qu’un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt;&#xA;est automatisé via le processus &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum&lt;/code&gt;, je répondrais qu’ils ont bien&#xA;raison, mais que ce &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; automatisé n’utilise pas la clause &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;PARALLEL&lt;/code&gt;&#xA;qui permettrait sa parallélisation. Pour le dire autrement, l’&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;autovacuum&lt;/code&gt; ne&#xA;peut pas exécuter un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;VACUUM&lt;/code&gt; parallélisé actuellement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Donc l’argument est difficilement contestable et, de ce fait, &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=e7a9496de9&#34;&gt;seule la&#xA;moitié du patch a été appliquée dans ce commit&lt;/a&gt;. Et voici le résultat&#xA;lorsqu’on interroge ces nouvelles colonnes :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT datname, parallel_workers_to_launch, parallel_workers_launched&#xA;FROM pg_stat_database&#xA;WHERE datname IS NOT null;&#xA;&#xA;  datname  | parallel_workers_to_launch | parallel_workers_launched&#xA;-----------+----------------------------+---------------------------&#xA; postgres  |                         50 |                        45&#xA; template1 |                          0 |                         0&#xA; template0 |                          0 |                         0&#xA;(3 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;h3 id=&#34;patch-3--pg_stat_statements&#34;&gt;Patch #3 : pg_stat_statements&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;La vue &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_statements&lt;/code&gt; donne des informations sur les requêtes exécutées.&#xA;Connaître la durée d’exécution, le nombre d’exécutions, l’utilisation du cache&#xA;ou de JIT sur ces requêtes aide beaucoup à leur optimisation. Il nous a donc&#xA;semblé intéressant d’ajouter des informations sur la parallélisation par&#xA;requête.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Le premier patch était un peu naïf, proposant ainsi sept nouvelles colonnes.&#xA;Beaucoup ont été contestées et au final, le patch, en sa version 3, a été&#xA;divisé en deux parties, bien plus modestes :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;v3-0001-Introduce-two-new-counters-in-EState.patch&lt;/code&gt; ajoute les compteurs de&#xA;parallélisation pour tracer la parallélisation des requêtes &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;SELECT&lt;/code&gt; (ces&#xA;compteurs sont aussi utilisés par les nouvelles colonnes de la vue&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_database&lt;/code&gt;).&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;  &lt;li&gt;&#xA;    &lt;p&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;v3-0002-Add-parallel-columns-to-pg_stat_statements.patch&lt;/code&gt; ajoute les deux colonnes acceptées dans &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_statements&lt;/code&gt;.&lt;/p&gt;&#xA;  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Ces deux parties ont été acceptées et intégrées (&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=de3a2ea3b2&#34;&gt;commit du patch v3-0001&lt;/a&gt;,&#xA;et &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=cf54a2c002&#34;&gt;commit du patch v3-0002&lt;/a&gt;). Ce que je retire de la discussion sur ce&#xA;patch, c’est qu’il faut proposer un nombre très limité de changements à la&#xA;fois pour qu’il y ait une chance que ce soit accepté. Et de faire ça&#xA;plusieurs fois si nécessaire, en avançant petit à petit, par itération.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici le résultat lorsqu’on interroge ces deux nouvelles colonnes :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;SELECT query, parallel_workers_to_launch, parallel_workers_launched&#xA;FROM pg_stat_statements&#xA;WHERE query LIKE &#39;SELECT%t1%&#39;;&#xA;&#xA;                query                | parallel_workers_to_launch | parallel_workers_launched&#xA;-------------------------------------+----------------------------+---------------------------&#xA; SELECT count(*) FROM t1             |                          2 |                         2&#xA; SELECT count(*) FROM t1 WHERE id&amp;gt;$1 |                          4 |                         4&#xA; SELECT * FROM t1                    |                          0 |                         0&#xA;(3 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;h3 id=&#34;patch-4--pg_stat_all_tables-et-pg_stat_all_indexes&#34;&gt;Patch #4 : pg_stat_all_tables et pg_stat_all_indexes&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Je ne vais pas m’éterniser sur ce patch. Il m’avait semblé intéressant de&#xA;connaître les tables qui étaient parcourues en parallélisé, pour améliorer la&#xA;configuration spécifique des tables en question avec un :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;ALTER TABLE ... WITH (parallel_workers=X);&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Le retour a été unanime. L’intérêt est très limité, voire nul. Je reconnais&#xA;qu’il est limité, mais je réfute qu’il est nul. Ceci étant dit, je n’ai pas&#xA;d’arguments supplémentaires pour défendre cette position, et j’ai donc&#xA;préféré consacrer mon énergie à l’argumentation pour les autres patchs,&#xA;notamment celui sur les traces.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://commitfest.postgresql.org/50/5238/&#34;&gt;Ce patch n’est officiellement pas rejeté&lt;/a&gt;, il serait certainement mieux que je&#xA;le déclare abandonné.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;pour-finir&#34;&gt;Pour finir&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Deux patchs acceptés sur quatre, et partiellement en plus. C’est une&#xA;demi-victoire. Il n’empêche que nous aurons ainsi plus de métriques sur la&#xA;parallélisation et que cela pourrait nous aider à améliorer sa configuration.&#xA;Et rien n’empêche de revenir plus tard avec les bouts non acceptés et&#xA;quelques arguments supplémentaires, venant de l’expérience rencontrée chez&#xA;nos clients.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tout le travail réalisé pour écrire un patch et réussir à le faire intégrer peut&#xA;sembler lourd mais la qualité du code et sa stabilité sont à ce prix.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cet article sera mis à jour quand les vidéos de la pgsession 17 seront&#xA;disponibles pour y mettre l lien vers ma conférence.&#xA;&lt;!--&#xA;Les vidéos de la pgsession 17 sont disponibles sur le [canal Dalibo de&#xA;YouTube], [playlist pgessions 17]. Vous y trouverez notamment [celle de ma&#xA;conférence], parlant de ce sujet, mais aussi de comment contribuer au&#xA;développement de PostgreSQL et de l&#39;organisation mise en place à Dalibo pour&#xA;permettre notre contribution.&#xA;--&gt;&lt;/p&gt;&#xA;&#xA;&lt;!--&#xA;[celle de ma conférence]: FIXME lien youtube&#xA;[canal Dalibo de YouTube]: https://www.youtube.com/c/dalibo&#xA;[playlist pgessions 17]: FIXME lien playlist YouTube&#xA;--&gt;&#xA;&#xA;&lt;!--&#xA;   vim: spelllang=fr spell&#xA;--&gt;</summary>
    <author>
      <name>blog.dalibo.com</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL : optimiser vos opérations vacuum et analyze !</title>
    <updated>2025-02-26T11:00:21Z</updated>
    <id>tag:blog.capdata.fr,2025-02-26:/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&amp;#038;title=PostgreSQL%20%3A%20optimiser%20vos%20op%C3%A9rations%20vacuum%20et%20analyze%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%20%3A%20optimiser%20vos%20op%C3%A9rations%20vacuum%20et%20analyze%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-medium wp-image-10677&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2025/02/vacuum-300x200.png&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;200&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2025/02/vacuum-300x200.png 300w, https://blog.capdata.fr/wp-content/uploads/2025/02/vacuum-768x513.png 768w, https://blog.capdata.fr/wp-content/uploads/2025/02/vacuum.png 800w&#34; sizes=&#34;auto, (max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Hello&lt;/p&gt;&#xA;&lt;p&gt;pour commencer cette année 2025 , voici un petit article PostgreSQL ou l&amp;#8217;on vous présente comment optimiser les opérations de maintenance que sont les VACUUM et les ANALYZE.&lt;/p&gt;&#xA;&lt;p&gt;Ces 2 opérations sont essentielles pour conserver des performances optimales pour notre instance et garantir au planner de construire des plans d&amp;#8217;exécutions optimisés.&lt;/p&gt;&#xA;&lt;p&gt;les opérations VACUUM et/ou ANALYZE peuvent être longues et sources de nombreuses écritures dans les WALs sur des tables volumineuses.&lt;br /&gt;&#xA;C&amp;#8217;est pourquoi, et ce depuis la version &lt;strong&gt;PostgreSQL 16&lt;/strong&gt;, il est possible de modifier le comportement de ces opérations en affectant une taille de buffer. Il s&amp;#8217;agit du &amp;#8220;&lt;a href=&#34;https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-VACUUM-BUFFER-USAGE-LIMIT&#34;&gt;buffer_usage_limit&lt;/a&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Principe de fonctionnement.&lt;/h2&gt;&#xA;&lt;p&gt;Ce procédé s&amp;#8217;appuie sur le principe de &amp;#8220;ring buffer&amp;#8221; configuré pour PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Attention, à ne pas confondre, évidement, avec les &amp;#8220;rings buffer&amp;#8221; de SQL Server !!&lt;/p&gt;&#xA;&lt;p&gt;Pour rappel, PostgreSQL utilise cette stratégie de &amp;#8220;ring buffer&amp;#8221; afin de dédier un espace mémoire pour les opérations lourdes , telles, la lecture séquentielle sur une table volumineuse, un CREATE TABLE AS SELECT, un COPY&amp;#8230;. mais aussi un VACUUM !&lt;/p&gt;&#xA;&lt;p&gt;En fait, cet espace est utilisé pour éviter de &amp;#8220;flusher&amp;#8221; sur disque de manière trop brutale les pages en mémoire montées dans le &amp;#8220;&lt;strong&gt;shared buffer&lt;/strong&gt;&amp;#8220;. Cela pénaliserait en grande partie toute opération concurrente à notre traitement actif puisqu&amp;#8217;elle n&amp;#8217;aurait plus d&amp;#8217;espace pour mettre ses propres pages en mémoire.&lt;/p&gt;&#xA;&lt;p&gt;Jusqu&amp;#8217;à la version PostgreSQL 16, cet espace mémoire était défini à&lt;strong&gt; 256Ko&lt;/strong&gt;. Ainsi, au cours d&amp;#8217;une lecture séquentielle, chaque page  de &lt;strong&gt;8Ko&lt;/strong&gt; par défaut, est montée en mémoire dans cet espace si le nombre de pages totales à traiter pour la table, dépasse 1/4 du paramètre &amp;#8220;&lt;strong&gt;shared_buffer&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Il en est de même pour une opération VACUUM ou ANALYZE qui utilise également ce ring buffer et permet d&amp;#8217;optimiser cette opération.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Nouveautés PostgreSQL 16 et PostgreSQL 17&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Depuis la version PostgreSQL 16, il est possible de configurer la taille du buffer de façon unitaire. Par exemple, lors d&amp;#8217;un VACUUM, il est tout à fait possible de choisir une valeur pour &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Depuis le version PostgreSQL 17, la valeur par défaut affectée à &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8221; est de &lt;strong&gt;2Mo&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Il vous est possible de paramétrer la valeur de &lt;strong&gt;128Ko&lt;/strong&gt; jusqu&amp;#8217;à &lt;strong&gt;16Go&lt;/strong&gt;. Attention, cependant, cette valeur ne peux excéder &lt;strong&gt;1/8&lt;/strong&gt; du paramètre &amp;#8220;&lt;strong&gt;shared_buffer&lt;/strong&gt;&amp;#8220;.&lt;br /&gt;&#xA;Si vous faites le calcul, pour un serveur comportant &lt;strong&gt;32Go de RAM&lt;/strong&gt;, vous ne pourrez obtenir, au plus, &lt;strong&gt;1Go&lt;/strong&gt; pour votre ring buffer.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h5&gt;Cas d&amp;#8217;utilisation pour un VACUUM&lt;/h5&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Sur une instance PostgreSQL 13, nous lançons un VACUUM simple sur une table de 2,5Go. Nous utilisons une base exemple créée via &amp;#8220;pgbench&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;Nous avons utilisé les options &amp;#8220;&lt;strong&gt;DISABLE_PAGE_SKIPPING&lt;/strong&gt;&amp;#8221; pour analyser, dans un premier temps, tous les blocs de notre table et ne pas sur baser sur les informations de la visibility_map.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum (verbose,DISABLE_PAGE_SKIPPING) public.pgbench_accounts;&#xD;&#xA;INFO: 00000: aggressively vacuuming &amp;quot;public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: lazy_scan_heap, vacuumlazy.c:797&#xD;&#xA;INFO: 00000: &amp;quot;pgbench_accounts&amp;quot;: found 0 removable, 20000000 nonremovable row versions in 327869 out of 327869 pages&#xD;&#xA;DETAIL: 0 dead row versions cannot be removed yet, oldest xmin: 196215&#xD;&#xA;There were 0 unused item identifiers.&#xD;&#xA;Skipped 0 pages due to buffer pins, 0 frozen pages.&#xD;&#xA;0 pages are entirely empty.&#xD;&#xA;CPU: user: 1.34 s, system: 0.67 s, elapsed: 18.90 s.&#xD;&#xA;LOCATION: lazy_scan_heap, vacuumlazy.c:1759&#xD;&#xA;VACUUM&#xD;&#xA;Time: 18920.292 ms (00:18.920)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Le temps passé pour cette opération est d&amp;#8217;un peu plus de 18 secondes en temps CPU pour analyser les 327869 blocs de notre table. Soit une taille de 2.5Go.&lt;/p&gt;&#xA;&lt;p&gt;Nous effectuons la même opération sur cette même table, mais sur un moteur &lt;strong&gt;PostgreSQL 17&lt;/strong&gt;. Nous positionnons le paramètre &lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;  à &lt;strong&gt;8Mo&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (verbose,DISABLE_PAGE_SKIPPING,BUFFER_USAGE_LIMIT &#39;8MB&#39;) public.pgbench_accounts;&#xD;&#xA;INFO: 00000: aggressively vacuuming &amp;quot;pgbenchmark.public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: heap_vacuum_rel, vacuumlazy.c:475&#xD;&#xA;INFO: 00000: finished vacuuming &amp;quot;pgbenchmark.public.pgbench_accounts&amp;quot;: index scans: 0&#xD;&#xA;pages: 0 removed, 327869 remain, 327869 scanned (100.00% of total)&#xD;&#xA;tuples: 0 removed, 20000000 remain, 0 are dead but not yet removable&#xD;&#xA;removable cutoff: 208163, which was 0 XIDs old when operation ended&#xD;&#xA;new relfrozenxid: 208163, which is 5 XIDs ahead of previous value&#xD;&#xA;frozen: 0 pages from table (0.00% of total) had 0 tuples frozen&#xD;&#xA;index scan not needed: 0 pages from table (0.00% of total) had 0 dead item identifiers removed&#xD;&#xA;avg read rate: 134.208 MB/s, avg write rate: 0.034 MB/s&#xD;&#xA;buffer usage: 330350 hits, 325508 misses, 83 dirtied&#xD;&#xA;WAL usage: 84 records, 83 full page images, 684232 bytes&#xD;&#xA;system usage: CPU: user: 1.41 s, system: 0.64 s, elapsed: 18.94 s&#xD;&#xA;LOCATION: heap_vacuum_rel, vacuumlazy.c:763&#xD;&#xA;VACUUM&#xD;&#xA;Time: 18955.006 ms (00:18.955)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;C&amp;#8217;est  à peu de chose près, dans le même temps d&amp;#8217;exécution. soir 18 secondes.&lt;/p&gt;&#xA;&lt;p&gt;La suite consiste à redémarrer l&amp;#8217;instance PostgreSQL 17 et constater les temps d&amp;#8217;exécution pour chaque occurrence de lancement.&lt;br /&gt;&#xA;Nous exécutons donc, les mêmes ordres VACUUM, mais sans l&amp;#8217;option &amp;#8220;&lt;strong&gt;DISABLE_PAGE_SKIPPING&lt;/strong&gt;&amp;#8221;&lt;/p&gt;&#xA;&lt;p&gt;Sur la version PostgreSQL 13, nous voyons qu&amp;#8217;à la première exécution, juste après redémarrage, nous sommes à 32 millisecondes. Et à chaque exécution suivante, nous ne descendons pas en dessous de 15 millisecondes&amp;#8230;.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 32.149 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 15.001 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 15.295 ms&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;En version PostgreSQL 17, nous faisons également un &amp;#8220;flush&amp;#8221; des pages dans le buffer cache à chaque exécution, tout en modifiant la valeur de &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (BUFFER_USAGE_LIMIT &#39;128kB&#39;) public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 18.098 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (BUFFER_USAGE_LIMIT &#39;8MB&#39;) public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 6.461 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (BUFFER_USAGE_LIMIT &#39;16MB&#39;) public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 4.333 ms&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Le constat est simple, plus nous augmentons le &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8220;, et plus le temps d&amp;#8217;exécution du VACUUM diminue.&lt;/p&gt;&#xA;&lt;p&gt;Nous comprendrons donc que sur une table de plus de 100Go, le gain peut être assez important.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h5&gt;Cas d&amp;#8217;utilisation pour un ANALYZE&lt;/h5&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Pour l&amp;#8217;instance PostgreSQL 13, nous exécutons le calcul de statistiques sur cette même table&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [pgbenchmark] primaire $  vacuum (analyze,verbose) public.pgbench_accounts;&#xD;&#xA;INFO: 00000: vacuuming &amp;quot;public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: lazy_scan_heap, vacuumlazy.c:802&#xD;&#xA;INFO: 00000: &amp;quot;pgbench_accounts&amp;quot;: found 0 removable, 52 nonremovable row versions in 1 out of 327869 pages&#xD;&#xA;DETAIL: 0 dead row versions cannot be removed yet, oldest xmin: 196278&#xD;&#xA;There were 0 unused item identifiers.&#xD;&#xA;Skipped 0 pages due to buffer pins, 0 frozen pages.&#xD;&#xA;0 pages are entirely empty.&#xD;&#xA;CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s.&#xD;&#xA;LOCATION: lazy_scan_heap, vacuumlazy.c:1759&#xD;&#xA;INFO: 00000: analyzing &amp;quot;public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: do_analyze_rel, analyze.c:336&#xD;&#xA;INFO: 00000: &amp;quot;pgbench_accounts&amp;quot;: scanned 30000 of 327869 pages, containing 1830000 live rows and 0 dead rows; 30000 rows in sample, 20000009 estimated total rows&#xD;&#xA;LOCATION: acquire_sample_rows, analyze.c:1190&#xD;&#xA;VACUUM&#xD;&#xA;Time: 29526.404 ms (00:29.526)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Nous sommes autour de 29 secondes pour analyser 30000 pages sur les 32769 que composent cette table.&lt;br /&gt;&#xA;Le sample est choisi en fonction de la valeur de &amp;#8220;&lt;strong&gt;default_statistics_target&lt;/strong&gt;&amp;#8220;, par défaut à 100, avec 30000 lignes analysées par défaut.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Sur la version PostgreSQL 17, les résultats sont les suivants&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (analyze,verbose,BUFFER_USAGE_LIMIT &#39;128kB&#39;) public.pgbench_accounts;&#xD;&#xA;INFO: 00000: vacuuming &amp;quot;pgbenchmark.public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: heap_vacuum_rel, vacuumlazy.c:480&#xD;&#xA;INFO: 00000: finished vacuuming &amp;quot;pgbenchmark.public.pgbench_accounts&amp;quot;: index scans: 0&#xD;&#xA;pages: 0 removed, 327869 remain, 1 scanned (0.00% of total)&#xD;&#xA;tuples: 0 removed, 20000000 remain, 0 are dead but not yet removable&#xD;&#xA;removable cutoff: 208163, which was 0 XIDs old when operation ended&#xD;&#xA;frozen: 0 pages from table (0.00% of total) had 0 tuples frozen&#xD;&#xA;index scan not needed: 0 pages from table (0.00% of total) had 0 dead item identifiers removed&#xD;&#xA;avg read rate: 46.211 MB/s, avg write rate: 0.000 MB/s&#xD;&#xA;buffer usage: 37 hits, 100 misses, 0 dirtied&#xD;&#xA;WAL usage: 0 records, 0 full page images, 0 bytes&#xD;&#xA;system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.01 s&#xD;&#xA;LOCATION: heap_vacuum_rel, vacuumlazy.c:763&#xD;&#xA;INFO: 00000: analyzing &amp;quot;public.pgbench_accounts&amp;quot;&#xD;&#xA;LOCATION: do_analyze_rel, analyze.c:321&#xD;&#xA;INFO: 00000: &amp;quot;pgbench_accounts&amp;quot;: scanned 30000 of 327869 pages, containing 1830000 live rows and 0 dead rows; 30000 rows in sample, 20000009 estimated total rows&#xD;&#xA;LOCATION: acquire_sample_rows, analyze.c:1301&#xD;&#xA;VACUUM&#xD;&#xA;Time: 8151.201 ms (00:08.151)&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [pgbenchmark] primaire $  vacuum (analyze,BUFFER_USAGE_LIMIT &#39;8MB&#39;) public.pgbench_accounts;&#xD;&#xA;VACUUM&#xD;&#xA;Time: 7282.546 ms (00:07.283)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Les différences de gains sont moins impressionnantes que sur un simple VACUUM à chaque changement de &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8220;, mais on voit qu&amp;#8217;en version PostgreSQL 17, nous sommes tout de même 4 fois plus rapide qu&amp;#8217;en version PostgreSQL 13.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h4&gt;Remarques&lt;/h4&gt;&#xA;&lt;p&gt;Gardez à l&amp;#8217;esprit que la valeur de &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&amp;#8221;&lt;/strong&gt; est plafonnée à &lt;strong&gt;1/8 &lt;/strong&gt;de&lt;strong&gt; &amp;#8220;shared_buffer&amp;#8221;&lt;/strong&gt;. Inutile donc de mettre à 1024Mo, si vous ne possédez que 8Go de RAM.&lt;/p&gt;&#xA;&lt;p&gt;Attention si vous mettez une valeur trop grande, les transactions concurrentes effectuant des lectures séquentielles seront pénalisées par les opérations VACUUM. D&amp;#8217;ailleurs, il est possible de mettre &amp;#8220;&lt;strong&gt;BUFFER_USAGE_LIMIT&lt;/strong&gt;&amp;#8221; à 0, mais ceci n&amp;#8217;est pas conseillé lors d&amp;#8217;une activité transactionnelle en cours.&lt;/p&gt;&#xA;&lt;p&gt;Pour aller plus loin dans l&amp;#8217;optimisation d&amp;#8217;une opération de vacuum, vous pouvez également passer le paramètre &amp;#8220;&lt;strong&gt;INDEX_CLEANUP&lt;/strong&gt;&amp;#8221; à &lt;strong&gt;off&lt;/strong&gt;. Ceci aura pour effet de ne pas s&amp;#8217;occuper de traiter les entrées des index qui pointent sur les lignes mortes de la table.&lt;br /&gt;&#xA;Un &amp;#8220;&lt;strong&gt;REINDEX&lt;/strong&gt;&amp;#8221; sera alors nécessaire à la fin du VACUUM sur les index de la table.&lt;/p&gt;&#xA;&lt;p&gt;De plus, il est possible de positionner l&amp;#8217;option &amp;#8220;&lt;strong&gt;SKIP_DATABASE_STATS&lt;/strong&gt;&amp;#8221; afin d&amp;#8217;indiquer à l&amp;#8217;ordre VACUUM de ne pas rechercher l&amp;#8217;ID de transaction le plus ancien pour l&amp;#8217;ensemble des tables de la base et de geler celui-ci (datfrozenid).&lt;/p&gt;&#xA;&lt;p&gt;Les opérations VACUUM sur les grosses tables seront bien entendu optimisées mais attention aux plages de maintenance choisies !!&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Bonne journée à vous.&lt;/p&gt;&#xA;&lt;p&gt;Emmanuel Rami&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-13-les-nouveautes-interessantes/&#34; rel=&#34;bookmark&#34; title=&#34;30 octobre 2020&#34;&gt;PostgreSQL 13 : présentation&lt;/a&gt; (Emmanuel RAMI) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pruning-de-partitions-sous-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;7 décembre 2020&#34;&gt;&amp;#8220;Pruning&amp;#8221; de partitions sous PostgreSQL ou comment bien élaguer !&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/requetes-consommatrices-sous-postgresql-episode-1/&#34; rel=&#34;bookmark&#34; title=&#34;24 mai 2016&#34;&gt;Requêtes consommatrices sous PostgreSQL (épisode 1)&lt;/a&gt; (David Baffaleuf) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/nouveautes-mysql-8-0-les-histogrammes/&#34; rel=&#34;bookmark&#34; title=&#34;25 juin 2019&#34;&gt;Nouveautés MySQL 8.0 : Les Histogrammes&lt;/a&gt; (Capdata team) [MySQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/replication-logique-avec-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;23 janvier 2020&#34;&gt;Réplication logique avec PostgreSQL&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 2.477 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&amp;#038;title=PostgreSQL%20%3A%20optimiser%20vos%20op%C3%A9rations%20vacuum%20et%20analyze%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%20%3A%20optimiser%20vos%20op%C3%A9rations%20vacuum%20et%20analyze%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10670&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/&#34;&gt;PostgreSQL : optimiser vos opérations vacuum et analyze !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Hello pour commencer cette année 2025 , voici un petit article PostgreSQL ou l&amp;#8217;on vous présente comment optimiser les opérations de maintenance que sont les VACUUM et les ANALYZE. Ces 2 opérations sont essentielles pour conserver des performances optimales pour&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-optimiser-vos-operations-vacuum-et-analyze/&#34;&gt;PostgreSQL : optimiser vos opérations vacuum et analyze !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>La montée de version en zero-downtime : merci la réplication !</title>
    <updated>2024-12-19T10:28:41Z</updated>
    <id>tag:blog.capdata.fr,2024-12-19:/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&amp;#038;title=La%20mont%C3%A9e%20de%20version%20en%20zero-downtime%20%3A%20merci%20la%20r%C3%A9plication%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=La%20mont%C3%A9e%20de%20version%20en%20zero-downtime%20%3A%20merci%20la%20r%C3%A9plication%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;h1&gt;Introduction :&lt;/h1&gt;&#xA;&lt;p&gt;Dans le monde des bases de données, garantir une disponibilité continue est une exigence incontournable, surtout pour les systèmes critiques où chaque minute d&amp;#8217;arrêt peut entraîner des pertes significatives. Lorsqu’il s’agit de migrer une base de données vers une nouvelle version, ce défi prend une toute autre dimension. Comment mettre à jour votre système sans interrompre les services, tout en préservant l’intégrité des données ?&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL offre une solution élégante : la réplication logique. Cet outil permet de transférer des données de manière fluide entre différentes versions de PostgreSQL, tout en maintenant la base de données source opérationnelle. Dans cet article, nous allons explorer étape par étape comment utiliser cette fonctionnalité pour réaliser une montée de version sans temps d&amp;#8217;arrêt, du déploiement initial à la bascule finale vers la nouvelle version.&lt;/p&gt;&#xA;&lt;p&gt;Que vous soyez en train de planifier une migration ou simplement curieux de découvrir les possibilités offertes par PostgreSQL, suivez ce guide pratique qui vous permettra de transformer un défi complexe en une opération maîtrisée et efficace.&lt;/p&gt;&#xA;&lt;h1&gt;Le test :&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;h3&gt;Préparation&lt;/h3&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Pour tester cette nouvelle méthode, nous aurons besoin de deux instances PostgreSQL. Pour cet article j&amp;#8217;ai choisit de démontrer la technique en migrant d&amp;#8217;une version 14 à une version 17 de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Je commence donc par installer les versions sur deux machines différentes pouvant communiquer entre elles (c&amp;#8217;est important) :&lt;/p&gt;&#xA;&lt;p&gt;Sur les deux machines nous pouvons exécuter les commandes suivantes :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# sudo apt update sudo apt upgrade -y&#xD;&#xA;&#xD;&#xA;...&#xD;&#xA;&#xD;&#xA;root@ip-192-1-1-246:~# sudo apt -y install gnupg2 wget vim&#xD;&#xA;&#xD;&#xA;...&#xD;&#xA;&#xD;&#xA;root@ip-192-1-1-246:~# sudo sh -c &#39;echo &amp;quot;deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main&amp;quot; &amp;amp;gt; /etc/apt/sources.list.d/pgdg.list&#39;&#xD;&#xA;root@ip-192-1-1-246:~# curl -fsSL https://www.postgresql.org/media/keys/ACCC4CF8.asc|sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/postgresql.gpg&#xD;&#xA;&#xD;&#xA;root@ip-192-1-1-246:~# sudo apt -y update&#xD;&#xA;Get:1 file:/etc/apt/mirrors/debian.list Mirrorlist [38 B]&#xD;&#xA;Get:2 file:/etc/apt/mirrors/debian-security.list Mirrorlist [47 B]&#xD;&#xA;Hit:3 https://cdn-aws.deb.debian.org/debian bookworm InRelease&#xD;&#xA;Hit:4 https://cdn-aws.deb.debian.org/debian bookworm-updates InRelease&#xD;&#xA;Hit:5 https://cdn-aws.deb.debian.org/debian bookworm-backports InRelease&#xD;&#xA;Hit:6 https://cdn-aws.deb.debian.org/debian-security bookworm-security InRelease&#xD;&#xA;Get:7 http://apt.postgresql.org/pub/repos/apt bookworm-pgdg InRelease [129 kB]&#xD;&#xA;Get:8 http://apt.postgresql.org/pub/repos/apt bookworm-pgdg/main amd64 Packages [359 kB]&#xD;&#xA;Fetched 489 kB in 1s (348 kB/s)&#xD;&#xA;Reading package lists... Done&#xD;&#xA;Building dependency tree... Done&#xD;&#xA;Reading state information... Done&#xD;&#xA;All packages are up to date.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Puis sur notre première machine :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# sudo apt install postgresql-14&#xD;&#xA;Reading package lists... Done&#xD;&#xA;Building dependency tree... Done&#xD;&#xA;Reading state information... Done&#xD;&#xA;The following additional packages will be installed:&#xD;&#xA;libcommon-sense-perl libgdbm-compat4 libio-pty-perl libipc-run-perl&#xD;&#xA;libjson-perl libjson-xs-perl libllvm16 libperl5.36 libpq5 libsensors-config&#xD;&#xA;libsensors5 libtypes-serialiser-perl libxslt1.1 libz3-4 logrotate perl&#xD;&#xA;perl-modules-5.36 postgresql-client-14 postgresql-client-common&#xD;&#xA;postgresql-common ssl-cert sysstat&#xD;&#xA;&#xD;&#xA;...&#xD;&#xA;&#xD;&#xA;root@ip-192-1-1-246:~# systemctl status postgresql@14-main.service&#xD;&#xA;● postgresql@14-main.service - PostgreSQL Cluster 14-main&#xD;&#xA;Loaded: loaded (/lib/systemd/system/postgresql@.service; enabled-runtime;&amp;amp;gt;&#xD;&#xA;Active: active (running) since Wed 2024-12-04 09:43:55 UTC; 2min 55s ago&#xD;&#xA;Process: 15248 ExecStart=/usr/bin/pg_ctlcluster --skip-systemctl-redirect &amp;amp;gt;&#xD;&#xA;Main PID: 15253 (postgres)&#xD;&#xA;Tasks: 7 (limit: 4633)&#xD;&#xA;Memory: 17.3M&#xD;&#xA;CPU: 239ms&#xD;&#xA;CGroup: /system.slice/system-postgresql.slice/postgresql@14-main.service&#xD;&#xA;├─15253 /usr/lib/postgresql/14/bin/postgres -D /var/lib/postgresq&amp;amp;gt;&#xD;&#xA;├─15255 &amp;quot;postgres: 14/main: checkpointer &amp;quot;&#xD;&#xA;├─15256 &amp;quot;postgres: 14/main: background writer &amp;quot;&#xD;&#xA;├─15257 &amp;quot;postgres: 14/main: walwriter &amp;quot;&#xD;&#xA;├─15258 &amp;quot;postgres: 14/main: autovacuum launcher &amp;quot;&#xD;&#xA;├─15259 &amp;quot;postgres: 14/main: stats collector &amp;quot;&#xD;&#xA;└─15260 &amp;quot;postgres: 14/main: logical replication launcher &amp;quot;&#xD;&#xA;&#xD;&#xA;Dec 04 09:43:53 ip-192-1-1-246 systemd[1]: Starting postgresql@14-main.service&amp;amp;gt;&#xD;&#xA;Dec 04 09:43:55 ip-192-1-1-246 systemd[1]: Started postgresql@14-main.service &amp;amp;gt;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Puis sur la deuxième machine :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;admin@ip-192-1-1-89:~$ sudo apt install postgresql-17&#xD;&#xA;Reading package lists... Done&#xD;&#xA;Building dependency tree... Done&#xD;&#xA;Reading state information... Done&#xD;&#xA;The following additional packages will be installed:&#xD;&#xA;libcommon-sense-perl libgdbm-compat4 libio-pty-perl libipc-run-perl&#xD;&#xA;libjson-perl libjson-xs-perl libllvm16 libperl5.36 libpq5 libsensors-config&#xD;&#xA;libsensors5 libtypes-serialiser-perl libxslt1.1 libz3-4 logrotate perl&#xD;&#xA;perl-modules-5.36 postgresql-client-17 postgresql-client-common&#xD;&#xA;postgresql-common ssl-cert sysstat&#xD;&#xA;&#xD;&#xA;admin@ip-192-1-1-89:~$ systemctl status postgresql@17-main.service&#xD;&#xA;● postgresql@17-main.service - PostgreSQL Cluster 17-main&#xD;&#xA;Loaded: loaded (/lib/systemd/system/postgresql@.service; enabled-runtime; &amp;amp;gt;&#xD;&#xA;Active: active (running) since Wed 2024-12-04 09:52:33 UTC; 2min 13s ago&#xD;&#xA;Process: 15235 ExecStart=/usr/bin/pg_ctlcluster --skip-systemctl-redirect 1&amp;amp;gt;&#xD;&#xA;Main PID: 15240 (postgres)&#xD;&#xA;Tasks: 6 (limit: 4633)&#xD;&#xA;Memory: 20.5M&#xD;&#xA;CPU: 332ms&#xD;&#xA;CGroup: /system.slice/system-postgresql.slice/postgresql@17-main.service&#xD;&#xA;├─15240 /usr/lib/postgresql/17/bin/postgres -D /var/lib/postgresql&amp;amp;gt;&#xD;&#xA;├─15241 &amp;quot;postgres: 17/main: checkpointer &amp;quot;&#xD;&#xA;├─15242 &amp;quot;postgres: 17/main: background writer &amp;quot;&#xD;&#xA;├─15244 &amp;quot;postgres: 17/main: walwriter &amp;quot;&#xD;&#xA;├─15245 &amp;quot;postgres: 17/main: autovacuum launcher &amp;quot;&#xD;&#xA;└─15246 &amp;quot;postgres: 17/main: logical replication launcher &amp;quot;&#xD;&#xA;&#xD;&#xA;Dec 04 09:52:31 ip-192-1-1-89 systemd[1]: Starting postgresql@17-main.service -&amp;amp;gt;&#xD;&#xA;Dec 04 09:52:33 ip-192-1-1-89 systemd[1]: Started postgresql@17-main.service -&amp;amp;gt;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Nos deux instances sont maintenant installées. Sur notre première base de données, nous allons créer une base, avec deux tables, et quelques lignes.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:/etc/postgresql/14/main$ psql&#xD;&#xA;psql (14.15 (Debian 14.15-1.pgdg120+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# CREATE DATABASE mydb;&#xD;&#xA;CREATE DATABASE&#xD;&#xA;postgres=# \c mydb&#xD;&#xA;You are now connected to database &amp;quot;mydb&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;mydb=# CREATE TABLE customers (&#xD;&#xA;id SERIAL PRIMARY KEY,&#xD;&#xA;name TEXT NOT NULL,&#xD;&#xA;email TEXT UNIQUE,&#xD;&#xA;created_at TIMESTAMP DEFAULT NOW()&#xD;&#xA;);&#xD;&#xA;CREATE TABLE&#xD;&#xA;mydb=# CREATE TABLE orders (&#xD;&#xA;id SERIAL PRIMARY KEY,&#xD;&#xA;customer_id INT REFERENCES customers(id),&#xD;&#xA;amount NUMERIC(10,2) NOT NULL,&#xD;&#xA;order_date TIMESTAMP DEFAULT NOW()&#xD;&#xA;);&#xD;&#xA;CREATE TABLE&#xD;&#xA;mydb=# INSERT INTO customers (name, email) VALUES&#xD;&#xA;(&#39;Alice&#39;, &#39;alice@example.com&#39;),&#xD;&#xA;(&#39;Bob&#39;, &#39;bob@example.com&#39;),&#xD;&#xA;(&#39;Charlie&#39;, &#39;charlie@example.com&#39;);&#xD;&#xA;INSERT 0 3&#xD;&#xA;mydb=# INSERT INTO orders (customer_id, amount) VALUES&#xD;&#xA;(1, 50.75),&#xD;&#xA;(2, 20.00),&#xD;&#xA;(1, 75.00);&#xD;&#xA;INSERT 0 3&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;2. Configurer la base de données source&lt;/h3&gt;&#xA;&lt;p&gt;Sur notre première machine, nous allons modifier les paramètres du fichier de configuration de PostgreSQL pour permettre de pouvoir créer la réplication :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# su - postgres&#xD;&#xA;postgres@ip-192-1-1-246:~$ cd /etc/postgresql/14/main&#xD;&#xA;postgres@ip-192-1-1-246:/etc/postgresql/14/main$ vi postgresql.conf&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il s&amp;#8217;agit de modifier les paramètres suivants :&lt;/p&gt;&#xA;&lt;blockquote&gt;&lt;p&gt;wal_level = logical&lt;br /&gt;&#xA;max_replication_slots = 4&lt;br /&gt;&#xA;max_wal_senders = 4&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;Nous modifierons ensuite le pg_hba pour rajouter l&amp;#8217;autorisation de connexion entre les deux machines :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:/etc/postgresql/14/main$ vi pg_hba.conf&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il suffira de rajouter une ligne :&lt;/p&gt;&#xA;&lt;blockquote&gt;&lt;p&gt;host replication &lt;span class=&#34;hljs-attribute&#34;&gt;all&lt;/span&gt; &amp;lt;destination_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host replication all &amp;lt;source_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host all replication &amp;lt;destination_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host all replication &amp;lt;source-ip&amp;gt; scram-sha-256&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;Il ne faut pas oublier de redémarrer le serveur PostgreSQL une fois ces modifications effectuées :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# systemctl stop postgresql@14-main.service&#xD;&#xA;root@ip-192-1-1-246:~# systemctl start postgresql@14-main.service&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;3. Configurer la base de donnée de destination&lt;/h3&gt;&#xA;&lt;p&gt;Après avoir configuré notre base de donnée depuis laquelle nous allons faire notre migration, il nous faut a présent configurer celle qui va recevoir la nouvelle base de donnée migrée.&lt;/p&gt;&#xA;&lt;p&gt;Pour cela, nous allons répéter les étapes de configuration de la base de donnée source, en les adaptant sur notre base de donnée de destination : modifier le postgresql.conf, puis le pg_hba.conf, redémarrer ensuite la base de données&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-89:~$ cd /etc/postgresql/17/main/&#xD;&#xA;postgres@ip-192-1-1-89:/etc/postgresql/17/main$ vi postgresql.conf&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;blockquote&gt;&lt;p&gt;wal_level = logical&lt;br /&gt;&#xA;max_replication_slots = 4&lt;br /&gt;&#xA;max_wal_senders = 4&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:/etc/postgresql/14/main$ vi pg_hba.conf&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;blockquote&gt;&lt;p&gt;host replication &lt;span class=&#34;hljs-attribute&#34;&gt;all&lt;/span&gt; &amp;lt;destination_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host replication all &amp;lt;source_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host all replication &amp;lt;destination_ip&amp;gt; scram-sha-256&lt;/p&gt;&#xA;&lt;p&gt;host all replication &amp;lt;source-ip&amp;gt; scram-sha-256&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-246:~# systemctl stop postgresql@14-main.service&#xD;&#xA;root@ip-192-1-1-246:~# systemctl start postgresql@14-main.service&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il ne faudra pas oublier de créer la base de donnée ainsi que toutes les structures de tables et autres objets dans notre base cible pour qu&amp;#8217;elle puisse recevoir les données. Pour avoir les scripts de création de la base de données, vous pouvez faire un pg_dump avec l&amp;#8217;option&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-89:~$ psql&#xD;&#xA;psql (17.2 (Debian 17.2-1.pgdg120+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# CREATE DATABASE mydb;&#xD;&#xA;CREATE DATABASE&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;N&amp;#8217;oubliez pas de donner tout les droits à votre utilisateur de replication pour qu&amp;#8217;il puisse lire, écrire&amp;#8230; Sur votre base de données repliquée, sur la source, comme sur la destination :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# GRANT ALL PRIVILEGES ON DATABASE &amp;quot;mydb&amp;quot; to replication;&#xD;&#xA;GRANT&#xD;&#xA;&#xD;&#xA;mydb=# GRANT ALL PRIVILEGES ON all tables in schema public to replication;&#xD;&#xA;GRANT&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;4. Mise en place de la réplication logique&lt;/h3&gt;&#xA;&lt;p&gt;Maintenant que nos deux environnement sont bien en place, nous sommes prêts à mettre en route le processus de réplication logique pour commencer à transférer les données. Les étapes du dessous ont demandé une première intervention hors horaire de prod, notamment pour redémarrer le service postgreSQL, mais le but d&amp;#8217;une migration avec réplication logique, c&amp;#8217;est de pouvoir ensuite n&amp;#8217;avoir rien à toucher jusqu&amp;#8217;au moment de basculer les applicatifs d&amp;#8217;une ip a une autre.&lt;/p&gt;&#xA;&lt;p&gt;Sur notre machine source, on créé la publication qui va nous servir à transférer nos tables :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:~$ psql&#xD;&#xA;psql (14.15 (Debian 14.15-1.pgdg120+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# \c mydb&#xD;&#xA;You are now connected to database &amp;quot;mydb&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;mydb=# CREATE PUBLICATION my_pub FOR ALL TABLES;&#xD;&#xA;CREATE PUBLICATION&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;On va ensuite créé la souscription sur la base de données cible de notre migration :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;mydb=# create subscription my_sub connection &#39;host=192.1.1.246 port=5432 dbname=mydb user=replication password=replication&#39;publication my_pub;&#xD;&#xA;NOTICE: created replication slot &amp;quot;my_sub&amp;quot; on publisher&#xD;&#xA;CREATE SUBSCRIPTION&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Maintenant que la subscription est en place, on peut vérifier qu&amp;#8217;elle fonctionne. Pendant ce temps, la vrai production, sur la version 14, peut continuer à fonctionner, elle sera automatiquement repliquée sur la nouvelle version 17.&lt;/p&gt;&#xA;&lt;p&gt;On peut vérifier ou en est notre replication avec la commande &lt;span class=&#34;hljs-keyword&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;hljs-operator&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;hljs-keyword&#34;&gt;FROM&lt;/span&gt; pg_stat_subscription;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;mydb=# SELECT * FROM pg_stat_subscription;&#xD;&#xA;-[ RECORD 1 ]---------+------------------------------&#xD;&#xA;subid | 16422&#xD;&#xA;subname | my_sub&#xD;&#xA;worker_type | apply&#xD;&#xA;pid | 16076&#xD;&#xA;leader_pid |&#xD;&#xA;relid |&#xD;&#xA;received_lsn | 0/1733988&#xD;&#xA;last_msg_send_time | 2024-12-04 14:23:59.873074+00&#xD;&#xA;last_msg_receipt_time | 2024-12-04 14:23:59.872357+00&#xD;&#xA;latest_end_lsn | 0/1733988&#xD;&#xA;latest_end_time | 2024-12-04 14:23:59.873074+00&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;5. Test de replication, bascule, et nettoyage&lt;/h3&gt;&#xA;&lt;p&gt;Une fois que la synchronisation de votre replication logique est terminée, ce qui peut prendre un certain temps si vous avez beaucoup de données, vous pouvez constater de vous même sur les lignes que vous ajoutez, modifiez ou supprimez sur votre instance source sont repliquées sur l&amp;#8217;instance de destination.&lt;/p&gt;&#xA;&lt;p&gt;Par exemple, ajoutons un nouveau customer sur notre base source :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres@ip-192-1-1-246:~$ psql&#xD;&#xA;psql (14.15 (Debian 14.15-1.pgdg120+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# \c mydb&#xD;&#xA;You are now connected to database &amp;quot;mydb&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;mydb=# INSERT INTO customers (name, email) VALUES (&#39;Diana&#39;, &#39;diana@example.com&#39;);&#xD;&#xA;INSERT 0 1&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Si nous allons requêter sur notre instance de destination :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;mydb=# select * from customers where name=&#39;Diana&#39;;&#xD;&#xA;id | name | email | created_at&#xD;&#xA;----+-------+-------------------+----------------------------&#xD;&#xA;4 | Diana | diana@example.com | 2024-12-04 14:31:05.708031&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Quand vous vous êtes bien assuré que tout fonctionne, vous pouvez alors rediriger les drivers odbc de vos applications vers le nouveau serveur et non plus l&amp;#8217;ancien.&lt;/p&gt;&#xA;&lt;p&gt;Une fois que cela est fait, vous pouvez alors supprimer le lien de replication, puisque l&amp;#8217;ancienne instance ne sera plus alimentée, et même supprimer l&amp;#8217;ancienne version si vous n&amp;#8217;en avez plus l&amp;#8217;utilité.&lt;/p&gt;&#xA;&lt;p&gt;Sur la destination, notre nouveau serveur de prod :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;DROP SUBSCRIPTION my_sub;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Sur la source, ancien serveur qui va être supprimé :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;DROP PUBLICATION my_pub;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h1&gt;Conclusion&lt;/h1&gt;&#xA;&lt;p&gt;La réplication logique se distingue comme l’une des meilleures solutions pour minimiser le temps d’arrêt lors d’une migration de version PostgreSQL. En permettant une synchronisation continue des données entre deux instances, elle garantit une transition en douceur sans jamais interrompre les services en cours. Cela en fait un choix idéal pour les environnements critiques où la disponibilité est primordiale.&lt;/p&gt;&#xA;&lt;h3&gt;Avantages :&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Zéro downtime :&lt;/strong&gt; la source reste opérationnelle pendant toute la migration.&lt;br /&gt;&#xA;&lt;strong&gt;Flexibilité :&lt;/strong&gt; possibilité de migrer vers une infrastructure différente (nouveau matériel, cloud, etc.).&lt;br /&gt;&#xA;&lt;strong&gt;Granularité :&lt;/strong&gt; la réplication logique peut se limiter à certaines tables si nécessaire.&lt;/p&gt;&#xA;&lt;h3&gt;Inconvénients :&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Complexité initiale :&lt;/strong&gt; la configuration et les tests nécessitent une bonne maîtrise des paramètres de PostgreSQL.&lt;br /&gt;&#xA;&lt;strong&gt;Impact sur les performances :&lt;/strong&gt; la charge de réplication peut légèrement affecter les performances de la base source, surtout avec un grand volume de données.&lt;br /&gt;&#xA;&lt;strong&gt;Non pris en charge pour certains types de données :&lt;/strong&gt; les types spécifiques ou les extensions non standards ne sont pas toujours compatibles avec la réplication logique.&lt;/p&gt;&#xA;&lt;p&gt;Si la réplication logique est souvent la méthode privilégiée pour des mises à jour critiques, elle n’est pas la seule option. Des alternatives comme les outils de sauvegarde et restauration ou la réplication physique peuvent répondre à d’autres besoins spécifiques, notamment pour des bases de données très volumineuses ou des scénarios nécessitant une réplication complète du système.&lt;/p&gt;&#xA;&lt;p&gt;Dans tous les cas, le choix de la méthode dépendra de votre contexte, de vos contraintes techniques et de vos objectifs métier. Prenez le temps d’évaluer les différentes options pour garantir une migration réussie et sans surprise.&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/replication-logique-avec-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;23 janvier 2020&#34;&gt;Réplication logique avec PostgreSQL&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/migration-postgresql-via-slony-i-ou-comment-reduire-le-temps-de-coupure/&#34; rel=&#34;bookmark&#34; title=&#34;27 janvier 2020&#34;&gt;Migration PostgreSQL via SLONY-I ou comment réduire le temps de coupure&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/migrer-dun-cluster-galera-mariadb-10-3-vers-mariadb-10-5-avec-la-replication-logique/&#34; rel=&#34;bookmark&#34; title=&#34;25 février 2022&#34;&gt;Migrer d&amp;#8217;un cluster Galera MariaDB 10.3 vers MariaDB 10.5 avec la réplication logique&lt;/a&gt; (David Baffaleuf) [ContainerMySQLNon classé]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/comparatif-des-gestionnaires-de-vip-dans-un-cluster-patroni-episode-1-keepalived/&#34; rel=&#34;bookmark&#34; title=&#34;6 mars 2022&#34;&gt;Comparatif des gestionnaires de VIP dans un cluster Patroni : épisode 1 (KEEPALIVED)&lt;/a&gt; (David Baffaleuf) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pyrseas-et-postgresql-comparer-facilement-des-schema-de-base-de-donnees/&#34; rel=&#34;bookmark&#34; title=&#34;3 janvier 2023&#34;&gt;Pyrseas et Postgresql : Comparer facilement des schémas de base de données&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 2.244 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&amp;#038;title=La%20mont%C3%A9e%20de%20version%20en%20zero-downtime%20%3A%20merci%20la%20r%C3%A9plication%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=La%20mont%C3%A9e%20de%20version%20en%20zero-downtime%20%3A%20merci%20la%20r%C3%A9plication%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10633&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/&#34;&gt;La montée de version en zero-downtime : merci la réplication !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Introduction : Dans le monde des bases de données, garantir une disponibilité continue est une exigence incontournable, surtout pour les systèmes critiques où chaque minute d&amp;#8217;arrêt peut entraîner des pertes significatives. Lorsqu’il s’agit de migrer une base de données vers&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/&#34;&gt;La montée de version en zero-downtime : merci la réplication !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>pg_vector : l’IA et PostgreSQL</title>
    <updated>2024-12-03T07:22:34Z</updated>
    <id>tag:blog.capdata.fr,2024-12-03:/index.php/pg_vector-lia-et-postgresql/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&amp;#038;title=pg_vector%20%3A%20l%E2%80%99IA%20et%20PostgreSQL&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=pg_vector%20%3A%20l%E2%80%99IA%20et%20PostgreSQL&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;h2&gt;1. Introduction : L&amp;#8217;intelligence artificielle et le rôle des bases de données&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;#8217;intelligence artificielle (IA) connaît une popularité croissante, des assistants virtuels aux voitures autonomes, en passant par les recommandations de films et de produits. Mais pour que ces technologies fonctionnent, elles ont besoin de données, souvent en grande quantité. C’est là qu’interviennent les bases de données : elles stockent, gèrent et permettent d&amp;#8217;accéder à ces données de manière efficace.&lt;/p&gt;&#xA;&lt;p&gt;Les bases de données, comme PostgreSQL, ont donc un rôle clé dans l’IA. Mais l&amp;#8217;IA ne traite pas toujours des informations simples comme des noms ou des chiffres ; souvent, elle doit manipuler des informations complexes, comme des représentations numériques d&amp;#8217;images, de sons, ou de textes. Pour gérer ces données spécifiques, il faut des outils adaptés, et c&amp;#8217;est là que l&amp;#8217;extension pg_vector de PostgreSQL entre en jeu.&lt;/p&gt;&#xA;&lt;h2&gt;2. Les vecteurs en informatique et dans pg_vector&lt;/h2&gt;&#xA;&lt;p&gt;Dans le cadre de l’informatique, un vecteur est simplement une liste de nombres. Ces nombres peuvent représenter n’importe quoi : les caractéristiques d’un produit, les mots d’un texte ou même une image. Par exemple, pour un document texte, chaque mot peut être transformé en une série de nombres qui capture son sens dans un certain contexte.&lt;/p&gt;&#xA;&lt;p&gt;L’extension pg_vector permet à PostgreSQL de stocker et de manipuler ces vecteurs. Elle offre un moyen simple de les utiliser directement dans une base de données. Imaginons que nous avons des centaines de documents et que nous souhaitions rechercher les plus similaires à un texte donné : en stockant les représentations numériques (ou embeddings) de ces documents sous forme de vecteurs, nous pouvons facilement comparer leur similarité grâce à pg_vector.&lt;/p&gt;&#xA;&lt;h2&gt;3. Le lien entre l&amp;#8217;IA et les vecteurs&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;#8217;intelligence artificielle repose sur la capacité à comprendre et traiter des informations complexes. Par exemple, quand une IA doit reconnaître une image, elle ne &amp;#8220;voit&amp;#8221; pas comme nous. Au lieu de cela, l&amp;#8217;image est transformée en une série de nombres, un vecteur, qui représente ses caractéristiques (couleurs, formes, etc.).&lt;/p&gt;&#xA;&lt;p&gt;Le même principe s’applique au texte. Les modèles de traitement du langage, comme ceux utilisés par les moteurs de recherche ou les chatbots, transforment chaque mot ou phrase en vecteur. Ces vecteurs capturent le sens des mots et permettent à l&amp;#8217;IA de manipuler des informations complexes sans &amp;#8220;comprendre&amp;#8221; le langage humain.&lt;/p&gt;&#xA;&lt;p&gt;C&amp;#8217;est ici que les embeddings entrent en jeu. Un embedding est un vecteur qui représente des données sous une forme que l’IA peut utiliser. Par exemple, dans un système de recommandation, chaque produit est converti en un embedding, et les produits les plus proches de celui que nous venons de consulter (en termes de vecteur) nous seront recommandés. Grâce à pg_vector, ces embeddings peuvent être stockés et comparés directement dans une base de données.&lt;/p&gt;&#xA;&lt;h2&gt;4. Pourquoi est-ce utile ?&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;#8217;extension pg_vector est très utile pour des applications qui nécessitent la recherche par similarité. Par exemple, dans un moteur de recherche, si nous voulons trouver les documents les plus proches d&amp;#8217;un texte donné, pg_vector permet de comparer les vecteurs (ou embeddings) de chaque document pour voir lesquels sont les plus similaires.&lt;/p&gt;&#xA;&lt;p&gt;Autre exemple, dans une plateforme de streaming musical, chaque chanson peut être convertie en vecteur qui représente ses caractéristiques (comme le tempo, la tonalité, etc.). Grâce à pg_vector, on peut facilement recommander des chansons similaires à celles que nous écoutons.&lt;/p&gt;&#xA;&lt;p&gt;L’avantage de pg_vector, c’est qu’il permet de gérer ces vecteurs directement dans la base de données, ce qui évite de passer par des systèmes externes plus complexes. Cela simplifie le développement et améliore la performance, car tout est géré au même endroit.&lt;/p&gt;&#xA;&lt;h2&gt;5. Le test&lt;/h2&gt;&#xA;&lt;p&gt;Pour démontrer le fonctionnement de l&amp;#8217;extension, rien de tel qu&amp;#8217;un petit test pour éprouver les fonctionnalités qu&amp;#8217;elle propose. Le test sera plutôt simple et succinct pour être accessible. Le prérequi est d&amp;#8217;avoir une version PostgreSQL 14 ou plus récente d&amp;#8217;installée.&lt;/p&gt;&#xA;&lt;h3&gt;Etape 1 :&lt;/h3&gt;&#xA;&lt;p&gt;On commence par installer l&amp;#8217;extension pg_vector. Pour cela, nous allons avoir besoin d&amp;#8217;un certain nombre d&amp;#8217;outils pour le faire fonctionner. Une partie de ces outils sont disponible dans la distribution dev de PostgreSQL&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# sudo apt install postgresql-server-dev-14&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Nous aurons également besoin de gcc et make :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# apt install make&#xD;&#xA;root@ip-192-1-1-201:~# apt-get install gcc&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;On effectue ensuite un git clone du projet :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# git clone https://github.com/pgvector/pgvector.git&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Et une fois que c&amp;#8217;est fait, on l&amp;#8217;installe avec make :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# cd pgvector&#xD;&#xA;root@ip-192-1-1-201:~# make &amp;amp;amp;&amp;amp;amp; sudo make install&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;Etape 2 :&lt;/h3&gt;&#xA;&lt;p&gt;On se connecte à PostgreSQL pour créer l&amp;#8217;extension. Au passage, on créé aussi une base de données pour faire nos test.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;root@ip-192-1-1-201:~# su - postgres&#xD;&#xA;postgres@ip-192-1-1-201:~$ psql&#xD;&#xA;psql (14.13 (Ubuntu 14.13-0ubuntu0.22.04.1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;postgres=# create database test_vector;&#xD;&#xA;CREATE DATABASE&#xD;&#xA;postgres=# \c test_vector&#xD;&#xA;You are now connected to database &amp;quot;test_vector&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;test_vector=# CREATE EXTENSION vector;&#xD;&#xA;CREATE EXTENSION&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Et dans la foulée, on crée une table qui contient les vecteurs sur lesquels nous allons faire les test&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;test_vector=# CREATE TABLE documents (&#xD;&#xA;id SERIAL PRIMARY KEY,&#xD;&#xA;title TEXT,&#xD;&#xA;embedding vector(3) -- vecteur de dimension 3 pour cet exemple&#xD;&#xA;);&#xD;&#xA;CREATE TABLE&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Insertion des données d&amp;#8217;exemple :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;test_vector=# INSERT INTO documents (title, embedding) VALUES&#xD;&#xA;(&#39;Document 1&#39;, &#39;[0.1, 0.2, 0.3]&#39;),&#xD;&#xA;(&#39;Document 2&#39;, &#39;[0.4, 0.5, 0.6]&#39;),&#xD;&#xA;(&#39;Document 3&#39;, &#39;[0.9, 0.8, 0.7]&#39;);&#xD;&#xA;INSERT 0 3&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;Etape 3 :&lt;/h3&gt;&#xA;&lt;p&gt;Nous avons deux types de choses à tester pour montrer l&amp;#8217;efficacité de notre extension. En effet, pour rechercher un vecteur, deux modes s&amp;#8217;offrent à nous :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;h4&gt;La distance cosinus&lt;/h4&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;La distance cosinus mesure non pas combien deux vecteurs sont éloignés, mais l&amp;#8217;angle entre eux. C’est un peu comme comparer la direction dans laquelle pointent deux vecteurs plutôt que la distance réelle entre eux.&lt;/p&gt;&#xA;&lt;p&gt;Imaginons que nous sommes en train de lancer deux flèches. La distance cosinus nous dira si les deux flèches pointent dans la même direction (sont similaires) ou si elles pointent dans des directions très différentes (sont moins similaires).&lt;/p&gt;&#xA;&lt;p&gt;Dans le cadre de l’IA, cette mesure est souvent utilisée pour comparer des embeddings (représentations numériques complexes), car elle se concentre sur la relation entre les éléments, indépendamment de leur taille exacte.&lt;/p&gt;&#xA;&lt;p&gt;Exemple simple :&lt;/p&gt;&#xA;&lt;p&gt;Prenons les deux films :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Film A : &lt;code&gt;[1, 5, 50, 120]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Film B : &lt;code&gt;[2, 4, 45, 110]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La distance cosinus ne va pas se soucier de la différence de valeur entre chaque composant, mais va regarder si les deux films ont des proportions similaires. Autrement dit, est-ce que leur &amp;#8220;profil&amp;#8221; général est proche ou éloigné ?&lt;/p&gt;&#xA;&lt;p&gt;Pour tester cette distance, dans notre pg vector, on utilise la méthode suivante :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;test_vector=# SELECT title, embedding, embedding &amp;amp;lt;=&amp;amp;gt; &#39;[0.2, 0.1, 0.3]&#39; AS distance&#xD;&#xA;FROM documents&#xD;&#xA;ORDER BY embedding &amp;amp;lt;=&amp;amp;gt; &#39;[0.2, 0.1, 0.3]&#39; ASC&#xD;&#xA;LIMIT 3;&#xD;&#xA;title | embedding | distance&#xD;&#xA;------------+---------------+---------------------&#xD;&#xA;Document 2 | [0.4,0.5,0.6] | 0.05582537807240784&#xD;&#xA;Document 1 | [0.1,0.2,0.3] | 0.07142855242198809&#xD;&#xA;Document 3 | [0.9,0.8,0.7] | 0.09815280896106982&#xD;&#xA;(3 rows)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Le symbole &amp;lt;=&amp;gt; représente une distance cosinus.&lt;/p&gt;&#xA;&lt;h4&gt;2. La distance Euclidienne&lt;/h4&gt;&#xA;&lt;p&gt;Imaginons que nous sommes sur une carte avec deux points : le point A et le point B. La distance euclidienne, c&amp;#8217;est la façon la plus intuitive de mesurer la distance entre ces deux points, comme si nous tracions une ligne droite entre eux. Pour parler en terme simple, c’est la &amp;#8220;distance à vol d&amp;#8217;oiseau&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;Dans le cadre des vecteurs, la distance euclidienne mesure la différence entre deux vecteurs, un peu comme si chaque vecteur était un point sur une carte en plusieurs dimensions. Plus cette distance est petite, plus les deux vecteurs (et donc les objets qu’ils représentent) sont similaires.&lt;/p&gt;&#xA;&lt;p&gt;Exemple simple :&lt;/p&gt;&#xA;&lt;p&gt;Imaginons deux films représentés par les vecteurs suivants :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Film A&lt;/strong&gt; : &lt;code&gt;[1, 5, 50, 120]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Film B&lt;/strong&gt; : &lt;code&gt;[2, 4, 45, 110]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La distance euclidienne va calculer la différence entre chaque nombre des deux vecteurs et déterminer à quel point ces films sont proches en termes de caractéristiques (genre, nombre d’acteurs, budget, etc.).&lt;/p&gt;&#xA;&lt;p&gt;Dans pg_vector on peut le tester ainsi :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;test_vector=# SELECT title, embedding, embedding &amp;amp;lt;-&amp;amp;gt; &#39;[0.2, 0.1, 0.3]&#39; AS distance&#xD;&#xA;FROM documents&#xD;&#xA;ORDER BY embedding &amp;amp;lt;-&amp;amp;gt; &#39;[0.2, 0.1, 0.3]&#39; ASC&#xD;&#xA;LIMIT 3;&#xD;&#xA;title | embedding | distance&#xD;&#xA;------------+---------------+--------------------&#xD;&#xA;Document 1 | [0.1,0.2,0.3] | 0.1414213612422477&#xD;&#xA;Document 2 | [0.4,0.5,0.6] | 0.5385165006363984&#xD;&#xA;Document 3 | [0.9,0.8,0.7] | 1.0677078185041473&#xD;&#xA;(3 rows)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Elle est représentée par le cigle &amp;lt;-&amp;gt; dans pg_vector.&lt;/p&gt;&#xA;&lt;h4&gt;3. Quand choisir l&amp;#8217;une ou l&amp;#8217;autre des distances ?&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;La distance euclidienne est utile quand tu veux mesurer la différence globale entre deux objets. Elle est facile à comprendre et à utiliser pour des comparaisons directes.&lt;/li&gt;&#xA;&lt;li&gt;La distance cosinus est utile quand tu veux savoir si deux objets sont globalement similaires dans leur profil, indépendamment de leur taille ou de leur échelle. Elle est souvent utilisée pour comparer des documents textuels ou des données complexes en IA&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Conclusion&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;#8217;extension pg_vector apporte une fonctionnalité puissante à PostgreSQL, permettant de manipuler des données complexes sous forme de vecteurs. Que ce soit pour des systèmes de recommandation, des moteurs de recherche ou toute autre application liée à l’intelligence artificielle, elle offre un moyen simple et efficace d&amp;#8217;intégrer l&amp;#8217;IA dans les bases de données. Et tout cela, sans avoir besoin de comprendre des mathématiques avancées : il suffit de savoir que ces vecteurs permettent de traiter des informations complexes de manière très efficace.&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/&#34; rel=&#34;bookmark&#34; title=&#34;3 avril 2024&#34;&gt;pg_recursively_delete : Simplifier les suppressions récursives&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pyrseas-et-postgresql-comparer-facilement-des-schema-de-base-de-donnees/&#34; rel=&#34;bookmark&#34; title=&#34;3 janvier 2023&#34;&gt;Pyrseas et Postgresql : Comparer facilement des schémas de base de données&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-planifier-une-tache-avec-pg_cron/&#34; rel=&#34;bookmark&#34; title=&#34;24 septembre 2019&#34;&gt;PostgreSQL : planifier une tâche avec pg_cron&lt;/a&gt; (Emmanuel RAMI) [Non classéPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/openrowset-episode-1/&#34; rel=&#34;bookmark&#34; title=&#34;13 juillet 2011&#34;&gt;OPENROWSET, épisode 1&lt;/a&gt; (David Baffaleuf) [SQL Server]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/transparent-data-encryption-pour-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;13 mai 2022&#34;&gt;Transparent Data Encryption pour PostgreSQL&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 1.995 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&amp;#038;title=pg_vector%20%3A%20l%E2%80%99IA%20et%20PostgreSQL&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=pg_vector%20%3A%20l%E2%80%99IA%20et%20PostgreSQL&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10620&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pg_vector-lia-et-postgresql/&#34;&gt;pg_vector : l&amp;#8217;IA et PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/pg_vector-lia-et-postgresql/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;1. Introduction : L&amp;#8217;intelligence artificielle et le rôle des bases de données L&amp;#8217;intelligence artificielle (IA) connaît une popularité croissante, des assistants virtuels aux voitures autonomes, en passant par les recommandations de films et de produits. Mais pour que ces technologies&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/pg_vector-lia-et-postgresql/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pg_vector-lia-et-postgresql/&#34;&gt;pg_vector : l&amp;#8217;IA et PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 17 : des sauvegardes incrémentales avec pg_basebackup</title>
    <updated>2024-07-16T11:24:05Z</updated>
    <id>tag:blog.capdata.fr,2024-07-16:/index.php/postgresql-17-sauvegardes-incrementales/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&amp;#038;title=PostgreSQL%2017%20%3A%20des%20sauvegardes%20incr%C3%A9mentales%20avec%20pg_basebackup&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%2017%20%3A%20des%20sauvegardes%20incr%C3%A9mentales%20avec%20pg_basebackup&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-full wp-image-10592&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2024/07/SalesGrowth.jpg&#34; alt=&#34;&#34; width=&#34;279&#34; height=&#34;180&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Bonjour&lt;/p&gt;&#xA;&lt;p&gt;Les 11 et 12 juin derniers, nous étions aux journées PGDAY à Lille pour découvrir les nouveautés autour de PostgreSQL.&lt;br /&gt;&#xA;Cette conférence regroupe différents professionnels, de la communauté francophone, qui agissent en contribuant sur des sujets techniques mais aussi sur les bonnes pratiques afin d&amp;#8217;utiliser PostgreSQL dans les meilleurs conditions.&lt;/p&gt;&#xA;&lt;p&gt;Un article m&amp;#8217;a particulièrement intéressé cette année, c&amp;#8217;est celui de &lt;a href=&#34;https://www.linkedin.com/in/stefan-fercot/?originalSubdomain=be&#34;&gt;Stefan Fercot&lt;/a&gt; Senior DBA PostgreSQL qui vit en Belgique, et travaille pour une société allemande experte dans les solutions PostgreSQL. Sa présentation portait sur le sujet &amp;#8220;démystifier les sauvegardes incrémentales sous PostgreSQL&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;J&amp;#8217;ai écouté sa conférence tout en ayant hâte de tester sa mise en place dès mon retour de Lille.&lt;/p&gt;&#xA;&lt;p&gt;Je tiens à remercier Stefan pour son travail sur ce sujet sauvegardes PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Tout d&amp;#8217;abord, il faut savoir que les sujets sauvegardes incrémentales ont été déjà abordés avec des outils comme &lt;strong&gt;Barman&lt;/strong&gt; ou &lt;strong&gt;Pg_BackRest&lt;/strong&gt;, et que certaines instances PostgreSQL de production sont sauvegardées via ces mécanismes depuis quelques années maintenant.&lt;/p&gt;&#xA;&lt;p&gt;Ici, nous parlons de la solution &amp;#8220;backup incremental&amp;#8221; inclu nativement dans le moteur PostgreSQL, et disponible avec l&amp;#8217;outil &amp;#8220;&lt;strong&gt;pg_basebackup&lt;/strong&gt;&amp;#8220;. C&amp;#8217;est d&amp;#8217;ailleurs ce point que Stefan a souligné durant la journée PGDAY du 11 juin dernier.&lt;/p&gt;&#xA;&lt;p&gt;Cette nouvelle fonctionnalité fait partie de la version &lt;strong&gt;PostgreSQL 17&lt;/strong&gt; qui est pour le moment, en version&lt;strong&gt; Beta 2&lt;/strong&gt;.&lt;br /&gt;&#xA;Celle ci devrait sortir, comme à l&amp;#8217;accoutumé, au cour de l&amp;#8217;automne prochain.&lt;/p&gt;&#xA;&lt;p&gt;Preuve que PostgreSQL est en perpétuel évolution, et rejoint la liste des SGBD étant capable, comme peuvent le faire Oracle et SQL Server, de proposer nativement des sauvegardes incrémentales.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Installation de PostgreSQL 17&lt;/h2&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Pour tester cette fonctionnalité, nous devons installer la toute dernière version de PostgreSQL , la 17 beta 2. Attention, celle ci n&amp;#8217;étant pas disponible dans les dépôts PGDG, nous devons nous charger d&amp;#8217;installer cette version via le site postgresql.org&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://download.postgresql.org/pub/repos/yum/testing/17/redhat/rhel-8-x86_64/&#34;&gt;https://download.postgresql.org/pub/repos/yum/testing/17/redhat/rhel-8-x86_64/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Nous disposons d&amp;#8217;un serveur Linux fork Red Hat 8 (Rocky Linux). Il nous faut donc télécharger les &amp;#8220;rpm&amp;#8221; liés à cette version.&lt;/p&gt;&#xA;&lt;p&gt;Les packages dont nous avons besoin sont les suivants&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# ls -lrt postgresql1* | awk &#39;{print$9}&#39;&#xD;&#xA;postgresql17-contrib-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;postgresql17-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;postgresql17-libs-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;postgresql17-server-17-beta2_1PGDG.rhel8.x86_64.rpm&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Nous les installons avec le compte &lt;strong&gt;root&lt;/strong&gt; de notre serveur.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[root@ tmp]# rpm -i postgresql17-libs-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;[root@ tmp]# rpm -i postgresql17-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;[root@ tmp]# rpm -i postgresql17-server-17-beta2_1PGDG.rhel8.x86_64.rpm&#xD;&#xA;[root@ tmp]# rpm -i postgresql17-contrib-17-beta2_1PGDG.rhel8.x86_64.rpm&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Comme nous sommes sur un environnement &amp;#8220;Red Hat like&amp;#8221;, la création d&amp;#8217;une première instance via &amp;#8220;initdb&amp;#8221; est nécessaire.&lt;br /&gt;&#xA;Surtout, ne pas oublier d&amp;#8217;activer les &amp;#8220;data checksums&amp;#8221; (option -k), nous verrons pourquoi dans la suite de cet article. La suite est à faire avec le compte &lt;strong&gt;postgres&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ initdb -D /data/postgres/17/pg_data -k&#xD;&#xA;The files belonging to this database system will be owned by user &amp;quot;postgres&amp;quot;.&#xD;&#xA;This user must also own the server process.&#xD;&#xA;&#xD;&#xA;The database cluster will be initialized with locale &amp;quot;en_US.UTF-8&amp;quot;.&#xD;&#xA;The default database encoding has accordingly been set to &amp;quot;UTF8&amp;quot;.&#xD;&#xA;The default text search configuration will be set to &amp;quot;english&amp;quot;.&#xD;&#xA;&#xD;&#xA;Data page checksums are enabled.&#xD;&#xA;&#xD;&#xA;creating directory /data/postgres/17/pg_data ... ok&#xD;&#xA;creating subdirectories ... ok&#xD;&#xA;selecting dynamic shared memory implementation ... posix&#xD;&#xA;selecting default &amp;quot;max_connections&amp;quot; ... 100&#xD;&#xA;selecting default &amp;quot;shared_buffers&amp;quot; ... 128MB&#xD;&#xA;selecting default time zone ... UTC&#xD;&#xA;creating configuration files ... ok&#xD;&#xA;running bootstrap script ... ok&#xD;&#xA;performing post-bootstrap initialization ... ok&#xD;&#xA;syncing data to disk ... ok&#xD;&#xA;&#xD;&#xA;initdb: warning: enabling &amp;quot;trust&amp;quot; authentication for local connections&#xD;&#xA;initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.&#xD;&#xA;&#xD;&#xA;Success. You can now start the database server using:&#xD;&#xA;&#xD;&#xA;pg_ctl -D /data/postgres/17/pg_data -l logfile start&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Démarrer cette instance pour s&amp;#8217;assurer que tout fonctionne&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ pg_ctl -D /data/postgres/17/pg_data -l logfile start&#xD;&#xA;waiting for server to start.... done&#xD;&#xA;server started&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Notre version enregistrée est bien une Beta 2. Version qui ne doit pas être mise sur un environnement de production comme le rappelle le site de la communauté PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ psql&#xD;&#xA;(postgres@[local]:5437) [postgres] &amp;gt; select * from version();&#xD;&#xA;version&#xD;&#xA;------------------------------------------------------------------------------------------------------------&#xD;&#xA;PostgreSQL 17beta2 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-22), 64-bit&#xD;&#xA;(1 row)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Upgrade de version&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Comme nous disposions deja d&amp;#8217;une version PostgreSQL15 sur ce serveur, nous passons par un upgrade via l&amp;#8217;outil &amp;#8220;pg_upgrade&amp;#8221; toujours disponible dans cette nouvelle version.&lt;/p&gt;&#xA;&lt;p&gt;Lancer pg_upgrade en mode check&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ pg_upgrade -b /usr/pgsql-15/bin/ -B /usr/pgsql-17/bin/ -c -d /data/postgres/15/pg_data/ -D /data/postgres/17/pg_data/ -p 5434 -P 5437&#xD;&#xA;.....&#xD;&#xA;.....&#xD;&#xA;&#xD;&#xA;*Clusters are compatible*&#xD;&#xA;&amp;quot;/usr/pgsql-17/bin/pg_ctl&amp;quot; -w -D &amp;quot;/data/postgres/17/pg_data&amp;quot; -o &amp;quot;&amp;quot; -m smart stop  &amp;quot;/data/postgres/17/pg_data/pg_upgrade_output.d/20240708T085906.955/log/pg_upgrade_server.log&amp;quot; &lt;/pre&gt;&#xA;&lt;p&gt;la log est générée dans le $PGDATA de la version 17.&lt;/p&gt;&#xA;&lt;p&gt;Puis lancer l&amp;#8217;exécution de pg_upgrade&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ pg_upgrade -b /usr/pgsql-15/bin/ -B /usr/pgsql-17/bin/ -d /data/postgres/15/pg_data/ -D /data/postgres/17/pg_data/ -p 5434 -P 5437&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Effectuer une sauvegarde&lt;/h2&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Prérequis&lt;/h3&gt;&#xA;&lt;p&gt;Avant de pouvoir effectuer une première sauvegarde avec l&amp;#8217;outil &amp;#8220;&lt;strong&gt;pg_basebackup&lt;/strong&gt;&amp;#8221; natif, il est primordial de respecter certains prérequis important.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;L&amp;#8217;instance PostgreSQL doit être créée avec les &amp;#8216;data checksums&amp;#8217; activés. Si ce n&amp;#8217;est pas le cas, utiliser l&amp;#8217;outil &amp;#8220;&lt;strong&gt;pg_checksums&lt;/strong&gt;&amp;#8221; avec l&amp;#8217;option &amp;#8220;&lt;strong&gt;-e&lt;/strong&gt;&amp;#8220;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Si vous lancez une sauvegarde full puis une incrémentale immédiatement, vous avez toutes les chances de tomber sur cette erreur&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;pg_basebackup: error: could not initiate base backup: ERROR: incremental backups cannot be taken unless WAL summarization is enabled&lt;/pre&gt;&#xA;&lt;p&gt;En effet, pour avoir toutes les informations concernant les blocks modifiés, PostgreSQL a besoin de tracer dans les WALs toutes les modifications sur les objets en base.&lt;br /&gt;&#xA;Pour les DBA Oracle, le &amp;#8220;block change tracking&amp;#8221; de la version Enterprise Edition vous parlera très certainement&amp;#8230;.&lt;br /&gt;&#xA;Il s&amp;#8217;agit ici de la même fonctionnalité, c&amp;#8217;est à dire, tracer les modifications effectuées dans les blocks de données.&lt;br /&gt;&#xA;Cette option est le &amp;#8220;&lt;strong&gt;summarize_wal&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Pour activer l&amp;#8217;option, nous aurons 2 paramètres à modifier, soit via un ALTER SYSTEM directement sous psql, ou bien dans le fichier &amp;#8220;postgresql.conf&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres backup]$ vi $PGDATA/postgresql.conf&#xD;&#xA;...&#xD;&#xA;&#xD;&#xA;# - WAL Summarization -&#xD;&#xA;&#xD;&#xA;#summarize_wal = off # run WAL summarizer process?&#xD;&#xA;#wal_summary_keep_time = &#39;10d&#39; # when to remove old summary files, 0 = never&lt;/pre&gt;&#xA;&lt;p&gt;Le premier paramètre permet d&amp;#8217;activer cette option.&lt;br /&gt;&#xA;Le second définit un temps de conservation des informations concernant les blocks modifiés entre une sauvegarde FULL et un incrémentale.&lt;/p&gt;&#xA;&lt;p&gt;Nous activons donc l&amp;#8217;option &amp;#8220;&lt;strong&gt;summarize_wal&lt;/strong&gt;&amp;#8221; et la passons à &lt;strong&gt;ON&lt;/strong&gt; et laissons à 10 jours le &amp;#8220;&lt;strong&gt;wal_summary_keep_time&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Attention, activez ces deux paramètres avant votre première sauvegarde FULL. Si vous le faites après, vous risquez de rencontrer l&amp;#8217;erreur suivante&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;pg_basebackup: error: could not initiate base backup: ERROR: WAL summaries are required on timeline 1 from 1/AA000028 to 1/AC000060, but the summaries for that timeline and LSN range are incomplete&#xD;&#xA;DETAIL: The first unsummarized LSN in this range is 1/AA000028.&lt;/pre&gt;&#xA;&lt;p&gt;Le LSN pris lors de la première sauvegarde FULL n&amp;#8217;est pas reconnu, et donc la sauvegarde incrémentale ne peut s&amp;#8217;appuyer dessus.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Redémarrer l&amp;#8217;instance une fois les modifications effectuées&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres ~]$ pg_ctl -D /data/postgres/17/pg_data/ restart&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Lancer une sauvegarde FULL&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Voici la nouvelle option présente pour l&amp;#8217;outil &amp;#8220;&lt;strong&gt;pg_basebackup&lt;/strong&gt;&amp;#8221;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres -]$ pg_basebackup --help&#xD;&#xA;pg_basebackup takes a base backup of a running PostgreSQL server.&#xD;&#xA;&#xD;&#xA;Usage:&#xD;&#xA;pg_basebackup [OPTION]...&#xD;&#xA;&#xD;&#xA;Options controlling the output:&#xD;&#xA;-D, --pgdata=DIRECTORY receive base backup into directory&#xD;&#xA;-F, --format=p|t output format (plain (default), tar)&#xD;&#xA;-i, --incremental=OLDMANIFEST&#xD;&#xA;take incremental backup&#xD;&#xA;-r, --max-rate=RATE maximum transfer rate to transfer data directory&#xD;&#xA;(in kB/s, or use suffix &amp;quot;k&amp;quot; or &amp;quot;M&amp;quot;)&#xD;&#xA;&#xD;&#xA;.... &lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Depuis la &lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-13-les-nouveautes-interessantes/&#34;&gt;version 13&lt;/a&gt; de PostgreSQL, nous disposons pour chaque sauvegarde, d&amp;#8217;un fichier nommé &amp;#8220;backup_manifest&amp;#8221;. Il s&amp;#8217;agit d&amp;#8217;un fichier json qui recense entièrement les objets bases de données sauvegardés avec leur emplacement, leur taille, leur date de modification et leur &amp;#8220;checksum&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;Celui ci est essentiel pour vérifier l&amp;#8217;intégrité de notre sauvegarde avec &amp;#8220;&lt;strong&gt;pg_verifybackup&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;p&gt;Nous pouvons à présent faire une première sauvegarde FULL de notre instance PG17.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres -]$ pg_basebackup -D /data/postgres/backup/pg_basebackup/PG17 -F p -l &amp;quot;Full Backup PG17&amp;quot; -P -v&#xD;&#xA;pg_basebackup: initiating base backup, waiting for checkpoint to complete&#xD;&#xA;pg_basebackup: checkpoint completed&#xD;&#xA;pg_basebackup: write-ahead log start point: 1/AD000028 on timeline 1&#xD;&#xA;pg_basebackup: starting background WAL receiver&#xD;&#xA;pg_basebackup: created temporary replication slot &amp;quot;pg_basebackup_8048&amp;quot;&#xD;&#xA;3097788/3097788 kB (100%), 1/1 tablespace&#xD;&#xA;pg_basebackup: write-ahead log end point: 1/AD000158&#xD;&#xA;pg_basebackup: waiting for background process to finish streaming ...&#xD;&#xA;pg_basebackup: syncing data to disk ...&#xD;&#xA;pg_basebackup: renaming backup_manifest.tmp to backup_manifest&#xD;&#xA;pg_basebackup: base backup completed&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Puis on effectue quelques transactions : création d&amp;#8217;une table et insertions de données sur cette table de test&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5437) [manu] $ &amp;gt; create table backup (nom varchar(20), type varchar(20), date_backup date);&#xD;&#xA;CREATE TABLE&#xD;&#xA;Time: 3.344 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; insert into backup values (&#39;sauvegarde&#39;,&#39;FULL&#39;,&#39;2024-07-08 12:00:00&#39;);&#xD;&#xA;INSERT 0 1&#xD;&#xA;Time: 3.612 ms&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; insert into backup values (&#39;sauvegarde&#39;,&#39;incremental&#39;,&#39;2024-07-08 13:00:00&#39;);&#xD;&#xA;INSERT 0 1&#xD;&#xA;Time: 1.461 ms&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; select * from backup;&#xD;&#xA;nom | type | date_backup&#xD;&#xA;------------+-------------+-------------&#xD;&#xA;sauvegarde | FULL | 2024-07-08&#xD;&#xA;sauvegarde | incremental | 2024-07-08&#xD;&#xA;(2 rows)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Repérer le fichier &amp;#8220;backup_manifest&amp;#8221; de la sauvegarde FULL réalisée dans le dossier &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17&lt;/strong&gt;&amp;#8221;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres PG17]$ ls -lrt backup*&#xD;&#xA;-rw-------. 1 postgres postgres 218 Jul 8 09:19 backup_label&#xD;&#xA;-rw-------. 1 postgres postgres 433295 Jul 8 09:20 backup_manifest&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Effectuer une sauvegarde incrémentale&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;A partir de là, lancer une sauvegarde incrémentale. Nous utilisons l&amp;#8217;option &amp;#8220;&lt;strong&gt;-i&lt;/strong&gt;&amp;#8221; pour indiquer à &lt;strong&gt;pg_basebackup&lt;/strong&gt; ou est situé le &amp;#8220;backup_manifest&amp;#8221; de la dernière sauvegarde FULL.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_basebackup -D /data/postgres/backup/pg_basebackup/PG17_incr -l &amp;quot;Incremental Backup PG17&amp;quot; -P -v -i /data/postgres/backup/pg_basebackup/PG17/backup_manifest&#xD;&#xA;pg_basebackup: initiating base backup, waiting for checkpoint to complete&#xD;&#xA;pg_basebackup: checkpoint completed&#xD;&#xA;pg_basebackup: write-ahead log start point: 1/AF000028 on timeline 1&#xD;&#xA;pg_basebackup: starting background WAL receiver&#xD;&#xA;pg_basebackup: created temporary replication slot &amp;quot;pg_basebackup_8139&amp;quot;&#xD;&#xA;12485/3097787 kB (100%), 1/1 tablespace&#xD;&#xA;pg_basebackup: write-ahead log end point: 1/AF000120&#xD;&#xA;pg_basebackup: waiting for background process to finish streaming ...&#xD;&#xA;pg_basebackup: syncing data to disk ...&#xD;&#xA;pg_basebackup: renaming backup_manifest.tmp to backup_manifest&#xD;&#xA;pg_basebackup: base backup completed&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;S&amp;#8217;il l&amp;#8217;on compare les deux répertoires de sauvegardes &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17&lt;/strong&gt;&amp;#8221; et &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17_incr&lt;/strong&gt;&amp;#8220;, nous voyons que les tailles sont bien différentes&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ du -h /data/postgres/backup/pg_basebackup/PG17&#xD;&#xA;......&#xD;&#xA;3.0G /data/postgres/backup/pg_basebackup/PG17&#xD;&#xA;&#xD;&#xA;[postgres - ]$ du -h /data/postgres/backup/pg_basebackup/PG17_incr&#xD;&#xA;......&#xD;&#xA;35M /data/postgres/backup/pg_basebackup/PG17_incr&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Un volume de 3Go pour la sauvegarde FULL de l&amp;#8217;instance contre 35Mo pour l&amp;#8217;incrémentale.&lt;br /&gt;&#xA;La taille occupée par les objets dans chacune des bases est bien plus faible dans la sauvegarde incrémentale.&lt;/p&gt;&#xA;&lt;p&gt;Nous continuons à insérer des données :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt; [postgres - ]$ psql -d manu&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; select * from backup;&#xD;&#xA;nom | type | date_backup&#xD;&#xA;------------+-------------+-------------&#xD;&#xA;sauvegarde | FULL | 2024-07-08&#xD;&#xA;sauvegarde | incremental | 2024-07-08&#xD;&#xA;(2 rows)&#xD;&#xA;&#xD;&#xA;Time: 0.614 ms&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; insert into backup values (&#39;sauvegarde&#39;,&#39;incremental 2&#39;,&#39;2024-07-08 14:00:00&#39;);&#xD;&#xA;INSERT 0 1&#xD;&#xA;Time: 1.436 ms&#xD;&#xA;(postgres@[local]:5437) [manu] $ &amp;gt; select * from backup;&#xD;&#xA;nom | type | date_backup&#xD;&#xA;------------+---------------+-------------&#xD;&#xA;sauvegarde | FULL | 2024-07-08&#xD;&#xA;sauvegarde | incremental | 2024-07-08&#xD;&#xA;sauvegarde | incremental 2 | 2024-07-08&#xD;&#xA;(3 rows)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Puis on lance une seconde sauvegarde incrémentale :&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_basebackup -D /data/postgres/backup/pg_basebackup/PG17_incr_2 -l &amp;quot;Incremental 2 Backup PG17&amp;quot; -P -v -i /data/postgres/backup/pg_basebackup/PG17_incr/backup_manifest&#xD;&#xA;pg_basebackup: initiating base backup, waiting for checkpoint to complete&#xD;&#xA;pg_basebackup: checkpoint completed&#xD;&#xA;pg_basebackup: write-ahead log start point: 1/B1000028 on timeline 1&#xD;&#xA;pg_basebackup: starting background WAL receiver&#xD;&#xA;pg_basebackup: created temporary replication slot &amp;quot;pg_basebackup_8313&amp;quot;&#xD;&#xA;12260/3097787 kB (100%), 1/1 tablespace&#xD;&#xA;pg_basebackup: write-ahead log end point: 1/B1000120&#xD;&#xA;pg_basebackup: waiting for background process to finish streaming ...&#xD;&#xA;pg_basebackup: syncing data to disk ...&#xD;&#xA;pg_basebackup: renaming backup_manifest.tmp to backup_manifest&#xD;&#xA;pg_basebackup: base backup completed&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Nous remarquons l&amp;#8217;appel au &amp;#8220;backup manifest&amp;#8221; de la dernière sauvegarde incrémentale présente dans le répertoire &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17_incr&lt;/strong&gt;&amp;#8221;&lt;/p&gt;&#xA;&lt;p&gt;Si l&amp;#8217;on regarde la taille de ce nouveau backup&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres pg_basebackup]$ du -h PG17_incr_2&#xD;&#xA;.......&#xD;&#xA;35M PG17_incr_2&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;A nouveau 35 Mo, mais vu le peu de modifications effectuées, la taille n&amp;#8217;est pas très représentative.&lt;/p&gt;&#xA;&lt;p&gt;Ce qu&amp;#8217;il faut retenir, c&amp;#8217;est qu&amp;#8217;en fonction du fichier &amp;#8220;backup manifest&amp;#8221; pris lors de l&amp;#8217;appel à &lt;strong&gt;pg_basebackup&lt;/strong&gt;, vous pourrez faire soit&lt;br /&gt;&#xA;&amp;#8211; une sauvegarde incrémentale qui prendra les dernières modifications depuis la dernière sauvegarde incrémentale effectuée.&lt;br /&gt;&#xA;&amp;#8211; une sauvegarde différentielle qui prendra les modifications faites depuis la dernière sauvegarde FULL si vous vous appuyez toujours sur le &amp;#8220;backup manifest&amp;#8221; de votre sauvegarde FULL.&lt;/p&gt;&#xA;&lt;p&gt;C&amp;#8217;est donc ce fichier json &amp;#8220;backup manifest&amp;#8221; qui a un rôle essentiel dans l&amp;#8217;élaboration de votre stratégie de sauvegarde au fur et à mesure du temps.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Et la restauration , comment ca se passe ?&lt;/h2&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Si l&amp;#8217;on souhaite restaurer tous ces jeux de sauvegardes, nous utilisons un nouvel outil qui est &amp;#8220;&lt;strong&gt;pg_combinebackup&lt;/strong&gt;&amp;#8220;.&lt;br /&gt;&#xA;Cet outil permet de &amp;#8220;merger&amp;#8221; les différentes sauvegardes dans un et un seul dossier que l&amp;#8217;on restaurera par la suite.&lt;/p&gt;&#xA;&lt;p&gt;Dans notre exemple, nous avons fait 1 sauvegarde FULL puis 2 incrémentales.&lt;br /&gt;&#xA;Nous allons donc restaurer ces 3 jeux de sauvegardes afin de retrouver les données. A noter qu&amp;#8217;il existe une option &amp;#8220;&amp;#8211;dry-run&amp;#8221; pour tester la commande&lt;/p&gt;&#xA;&lt;p&gt;Exécuter la commande en prenant en paramètre les dossiers de sauvegardes dans l&amp;#8217;ordre chronologique.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_combinebackup -n -o /data/postgres/backup/pg_basebackup/PG17_ALL /data/postgres/backup/pg_basebackup/PG17 /data/postgres/backup/pg_basebackup/PG17_incr /data/postgres/backup/pg_basebackup/PG17_incr_2 &lt;/pre&gt;&#xA;&lt;p&gt;Si aucune erreur en sortie, on exécute sans l&amp;#8217;option &amp;#8220;dry run&amp;#8221;.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; [postgres - ]$ pg_combinebackup -o /data/postgres/backup/pg_basebackup/PG17_ALL /data/postgres/backup/pg_basebackup/PG17 /data/postgres/backup/pg_basebackup/PG17_incr /data/postgres/backup/pg_basebackup/PG17_incr_2 &lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Le répertoire &amp;#8220;&lt;strong&gt;/data/postgres/backup/pg_basebackup/PG17_ALL&lt;/strong&gt;&amp;#8221; ainsi généré, doit avoir une taille très légèrement supérieure au dossier de la sauvegarde FULL.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ du -h PG17_ALL&#xD;&#xA;....&#xD;&#xA;3.0G PG17_ALL&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Dernière étape, nous passons à la restauration des données.&lt;/p&gt;&#xA;&lt;p&gt;Nous arrêtons l&amp;#8217;instance PG17&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_ctl -D /data/postgres/17/pg_data/ stop&#xD;&#xA;waiting for server to shut down.... done&#xD;&#xA;server stopped&lt;/pre&gt;&#xA;&lt;p&gt;Nous supprimons les données dans $PGDATA&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ rm -rf /data/postgres/17/pg_data/* &lt;/pre&gt;&#xA;&lt;p&gt;Puis nous restaurons ce jeu complet de données avec une simple copie.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ cp -r /data/postgres/backup/pg_basebackup/PG17_ALL/* /data/postgres/17/pg_data/ &lt;/pre&gt;&#xA;&lt;p&gt;Enfin redémarrons l&amp;#8217;instance&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_ctl -D /data/postgres/17/pg_data/ start&#xD;&#xA;waiting for server to start....2024-07-08 10:51:45.671 UTC [8909] LOG: redirecting log output to logging collector process&#xD;&#xA;2024-07-08 10:51:45.671 UTC [8909] HINT: Future log output will appear in directory &amp;quot;log&amp;quot;.&#xD;&#xA;done&#xD;&#xA;server started&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Puis contrôler que nous récupérons bien toutes les lignes de notre table &amp;#8220;backup&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres@ip-172-44-2-96 pg_basebackup]$ psql -d manu&#xD;&#xA;(postgres@[local]:5437) [manu] primaire $ &amp;gt; select * from backup;&#xD;&#xA;nom | type | date_backup&#xD;&#xA;------------+---------------+-------------&#xD;&#xA;sauvegarde | FULL | 2024-07-08&#xD;&#xA;sauvegarde | incremental | 2024-07-08&#xD;&#xA;sauvegarde | incremental 2 | 2024-07-08&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h3&gt;&lt;/h3&gt;&#xA;&lt;h3&gt;&lt;/h3&gt;&#xA;&lt;h3&gt;Remarques&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Attention, toujours vérifier les sauvegardes à chaque étape avec l&amp;#8217;outil &lt;strong&gt;pg_verifybackup &lt;/strong&gt;car rien ne garantit qu&amp;#8217;au moment de l&amp;#8217;appel à &lt;strong&gt;pg_combinebackup&lt;/strong&gt; les différents jeux de sauvegardes FULL et/ou incrémentales ne soient pas corrompus.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Assurez vous d&amp;#8217;être en mode &amp;#8220;data_checksum&amp;#8221; activé et ne pas changer de mode entre les jeux de backup. Le &amp;#8220;backup manifest&amp;#8221; s&amp;#8217;appuie sur ce paramétrage pour valider les checksums de chaque fichier.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Le mode TAR pour &lt;strong&gt;pg_basebackup&lt;/strong&gt; n&amp;#8217;est pas compatible pour les sauvegardes full et incrémentales même si celui ci est possible. Mais c&amp;#8217;est à vous de détarer les fichiers &amp;#8220;&lt;strong&gt;base.tar.gz&lt;/strong&gt;&amp;#8221; Et au moment de la restauration  avec &amp;#8220;&lt;strong&gt;pg_combinebackup&lt;/strong&gt;&amp;#8220;, une possible corruption est rencontrée.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres - ]$ pg_combinebackup -o /data/postgres/backup/pg_basebackup/PG17_all_tar /data/postgres/backup/pg_basebackup/PG17_TAR /data/postgres/backup/pg_basebackup/PG17_incr_TAR&#xD;&#xA;pg_combinebackup: error: could not write to file &amp;quot;/data/postgres/backup/pg_basebackup/PG17_all_tar/base/25284/25332&amp;quot;, offset 122470400: wrote 380928 of 409600&#xD;&#xA;pg_combinebackup: removing output directory &amp;quot;/data/postgres/backup/pg_basebackup/PG17_all_tar&amp;quot; &lt;/pre&gt;&#xA;&lt;p&gt;La compression a potentiellement ajoutée une corruption ne rendant pas possible l&amp;#8217;opération de &amp;#8220;merge&amp;#8221; des données.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;La restauration PITR est possible bien entendu. N&amp;#8217;oubliez pas de créer le &amp;#8220;&lt;strong&gt;recovery.signal&lt;/strong&gt;&amp;#8221; dans $PGDATA et de définir dans le fichier &amp;#8220;postgresql.conf&amp;#8221; les quelques paramètres suivants&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #3366ff;&#34;&gt;recovery_target_name &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #3366ff;&#34;&gt;recovery_target_time &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #3366ff;&#34;&gt;recovery_target_xid &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #3366ff;&#34;&gt;recovery_target_lsn &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #808000;&#34;&gt;recovery_target_inclusive = off ou on&lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #808000;&#34;&gt;recovery_target_timeline = &amp;#8216;latest&amp;#8217; &lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;span style=&#34;color: #808000;&#34;&gt;recovery_target_action = &amp;#8216;pause&amp;#8217; &lt;/span&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://s.w.org/images/core/emoji/15.0.3/72x72/1f642.png&#34; alt=&#34;🙂&#34; class=&#34;wp-smiley&#34; style=&#34;height: 1em; max-height: 1em;&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-la-streaming-replication-en-12/&#34; rel=&#34;bookmark&#34; title=&#34;19 novembre 2019&#34;&gt;PostgreSQL : la streaming replication en 12.&lt;/a&gt; (Emmanuel RAMI) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-13-les-nouveautes-interessantes/&#34; rel=&#34;bookmark&#34; title=&#34;30 octobre 2020&#34;&gt;PostgreSQL 13 : présentation&lt;/a&gt; (Emmanuel RAMI) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/oracle-rds-effectuer-des-backup-rman-en-mode-paas/&#34; rel=&#34;bookmark&#34; title=&#34;25 juin 2019&#34;&gt;Oracle RDS : effectuer des backup RMAN en mode PaaS.&lt;/a&gt; (Emmanuel RAMI) [AWSNon classéOracle]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-comparatif-entre-barman-et-pgbackrest/&#34; rel=&#34;bookmark&#34; title=&#34;4 février 2020&#34;&gt;PostgreSQL : Comparatif entre Barman et pgBackRest&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/haute-disponibilite-de-postgresql-avec-patroni/&#34; rel=&#34;bookmark&#34; title=&#34;2 février 2022&#34;&gt;Haute disponibilité de PostgreSQL avec Patroni&lt;/a&gt; (Ludovic AUGEREAU) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 2.654 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&amp;#038;title=PostgreSQL%2017%20%3A%20des%20sauvegardes%20incr%C3%A9mentales%20avec%20pg_basebackup&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%2017%20%3A%20des%20sauvegardes%20incr%C3%A9mentales%20avec%20pg_basebackup&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10584&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-17-sauvegardes-incrementales/&#34;&gt;PostgreSQL 17 : des sauvegardes incrémentales avec pg_basebackup&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/postgresql-17-sauvegardes-incrementales/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&amp;#160; Bonjour Les 11 et 12 juin derniers, nous étions aux journées PGDAY à Lille pour découvrir les nouveautés autour de PostgreSQL. Cette conférence regroupe différents professionnels, de la communauté francophone, qui agissent en contribuant sur des sujets techniques mais&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-17-sauvegardes-incrementales/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-17-sauvegardes-incrementales/&#34;&gt;PostgreSQL 17 : des sauvegardes incrémentales avec pg_basebackup&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>PGO : la suite</title>
    <updated>2024-05-29T08:58:17Z</updated>
    <id>tag:blog.capdata.fr,2024-05-29:/index.php/pgo-la-suite/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&amp;#038;title=PGO%20%3A%20la%20suite&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PGO%20%3A%20la%20suite&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;La gestion efficace des clusters PostgreSQL dans un environnement Kubernetes est un défi complexe auquel sont confrontées de nombreuses entreprises aujourd&amp;#8217;hui. PGO offre une solution déclarative qui automatise la gestion des clusters PostgreSQL, simplifiant ainsi le déploiement, la mise à l&amp;#8217;échelle et la gestion des bases de données PostgreSQL dans un environnement Kubernetes.&lt;/p&gt;&#xA;&lt;p&gt;Pour faire suite à l&amp;#8217;article de David sur PGO et à la demande d&amp;#8217;un de nos clients, j&amp;#8217;ai réalisé une étude approfondie de plusieurs fonctionnalités de PGO.&lt;br /&gt;&#xA;Cet article va faire un petit tour d&amp;#8217;horizon des outils principaux inclus dans l&amp;#8217;implémentation de PGO. Que ce soit pour la sauvegarde avec pgbackrest, pour la balance des connexion avec pgbouncer ou pour le monitoring avec prometheus, PGO ne manque pas d&amp;#8217;utilitaire dont l&amp;#8217;utilisation est facilitée par la solution tout embarqué.&lt;/p&gt;&#xA;&lt;h3&gt;Pgbackrest :&lt;/h3&gt;&#xA;&lt;h4&gt;Utilité :&lt;/h4&gt;&#xA;&lt;p&gt;PgBackRest est une solution de sauvegarde et de restauration pour les bases de données PostgreSQL qui propose plusieurs fonctionnalités, telles que la sauvegarde et la restauration parallèles, la compression, les sauvegardes complètes, différentielles et incrémentielles, la rotation des sauvegardes et l&amp;#8217;expiration des archives, l&amp;#8217;intégrité des sauvegardes, etc. Il prend en charge plusieurs référentiels, qui peuvent être situés localement ou à distance via TLS/SSH, ou être des stockages fournis par le cloud comme S3/GCS/Azure.&lt;br /&gt;&#xA;L&amp;#8217;architecture de pgbackrest pour PGO est la suivante :&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image1.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-medium wp-image-10564&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image1-300x168.png&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;168&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image1-300x168.png 300w, https://blog.capdata.fr/wp-content/uploads/2024/05/Image1.png 605w&#34; sizes=&#34;auto, (max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h4&gt;Mise en place :&lt;/h4&gt;&#xA;&lt;p&gt;On peut imaginer plusieurs moyens de mettre en place le pgbackrest. Dans un premier temps, nous avons la sauvegarde classique en système de fichier, comme dans notre exemple sur le blog :&lt;/p&gt;&#xA;&lt;h5&gt;1) La sauvegarde sur volume persistant Kubernetes :&lt;/h5&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;- name: repo1&#xD;&#xA;  volume:&#xD;&#xA;    volumeClaimSpec:&#xD;&#xA;      accessModes:&#xD;&#xA;      - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;      resources:&#xD;&#xA;        requests:&#xD;&#xA;          storage: 1Gi&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Ce type de sauvegarde utilise un volume persistant de Kubernetes pour recueillir nos sauvegardes et les garder.&lt;br /&gt;&#xA;Une PersistentVolumeClaim (PVC) est une demande de stockage faite par un utilisateur. Elle est similaire à un Pod. Les Pods consomment des ressources de nœud et les PVC consomment des ressources de PV (PersistentVolume). Les Pods peuvent demander des niveaux spécifiques de ressources (CPU et mémoire). Les revendications peuvent demander une taille spécifique et des modes d&amp;#8217;accès spécifiques (par exemple, elles peuvent être montées en ReadWriteOnce, ReadOnlyMany, ReadWriteMany, ou ReadWriteOncePod, voir AccessModes).&lt;/p&gt;&#xA;&lt;h5&gt;2) Le stockage pour S3 :&lt;/h5&gt;&#xA;&lt;p&gt;Pour pouvoir faire du stockage dans S3, il faut rajouter un fichier de configuration dans notre dossier de déploiement. Le fichier doit s’appeler s3.conf. Ce fichier contient les crédential de connexion à un AWS S3 :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;repo1-s3-key=$YOUR_AWS_S3_KEY&#xD;&#xA;repo1-s3-key-secret=$YOUR_AWS_S3_KEY_SECRET&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Une fois que c’est configuré dans votre fichier, il ne reste plus qu’à modifier le postgresql.yaml, et configurer dans la partie backup :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      configuration:&#xD;&#xA;      - secret:&#xD;&#xA;          name: pgo-s3-creds&#xD;&#xA;      global:&#xD;&#xA;        repo1-path: /pgbackrest/postgres-operator/pgcluster1/repo1&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        s3:&#xD;&#xA;          bucket: &amp;quot;&amp;lt;YOUR_AWS_S3_BUCKET_NAME&amp;gt;&amp;quot;&#xD;&#xA;          endpoint: &amp;quot;&amp;lt;YOUR_AWS_S3_ENDPOINT&amp;gt;&amp;quot;&#xD;&#xA;          region: &amp;quot;&amp;lt;YOUR_AWS_S3_REGION&amp;gt;&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Une fois configuré, et le job mis dans le cron, vous devriez voir apparaitre les sauvegardes sur le volume S3.&lt;/p&gt;&#xA;&lt;h5&gt;3) Le stockage GCS :&lt;/h5&gt;&#xA;&lt;p&gt;Comme pour Amazon S3 on peut sauvegarder nos backups dans Google Cloud Storage. Pour pouvoir le faire fonctionner il vous faut copier votre GCS key secret (qui est un fichier JSON) dans un gcs.conf que vous allez placer dans votre dossier Kustomize.&lt;br /&gt;&#xA;Il vous suffit ensuite de modifier votre fichier postgres.yaml pour ajouter dans la partie backup la configuration pour une sauvegarde gcs :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      configuration:&#xD;&#xA;      - secret:&#xD;&#xA;          name: pgo-gcs-creds&#xD;&#xA;      global:&#xD;&#xA;        repo1-path: /pgbackrest/postgres-operator/pgcluster1/repo1&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        gcs:&#xD;&#xA;          bucket: &amp;quot;&amp;lt;YOUR_GCS_BUCKET_NAME&amp;gt;&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il ne vous reste plus qu’à regénérer vos pods, et votre sauvegarde arrivera directement dans votre Google Cloud Service.&lt;/p&gt;&#xA;&lt;h5&gt;4) Le stockage Azur Blob Storage :&lt;/h5&gt;&#xA;&lt;p&gt;Comme pour les deux points précédents, vous pouvez également stocker vos sauvegardes sur le blob storage d’Azure. Pour cela il vous faut créer un fichier dans votre kustomize, avec à l’intérieur la configuration pour votre point de sauvegarde Azure. Il vous faut l’appeler azure.conf et il devra contenir les lignes suivantes :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;repo1-azure-account=$YOUR_AZURE_ACCOUNT&#xD;&#xA;repo1-azure-key=$YOUR_AZURE_KEY&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il faut ensuite intégrer ces modifications dans votre fichier postgres.yaml :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      configuration:&#xD;&#xA;      - secret:&#xD;&#xA;          name: pgo-azure-creds&#xD;&#xA;      global:&#xD;&#xA;        repo1-path: /pgbackrest/postgres-operator/pgcluster/repo1&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        azure:&#xD;&#xA;          container: &amp;quot;&amp;lt;YOUR_AZURE_CONTAINER&amp;gt;&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Bien sur rien ne vous interdit, et c’est même conseillé, de joindre plusieurs moyens de sauvegarde. Cela permet notamment de s’assurer une plus grande fiabilité du système de sauvegarde, en s’assurant qu’elles sont disponibles à plusieurs endroits.&lt;br /&gt;&#xA;Une fois que vous avez décidé d’où vous allez stocker vos sauvegardes, et que vous l’avez configuré, il faut maintenant décider des différents paramètres de ces sauvegardes : la programmation, la rétention…&lt;/p&gt;&#xA;&lt;h5&gt;5) La programmation des sauvegardes :&lt;/h5&gt;&#xA;&lt;p&gt;Il faut savoir que par défaut, PGO sauvegarde automatiquement les WAL dans la méthode de sauvegarde que vous lui avez configuré. C’est donc une forme de sauvegarde en soit.&lt;br /&gt;&#xA;Mais dans le cadre d’une récupération après incident majeur, il peut aussi être utilise d’avoir des sauvegardes full programmées. Pgbackrest, qui est l’outil utilisé par PGO permet de mettre en place trois types de sauvegarde : les incrémentales, les différentielles et les fulls.&lt;br /&gt;&#xA;Chaque type de sauvegarde peut être programmée en suivant une notation identique à celle des crontab. Par exemple :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        schedules:&#xD;&#xA;          full: &amp;quot;0 1 * * 0&amp;quot;&#xD;&#xA;          differential: &amp;quot;0 1 * * 1-6&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Le fait d’implémenter ces planifications créera des CronJobs dans Kubernetes.&lt;/p&gt;&#xA;&lt;h5&gt;6) La rétention des backups :&lt;/h5&gt;&#xA;&lt;p&gt;Vous pouvez définir une rétention maximum pour vos backups sur le support de backup de votre choix. Une fois que cette rétention sera atteinte, pgbackrest fera le ménage tout seul des sauvegardes et des WAL qui lui sont reliées.&lt;br /&gt;&#xA;Il y a deux types de rétentions que l’on peut définir : les rétentions « count » basées sur le nombre de backup que l’on souhaite garder et les rétentions « time » basées sur le nombre de jours ou vous souhaitez garder votre sauvegarde.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      global:&#xD;&#xA;        repo1-retention-full: &amp;quot;14&amp;quot;&#xD;&#xA;        repo1-retention-full-type: time&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h5&gt;7) La sauvegarde unique :&lt;/h5&gt;&#xA;&lt;p&gt;Si dans le cadre d’un besoin particuliers, une grosse modification ou une migration par exemple, vous avez besoin de prendre une sauvegarde immédiate sans forcément attendre que le cron n’arrive, vous pouvez le faire.&lt;br /&gt;&#xA;Pour la configuration de cette sauvegarde, il faudra l’annoter comme « manuelle » :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      manual:&#xD;&#xA;        repoName: repo1&#xD;&#xA;        options:&#xD;&#xA;         - --type=full&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il vous faudra ensuite déclencher cette sauvegarde avec une commande manuelle. Dans le cadre de notre cluster exemple pgcluster1 :&lt;br /&gt;&#xA;kubectl annotate -n postgres-operator postgrescluster pgcluster1 \ postgres-operator.crunchydata.com/pgbackrest-backup=&amp;#8221;$(date)&amp;#8221;&lt;/p&gt;&#xA;&lt;h5&gt;8) Faire un clone à partir d’un repo :&lt;/h5&gt;&#xA;&lt;p&gt;Quand on a configuré un repo sur notre instance primaire, on peut facilement créer un clone de notre instance à l’aide de notre sauvegarde. Ainsi, on créer un tout nouveau Pods à partir des informations stockées à propos du pod que l’on possède déjà. Ici, nous allons créer un nouveau pod à partir de notre pod pgcluster1 :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;apiVersion: postgres-operator.crunchydata.com/v1beta1&#xD;&#xA;kind: PostgresCluster&#xD;&#xA;metadata:&#xD;&#xA;  name: pgcluster2&#xD;&#xA;spec:&#xD;&#xA;  dataSource:&#xD;&#xA;    postgresCluster:&#xD;&#xA;      clusterName: pgcluster1&#xD;&#xA;      repoName: repo1&#xD;&#xA;  image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres:ubi8-16.2-0&#xD;&#xA;  postgresVersion: 16&#xD;&#xA;  instances:&#xD;&#xA;    - dataVolumeClaimSpec:&#xD;&#xA;        accessModes:&#xD;&#xA;        - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;        resources:&#xD;&#xA;          requests:&#xD;&#xA;            storage: 1Gi&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        volume:&#xD;&#xA;          volumeClaimSpec:&#xD;&#xA;            accessModes:&#xD;&#xA;            - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;            resources:&#xD;&#xA;              requests:&#xD;&#xA;                storage: 1Gi&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Ici on peut noter entre autres la partie spec de la configuration, qui est le morceau de yaml nous permettant de dire qu’on s’appuie sur le cluster existant pour créer un clone indépendant :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;spec:&#xD;&#xA;  dataSource:&#xD;&#xA;    postgresCluster:&#xD;&#xA;      clusterName: pgcluster1&#xD;&#xA;      repoName: repo1&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h5&gt;9) Point in Time Recovery :&lt;/h5&gt;&#xA;&lt;p&gt;De la même façon, si l’on veut faire une restauration PITR, nous allons remplir la balise spec de notre yaml. Attention cependant, pour faire une restauration PITR, nous avons besoin de posséder encore la sauvegarde. On ne peut pas faire une restauration PITR sur une sauvegarde lointaine qu’on ne possèderait plus. Imaginons que je souhaite repartir d’une sauvegarde datant d’hier soir à 20h30 de mon instance pgcluster1 sur mon instance pgcluster2, la configuration serait la suivante :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;apiVersion: postgres-operator.crunchydata.com/v1beta1&#xD;&#xA;kind: PostgresCluster&#xD;&#xA;metadata:&#xD;&#xA;  name: pgcluster2&#xD;&#xA;spec:&#xD;&#xA;  dataSource:&#xD;&#xA;    postgresCluster:&#xD;&#xA;      clusterName: pgcluster1&#xD;&#xA;      repoName: repo1&#xD;&#xA;      options:&#xD;&#xA;      - --type=time&#xD;&#xA;      - --target=&amp;quot;2024-04-09 20:30:00-00&amp;quot;&#xD;&#xA;  image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres:ubi8-16.2-0&#xD;&#xA;  postgresVersion: 16&#xD;&#xA;  instances:&#xD;&#xA;    - dataVolumeClaimSpec:&#xD;&#xA;        accessModes:&#xD;&#xA;        - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;        resources:&#xD;&#xA;          requests:&#xD;&#xA;            storage: 1Gi&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.49-0&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        volume:&#xD;&#xA;          volumeClaimSpec:&#xD;&#xA;            accessModes:&#xD;&#xA;            - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;            resources:&#xD;&#xA;              requests:&#xD;&#xA;                storage: 1Gi&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;La partie qui nous intéresse ici est la partie spec, ou nous avons rajouter un type de restauration (ici time) et une heure target. Cela indique à pgbackrest qu’il doit aller chercher tous les fichiers de sauvegarde et WAL sur notre point de sauvegarde repo1 venant de l’instance pgcluster1 pour les réappliquer sur notre nouveau cluster pgcluster2.&lt;br /&gt;&#xA;Vous pouvez également vouloir réaliser une restauration In Place, c’est-à-dire écraser l’instance présente pour la remplacer par la restauration. Auquel cas, plutôt que de préciser comment s’appellera notre nouveau cluster, il faut alors passer par la balise restore :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;spec:&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      restore:&#xD;&#xA;        enabled: true&#xD;&#xA;        repoName: repo1&#xD;&#xA;        options:&#xD;&#xA;        - --type=time&#xD;&#xA;        - --target=&amp;quot;2024-04-09 20:30:00-00&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Ici, comme précédemment, nous restaurons à l’heure de 20 :30 hier soir, et cela sur notre propre instance. Ne reste plus qu’à lancer la restauration :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;kubectl annotate -n postgres-operator postgrescluster pgcluster1 --overwrite \ postgres-operator.crunchydata.com/pgbackrest-restore=&amp;quot;$(date)&amp;quot;&lt;/pre&gt;&#xA;&lt;p&gt;A noter qu’il ne faut pas oublier de désactiver ensuite le restore en le passant à false si vous ne souhaitez pas qu’il soit de nouveau écrasé au prochain changement de configuration.&lt;/p&gt;&#xA;&lt;h5&gt;10) Restaurer une base de données spécifique :&lt;/h5&gt;&#xA;&lt;p&gt;Si votre besoin est de restaurer une base de données spécifique plutôt que l’intégralité de l’instance, vous pouvez le préciser dans les paramètres de votre restauration.&lt;br /&gt;&#xA;Attention cependant, ce n’est pas une restauration comme le serais un pg_dump. Ici si vous restaurez simplement une seule base de données et pas le reste du cluster, les autres bases que vous n’avez pas choisit de restaurer deviendront inaccessibles.&lt;br /&gt;&#xA;Si nous voulons restaurer une base de données, et uniquement elle, voici la procédure :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;spec:&#xD;&#xA;backups:&#xD;&#xA;  pgbackrest:&#xD;&#xA;    restore:&#xD;&#xA;      enabled: true&#xD;&#xA;      repoName: repo1&#xD;&#xA;      options:&#xD;&#xA;        - --db-include=capdata&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Ici, on ne restaurera que la base de données capdata, et aucunes autres bases à partir de notre repo1.&lt;/p&gt;&#xA;&lt;h3&gt;PgBouncer :&lt;/h3&gt;&#xA;&lt;h4&gt;Utilité :&lt;/h4&gt;&#xA;&lt;p&gt;PgBouncer est un pooler de connexion pour PostgreSQL. Un pooler de connexion permet de maintenir ouvertes des sessions entre lui-même et le serveur, ce qui rend plus rapide l&amp;#8217;ouverture de sessions depuis les clients, une application Web par exemple.&lt;br /&gt;&#xA;PgBouncer permet aussi de mutualiser les sessions dans le serveur, économisant ainsi des ressources. PgBouncer propose plusieurs modes de partage : par requête (default), par transaction ou par session.&lt;/p&gt;&#xA;&lt;h4&gt;Mise en place :&lt;/h4&gt;&#xA;&lt;p&gt;Pour ajouter un bouncer à notre configuration c’est une réalité très simple. Il suffit d’ajouter dans notre fichier postgres.yaml la rubrique proxy :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;proxy:&#xD;&#xA;  pgBouncer:&#xD;&#xA;    image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbouncer:ubi8-1.21-3&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Une fois que vous avez rajouté cela dans la configuration, il n’y a plus qu’à appliquer celle-ci :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; kubectl apply -k kustomize/keycloak &lt;/pre&gt;&#xA;&lt;p&gt;Quand PGO créé un nouveau connexion pooler sur notre instance déployée, il modifier le fichier secrets de l’utilisateur.&lt;br /&gt;&#xA;On voit que plusieurs champs qui concerne pg_bouncer sont apparus. Ils constituent les informations qui vont vous permettre de vous connecter sur votre bouncer nouvellement créé :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;{&#xD;&#xA;    &amp;quot;apiVersion&amp;quot;: &amp;quot;v1&amp;quot;,&#xD;&#xA;    &amp;quot;data&amp;quot;: {&#xD;&#xA;        &amp;quot;dbname&amp;quot;: &amp;quot;cGdjbHVzdGVyMQ==&amp;quot;,&#xD;&#xA;        &amp;quot;host&amp;quot;: &amp;quot;cGdjbHVzdGVyMS1wcmltYXJ5LnBvc3RncmVzLW9wZXJhdG9yLnN2Yw==&amp;quot;,&#xD;&#xA;        &amp;quot;jdbc-uri&amp;quot;: &amp;quot;amRiYzpwb3N0Z3Jlc3FsOi8vcGdjbHVzdGVyMS1wcmltYXJ5LnBvc3RncmVzLW9wZXJhdG9yLnN2Yzo1NDMyL3BnY2x1c3RlcjE/cGFzc3dvcmQ9NXNSaSUzRCU1QmZZbSUzQ2lSSGslMkElNUIlM0VuWGhqaiU3Q1EmdXNlcj1wZ2NsdXN0ZXIx&amp;quot;,&#xD;&#xA;        &amp;quot;password&amp;quot;: &amp;quot;NXNSaT1bZlltPGlSSGsqWz5uWGhqanxR&amp;quot;,&#xD;&#xA;        &amp;quot;pgbouncer-host&amp;quot;: &amp;quot;cGdjbHVzdGVyMS1wZ2JvdW5jZXIucG9zdGdyZXMtb3BlcmF0b3Iuc3Zj&amp;quot;,&#xD;&#xA;        &amp;quot;pgbouncer-jdbc-uri&amp;quot;: &amp;quot;amRiYzpwb3N0Z3Jlc3FsOi8vcGdjbHVzdGVyMS1wZ2JvdW5jZXIucG9zdGdyZXMtb3BlcmF0b3Iuc3ZjOjU0MzIvcGdjbHVzdGVyMT9wYXNzd29yZD01c1JpJTNEJTVCZlltJTNDaVJIayUyQSU1QiUzRW5YaGpqJTdDUSZwcmVwYXJlVGhyZXNob2xkPTAmdXNlcj1wZ2NsdXN0ZXIx&amp;quot;,&#xD;&#xA;        &amp;quot;pgbouncer-port&amp;quot;: &amp;quot;NTQzMg==&amp;quot;,&#xD;&#xA;        &amp;quot;pgbouncer-uri&amp;quot;: &amp;quot;cG9zdGdyZXNxbDovL3BnY2x1c3RlcjE6NXNSaT0lNUJmWW0lM0NpUkhrJTJBJTVCJTNFblhoamolN0NRQHBnY2x1c3RlcjEtcGdib3VuY2VyLnBvc3RncmVzLW9wZXJhdG9yLnN2Yzo1NDMyL3BnY2x1c3RlcjE=&amp;quot;,&#xD;&#xA;        &amp;quot;port&amp;quot;: &amp;quot;NTQzMg==&amp;quot;,&#xD;&#xA;        &amp;quot;uri&amp;quot;: &amp;quot;cG9zdGdyZXNxbDovL3BnY2x1c3RlcjE6NXNSaT0lNUJmWW0lM0NpUkhrJTJBJTVCJTNFblhoamolN0NRQHBnY2x1c3RlcjEtcHJpbWFyeS5wb3N0Z3Jlcy1vcGVyYXRvci5zdmM6NTQzMi9wZ2NsdXN0ZXIx&amp;quot;,&#xD;&#xA;        &amp;quot;user&amp;quot;: &amp;quot;cGdjbHVzdGVyMQ==&amp;quot;,&#xD;&#xA;        &amp;quot;verifier&amp;quot;: &amp;quot;U0NSQU0tU0hBLTI1NiQ0MDk2OlgyQ3NQRU1FZjh3QkVlc05McDFJTkE9PSRKcDhKakl5Q0o1ZEpFRVhia1ptUERTNE5rR3d0V00rczdrMElsQmx0YkpvPTpEaHg3VzNCOE5vNDRYSHJ1Qm1RdENMQW9jNEtnSUZQa2dIeStUMkVWUUowPQ==&amp;quot;&#xD;&#xA;    },&#xD;&#xA;    &amp;quot;kind&amp;quot;: &amp;quot;Secret&amp;quot;,&#xD;&#xA;    &amp;quot;metadata&amp;quot;: {&#xD;&#xA;        &amp;quot;creationTimestamp&amp;quot;: &amp;quot;2024-04-09T16:37:36Z&amp;quot;,&#xD;&#xA;        &amp;quot;labels&amp;quot;: {&#xD;&#xA;            &amp;quot;postgres-operator.crunchydata.com/cluster&amp;quot;: &amp;quot;pgcluster1&amp;quot;,&#xD;&#xA;            &amp;quot;postgres-operator.crunchydata.com/pguser&amp;quot;: &amp;quot;pgcluster1&amp;quot;,&#xD;&#xA;            &amp;quot;postgres-operator.crunchydata.com/role&amp;quot;: &amp;quot;pguser&amp;quot;&#xD;&#xA;        },&#xD;&#xA;        &amp;quot;name&amp;quot;: &amp;quot;pgcluster1-pguser-pgcluster1&amp;quot;,&#xD;&#xA;        &amp;quot;namespace&amp;quot;: &amp;quot;postgres-operator&amp;quot;,&#xD;&#xA;        &amp;quot;ownerReferences&amp;quot;: [&#xD;&#xA;            {&#xD;&#xA;                &amp;quot;apiVersion&amp;quot;: &amp;quot;postgres-operator.crunchydata.com/v1beta1&amp;quot;,&#xD;&#xA;                &amp;quot;blockOwnerDeletion&amp;quot;: true,&#xD;&#xA;                &amp;quot;controller&amp;quot;: true,&#xD;&#xA;                &amp;quot;kind&amp;quot;: &amp;quot;PostgresCluster&amp;quot;,&#xD;&#xA;                &amp;quot;name&amp;quot;: &amp;quot;pgcluster1&amp;quot;,&#xD;&#xA;                &amp;quot;uid&amp;quot;: &amp;quot;7260b882-116f-4b02-b51a-18d4fe3a8038&amp;quot;&#xD;&#xA;            }&#xD;&#xA;        ],&#xD;&#xA;        &amp;quot;resourceVersion&amp;quot;: &amp;quot;9495&amp;quot;,&#xD;&#xA;        &amp;quot;uid&amp;quot;: &amp;quot;1fbdf1d2-48ea-4a45-b7d6-01248317dbee&amp;quot;&#xD;&#xA;    },&#xD;&#xA;    &amp;quot;type&amp;quot;: &amp;quot;Opaque&amp;quot;&#xD;&#xA;}&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Pour se connecter à notre pgbouncer, il suffit d’utiliser les informations fournies par le fichier de secret à la place de nos infos de connexion habituelles, et cela nous permet d’accéder directement au bouncer et non plus à l’instance elle-même.&lt;/p&gt;&#xA;&lt;p&gt;Cette connexion peut être facilement modifiée en utilisant la documentation de pgbouncer afin de pouvoir configurer à notre guise notre pgbouncer. Un exemple de configuration qu’on pourrais rencontrer serait :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;  proxy:&#xD;&#xA;    pgBouncer:&#xD;&#xA;      image: {{.Values.image.pgBouncer }}&#xD;&#xA;      config:&#xD;&#xA;        global:&#xD;&#xA;          default_pool_size: &amp;quot;100&amp;quot;&#xD;&#xA;          max_client_conn: &amp;quot;10000&amp;quot;&#xD;&#xA;          pool_mode: transaction&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Pour cet exemple on voit qu’on a définit un nombre de client maximum, la taille du pool à 100 et un mode transaction pour notre pool.&lt;/p&gt;&#xA;&lt;h3&gt;PGO et Prometheus&lt;/h3&gt;&#xA;&lt;h4&gt;Utilité :&lt;/h4&gt;&#xA;&lt;p&gt;Prometheus est une trousse à outils de surveillance et d&amp;#8217;alerte des systèmes en open source.&lt;br /&gt;&#xA;Prometheus collecte et stocke ses métriques sous forme de données de séries temporelles, c&amp;#8217;est-à-dire que les informations de métriques sont stockées avec le timestamp auquel elles ont été enregistrées, aux côtés de paires clé-valeur optionnelles appelées labels.&lt;br /&gt;&#xA;&amp;#8211; Un modèle de données multidimensionnel avec des données de séries temporelles identifiées par le nom de la métrique et des paires clé-valeur&lt;br /&gt;&#xA;&amp;#8211; PromQL, un langage de requête flexible pour exploiter cette dimensionnalité&lt;br /&gt;&#xA;&amp;#8211; Aucune dépendance sur le stockage distribué ; les nœuds de serveur individuels sont autonomes&lt;br /&gt;&#xA;&amp;#8211; La collecte de séries temporelles se fait via un modèle de tirage sur HTTP&lt;br /&gt;&#xA;&amp;#8211; La poussée de séries temporelles est prise en charge via une passerelle intermédiaire&lt;br /&gt;&#xA;&amp;#8211; Les cibles sont découvertes via la découverte de service ou la configuration statique&lt;br /&gt;&#xA;&amp;#8211; Prise en charge de plusieurs modes de graphiques et de tableaux de bord&lt;/p&gt;&#xA;&lt;h4&gt;Mise en place :&lt;/h4&gt;&#xA;&lt;p&gt;Pour pouvoir mettre en place une surveillance pour notre cluster, il est plus simple de télécharger et compléter le modèle fournit dans les exemples de pgo.&lt;br /&gt;&#xA;Ainsi, on peut récupérer les exemples à l’aide de git :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;YOUR_GITHUB_UN=&amp;quot;$YOUR_GITHUB_USERNAME&amp;quot;&#xD;&#xA;git clone --depth 1 &amp;quot;git@github.com:${YOUR_GITHUB_UN}/postgres-operator-examples.git&amp;quot;&#xD;&#xA;cd postgres-operator-examples&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Les différentes configurations se trouvent dans le dossier kustomize/monitoring.&lt;br /&gt;&#xA;Pour activer le monitoring de notre instance, il faut ajouter la balise monitoring à notre fichier postgres.yaml :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;monitoring:&#xD;&#xA;  pgmonitor:&#xD;&#xA;    exporter:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres-exporter:ubi8-5.5.1-0&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Une fois notre configuration modifiée, on l’applique afin que PGO détecte les changements et configure tout seul l’exporter pour qu’il puisse se connecter à nos bases de données et récupérer les métriques.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;kubectl apply -k kustomize/postgres&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il faut ensuite appliquer la configuration de base de pgmonitor pour qu’il créé lui-même les fichiers de configuration pour prometheus (il le fera en même temps pour Grafana et Alertmanager qui sont deux autres outils de surveillance). Pour cela on applique le kustomize présent dans le dossier monitoring :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$kubectl apply -k kustomize\postgres&#xD;&#xA;postgrescluster.postgres-operator.crunchydata.com/pgcluster1 configured&#xD;&#xA;$kubectl apply -k kustomize\monitoring&#xD;&#xA;serviceaccount/alertmanager created&#xD;&#xA;serviceaccount/grafana created&#xD;&#xA;serviceaccount/prometheus created&#xD;&#xA;clusterrole.rbac.authorization.k8s.io/prometheus created&#xD;&#xA;clusterrolebinding.rbac.authorization.k8s.io/prometheus created&#xD;&#xA;configmap/alert-rules-config created&#xD;&#xA;configmap/alertmanager-config created&#xD;&#xA;configmap/crunchy-prometheus created&#xD;&#xA;configmap/grafana-dashboards created&#xD;&#xA;configmap/grafana-datasources created&#xD;&#xA;secret/grafana-admin created&#xD;&#xA;service/crunchy-alertmanager created&#xD;&#xA;service/crunchy-grafana created&#xD;&#xA;service/crunchy-prometheus created&#xD;&#xA;persistentvolumeclaim/alertmanagerdata created&#xD;&#xA;persistentvolumeclaim/grafanadata created&#xD;&#xA;persistentvolumeclaim/prometheusdata created&#xD;&#xA;deployment.apps/crunchy-alertmanager created&#xD;&#xA;deployment.apps/crunchy-grafana created&#xD;&#xA;deployment.apps/crunchy-prometheus created&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Nos services ont été correctement déployés, il ne nous reste plus qu’à utiliser celui qui nous intéresse, ici service/crunchy-prometheus et lui indiquer de commencer à envoyer les informations sur notre prometheus :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$kubectl -n postgres-operator port-forward service/crunchy-prometheus 9090:9090&#xD;&#xA;Forwarding from 127.0.0.1:9090 -&amp;gt; 9090&#xD;&#xA;Forwarding from [::1]:9090 -&amp;gt; 9090&#xD;&#xA;Handling connection for 9090&#xD;&#xA;Handling connection for 9090&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Afin d’accéder à notre service prometheus, il ne nous reste plus qu’à se connecter avec l’adresse de notre machine, sur le port 9090 préalablement ouvert, pour voir apparaitre le dashboard de prometheus :&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image2.jpg&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-medium wp-image-10567&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image2-300x66.jpg&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;66&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2024/05/Image2-300x66.jpg 300w, https://blog.capdata.fr/wp-content/uploads/2024/05/Image2-1024x226.jpg 1024w, https://blog.capdata.fr/wp-content/uploads/2024/05/Image2-768x170.jpg 768w, https://blog.capdata.fr/wp-content/uploads/2024/05/Image2.jpg 1386w&#34; sizes=&#34;auto, (max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3&gt;PGO Client :&lt;/h3&gt;&#xA;&lt;h4&gt;Utilité :&lt;/h4&gt;&#xA;&lt;p&gt;Pour pouvoir gérer plus facilement le cluster créé par PGO, CrunchyData à développé une surcouche à kubectl qui permet de faciliter les commandes que nous pouvons réaliser sur le cluster.&lt;br /&gt;&#xA;Cela permet de ne pas avoir à taper les longues lignes de commandes qui permettent par exemple de démarrer les sauvegardes unitaires.&lt;/p&gt;&#xA;&lt;h4&gt;Mise en place :&lt;/h4&gt;&#xA;&lt;p&gt;Pour pouvoir installer cette surcouche, il faut télécharger la version qui correspond au système d’exploitation à partir du GIT de pgo client :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;# wget https://github.com/CrunchyData/postgres-operator-client/releases/download/v0.4.1/kubectl-pgo-linux-arm64&#xD;&#xA;--2024-04-11 12:07:45--  https://github.com/CrunchyData/postgres-operator-client/releases/download/v0.4.1/kubectl-pgo-linux-arm64&#xD;&#xA;Resolving github.com (github.com)... 140.82.121.4&#xD;&#xA;Connecting to github.com (github.com)|140.82.121.4|:443... connected.&#xD;&#xA;HTTP request sent, awaiting response... 302 Found&#xD;&#xA;Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...&#xD;&#xA;Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.&#xD;&#xA;HTTP request sent, awaiting response... 200 OK&#xD;&#xA;Length: 47895849 (46M) [application/octet-stream]&#xD;&#xA;Saving to: ‘kubectl-pgo-linux-arm64’&#xD;&#xA;&#xD;&#xA;kubectl-pgo-linux-arm64                                     100%[========================================================================================================================================&amp;gt;]  45.68M  --.-KB/s    in 0.1s&#xD;&#xA;&#xD;&#xA;2024-04-11 12:07:45 (373 MB/s) - ‘kubectl-pgo-linux-arm64’ saved [47895849/47895849]&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;On renome le fichier téléchargé en kubectl-pgo et on le déplace dans nos bin pour pouvoir les utiliser :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;# mv kubectl-pgo-linux-arm64 kubectl-pgo&#xD;&#xA;# sudo mv kubectl-pgo /usr/local/bin/kubectl-pgo&#xD;&#xA;# sudo chmod +x /usr/local/bin/kubectl-pgo&#xD;&#xA;Une fois que ces actions sont réalisées, on peut tester le fonctionnement :&#xD;&#xA;# kubectl pgo version&#xD;&#xA;Client Version: v0.4.1&#xD;&#xA;Operator Version: v5.5.1&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Les commandes disponibles avec cette extension sont les suivantes :&lt;br /&gt;&#xA;&amp;#8211; backup : Backup cluster&lt;br /&gt;&#xA;&amp;#8211; create : Create a resource&lt;br /&gt;&#xA;&amp;#8211; delete : Delete a resource&lt;br /&gt;&#xA;&amp;#8211; help : Help about any command&lt;br /&gt;&#xA;&amp;#8211; restore : Restore cluster&lt;br /&gt;&#xA;&amp;#8211; show Show : PostgresCluster details&lt;br /&gt;&#xA;&amp;#8211; start : Start cluster&lt;br /&gt;&#xA;&amp;#8211; stop : Stop cluster&lt;br /&gt;&#xA;&amp;#8211; support : Crunchy Support commands for PGO&lt;br /&gt;&#xA;&amp;#8211; version : PGO client&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pgo-operateurs-kubernetes-pour-postgresql-la-suite/&#34; rel=&#34;bookmark&#34; title=&#34;6 juin 2023&#34;&gt;PGO : opérateurs kubernetes pour PostgreSQL, la suite !&lt;/a&gt; (David Baffaleuf) [ContainerDevopsPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;26 avril 2023&#34;&gt;Kubegres : l&amp;#8217;opérateur Kubernetes clé en main pour PostgreSQL&lt;/a&gt; (David Baffaleuf) [ContainerDevopsPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/&#34; rel=&#34;bookmark&#34; title=&#34;29 mars 2023&#34;&gt;PostgreSQL sur la solution Kubernetes locale Minikube&lt;/a&gt; (Emmanuel RAMI) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-comparatif-entre-barman-et-pgbackrest/&#34; rel=&#34;bookmark&#34; title=&#34;4 février 2020&#34;&gt;PostgreSQL : Comparatif entre Barman et pgBackRest&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/sauvegardes-sql-server-dans-un-azure-blob-storage/&#34; rel=&#34;bookmark&#34; title=&#34;21 août 2018&#34;&gt;Sauvegardes SQL Server dans un Azure Blob Storage&lt;/a&gt; (Capdata team) [AzureSQL Server]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 3.496 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&amp;#038;title=PGO%20%3A%20la%20suite&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PGO%20%3A%20la%20suite&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10562&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pgo-la-suite/&#34;&gt;PGO : la suite&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/pgo-la-suite/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;La gestion efficace des clusters PostgreSQL dans un environnement Kubernetes est un défi complexe auquel sont confrontées de nombreuses entreprises aujourd&amp;#8217;hui. PGO offre une solution déclarative qui automatise la gestion des clusters PostgreSQL, simplifiant ainsi le déploiement, la mise à&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/pgo-la-suite/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pgo-la-suite/&#34;&gt;PGO : la suite&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>pg_recursively_delete : Simplifier les suppressions récursives</title>
    <updated>2024-04-03T13:11:08Z</updated>
    <id>tag:blog.capdata.fr,2024-04-03:/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&amp;#038;title=pg_recursively_delete%20%3A%20Simplifier%20les%20suppressions%20r%C3%A9cursives&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=pg_recursively_delete%20%3A%20Simplifier%20les%20suppressions%20r%C3%A9cursives&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;Si vous avez été amené au fil de votre carrière à manipuler de gros volumes de données contenus dans plusieurs tables possédant des références croisées entre elles, dépendantes d&amp;#8217;autres tables, qui elles-mêmes dépendent d&amp;#8217;autres tables, vous savez à quel point il peut être compliqué de remonter l&amp;#8217;intégralité de l&amp;#8217;arbre de dépendance pour supprimer la moindre ligne. Cela peut être long et fastidieux.&lt;/p&gt;&#xA;&lt;p&gt;Vous ne savez pas vraiment ce que vous supprimez, dans quelles tables, et quels impacts cela peut avoir sur votre base de données. Si les dépendances sont nombreuses, il est d&amp;#8217;autant plus compliqué de tout retracer et d&amp;#8217;être sûr à 100 % de ce que votre DELETE va entraîner.&lt;/p&gt;&#xA;&lt;p&gt;Dans cet article, je vais vous présenter rapidement un petit outil sous la forme d&amp;#8217;une extension que je trouve pratique à utiliser dans ce cas de figure. L&amp;#8217;outil s&amp;#8217;appelle pg_recursively_delete, et il permet de tracer avant d&amp;#8217;exécuter l&amp;#8217;ordre de suppression de votre ligne, et d&amp;#8217;avoir une arborescence des différentes données que vous allez impacter.&lt;/p&gt;&#xA;&lt;h2&gt;Installation d&amp;#8217;un moteur et de l&amp;#8217;extension :&lt;/h2&gt;&#xA;&lt;p&gt;Pour cet article, j&amp;#8217;ai choisi d&amp;#8217;utiliser PostgreSQL en version 16 pour tester si l&amp;#8217;extension fonctionnait toujours.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;root:~#sudo apt update &amp;amp;amp;&amp;amp;amp; sudo apt upgrade&#xD;&#xA;root:~#sudo sh -c &#39;echo &amp;quot;deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main&amp;quot; &amp;amp;gt; /etc/apt/sources.list.d/pgdg.list&#39;&#xD;&#xA;root:~#wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -&#xD;&#xA;root:~#sudo apt -y update&#xD;&#xA;root:~#sudo apt -y install postgresql-16&lt;/pre&gt;&#xA;&lt;p&gt;Notre moteur de base de données est installé, à présent il nous faut télécharger les sources de l&amp;#8217;extension, et l&amp;#8217;installer.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;root:~# git clone https://github.com/trlorenz/PG-recursively_delete.git&#xD;&#xA;Cloning into &#39;PG-recursively_delete&#39;...&#xD;&#xA;remote: Enumerating objects: 155, done.&#xD;&#xA;remote: Counting objects: 100% (95/95), done.&#xD;&#xA;remote: Compressing objects: 100% (62/62), done.&#xD;&#xA;remote: Total 155 (delta 41), reused 74 (delta 29), pack-reused 60&#xD;&#xA;Receiving objects: 100% (155/155), 38.55 KiB | 3.21 MiB/s, done.&#xD;&#xA;Resolving deltas: 100% (70/70), done.&#xD;&#xA;root:~# cd PG-recursively_delete/&#xD;&#xA;root:~/PG-recursively_delete# make&#xD;&#xA;cp sql/recursively_delete.sql sql/recursively_delete--0.1.5.sql&#xD;&#xA;root:~/PG-recursively_delete# sudo make install&#xD;&#xA;/bin/mkdir -p &#39;/usr/share/postgresql/16/extension&#39;&#xD;&#xA;/bin/mkdir -p &#39;/usr/share/postgresql/16/extension&#39;&#xD;&#xA;/bin/mkdir -p &#39;/usr/share/doc/postgresql-doc-16/extension&#39;&#xD;&#xA;/usr/bin/install -c -m 644 .//recursively_delete.control &#39;/usr/share/postgresql/16/extension/&#39;&#xD;&#xA;/usr/bin/install -c -m 644 .//sql/recursively_delete--0.1.5.sql  &#39;/usr/share/postgresql/16/extension/&#39;&#xD;&#xA;/usr/bin/install -c -m 644 .//doc/changelog.md &#39;/usr/share/doc/postgresql-doc-16/extension/&#39;&lt;/pre&gt;&#xA;&lt;h2&gt;Mise en place de l&amp;#8217;environnement&lt;/h2&gt;&#xA;&lt;p&gt;Pour illustrer le fonctionnement de l&amp;#8217;extension, je vais utiliser la base de données de démonstration dvdrental. Nous allons donc la télécharger et la charger dans une toute nouvelle base de données que nous aurons créée sur notre instance fraîchement créée :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; postgres:~$ wget https://www.postgresqltutorial.com/wp-content/uploads/2019/05/dvdrental.zip&#xD;&#xA;--2024-03-11 08:34:54--  https://www.postgresqltutorial.com/wp-content/uploads/2019/05/dvdrental.zip&#xD;&#xA;Resolving www.postgresqltutorial.com (www.postgresqltutorial.com)... 104.21.2.174, 172.67.129.129, 2606:4700:3037::6815:2ae, ...&#xD;&#xA;Connecting to www.postgresqltutorial.com (www.postgresqltutorial.com)|104.21.2.174|:443... connected.&#xD;&#xA;HTTP request sent, awaiting response... 200 OK&#xD;&#xA;Length: 550906 (538K) [application/zip]&#xD;&#xA;Saving to: ‘dvdrental.zip’&#xD;&#xA;&#xD;&#xA;dvdrental.zip                                               100%[========================================================================================================================================&amp;gt;] 537.99K  --.-KB/s    in 0.01s&#xD;&#xA;&#xD;&#xA;2024-03-11 08:34:54 (46.0 MB/s) - ‘dvdrental.zip’ saved [550906/550906]  &lt;/pre&gt;&#xA;&lt;p&gt;Une fois téléchargée, on la dezippe :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;postgres:~$ ls -l&#xD;&#xA;total 544&#xD;&#xA;drwxr-xr-x 3 postgres postgres   4096 Mar 11 08:30 16&#xD;&#xA;-rw-rw-r-- 1 postgres postgres 550906 May 12  2019 dvdrental.zip&#xD;&#xA;postgres:~$ unzip dvdrental.zip&#xD;&#xA;Archive:  dvdrental.zip&#xD;&#xA;  inflating: dvdrental.tar&#xD;&#xA;postgres:~$ ls -l&#xD;&#xA;total 3316&#xD;&#xA;drwxr-xr-x 3 postgres postgres    4096 Mar 11 08:30 16&#xD;&#xA;-rw-rw-r-- 1 postgres postgres 2835456 May 12  2019 dvdrental.tar&#xD;&#xA;-rw-rw-r-- 1 postgres postgres  550906 May 12  2019 dvdrental.zip&lt;/pre&gt;&#xA;&lt;p&gt;On créé la base de données pour accueillir nos données, et on charge le fichier de sauvegarde :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;postgres:~$ psql&#xD;&#xA;psql (16.2 (Ubuntu 16.2-1.pgdg22.04+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help. &lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;postgres=# create database dvdrental;&#xD;&#xA;CREATE DATABASE&#xD;&#xA;postgres=# \l&#xD;&#xA;                                                   List of databases&#xD;&#xA;   Name    |  Owner   | Encoding | Locale Provider | Collate |  Ctype  | ICU Locale | ICU Rules |   Access privileges&#xD;&#xA;-----------+----------+----------+-----------------+---------+---------+------------+-----------+-----------------------&#xD;&#xA; dvdrental | postgres | UTF8     | libc            | C.UTF-8 | C.UTF-8 |            |           |&#xD;&#xA; postgres  | postgres | UTF8     | libc            | C.UTF-8 | C.UTF-8 |            |           |&#xD;&#xA; template0 | postgres | UTF8     | libc            | C.UTF-8 | C.UTF-8 |            |           | =c/postgres          +&#xD;&#xA;           |          |          |                 |         |         |            |           | postgres=CTc/postgres&#xD;&#xA; template1 | postgres | UTF8     | libc            | C.UTF-8 | C.UTF-8 |            |           | =c/postgres          +&#xD;&#xA;           |          |          |                 |         |         |            |           | postgres=CTc/postgres&#xD;&#xA;(4 rows)&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;postgres:~$ pg_restore -U postgres -d dvdrental dvdrental.tar&lt;/pre&gt;&#xA;&lt;p&gt;Une fois que c&amp;#8217;est fait, on peut se connecter pour vérifier que tout a bien été chargé :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;postgres:~$ psql&#xD;&#xA;psql (16.2 (Ubuntu 16.2-1.pgdg22.04+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;postgres=# \c dvdrental&#xD;&#xA;You are now connected to database &amp;quot;dvdrental&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;dvdrental=# \dt&#xD;&#xA;             List of relations&#xD;&#xA; Schema |     Name      | Type  |  Owner&#xD;&#xA;--------+---------------+-------+----------&#xD;&#xA; public | actor         | table | postgres&#xD;&#xA; public | address       | table | postgres&#xD;&#xA; public | category      | table | postgres&#xD;&#xA; public | city          | table | postgres&#xD;&#xA; public | country       | table | postgres&#xD;&#xA; public | customer      | table | postgres&#xD;&#xA; public | film          | table | postgres&#xD;&#xA; public | film_actor    | table | postgres&#xD;&#xA; public | film_category | table | postgres&#xD;&#xA; public | inventory     | table | postgres&#xD;&#xA; public | language      | table | postgres&#xD;&#xA; public | payment       | table | postgres&#xD;&#xA; public | rental        | table | postgres&#xD;&#xA; public | staff         | table | postgres&#xD;&#xA; public | store         | table | postgres&#xD;&#xA;(15 rows)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h2&gt;L&amp;#8217;extension :&lt;/h2&gt;&#xA;&lt;p&gt;Pour tester l&amp;#8217;extension, nous allons essayer de supprimer un client de la liste des clients.&lt;br /&gt;&#xA;Le schéma de la base de données dvdrental est le suivant :&lt;br /&gt;&#xA;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2024/03/dvd-rental-sample-database-diagram.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone wp-image-10507&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2024/03/dvd-rental-sample-database-diagram-238x300.png&#34; alt=&#34;&#34; width=&#34;336&#34; height=&#34;424&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2024/03/dvd-rental-sample-database-diagram-238x300.png 238w, https://blog.capdata.fr/wp-content/uploads/2024/03/dvd-rental-sample-database-diagram.png 730w&#34; sizes=&#34;auto, (max-width: 336px) 100vw, 336px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Si l&amp;#8217;on observe attentivement le schéma ci-dessus, en voulant supprimer une donnée de la table customer, cela devrait avoir un impact sur les tables rental et payment qui sont directement liées à la table customer. De plus, ces deux tables sont également liées entre elles, ce qui signifie que supprimer une donnée dans la table rental modifiera nécessairement la table payment.&lt;/p&gt;&#xA;&lt;p&gt;Prenons l&amp;#8217;exemple de la suppression du client numéro 1. Si nous recherchons les dépendances de ce client dans la table rental, nous obtenons 32 lignes associées au customer_id 1 :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt; dvdrental=# select count(*) from rental where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;    32&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Et si nous allons maintenant chercher toutes les occurrences de ce même client dans la table des paiements, nous obtenons :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;dvdrental=# select count(*) from payment where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;    30&#xD;&#xA;(1 row) &lt;/pre&gt;&#xA;&lt;p&gt;À présent, avec l&amp;#8217;extension recursive_delete, nous allons chercher à obtenir le schéma de suppression pour vérifier si les résultats que nous avons trouvés sont corrects :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;dvdrental=# create extension recursively_delete;&#xD;&#xA;CREATE EXTENSION&#xD;&#xA;dvdrental=# \set VERBOSITY terse&#xD;&#xA;dvdrental=# select recursively_delete(&#39;customer&#39;, 1);&#xD;&#xA;INFO:  DAMAGE PREVIEW (recursively_delete v0.1.5)&#xD;&#xA;INFO:&#xD;&#xA;INFO:          1     customer&#xD;&#xA;INFO:         30 r   | payment.[&amp;quot;customer_id&amp;quot;]&#xD;&#xA;INFO:         32 r   | rental.[&amp;quot;customer_id&amp;quot;]&#xD;&#xA;INFO:          ~ n   | | payment.[&amp;quot;rental_id&amp;quot;]&#xD;&#xA;INFO:&#xD;&#xA; recursively_delete&#xD;&#xA;--------------------&#xD;&#xA;                  0&#xD;&#xA;(1 row) &lt;/pre&gt;&#xA;&lt;p&gt;La fonction de suppression de l&amp;#8217;extension fonctionne avec les paramètres suivants :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Le nom de la table en premier paramètre&lt;/li&gt;&#xA;&lt;li&gt;La clause WHERE du DELETE en second paramètre, qui peut être de multiples types (des entiers, des chaînes de caractères, des listes, des UUID&amp;#8230;)&lt;/li&gt;&#xA;&lt;li&gt;Le mode de fonctionnement de l&amp;#8217;extension, par défaut à false, qui indique au programme de ne pas effectuer les suppressions, mais simplement de dresser le schéma. Le passer à true entraînerait les suppressions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Pour interpréter le schéma, voici la composition de chaque nœud :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;La première colonne correspond au nombre de lignes&lt;/li&gt;&#xA;&lt;li&gt;Le type de contraintes qui expliquent l&amp;#8217;implication de la table dans le schéma : &amp;#8216;a&amp;#8217;, &amp;#8216;r&amp;#8217;, &amp;#8216;c&amp;#8217;, &amp;#8216;n&amp;#8217;, ou &amp;#8216;d&amp;#8217; (&amp;#8216;no action&amp;#8217;, &amp;#8216;restrict&amp;#8217;, &amp;#8216;cascade&amp;#8217;, &amp;#8216;set null&amp;#8217;, ou &amp;#8216;set default&amp;#8217;)&lt;/li&gt;&#xA;&lt;li&gt;Un indicateur de si oui ou non le champ en question participe à une référence circulaire.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;En examinant le résultat renvoyé par notre extension, nous constatons que nous obtenons les mêmes résultats : 30 lignes pour payment et 32 lignes pour rental. Nous obtenons également une dernière ligne qui nous indique que payment possède une référence à rental dans sa structure, et qu&amp;#8217;il va lui aussi procéder à des suppressions en fonction du rental_id. Cela pourrait être par exemple le cas où une location effectuée par un client serait payée par un autre.&lt;/p&gt;&#xA;&lt;p&gt;Pour effectuer la suppression, il suffit simplement de préciser true en troisième paramètre.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;dvdrental=# select recursively_delete(&#39;customer&#39;, 1, true);&#xD;&#xA; recursively_delete&#xD;&#xA;--------------------&#xD;&#xA;                  1&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Et à présent, si nous consultons notre table customer, la ligne 1 a disparu, ainsi que toutes les lignes qui la concernent dans d&amp;#8217;autres tables également.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;dvdrental=# select count(*) from customer where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;     0&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA;dvdrental=# select count(*) from rental where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;     0&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA;dvdrental=# select count(*) from payment where customer_id = 1;&#xD;&#xA; count&#xD;&#xA;-------&#xD;&#xA;     0&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Nos lignes ont bel et bien disparu.&lt;/p&gt;&#xA;&lt;p&gt;Cette extension fonctionne également avec les clés primaires composites. Il suffit de préciser entre crochets les deux valeurs de notre clé primaire, et le tour est joué.&lt;/p&gt;&#xA;&lt;p&gt;Pour illustrer davantage le fonctionnement, je vais réaliser une suppression sur la table film. Cette table possède quelques dépendances.&lt;br /&gt;&#xA;Disons que nous souhaitons supprimer les 10 premiers films de notre liste, car ils ne sont plus loués étant trop anciens (plus personne n&amp;#8217;a de magnétoscope pour regarder de bonnes vieilles cassettes !).&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;dvdrental=# select recursively_delete(&#39;film&#39;, (SELECT array_agg(film_id) FROM film  WHERE film_id between 1 and 10));&#xD;&#xA;INFO:  DAMAGE PREVIEW (recursively_delete v0.1.5)&#xD;&#xA;INFO:&#xD;&#xA;INFO:         10     film&#xD;&#xA;INFO:         62 r   | film_actor.[&amp;quot;film_id&amp;quot;]&#xD;&#xA;INFO:         10 r   | film_category.[&amp;quot;film_id&amp;quot;]&#xD;&#xA;INFO:         52 r   | inventory.[&amp;quot;film_id&amp;quot;]&#xD;&#xA;INFO:        165 r   | | rental.[&amp;quot;inventory_id&amp;quot;]&#xD;&#xA;INFO:          ~ n   | | | payment.[&amp;quot;rental_id&amp;quot;]&#xD;&#xA;INFO:&#xD;&#xA; recursively_delete&#xD;&#xA;--------------------&#xD;&#xA;                  0&#xD;&#xA;(1 row)&lt;/pre&gt;&#xA;&lt;p&gt;Nous observons donc que notre suppression de 10 films (dans un array) entraîne la suppression d&amp;#8217;acteurs, de catégories, d&amp;#8217;inventaires, et par extension, de locations et de paiements&lt;/p&gt;&#xA;&lt;h2&gt;Conclusion :&lt;/h2&gt;&#xA;&lt;p&gt;En conclusion, l&amp;#8217;extension pg_recursively_delete offre une solution pratique pour supprimer récursivement des données dans PostgreSQL, simplifiant ainsi les tâches de maintenance et de nettoyage des bases de données. Cependant, malgré ses avantages, cette extension présente certaines limites en termes de performances.&lt;/p&gt;&#xA;&lt;p&gt;L&amp;#8217;une des principales limitations réside dans le fait que la suppression récursive peut entraîner des opérations coûteuses en termes de temps d&amp;#8217;exécution, surtout lorsque les données concernées sont fortement imbriquées ou que la base de données est volumineuse. Les performances peuvent également être affectées lorsque les tables impliquées dans la suppression ont des index complexes ou des contraintes de clés étrangères.&lt;/p&gt;&#xA;&lt;p&gt;De plus, il est crucial de reconnaître les risques associés à la suppression de données ayant de nombreuses dépendances dans une base de données. La suppression inconsidérée de telles données peut entraîner des incohérences dans la base de données, des erreurs d&amp;#8217;intégrité référentielle et même des pertes de données importantes. Il est donc essentiel de procéder avec prudence et de prendre en compte toutes les implications potentielles avant d&amp;#8217;utiliser cette extension.&lt;/p&gt;&#xA;&lt;p&gt;En résumé, bien que l&amp;#8217;extension pg_recursively_delete offre une fonctionnalité utile pour gérer les opérations de suppression récursive dans PostgreSQL, il est essentiel pour les utilisateurs de comprendre ses limites en termes de performances et les risques potentiels associés à la suppression de données avec de nombreuses dépendances. Une utilisation judicieuse et une évaluation minutieuse des scénarios d&amp;#8217;utilisation sont indispensables pour garantir l&amp;#8217;intégrité et la performance de la base de données.&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pg_dirtyread-ou-comment-reparer-facilement-un-delete-sauvage/&#34; rel=&#34;bookmark&#34; title=&#34;27 mars 2024&#34;&gt;pg_dirtyread où comment réparer facilement un delete sauvage&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pyrseas-et-postgresql-comparer-facilement-des-schema-de-base-de-donnees/&#34; rel=&#34;bookmark&#34; title=&#34;3 janvier 2023&#34;&gt;Pyrseas et Postgresql : Comparer facilement des schémas de base de données&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-planifier-une-tache-avec-pg_cron/&#34; rel=&#34;bookmark&#34; title=&#34;24 septembre 2019&#34;&gt;PostgreSQL : planifier une tâche avec pg_cron&lt;/a&gt; (Emmanuel RAMI) [Non classéPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-anonymizer/&#34; rel=&#34;bookmark&#34; title=&#34;7 juillet 2022&#34;&gt;PostgreSQL Anonymizer&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/la-montee-de-version-en-zero-downtime-merci-la-replication/&#34; rel=&#34;bookmark&#34; title=&#34;19 décembre 2024&#34;&gt;La montée de version en zero-downtime : merci la réplication !&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 2.397 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&amp;#038;title=pg_recursively_delete%20%3A%20Simplifier%20les%20suppressions%20r%C3%A9cursives&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=pg_recursively_delete%20%3A%20Simplifier%20les%20suppressions%20r%C3%A9cursives&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10505&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/&#34;&gt;pg_recursively_delete : Simplifier les suppressions récursives&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Si vous avez été amené au fil de votre carrière à manipuler de gros volumes de données contenus dans plusieurs tables possédant des références croisées entre elles, dépendantes d&amp;#8217;autres tables, qui elles-mêmes dépendent d&amp;#8217;autres tables, vous savez à quel point&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pg_recursively_delete-simplifier-les-suppressions-recursives/&#34;&gt;pg_recursively_delete : Simplifier les suppressions récursives&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #120</title>
    <updated>2025-02-21T15:20:00Z</updated>
    <id>tag:sebastien.lardiere.net,2025-02-21:/blog/index.php/post/2025/02/21/PostgreSQL-Hebdo-120</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2025/02/21/PostgreSQL-Hebdo-120" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.octo.com/7-things-a-developer-should-know-about-databases&#34;&gt;7 things a developer should know about databases&lt;/a&gt; : de précieux conseils, à lire attentivement et à faire circuler auprès de vos équipes !&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.dalibo.com//2025/02/10/patchs_parallelisations_2.html&#34;&gt;La suite des patchs sur la parallélisation &lt;/a&gt; : Au-delà du fond, qui est intéressant, c’est le point de vue sur le développement de PostgreSQL est mis en évidence, et cela permet de mieux comprendre cet aspect de la communauté PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.loxodata.com/post/pgwatch3/&#34;&gt;pgwatch3&lt;/a&gt; : quelques explications sur la nouvelle version de l&#39;outil de supervision pgwatch ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.twilio.com/en-us/blog/sqlite-postgresql-complicated&#34;&gt;SQLite or PostgreSQL? It&#39;s Complicated!&lt;/a&gt; : comparatif de performances sur de vraies données !&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-174-168-1512-1417-and-1320-released-3018/&#34;&gt;PostgreSQL 17.4, 16.8, 15.12, 14.17, and 13.20 Released!&lt;/a&gt; et &lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-173-167-1511-1416-and-1319-released-3015/&#34;&gt;PostgreSQL 17.3, 16.7, 15.11, 14.16, and 13.19 Released!&lt;/a&gt; : mettez à jour !&#xA;&lt;ul&gt;&#xA;&lt;li&gt;en français : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-4/&#34;&gt;PostgreSQL 17.4 et autres correctifs&lt;/a&gt; et  &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-3/&#34;&gt;PostgreSQL 17.3 et autres correctifs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/end-of-the-road-for-postgresql-streaming-replication/&#34;&gt;End of the road for PostgreSQL streaming replication?&lt;/a&gt; : pourquoi il est difficile de paralléliser le rejeu de la réplication dans une instance Standby ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.crunchydata.com/blog/enhanced-postgres-release-notes&#34;&gt;Enhanced Postgres Release Notes&lt;/a&gt; : très bonne idée, et gros travail : on trouve maintenant un lien vers le commit pour chacune des entrées des notes de publication ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #119</title>
    <updated>2025-01-31T16:16:00Z</updated>
    <id>tag:sebastien.lardiere.net,2025-01-31:/blog/index.php/post/2025/01/31/PostgreSQL-Hebdo-119</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2025/01/31/PostgreSQL-Hebdo-119" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.depesz.com/2024/12/01/sql-best-practices-dont-compare-count-with-0/&#34;&gt;SQL best practices – don’t compare count(*) with 0&lt;/a&gt; : il n&#39;est pas utile de compter quelque chose alors qu&#39;on juste savoir s&#39;il existe ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://raymondtukpe.com/sql-nulls-are-weird.html&#34;&gt;SQL NULLs are Weird!&lt;/a&gt; : maîtriser cet aspect du SQL n&#39;est pas si évident, et pourtant fondamental ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://notso.boringsql.com/posts/deletes-are-difficult/&#34;&gt;DELETEs are difficult&lt;/a&gt;: tout savoir sur l&#39;opération DELETE ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.pgedge.com/blog/understanding-and-reducing-postgresql-replication-lag&#34;&gt;Understanding and Reducing PostgreSQL Replication Lag&lt;/a&gt; : le retard de réplication peut avoir de nombreux impacts, le mesurer et le maitriser est important ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://thebuild.com/blog/2025/01/28/vacuum-index_cleanup-off-considered-harmful/&#34;&gt;VACUUM (INDEX_CLEANUP OFF) Considered Harmful&lt;/a&gt; : attention aux options de commandes qui pourraient paraître intéressantes au premier abord ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.binwang.me/2024-12-02-PostgreSQL-High-Availability-Solutions-Part-1.html&#34;&gt;Jepsen Test on Patroni: A PostgreSQL High Availability Solution&lt;/a&gt; : test très complet de Patroni ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rodoq.medium.com/are-all-your-update-useful-6b8d548085bf&#34;&gt;Are all your UPDATE useful ?&lt;/a&gt; : Vos UPDATE sont-ils toujours utiles ?&lt;/li&gt;&#xA;&lt;li&gt;Le projet PostgreSQL Ecosystem est maintenant public : &lt;a href=&#34;https://www.loxodata.com/post/pg-ecosystem/&#34; title=&#34;https://www.loxodata.com/post/pg-ecosystem/&#34;&gt;https://www.loxodata.com/post/pg-ec...&lt;/a&gt; et &lt;a href=&#34;https://pg-ecosystem.gitlab.io/pg-ecosystem/&#34; title=&#34;https://pg-ecosystem.gitlab.io/pg-ecosystem/&#34;&gt;https://pg-ecosystem.gitlab.io/pg-e...&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #118</title>
    <updated>2024-11-22T16:09:00Z</updated>
    <id>tag:sebastien.lardiere.net,2024-11-22:/blog/index.php/post/2024/11/22/PostgreSQL-Hebdo-118</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2024/11/22/PostgreSQL-Hebdo-118" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pgversions.com/&#34; title=&#34;https://pgversions.com/&#34;&gt;https://pgversions.com/&lt;/a&gt; : outil permettant de connaitre les différences entre une version mineure et l&#39;état actuel de PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pgpedia.info/blog/index.html&#34; title=&#34;https://pgpedia.info/blog/index.html&#34;&gt;https://pgpedia.info/blog/index.htm...&lt;/a&gt; : blog résumant l&#39;activité de développement de PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rhaas.blogspot.com/2024/11/why-pgdump-is-amazing.html&#34;&gt;Why pg_dump Is Amazing&lt;/a&gt; : oui, pg_dump est un bon outil, très utile, qu&#39;il faut maitriser ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://databaserookies.wordpress.com/2024/11/02/plpgsql-how-conditional-expressions-are-evaluated/&#34;&gt;PL/pgSQL Secrets: How Conditional Expressions Are Parsed and Evaluated Under the Hood.&lt;/a&gt; : ou on comprend qu&#39;un IF est en fait un SELECT ;&lt;/li&gt;&#xA;&lt;li&gt;Publication de PostgreSQL 17.2 : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-2/&#34; title=&#34;https://www.loxodata.com/post/postgresql-17-2/&#34;&gt;https://www.loxodata.com/post/postg...&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.crunchydata.com/blog/a-change-to-relresultinfo-a-near-miss-with-postgres-17-1&#34;&gt;A change to ResultRelInfo - A Near Miss with Postgres 17.1&lt;/a&gt; : retour sur un petit couac&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://challahscript.com/what_i_wish_someone_told_me_about_postgres&#34;&gt;What I Wish Someone Told Me About Postgres&lt;/a&gt; : le plein de bonnes idées à retenir ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stormatics.tech/blogs/scenarios-that-trigger-autovacuum-in-postgresql&#34;&gt;Scenarios That Trigger Autovacuum in PostgreSQL&lt;/a&gt; : article assez complet sur le fonctionnement d&#39;autovacuum.&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #117</title>
    <updated>2024-10-31T16:00:00Z</updated>
    <id>tag:sebastien.lardiere.net,2024-10-31:/blog/index.php/post/2024/31/10/PostgreSQL-Hebdo-117</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2024/31/10/PostgreSQL-Hebdo-117" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rhaas.blogspot.com/2024/10/is-pgdump-backup-tool.html&#34;&gt;Is pg_dump a Backup Tool?&lt;/a&gt; : la sauvegarde, et la restauration des données, et en réalité un processus, et non pas juste un problème d&#39;outil. pg_dump est un outil qui peut faire partie du processus de sauvegarde/restauration, et ça peut-être utile pour BACK UP, c&#39;est-à-dire revenir dans un état normal ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-17-released-2936/&#34;&gt;PostgreSQL 17 Released!&lt;/a&gt; : Publication de PostgreSQL 17.0 ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/whats-so-great-about-postgresql-v17/&#34;&gt;What&#39;s so great about PostgreSQL v17?&lt;/a&gt; : aperçu de quelques fonctionnalités de PostgreSQL 17 ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dev.to/lifen/as-rails-developers-why-we-are-excited-about-postgresql-17-27nj&#34;&gt;As Rails developers, why we are excited about PostgreSQL 17 &lt;/a&gt; : PostgreSQL 17 du point de vue d&#39;un développeur Rails ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://notso.boringsql.com/posts/custom-postgresql-extensions-with-rust/&#34;&gt;Custom PostgreSQL extensions with Rust&lt;/a&gt; : comment faire une extension PostgreSQL en Rust ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://danolivo.substack.com/p/7456653e-9716-4e91-ad09-83737784c665&#34;&gt;PostgreSQL &#39;VALUES -&amp;gt; ANY&#39; transformation&lt;/a&gt; : à propos de l&#39;adaptation du Planner aux requêtes des utilisateurs ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://amitkapila16.blogspot.com/2024/09/online-upgrading-logical-and-physical.html?m=1&#34;&gt;Online Upgrading Logical and Physical Replication Nodes&lt;/a&gt; : à propos de la réplication logique lors d&#39;une mise à jour majeure ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.depesz.com/2024/10/29/new-way-to-search-postgresql-documentation/&#34;&gt;New way to search PostgreSQL documentation&lt;/a&gt; : un prompt simple pour rechercher dans la documentation de PostgreSQL, à mettre dans ses bookmarks ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #116</title>
    <updated>2024-09-09T14:06:00Z</updated>
    <id>tag:sebastien.lardiere.net,2024-09-09:/blog/index.php/post/2024/09/09/PostgreSQL-Hebdo-116</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2024/09/09/PostgreSQL-Hebdo-116" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://begriffs.com/posts/2018-03-20-user-defined-order.html&#34;&gt;User-defined Order in SQL&lt;/a&gt; : Ordonner les informations, c&#39;est souvent adopter un certain point de vue, et cette démarche fait partie de la modélisation des données ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mccue.dev/pages/8-16-24-just-use-postgres&#34;&gt;Just use Postgres&lt;/a&gt; : passage en revue des alternatives à PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/do-you-still-need-pgbadger-youre-using-grafana-alicja-kucharczyk-cgfmf&#34;&gt;Do you still need pgBadger if you’re using Grafana?&lt;/a&gt; : Grafana ne remplace pas complètement un rapport pgBadger, dans lequel on trouve de nombreuses informations utiles à la compréhension du fonctionnement d&#39;une instance PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/not-so-good-idea-pipe-syntax-sql-franck-pachot-dx6he/&#34;&gt;&lt;/a&gt; : De la façon dont le language SQL s&#39;écrit, ou pourquoi on manipule des ensembles et non pas des flux ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cybertec-postgresql/pgwatch&#34; title=&#34;https://github.com/cybertec-postgresql/pgwatch&#34;&gt;https://github.com/cybertec-postgre...&lt;/a&gt; la prochaine version de PgWatch poursuit son développement avec la version 3.0 beta4&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dataegret.com/2024/08/handling_cancellation_request/&#34;&gt;Handling Cancellation Request&lt;/a&gt; : Comment annuler correctement une requête, depuis l&#39;application client, vers un cluster PostgreSQL avec le gestionnaire de connexions PgBouncer ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.shayon.dev/post/2024/225/stop-relying-on-if-not-exists-for-concurrent-index-creation-in-postgresql/&#34;&gt;Stop Relying on IF NOT EXISTS for Concurrent Index Creation in PostgreSQL&lt;/a&gt; : à propos d&#39;index invalide et de création conditionelle ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://anyblockers.com/posts/postgres-as-a-search-engine&#34;&gt;Postgres as a search engine&lt;/a&gt; : Peut-on utiliser PostgreSQL comme moteur de recherche ?&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://okbob.blogspot.com/2024/09/how-to-get-info-about-relations-between.html?m=1&#34;&gt;How to get info about relations between system tables?&lt;/a&gt; : à propos des liens internes du catalogue ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-17-rc1-released-2926/&#34;&gt;PostgreSQL 17 RC1 Released!&lt;/a&gt;  (et en français : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-17-rc1/&#34; title=&#34;https://www.loxodata.com/post/postgresql-17-rc1/&#34;&gt;https://www.loxodata.com/post/postg...&lt;/a&gt;) : la date prévue pour PostgreSQL 17.0 est le 26 septembre !&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/patroni/patroni/blob/master/docs/releases.rst#version-401&#34;&gt;Patroni 4.0&lt;/a&gt; : nouvelle version de l&#39;outil de gestion de la haute disponibilité, avec quelques ruptures de compatibilité ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #115</title>
    <updated>2024-08-09T14:39:00Z</updated>
    <id>tag:sebastien.lardiere.net,2024-08-09:/blog/index.php/post/2024/08/09/PostgreSQL-Hebdo-115</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2024/08/09/PostgreSQL-Hebdo-115" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://swizec.com/blog/why-sql-is-forever/&#34;&gt;Why SQL is Forever&lt;/a&gt; : billet sur la pertinence du SQL et des transactions face aux bases de données « NoSQL », et sur le point de vue de Stonebraker (le créateur de PostgreSQL) à ce sujet ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ubicloud.com/blog/difference-between-running-postgres-for-yourself-and-for-others&#34;&gt;Difference between running Postgres for yourself and for others&lt;/a&gt; : comparaison des modes d&#39;hébergement d&#39;une instance PostgreSQL (du point de vue d&#39;un clouder) ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://proopensource.it/blog/postgresql-connection-poolers&#34;&gt;PostgreSQL Connection Poolers&lt;/a&gt; : court billet sur les gestionnaires de connexions à PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://danolivo.substack.com/p/designing-a-prototype-postgres-plan&#34;&gt;Designing a Prototype: Postgres Plan Freezing&lt;/a&gt; : intéressante démarche à propos de la mise en cache de plan d&#39;exécution de requêtes ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://drew.silcock.dev/blog/how-postgres-stores-data-on-disk/&#34;&gt;How Postgres stores data on disk – this one&#39;s a page turner&lt;/a&gt; : article complet sur la technique de stockage des donnés de PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-164-158-1413-1316-1220-and-17-beta-3-released-2910/&#34;&gt;PostgreSQL 16.4, 15.8, 14.13, 13.16, 12.20, and 17 Beta 3 Released!&lt;/a&gt; (en français : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-16-4/&#34;&gt;PostgreSQL 16.4 et autres correctifs&lt;/a&gt;) : Troisième Bêta pour PostgreSQL 17 ! À vos tests !&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&lt;p&gt;À venir :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Le programme de PgConf Europe 2024, qui a lieu à Athènes, est publié : &lt;a href=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/&#34; title=&#34;https://www.postgresql.eu/events/pgconfeu2024/schedule/&#34;&gt;https://www.postgresql.eu/events/pg...&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>Substituer une variable dans un script SQL</title>
    <updated>2024-11-25T08:00:00Z</updated>
    <id>tag:fljd.in,2024-11-25:/2024/11/25/substituer-une-variable-dans-un-script-sql/</id>
    <link href="https://fljd.in/2024/11/25/substituer-une-variable-dans-un-script-sql/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Il est fréquent de vouloir automatiser une tâche répétitive en la scriptant&#xA;rapidement, puis à force d&amp;rsquo;itérations, de l&amp;rsquo;enrichir, voire de l&amp;rsquo;intégrer dans&#xA;la base de code d&amp;rsquo;un projet. À ce jeu, les outils comme SQL*Plus et psql peuvent&#xA;être de puissants alliés et des interpréteurs aussi pertinents que Bash ou&#xA;Python.&lt;/p&gt;&#xA;&lt;p&gt;Dans le cadre des projets de migration que je mène régulièrement, il m&amp;rsquo;arrive de&#xA;tomber sur ces scripts, en grand nombre. Certains ont la particularité de&#xA;proposer des paramètres d&amp;rsquo;entrée, traités par SQL*Plus avec le mécanisme très&#xA;confortable de substitution de variables. Dans cet article, je partage quelques&#xA;astuces pour convertir certains aspects de ces scripts grâce aux fonctionnalités&#xA;équivalentes que l&amp;rsquo;on retrouve sur l&amp;rsquo;outil psql de PostgreSQL.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Poissons et coquillages</title>
    <updated>2024-10-14T08:30:00Z</updated>
    <id>tag:fljd.in,2024-10-14:/2024/10/14/poissons-et-coquillages/</id>
    <link href="https://fljd.in/2024/10/14/poissons-et-coquillages/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;En tant que pur produit académique des années 2010, mon langage de script de prédilection a&#xA;toujours été le Bash (&lt;em&gt;Bourne Again Shell&lt;/em&gt;). Non sans ignorer qu&amp;rsquo;il ait pu en exister d&amp;rsquo;autres, je&#xA;ne me suis jamais vraiment tourné vers d&amp;rsquo;autres shells pour automatiser les tâches du quotidien&#xA;dans mon métier de DBA.&lt;/p&gt;&#xA;&lt;p&gt;Et pour cause, j&amp;rsquo;ai administré des centaines de serveurs de distributions très variées et il&#xA;n&amp;rsquo;était pas bien vu d&amp;rsquo;installer des dépendances systèmes lourdes pour enrichir des scripts Python&#xA;ou Perl. Nous apprenions donc à écrire des scripts portables et universels, compatibles partout&#xA;où nous déposions nos valises.&lt;/p&gt;&#xA;&lt;p&gt;Me suis-je enfermé dans un dogme conservateur, en m&amp;rsquo;interdisant &lt;em&gt;de facto&lt;/em&gt; à me tourner vers des&#xA;shells modernes et bien plus aisés à appréhender ?&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Les types hiérarchiques</title>
    <updated>2024-09-19T11:20:00Z</updated>
    <id>tag:fljd.in,2024-09-19:/2024/09/19/les-types-hierarchiques/</id>
    <link href="https://fljd.in/2024/09/19/les-types-hierarchiques/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bien que la norme SQL définisse un ensemble de règles pour que les systèmes de bases&#xA;de données puissent être interchangeables, il existe de petites singularités dans la&#xA;nature. À ce titre, le type de données &lt;code&gt;hierarchyid&lt;/code&gt; fourni par SQL Server est un&#xA;exemple flagrant. Si vous êtes amené à basculer vers PostgreSQL, deux solutions s&amp;rsquo;offrent&#xA;à vous.&lt;/p&gt;&#xA;&lt;p&gt;Une première et plus simple consiste à lier chaque nœud à son parent à l&amp;rsquo;aide d&amp;rsquo;une nouvelle&#xA;colonne &lt;code&gt;parentid&lt;/code&gt; et d&amp;rsquo;y appliquer une contrainte de clé étrangère. Une autre approche,&#xA;plus complète, consiste à utiliser l&amp;rsquo;extension &lt;code&gt;ltree&lt;/code&gt;. Cet article traite de ce dernier&#xA;cas.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Faire vivre une communauté</title>
    <updated>2024-07-30T09:30:00Z</updated>
    <id>tag:fljd.in,2024-07-30:/2024/07/30/faire-vivre-une-communaute/</id>
    <link href="https://fljd.in/2024/07/30/faire-vivre-une-communaute/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le &lt;a href=&#34;https://pgday.fr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PG Day France&lt;/a&gt; s&amp;rsquo;est tenu les 11 et 12 juin derniers à Lille, ma ville natale.&#xA;Il s&amp;rsquo;agit de l&amp;rsquo;événement de la communauté française de PostgreSQL qui pose ses valises dans une&#xA;ville différente chaque année. L&amp;rsquo;occasion était trop belle pour moi et j&amp;rsquo;y ai rencontré de nombreuses&#xA;personnes venant de toute la France et de ses alentours, pour discuter de PostgreSQL au cours&#xA;de deux jours d&amp;rsquo;ateliers et de conférences.&lt;/p&gt;&#xA;&lt;p&gt;Pour cette édition, j&amp;rsquo;ai eu le plaisir de prendre la parole et de faire un retour d&amp;rsquo;expérience&#xA;sur l&amp;rsquo;animation du groupe Meetup local dont j&amp;rsquo;ai repris les rennes il y a maintenant quatre ans.&#xA;Dans cet article, je souhaite retranscrire les principaux points abordés lors de cette présentation,&#xA;en attendant que la vidéo de la conférence soit mise en ligne.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Un assistant pour copier les données distantes</title>
    <updated>2024-05-28T00:00:00Z</updated>
    <id>tag:fljd.in,2024-05-28:/2024/05/28/un-assistant-pour-copier-les-donnees-distantes/</id>
    <link href="https://fljd.in/2024/05/28/un-assistant-pour-copier-les-donnees-distantes/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lors de la dernière &lt;a href=&#34;https://blog.dalibo.com/2023/12/08/pgsession16_programme.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PGSession 16&lt;/a&gt;, j&amp;rsquo;ai rédigé et animé un &lt;a href=&#34;https://dali.bo/wsfdw_html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;atelier&lt;/a&gt; de&#xA;trois heures au sujet de la migration vers PostgreSQL à l&amp;rsquo;aide des Foreign Data&#xA;Wrappers, ou FDW. Ce fut notamment l&amp;rsquo;occasion de présenter au grand public,&#xA;l&amp;rsquo;extension &lt;a href=&#34;https://github.com/cybertec-postgresql/db_migrator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;db_migrator&lt;/code&gt;&lt;/a&gt; pour laquelle j&amp;rsquo;ai dédié un &lt;a href=&#34;https://fljd.in/2023/07/28/en-route-vers-la-liberte-avec-db_migrator/&#34;&gt;article&lt;/a&gt; sur ce&#xA;blog.&lt;/p&gt;&#xA;&lt;p&gt;Au cours de cet atelier, nous pouvons constater que la copie des données avec&#xA;l&amp;rsquo;extension &lt;code&gt;db_migrator&lt;/code&gt; n&amp;rsquo;est pas parfaitement prise en charge. En effet, bien&#xA;qu&amp;rsquo;il existe une fonction de bas niveau pour répartir sur plusieurs processus le&#xA;transfert table à table, de nombreuses situations devront exiger de rédiger un&#xA;grand nombre de requêtes SQL pour se tirer d&amp;rsquo;affaire. Au cours des mois qui&#xA;suivirent, je me suis attelé à la conception d&amp;rsquo;un &lt;a href=&#34;https://github.com/fljdin/fdw-assistant&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;assistant&lt;/a&gt; écrit en&#xA;PL/pgSQL dont le but est de simplifier la génération de ces requêtes.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>On analyse la nouvelle collation de PostgreSQL 17</title>
    <updated>2024-06-07T11:40:12Z</updated>
    <id>tag:blog-postgresql.verite.pro,2024-06-07:/2024/06/07/pg17-utf8-collation.html</id>
    <link href="https://blog-postgresql.verite.pro/2024/06/07/pg17-utf8-collation.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PostgreSQL 17 est sorti en version bêta le 23 mai dernier, et dans ce billet on&#xA;va détailler une de ses nouveautés: une collation interne gérant l’UTF-8 avec des&#xA;comparaisons de texte en binaire.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Les rapports de bugs de Postgres en 2023</title>
    <updated>2024-01-24T10:23:10Z</updated>
    <id>tag:blog-postgresql.verite.pro,2024-01-24:/2024/01/24/pgsql-bugs-annee-2023.html</id>
    <link href="https://blog-postgresql.verite.pro/2024/01/24/pgsql-bugs-annee-2023.html" rel="alternate"></link>
    <summary type="html">Une revue quantitative des rapports de bugs de Postgres en 2023</summary>
  </entry>
  <entry>
    <title>Classification des caractères avec ICU</title>
    <updated>2023-06-11T14:32:00Z</updated>
    <id>tag:blog-postgresql.verite.pro,2023-06-11:/2023/06/11/caracteres-icu.html</id>
    <link href="https://blog-postgresql.verite.pro/2023/06/11/caracteres-icu.html" rel="alternate"></link>
    <summary type="html">Avec PostgreSQL 16 où ICU devient le fournisseur de collations par défaut, il y a quelques différences sémantiques à anticiper dans la classification des caractères. Cet article en détaille quelques-unes.</summary>
  </entry>
  <entry>
    <title>Isolation Repeatable Read avec PostgreSQL versus MySQL</title>
    <updated>2020-02-10T17:50:00Z</updated>
    <id>tag:blog-postgresql.verite.pro,2020-02-10:/2020/02/10/isolation-postgresql-vs-mysql.html</id>
    <link href="https://blog-postgresql.verite.pro/2020/02/10/isolation-postgresql-vs-mysql.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Les moteurs SQL permettent aux transactions concurrentes d’être&#xA;isolées les unes des autres pour éviter les interférences.&#xA;Cette propriété d’isolation correspond à la lettre I de l’acronyme&#xA;bien connu &lt;a href=&#34;https://fr.wikipedia.org/wiki/Propri%C3%A9t%C3%A9s_ACID&#34;&gt;“ACID”&lt;/a&gt;,&#xA;les autres propriétés étant Atomicité, Cohérence&#xA;(&lt;em&gt;Consistency&lt;/em&gt; en anglais) et Durabilité.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Recherche et remplacement multiple avec plperl</title>
    <updated>2020-01-22T09:05:14Z</updated>
    <id>tag:blog-postgresql.verite.pro,2020-01-22:/2020/01/22/multi-replace.html</id>
    <link href="https://blog-postgresql.verite.pro/2020/01/22/multi-replace.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Remplacer une chaîne par une autre dans une chaîne plus large est simple&#xA;en SQL, avec la fonction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;replace&lt;/code&gt;:&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Les collations non déterministes</title>
    <updated>2019-10-16T16:32:15Z</updated>
    <id>tag:blog-postgresql.verite.pro,2019-10-16:/2019/10/16/collations-non-deterministes.html</id>
    <link href="https://blog-postgresql.verite.pro/2019/10/16/collations-non-deterministes.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Depuis la version 12, les collations de PostgreSQL peuvent être créées&#xA;avec un paramètre nommé &lt;strong&gt;deterministic&lt;/strong&gt;, qui peut être vrai&#xA;ou faux, si bien que les collations  sont maintenant&#xA;soit &lt;strong&gt;déterministes&lt;/strong&gt; (ce qu’elles sont par défaut), soit&#xA;&lt;strong&gt;non déterministes&lt;/strong&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>De retour du pgDay Paris 2024.</title>
    <updated>2024-03-18T09:39:28Z</updated>
    <id>tag:blog.anayrat.info,2024-03-18:/2024/03/18/de-retour-du-pgday-paris-2024./</id>
    <link href="https://blog.anayrat.info/2024/03/18/de-retour-du-pgday-paris-2024./" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Me voilà rentré du pgDay Paris. J’ai beaucoup aimé cette édition. J’étais déjà venu à celle de &lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2019/schedule/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2019&lt;/a&gt; et je dois dire que je n’ai pas été déçu. Pour rappel, le pgDay Paris est une conférence internationale. Les présentations sont en anglais et permettent d’attirer des orateurs et un public plus anglophone.&lt;/p&gt;&#xA;&lt;p&gt;Je vois souvent cette conférence comme un petit &lt;a href=&#34;https://www.postgresql.eu/events/series/pgconfeu-1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PGConf Europe&lt;/a&gt; : on retrouve un contenu assez riche avec la dimension internationale.&lt;/p&gt;&#xA;&lt;p&gt;On croise des têtes déjà connues : public, orateurs, bénévoles, contributeurs : Tout ce petit monde qui fait vivre la communauté Postgres.&lt;/p&gt;&#xA;&lt;p&gt;Puis, c’est l’occasion de mettre des visages sur des noms que l’on croise en lisant des articles ou les mailing-list Postgres.&lt;/p&gt;&#xA;&lt;p&gt;Voici un petit retour sur les conférences auxquelles j’ai assisté :&lt;/p&gt;&#xA;&lt;h1 id=&#34;elephant-in-a-nutshell---navigating-the-postgres-community-101&#34;&gt;Elephant in a nutshell - Navigating the Postgres community 101&lt;/h1&gt;&#xA;&lt;p&gt;Avec &lt;a href=&#34;https://2024.pgday.paris/organization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Carole et Stéphanie&lt;/a&gt;, on a pensé que ce serait bien d’avoir cette conférence en introduction.&lt;/p&gt;&#xA;&lt;p&gt;Je l’ai trouvé très complète. Elle parle de Postgres, mais aussi et surtout de sa communauté. C’est ce qui fait sa force.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2024/sessions/session/5293/slides/481/pgDay%20Paris_Valeria%27s%20talk%20-%20Elephant%20in%20a%20nutshell.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Les slides sont disponibles.&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;sustainable-database-performance-profiling-in-postgresql&#34;&gt;Sustainable Database Performance profiling in PostgreSQL&lt;/h1&gt;&#xA;&lt;p&gt;Postgres dispose de nombreuses vues statistiques apportant des informations sur son fonctionnement.&lt;/p&gt;&#xA;&lt;p&gt;Elles peuvent être natives (&lt;em&gt;pg_stat_statements&lt;/em&gt; …) ou via des extensions &lt;em&gt;pg_stat_kcache&lt;/em&gt;, &lt;em&gt;pg_wait_sampling&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Cependant, et c’est ce que souligne cette conférence, elles apportent une vue à un instant T.&lt;/p&gt;&#xA;&lt;p&gt;Pour les exploiter, il faut les historiser. L’orateur présente un outil basé sur ce qui se fait sur Oracle : &lt;a href=&#34;https://github.com/zubkov-andrei/pg_profile&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pg_profile&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;En revanche, il le présente comme l’unique outil permettant d’exploiter ces informations. Une personne dans le public lui a fait remarquer qu’il existait un autre projet : &lt;a href=&#34;https://powa.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PoWA&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Les deux outils ne fournissent pas les mêmes fonctions, &lt;em&gt;pg_profile&lt;/em&gt; génère un rapport HTML. Il est plutôt facile à installer, il ne nécessite pas de librairies externe car il est écrit en pl/pgsql.&lt;/p&gt;&#xA;&lt;p&gt;PoWA apporte des graphes, de la suggestion d’index… mais est plus lourd à installer.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2024/sessions/session/5067/slides/482/20240314_dkrautschick_PGdayParis_SustainableDatabasePerformanceProfilingInPostgreSQL.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Les slides sont disponibles&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;postgresql-without-permanent-local-data-storage&#34;&gt;PostgreSQL without permanent local data storage&lt;/h1&gt;&#xA;&lt;p&gt;Là, on rentre dans une conférence très technique. Matthias travaille sur le projet &lt;a href=&#34;https://neon.tech/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neon&lt;/a&gt; et il participe régulièrement sur les &lt;a href=&#34;https://www.postgresql.org/list/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mailing-list Postgres&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Neon est un fork opensource de Postgres visant à séparer le &lt;em&gt;compute&lt;/em&gt; et le &lt;em&gt;storage&lt;/em&gt;. C’est ce qu’a fait AWS avec le projet Aurora.&lt;/p&gt;&#xA;&lt;p&gt;Heikki Linnakangas, un des co-fondateurs de Neon et committer de Postgres a fait plusieurs présentations :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=rES0yzeERns&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neon: Serverless PostgreSQL! (Heikki Linnakangas)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://neon.tech/blog/architecture-decisions-in-neon&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Architecture decisions in Neon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Matthias a présenté les différents problèmes que cela posait de vouloir séparer le stockage du reste du moteur. C’est clairement un projet très ambitieux. Pour le moment, il est difficile de savoir si ce fork perdurera ou non.&lt;/p&gt;&#xA;&lt;p&gt;Cependant, on peut souligner que les personnes travaillant dessus ont une très grande connaissance du moteur. On peut espérer que ça ait des implications positives dans le projet Postgres.&lt;/p&gt;&#xA;&lt;p&gt;Affaire à suivre…&lt;/p&gt;&#xA;&lt;h1 id=&#34;lightning-talks&#34;&gt;Lightning Talks!&lt;/h1&gt;&#xA;&lt;p&gt;Les Lightning Talks sont une bonne occasion de balayer certains sujets un peu plus légers. Ca passe plutôt bien après le repas. C’est assez divertissant. J’ai bien aimé la présentation de Léo Unbekandt sur l’architecture des instances Postgres à Scalingo. Pas de K8S, une architecture simple et éprouvée.&lt;/p&gt;&#xA;&lt;p&gt;J’ai aussi aimé la présentation de Chris Ellis où il fabrique un objet décoratif lumineux avec de l’ESP32 dedans.&lt;/p&gt;&#xA;&lt;h1 id=&#34;multi-tenant-database-the-good-the-bad-the-ugly&#34;&gt;Multi-tenant database: the good, the bad, the ugly.&lt;/h1&gt;&#xA;&lt;p&gt;Après, les Lightning Talks, on retourne dans le vif du sujet avec cette présentation de Pierre Ducroquet.&lt;/p&gt;&#xA;&lt;p&gt;Je connais bien Pierre, la première fois que je l’ai croisé, c’était au pgDay France 2016. Il avait fait une très bonne présentation sur &lt;a href=&#34;https://2016.pgday.fr/programme.html#comprendre-requete-lente&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Comprendre pourquoi une requête est lente, et comment régler le soucis&lt;/a&gt;. Ensuite, ça a été mon collègue de travail pendant quelques années où on a rencontré les problèmes que pouvaient poser les bases de données &lt;em&gt;multi-tenant&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Il présente différentes façons de faire du &lt;em&gt;multi-tenant&lt;/em&gt; avec les contraintes que cela implique. Il donne des chiffres assez impressionnants comme plus de 200 000 tables!&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.pinaraf.info/2024/03/look-ma-i-wrote-a-new-jit-compiler-for-postgresql/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quelque chose me dit qu’on ne va pas tarder à le revoir&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;beyond-b-trees-looking-at-columnar-storage-and-lsm-trees&#34;&gt;Beyond B-trees looking at Columnar Storage and LSM trees&lt;/h1&gt;&#xA;&lt;p&gt;Une autre conférence assez bas niveau sur le stockage colonne et les LSM Tree.&lt;/p&gt;&#xA;&lt;p&gt;Ce type de stockage peut effectivement faire partie du futur de Postgres. Le moteur commence à être utilisé pour de plus en plus de projets analytiques où on manipule de gros volumes de données.&lt;/p&gt;&#xA;&lt;p&gt;Il faut donc des méthodes de stockage capable d’encaisse des écritures rapides.&lt;/p&gt;&#xA;&lt;h1 id=&#34;postgres-16-highlight-logical-decoding-on-standby&#34;&gt;Postgres 16 highlight: Logical decoding on standby&lt;/h1&gt;&#xA;&lt;p&gt;Une nouveauté assez attendue sur Postgres 16 : La possibilité de faire du décodage logique sur un secondaire.&lt;/p&gt;&#xA;&lt;p&gt;Qui mieux qu’un des auteurs de cette fonctionnalité pour en parler ?&lt;/p&gt;&#xA;&lt;p&gt;Bertrand présente les difficultés pour faire un décodage logique sur un secondaire, et comment elles ont été résolues.&lt;/p&gt;&#xA;&lt;p&gt;Il a aussi fait une démonstration. C’est vraiment impressionnant, car c’est un sujet assez compliqué.&lt;/p&gt;&#xA;&lt;p&gt;Point bonus, il explique aussi une nouveauté de Postres 17 : la synchronisation des slots de réplication.&lt;/p&gt;&#xA;&lt;p&gt;Actuellement, on peut difficilement “raccrocher” une réplication logique en cas de bascule. Il y a un risque de perte de transaction.&lt;/p&gt;&#xA;&lt;p&gt;Postgres 17 devrait permettre de synchroniser un slot de réplication. En cas de bascule, on peut reprendre la réplication.&#xA;On est chanceux, il vient tout juste d’écrire un article sur le sujet : &lt;a href=&#34;https://bdrouvot.github.io/2024/03/16/postgres-17-highlight-logical-replication-slots-synchronization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Postgres 17 highlight: Logical replication slots synchronization&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2024/sessions/session/5122/slides/483/pgdayParis2024.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Les slides sont disponibles&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;closing&#34;&gt;Closing&lt;/h1&gt;&#xA;&lt;p&gt;C’était la dernière conférence de la journée. On a pu se retrouver pour le social event.&lt;/p&gt;&#xA;&lt;p&gt;C’est un moment que j’affectionne particulièrement. Car au-delà des conférences, c’est surtout une occasion d’échanger entre passionnés. De retrouver des connaissances et amis de longue date.&lt;/p&gt;&#xA;&lt;p&gt;J’ai réalisé que j’avais un peu délaissé les conférences, entre le covid, mon passage en freelance etc… A l’avenir, j’essaierai d’être plus présent sur ce genre d’évènement (si je peux prendre le train).&lt;/p&gt;&#xA;&lt;h1 id=&#34;merci&#34;&gt;Merci&lt;/h1&gt;&#xA;&lt;p&gt;J’en profite aussi pour remercier les &lt;a href=&#34;https://2024.pgday.paris/organization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;organisateurs et bénévoles&lt;/a&gt;. On a du mal à réaliser l’investissement que ça demande. Un grand merci à eux pour cet évènement !&lt;/p&gt;&#xA;&lt;p&gt;On se verra sûrement au pgDay 2025 !&lt;/p&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>Recommandations de lectures pour améliorer ses connaissances en base de données et PostgreSQL</title>
    <updated>2024-02-12T08:00:00Z</updated>
    <id>tag:blog.anayrat.info,2024-02-12:/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/</id>
    <link href="https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/" rel="alternate"></link>
    <summary type="html">&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;&#xA;  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table des matières&lt;/summary&gt;&#xA;  &lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#fondamentaux-des-bases-de-données&#34;&gt;Fondamentaux des bases de données&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#the-manga-guide-to-databases&#34;&gt;The Manga Guide to Databases&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#database-design-for-mere-mortals&#34;&gt;Database Design for Mere Mortals&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#sql-antipatterns&#34;&gt;SQL Antipatterns&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#sql-for-smarties&#34;&gt;SQL for Smarties&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#the-art-of-sql&#34;&gt;The Art Of SQL&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#performance&#34;&gt;Performance&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#sql-performance-explained&#34;&gt;SQL Performance Explained&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#indexing-beyond-the-basics&#34;&gt;Indexing Beyond the Basics&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#postgresql&#34;&gt;PostgreSQL&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#practical-sql&#34;&gt;Practical SQL&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#postgresql---architecture-et-notions-avancées&#34;&gt;PostgreSQL - Architecture et notions avancées&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#learn-postgresql&#34;&gt;Learn PostgreSQL&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#postgresql-14-internals&#34;&gt;PostgreSQL 14 Internals&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;/details&gt;&#xA;&lt;p&gt;Je ne vais lister que quelques livres, mais je pourrais en citer pleins d&amp;rsquo;autres &amp;#x1f603; . J&amp;rsquo;espère que ça permettra à plus de développeurs, DBA, DEVOPS, CTO &amp;hellip; de mieux comprendre les bases de données et leurs enjeux.&lt;/p&gt;&#xA;&lt;h1 id=&#34;fondamentaux-des-bases-de-données&#34;&gt;Fondamentaux des bases de données&lt;/h1&gt;&#xA;&lt;h2 id=&#34;the-manga-guide-to-databases&#34;&gt;The Manga Guide to Databases&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-the-manga-guide-to-databases&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;manga&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/manga_hu5aa70ea30ae3275c65d27c3d87d1e70c_108868_79a33cb973abaedb22e66948cdc60d80.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/manga_hu5aa70ea30ae3275c65d27c3d87d1e70c_108868_c3accdb2c9ecf2675e6df1dee150cd9e.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/manga_hu5aa70ea30ae3275c65d27c3d87d1e70c_108868_1200x1200_fit_q75_h2_lanczos_2.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/manga_hu5aa70ea30ae3275c65d27c3d87d1e70c_108868_79a33cb973abaedb22e66948cdc60d80.webp&#34;&#xA;               width=&#34;474&#34;&#xA;               height=&#34;626&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      The Manga Guide to Databases&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Niveau : Débutant&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://nostarch.com/mg_databases.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Manga Guide to Databases&lt;/a&gt; est celui que je recommande dans la plupart de mes rapports d&amp;rsquo;audit.&lt;/p&gt;&#xA;&lt;p&gt;Il est vraiment génial, facile à lire et pour autant, il ne sacrifie pas le fond à la forme.&lt;/p&gt;&#xA;&lt;p&gt;Il couvre un peu tous les aspects importants :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Modélisation&lt;/li&gt;&#xA;&lt;li&gt;Écriture de requêtes simples&lt;/li&gt;&#xA;&lt;li&gt;Grands principes des bases de données : transaction, isolation&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;database-design-for-mere-mortals&#34;&gt;Database Design for Mere Mortals&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-database-design-for-mere-mortals&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;design&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/design_hue35134dfe8ede24af1874bb4631ce208_182026_721347960fb63df78ab2314199294f15.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/design_hue35134dfe8ede24af1874bb4631ce208_182026_2a81b8ec12f19038971875854feca26c.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/design_hue35134dfe8ede24af1874bb4631ce208_182026_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/design_hue35134dfe8ede24af1874bb4631ce208_182026_721347960fb63df78ab2314199294f15.webp&#34;&#xA;               width=&#34;616&#34;&#xA;               height=&#34;760&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      Database Design for Mere Mortals&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Niveau : Intermédiaire&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.informit.com/store/database-design-for-mere-mortals-25th-anniversary-edition-9780136788041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Database Design for Mere Mortals&lt;/a&gt; de &lt;em&gt;Michael J. Hernandez&lt;/em&gt; est, comme son nom l&amp;rsquo;indique, orienté sur la modélisation.&lt;/p&gt;&#xA;&lt;p&gt;C&amp;rsquo;est un gros pavé de plus de 600 pages, mais il ne faut pas se laisser impressionner. Il se lit très bien, c&amp;rsquo;est bien vulgarisé et l&amp;rsquo;auteur a fait attention  à éviter de s&amp;rsquo;embarquer dans la théorie qui peut parfois être indigeste.&lt;/p&gt;&#xA;&lt;p&gt;J&amp;rsquo;ai beaucoup aimé le processus d&amp;rsquo;interviews pour construire le modèle de données, l&amp;rsquo;accent mis sur la documentation du modèle. Il  parle peu des formes normales, c&amp;rsquo;est un parti pris. Cependant, si on suit son processus, le modèle respecte bien les formes normales.&lt;/p&gt;&#xA;&lt;h2 id=&#34;sql-antipatterns&#34;&gt;SQL Antipatterns&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-sql-antipatterns&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;antipatterns&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/antipatterns_hu78d2e974f3c547630262f79e552a0ea6_2096124_c320047c4b1f0cff61ce38e7e7f6d3dc.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/antipatterns_hu78d2e974f3c547630262f79e552a0ea6_2096124_0d0faf00cb44ab3739d2b4e20f0b205e.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/antipatterns_hu78d2e974f3c547630262f79e552a0ea6_2096124_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/antipatterns_hu78d2e974f3c547630262f79e552a0ea6_2096124_c320047c4b1f0cff61ce38e7e7f6d3dc.webp&#34;&#xA;               width=&#34;633&#34;&#xA;               height=&#34;760&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      SQL Antipatterns&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://pragprog.com/titles/bksap1/sql-antipatterns-volume-1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SQL Antipatterns&lt;/a&gt; est un bon livre pour identifier les &lt;em&gt;anti-patterns&lt;/em&gt; et apporte des solutions.&#xA;Je m&amp;rsquo;en sers régulièrement quand j&amp;rsquo;ai besoin d&amp;rsquo;expliquer ce qui ne va pas dans un modèle ou une requête.&lt;/p&gt;&#xA;&lt;h2 id=&#34;sql-for-smarties&#34;&gt;SQL for Smarties&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-sql-for-smarties&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;smarties&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/smarties_hua93406d09d9e5354756184b8dd00daf0_137495_c6c3d9973032c4ac34459909ff559894.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/smarties_hua93406d09d9e5354756184b8dd00daf0_137495_ca4d66cca791addd71955b48a3f29c2c.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/smarties_hua93406d09d9e5354756184b8dd00daf0_137495_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/smarties_hua93406d09d9e5354756184b8dd00daf0_137495_c6c3d9973032c4ac34459909ff559894.webp&#34;&#xA;               width=&#34;616&#34;&#xA;               height=&#34;760&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      SQL for Smarties&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Niveau : Avancé&lt;/p&gt;&#xA;&lt;p&gt;Comment ne pas mentionner les livres de &lt;a href=&#34;https://en.wikipedia.org/wiki/Joe_Celko&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Joe Celko&lt;/a&gt;.&#xA;Il a participé au standard SQL et écrit de &lt;a href=&#34;https://www.oreilly.com/pub/au/1919&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nombreux livres&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.sciencedirect.com/book/9780128007617/joe-celkos-sql-for-smarties&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SQL for Smarties&lt;/a&gt; fait partie&#xA;des références en matière de SQL. La première édition date de 1995&amp;hellip; oui&amp;hellip; presque 30 ans quand j&amp;rsquo;écris ces lignes !&#xA;La cinquième édition date de 2015, malgré ces 10 ans, le contenu est toujours d&amp;rsquo;actualité. On trouve même des ordres assez récents comme &lt;code&gt;LATERAL&lt;/code&gt;, les &lt;em&gt;window functions&lt;/em&gt;, &lt;code&gt;CTE&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;On est aussi sur un gros pavé de plus de 800 pages, le livre est très complet, assez exhaustif. Je dirai réservé à ceux qui veulent vraiment approfondir leurs connaissances en SQL.&lt;/p&gt;&#xA;&lt;p&gt;À noter qu&amp;rsquo;il existe une version en français basé sur la seconde édition qui date de 2000, elle accuse un peu l&amp;rsquo;age : &lt;a href=&#34;https://www.decitre.fr/livres/sql-avance-9782711786367.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SQL Avancé&lt;/a&gt;. On peut le trouver &lt;a href=&#34;https://www.momox-shop.fr/joe-celko-sql-avance-taschenbuch-M02841801411.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;d&amp;rsquo;occasion&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-art-of-sql&#34;&gt;The Art Of SQL&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-the-art-of-sql&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;art&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/art_hu3e5eba633759e8230aa87338f68d1a3b_220155_2bb5db8f1a45e313260bc7467bf92c17.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/art_hu3e5eba633759e8230aa87338f68d1a3b_220155_ad989b301e7ba70987c52db0c9c535e3.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/art_hu3e5eba633759e8230aa87338f68d1a3b_220155_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/art_hu3e5eba633759e8230aa87338f68d1a3b_220155_2bb5db8f1a45e313260bc7467bf92c17.webp&#34;&#xA;               width=&#34;579&#34;&#xA;               height=&#34;760&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      The Art Of SQL&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Niveau : Avancé&lt;/p&gt;&#xA;&lt;p&gt;Avec &lt;a href=&#34;https://www.oreilly.com/library/view/the-art-of/0596008945/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Art of SQL&lt;/a&gt; de &lt;a href=&#34;https://www.oreilly.com/pub/au/2005&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stephane Faroult&lt;/a&gt;, on change de catégorie. Là, on est sur du SQL plus avancé.&#xA;Le livre va être orienté performances, bonnes pratiques. Malgré ses 18 ans, son contenu est toujours d&amp;rsquo;actualité. C&amp;rsquo;est un livre très puissant, il vous faudra du temps pour le lire et assimiler chaque page.&lt;/p&gt;&#xA;&lt;h1 id=&#34;performance&#34;&gt;Performance&lt;/h1&gt;&#xA;&lt;h2 id=&#34;sql-performance-explained&#34;&gt;SQL Performance Explained&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-sql-performance-explained&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;luke&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/luke_hu753ac19229e8013f92d2513650643829_89166_d25868af42f9fe155d70736822260a43.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/luke_hu753ac19229e8013f92d2513650643829_89166_c361959935046d9adedd33681287b70f.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/luke_hu753ac19229e8013f92d2513650643829_89166_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/luke_hu753ac19229e8013f92d2513650643829_89166_d25868af42f9fe155d70736822260a43.webp&#34;&#xA;               width=&#34;480&#34;&#xA;               height=&#34;737&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      SQL Performance Explained&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Niveau : Intermédiaire&lt;/p&gt;&#xA;&lt;p&gt;Impossible de ne pas mentionner l&amp;rsquo;excellent livre de &lt;a href=&#34;https://winand.at/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Markus Winand&lt;/a&gt;, &lt;a href=&#34;https://sql-performance-explained.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SQL Performance Explained&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Comme son titre l&amp;rsquo;indique, on va parler performance, indexation, écriture de requêtes. À noter qu&amp;rsquo;il a également été traduit en plusieurs langues : Allemand, Espagnol, Japonais et Français grâce à Guillaume Lelarge &lt;a href=&#34;https://sql-au-coeur-des-performances.fr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SQL : Au cœur des performances&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Le contenu du livre est également disponible sur son site &lt;a href=&#34;https://use-the-index-luke.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Use the Index, Luke !&lt;/a&gt;. Markus est aussi l&amp;rsquo;auteur d&amp;rsquo;un excellent site sur les fonctionnalités avancés du SQL : &lt;a href=&#34;https://modern-sql.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Modern SQL&lt;/a&gt;. Lors de l&amp;rsquo;émission &lt;a href=&#34;https://youtu.be/mGqqQg-dG-w?si=he4R6eTC_2VckAVA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Modern SQL sur Postgres.FM&lt;/a&gt;, il a annoncé la volonté d&amp;rsquo;en faire un livre. J&amp;rsquo;ai hâte ! Il a aussi fait de nombreuses &lt;a href=&#34;https://winand.at/sql-slides-for-developers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;présentations&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;indexing-beyond-the-basics&#34;&gt;Indexing Beyond the Basics&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-indexing-beyond-the-basics&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;indexing&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/indexing_hu4ec3b1968fb5d81fd5627bea5287bed7_530622_cd04fe528416e6d69ed46ae57835a97e.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/indexing_hu4ec3b1968fb5d81fd5627bea5287bed7_530622_7b7f71022bce674d799dc5af2cfdb5cb.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/indexing_hu4ec3b1968fb5d81fd5627bea5287bed7_530622_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/indexing_hu4ec3b1968fb5d81fd5627bea5287bed7_530622_cd04fe528416e6d69ed46ae57835a97e.webp&#34;&#xA;               width=&#34;668&#34;&#xA;               height=&#34;760&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      Indexing Beyond the Basics&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Niveau : Débutant - Intermédiaire&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://sqlfordevs.com/ebooks/indexing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Indexing Beyond the Basics&lt;/a&gt; est un e-book orienté sur les index. Un point intéressant est qu&amp;rsquo;il mentionne aussi pourquoi le moteur n&amp;rsquo;utilise pas un index.&lt;/p&gt;&#xA;&lt;h1 id=&#34;postgresql&#34;&gt;PostgreSQL&lt;/h1&gt;&#xA;&lt;h2 id=&#34;practical-sql&#34;&gt;Practical SQL&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-practical-sql&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;practical&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/practical_hu01f19f83ea7b9b959997133246dda201_161098_c3df0446f9f62391d13c57dd10ec2e89.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/practical_hu01f19f83ea7b9b959997133246dda201_161098_f2aecb321cb118f7fb40dddd50422be5.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/practical_hu01f19f83ea7b9b959997133246dda201_161098_1200x1200_fit_q75_h2_lanczos_2.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/practical_hu01f19f83ea7b9b959997133246dda201_161098_c3df0446f9f62391d13c57dd10ec2e89.webp&#34;&#xA;               width=&#34;477&#34;&#xA;               height=&#34;630&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      Practical SQL&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Niveau : Débutant - intermédiaire&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://nostarch.com/practical-sql-2nd-edition/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Practical SQL&lt;/a&gt; est un super livre pour quelqu&amp;rsquo;un qui débute sur Postgres. Il parle d&amp;rsquo;un peu de tout, du SQL jusqu&amp;rsquo;aux types avancés. Comment utiliser le SQL pour analyser des données, faire du &lt;em&gt;full text search&lt;/em&gt;, opération d&amp;rsquo;administration&amp;hellip;&lt;/p&gt;&#xA;&lt;h2 id=&#34;postgresql---architecture-et-notions-avancées&#34;&gt;PostgreSQL - Architecture et notions avancées&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-postgresql---architecture-et-notions-avancées&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;architecture&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/architecture_hu4e070f54fbcfe012d689b7262a78d531_408340_8da2fb9ff08beb89b92a47f2af0154cc.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/architecture_hu4e070f54fbcfe012d689b7262a78d531_408340_504568017e4d0ef28b5f0f36871185ec.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/architecture_hu4e070f54fbcfe012d689b7262a78d531_408340_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/architecture_hu4e070f54fbcfe012d689b7262a78d531_408340_8da2fb9ff08beb89b92a47f2af0154cc.webp&#34;&#xA;               width=&#34;559&#34;&#xA;               height=&#34;760&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      PostgreSQL - Architecture et notions avancées&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Niveau : Intermédiaire - avancé&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.d-booker.fr/bases-de-donnees/805-1338-postgresql-architecture-et-notions-avancees-5ed.html#/21-option-consultation_en_ligne&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PostgreSQL - Architecture et notions avancées&lt;/a&gt; par Guillaume Lelarge et Julien Rouhaud est &lt;strong&gt;le&lt;/strong&gt; livre que je recommande pour qui veut comprendre comment fonctionne Postgres. Mon seul regret est qu&amp;rsquo;il ne soit pas traduit en anglais pour en faire profiter plus de lecteurs.&lt;/p&gt;&#xA;&lt;p&gt;À noter aussi qu&amp;rsquo;il est mis à jour tous les ans.&lt;/p&gt;&#xA;&lt;h2 id=&#34;learn-postgresql&#34;&gt;Learn PostgreSQL&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-learn-postgresql&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;learn&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/learn_hu00fe0c0efabc0ae6d85710a22f715230_111765_2e08c564415b06ee6ac817f7ac0914b0.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/learn_hu00fe0c0efabc0ae6d85710a22f715230_111765_c22b1c79c1fe1d43eb51d2ce83b5ee11.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/learn_hu00fe0c0efabc0ae6d85710a22f715230_111765_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/learn_hu00fe0c0efabc0ae6d85710a22f715230_111765_2e08c564415b06ee6ac817f7ac0914b0.webp&#34;&#xA;               width=&#34;616&#34;&#xA;               height=&#34;760&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      Learn PostgreSQL&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.packtpub.com/product/learn-postgresql-second-edition/9781837635641&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learn PostgreSQL&lt;/a&gt; par Lucas Ferrari et Enrico Pirozzi est un livre très complet sur l&amp;rsquo;administration de Postgres. Un &lt;em&gt;must have&lt;/em&gt; pour un DBA.&lt;/p&gt;&#xA;&lt;p&gt;Pour les francophones, vous pouvez vous orienter vers &lt;a href=&#34;https://www.editions-eni.fr/livre/postgresql-administration-et-exploitation-de-vos-bases-de-donnees-4e-edition-9782409011467&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PostgreSQL Administration et exploitation de vos bases de données&lt;/a&gt; de Sébastien Lardière.&lt;/p&gt;&#xA;&lt;h2 id=&#34;postgresql-14-internals&#34;&gt;PostgreSQL 14 Internals&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure  id=&#34;figure-postgresql-14-internals&#34;&gt;&#xA;  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;&#xA;    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;internals&#34; srcset=&#34;&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/internals_hu8a8cf4e0b43f0fa4f74d2b36d2f27852_60433_8639f0d8b0e15fe8fb464f6e5412e100.webp 400w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/internals_hu8a8cf4e0b43f0fa4f74d2b36d2f27852_60433_3d76ec668fd76ab0113449dbb278d740.webp 760w,&#xA;               /2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/internals_hu8a8cf4e0b43f0fa4f74d2b36d2f27852_60433_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;&#xA;               src=&#34;https://blog.anayrat.info/2024/02/12/recommandations-de-lectures-pour-ameliorer-ses-connaissances-en-base-de-donnees-et-postgresql/internals_hu8a8cf4e0b43f0fa4f74d2b36d2f27852_60433_8639f0d8b0e15fe8fb464f6e5412e100.webp&#34;&#xA;               width=&#34;384&#34;&#xA;               height=&#34;552&#34;&#xA;               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&lt;figcaption&gt;&#xA;      PostgreSQL 14 Internals&#xA;    &lt;/figcaption&gt;&lt;/figure&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://postgrespro.com/community/books/internals&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PostgreSQL 14 Internals&lt;/a&gt; par Egor Rogov est un livre sur les entrailles de Postgres. Il est vraiment très complet. Un grand merci à lui de le mettre à disposition en accès libre.&lt;/p&gt;&#xA;&lt;p&gt;Dans le même style, il existe un site &lt;a href=&#34;https://www.interdb.jp/pg/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Internals of PostgreSQL&lt;/a&gt; par Hironobu SUZUKI.&lt;/p&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>Postgres à nouveau élu SGBD de l&#39;année en 2023, mais je suis inquiet</title>
    <updated>2024-02-05T08:00:00Z</updated>
    <id>tag:blog.anayrat.info,2024-02-05:/2024/02/05/postgres-a-nouveau-elu-sgbd-de-lannee-en-2023-mais-je-suis-inquiet/</id>
    <link href="https://blog.anayrat.info/2024/02/05/postgres-a-nouveau-elu-sgbd-de-lannee-en-2023-mais-je-suis-inquiet/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cette année encore, Postgres a été élu SGBD de l&amp;rsquo;année par &lt;a href=&#34;https://db-engines.com/en/blog_post/106&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DB-Engines&lt;/a&gt;. Même si ce n&amp;rsquo;est qu&amp;rsquo;un classement, cela donne une tendance. Cela fait aussi plusieurs années qu&amp;rsquo;il est reconnu selon&#xA;les sondages de Stackoverflow : &lt;a href=&#34;https://survey.stackoverflow.co/2023/#section-most-popular-technologies-databases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Most popular Databases&lt;/a&gt;.&#xA;C&amp;rsquo;est un SGBD très apprécié, tant par les développeurs, que par les DBA chevronnés&amp;hellip; Mais aussi par les directeurs qui y trouvent une stabilité&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Postgres a tout pour séduire :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Année après année, de nouvelles fonctionnalités sont rajoutées. Je pense notamment à : la parallélisation, le partitionnement, la réplication logique&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;Il a su, depuis toujours, garder sa fiabilité.&lt;/li&gt;&#xA;&lt;li&gt;Sa communauté n&amp;rsquo;a fait que grandir. Les conférences dédiées à Postgres battent des records d&amp;rsquo;affluence tous les ans.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;&#xA;&lt;li&gt;C&amp;rsquo;est devenu un standard, même pour les autres logiciels : les éditeurs rajoutent même le support du protocole Postgres pour faciliter leur intégration : Aurora, AlloyDB, QuestDB&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;C&amp;rsquo;est un des rares projets de cette envergure à être communautaire. On a pu voir qu&amp;rsquo;il ne suffit pas que le projet soit opensource, il faut aussi compter sur la communauté et son écosystème.&lt;/li&gt;&#xA;&lt;li&gt;Il est supporté par les gros acteurs : les GAFAM emploient de nombreux committers et contributeurs. Ils sponsorisent également les conférences. Par exemple, le prochain &lt;a href=&#34;https://2024.pgday.paris/sponsors/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pgDay Paris est sponsorisé par Microsoft&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Cependant, je suis un peu inquiet pour le futur. Non pas pour PostgreSQL. Bruce Momjian a fait plusieurs présentations sur ce sujet :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://momjian.us/main/writings/pgsql/challenges.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Future Postgres Challenges&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://momjian.us/main/writings/pgsql/forever.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Will Postgres Live Forever?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://momjian.us/main/writings/pgsql/past_present_future.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PostgreSQL: Past, Present, and Future&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;C&amp;rsquo;est même le sujet de la Keynote d&amp;rsquo;ouverture du dernier PGConf Europe : &lt;a href=&#34;https://www.youtube.com/watch?v=8W-J36IxYv4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simon Riggs: The Next 20 Years (PGConf.EU 2023)&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Non, je suis plutôt inquiet sur la perte de connaissance du métier de DBA.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;A quoi servira Postgres si on ne sait pas l&amp;rsquo;utiliser correctement ?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;&#xA;  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table des matières&lt;/summary&gt;&#xA;  &lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#un-peu-dhistoire&#34;&gt;Un peu d&amp;rsquo;histoire&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#quest-ce-quon-oublie-&#34;&gt;Qu&amp;rsquo;est-ce qu&amp;rsquo;on oublie ?&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#oui-mais-le-cloud&#34;&gt;Oui, mais le cloud!&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#on-oublie-le-métier-de-dba&#34;&gt;On oublie le métier de DBA&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#on-oublie-le-passé&#34;&gt;On oublie le passé&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#le-code-change-la-donnée-reste&#34;&gt;Le code change, la donnée reste&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#il-faut-quelques-minutes-pour-prendre-une-mauvaise-décision-sur-une-base-de-donnée&#34;&gt;Il faut quelques minutes pour prendre une mauvaise décision sur une base de donnée&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#lusage-du-cloud&#34;&gt;L&amp;rsquo;usage du cloud&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#ce-quil-faudrait-changer&#34;&gt;Ce qu&amp;rsquo;il faudrait changer&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#pour-conclure&#34;&gt;Pour conclure&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;/details&gt;&#xA;&lt;h1 id=&#34;un-peu-dhistoire&#34;&gt;Un peu d&amp;rsquo;histoire&lt;/h1&gt;&#xA;&lt;p&gt;Par le passé, il y avait une spécialisation forte des compétences : développeurs, testeurs, DBA étude, DBA prod, ingénieur système, ingénieur stockage, ingénieur sauvegarde&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;Chaque spécialité évoluait un peu dans sa bulle, ce qui compliquait la collaboration avec des cycles de développement longs.&lt;/p&gt;&#xA;&lt;p&gt;Cette organisation a laissé place à une nouvelle façon de travailler : développeurs &lt;em&gt;fullstack&lt;/em&gt;, &lt;em&gt;DEVOPS/SRE&lt;/em&gt;, des data &amp;ldquo;quelque chose&amp;rdquo; (engineer, analyst, steward&amp;hellip;).&lt;/p&gt;&#xA;&lt;p&gt;Les compétences se sont diluées sur les différents métiers. Je croise de plus en plus rarement des DBA.&lt;/p&gt;&#xA;&lt;p&gt;A la place, la base de donnée est &lt;em&gt;gérée&lt;/em&gt; par les développeurs. Ou, si on a un peu de chance, par des &amp;ldquo;data engineer&amp;rdquo; ou &amp;ldquo;data analyst&amp;rdquo;.&lt;/p&gt;&#xA;&lt;p&gt;Après plusieurs années, alors que je baigne dedans, j&amp;rsquo;ai encore du mal à définir ces métiers.&lt;/p&gt;&#xA;&lt;p&gt;Le constat : bonne connaissance du python, monte des pipelines, on assemble en quelque sorte des Legos avec pleins d&amp;rsquo;outils : airflow, dbt&amp;hellip; Puis, on envoie ces données dans du Redshift, Biquery, Snowflake&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;Cependant, j&amp;rsquo;ai l&amp;rsquo;impression que la connaissance du SQL s&amp;rsquo;appauvrit à cause des couches d&amp;rsquo;abstraction.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Du moment où on manipule de la donnée, la première des compétences à avoir, devrait être la maitrise du SQL.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;quest-ce-quon-oublie-&#34;&gt;Qu&amp;rsquo;est-ce qu&amp;rsquo;on oublie ?&lt;/h1&gt;&#xA;&lt;p&gt;J&amp;rsquo;ai le sentiment, qu&amp;rsquo;année après année, on oublie le métier de DBA.&lt;/p&gt;&#xA;&lt;p&gt;Pour rappel, ce dernier va être à la croisée de plusieurs chemins :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Il a des compétences pures sur la base de données :&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Modélisation.&lt;/li&gt;&#xA;&lt;li&gt;Maitrise du SQL.&lt;/li&gt;&#xA;&lt;li&gt;Maitrise du SGBD : connait le fonctionnement du moteur (&lt;em&gt;vacuum&lt;/em&gt;, &lt;em&gt;checkpoint&lt;/em&gt; &amp;hellip;). Comprend les mécanismes de verrouillages (&lt;em&gt;MVCC&lt;/em&gt;, &lt;em&gt;locks&lt;/em&gt;&amp;hellip;).&lt;/li&gt;&#xA;&lt;li&gt;Conserve une veille technique : le Postgres que j&amp;rsquo;ai connu à mes débuts est très loin du Postgres actuel.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Mais également des compétences plus transverses :&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Avoir une bonne connaissance système pour investiguer sur les problèmes de performance, dimensionner les ressources.&lt;/li&gt;&#xA;&lt;li&gt;Un vernis en développement pour comprendre les besoins des développeurs et pouvoir les accompagner.&lt;/li&gt;&#xA;&lt;li&gt;De la culture &amp;ldquo;computer science&amp;rdquo;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;oui-mais-le-cloud&#34;&gt;Oui, mais le cloud!&lt;/h1&gt;&#xA;&lt;p&gt;On pourrait penser que le cloud a rebattu les cartes et qu&amp;rsquo;on n&amp;rsquo;a plus besoin de DBA. Dans la liste que j&amp;rsquo;ai donnée ci-dessus, quelles compétences sont couvertes par le cloud ?&lt;/p&gt;&#xA;&lt;p&gt;Le cloud résout une partie des besoins : hébergement, maintenance, réseau, monitoring (qu&amp;rsquo;il faut souvent compléter avec un APM ou un Datadog like).&#xA;Et il rajoute d&amp;rsquo;autres problèmes :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Il faut rajouter un métier de &lt;a href=&#34;https://lota.cloud/finops-cloud-2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FinOps&lt;/a&gt; pour maitriser et optimiser les dépenses.&lt;/li&gt;&#xA;&lt;li&gt;C&amp;rsquo;est parfois une boite noire et il peut être difficile d&amp;rsquo;investiguer sur des problèmes de performance&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Cet excellent article de Markus Winand présente aussi d&amp;rsquo;autres inconvénients : &lt;a href=&#34;https://winand.at/newsletter/2024-01/clouds-bring-rain&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sometimes Clouds Bring Rain&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Changer de cloud provider est difficile. Je dirais même que c&amp;rsquo;est volontaire de leur part.&lt;/li&gt;&#xA;&lt;li&gt;Les coûts peuvent changer &lt;em&gt;Just because it is cheap today doesn’t mean it will be cheap forever&lt;/em&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Il faut prévoir un plan de sortie : éviter les services propriétaires, conserver un faible nombre de services.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Car une fois dans le cloud, qui s&amp;rsquo;occupe de : la modélisation, l&amp;rsquo;optimisation des requêtes, l&amp;rsquo;indexation, la veille technique sur le SGBD&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;, l&amp;rsquo;investigation sur les performances, comprendre les problèmes de verrouillages, l&amp;rsquo;accompagnement des développeurs ?&lt;/p&gt;&#xA;&lt;p&gt;Ceci est confirmé dans mes audits, je vois régulièrement des problèmes très basiques :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Absence de clé primaire.&lt;/li&gt;&#xA;&lt;li&gt;Pas d&amp;rsquo;index sur des cas très simples.&lt;/li&gt;&#xA;&lt;li&gt;Aucun respect des formes normales, même les plus basiques. Le JSON n&amp;rsquo;a pas arrangé les choses.&lt;/li&gt;&#xA;&lt;li&gt;Requêtes spaghetti.&lt;/li&gt;&#xA;&lt;li&gt;Des jointures façon SQL-89 alors que ça fait plus de 30 ans que le mot clé &lt;code&gt;JOIN&lt;/code&gt; existe.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;S&amp;rsquo;il faut retenir une chose : &lt;strong&gt;Le cloud ne permet pas de s&amp;rsquo;affranchir du DBA. Ce n&amp;rsquo;est pas parce qu&amp;rsquo;on peut obtenir les clés d&amp;rsquo;un avion, qu&amp;rsquo;on sait le piloter.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Un article intéressant sur le nombre de DBA dont vous avez besoin : &lt;a href=&#34;https://www.bytebase.com/blog/how-many-dbas-should-a-company-hire/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How many DBAs should a company hire?&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;on-oublie-le-métier-de-dba&#34;&gt;On oublie le métier de DBA&lt;/h1&gt;&#xA;&lt;p&gt;On pourrait naïvement penser qu&amp;rsquo;on confie ces tâches à des DBA experts, mais j&amp;rsquo;ai de plus en plus de doutes. J&amp;rsquo;ai l&amp;rsquo;impression &amp;ldquo;qu&amp;rsquo;on&amp;rdquo; est en train de perdre la connaissance d&amp;rsquo;un métier.&#xA;J&amp;rsquo;ai déjà croisé des développeurs expérimentés qui ne savaient même pas que le métier de DBA existait.&#xA;Des recruteurs qui me demandaient si en tant que DBA, je savais optimiser des requêtes et si je connaissais le SQL. C&amp;rsquo;est mon métier ! C&amp;rsquo;est un peu comme demander à un plombier s&amp;rsquo;il sait changer un robinet !&lt;/p&gt;&#xA;&lt;p&gt;Ce qui est d&amp;rsquo;autant plus alarmant, c&amp;rsquo;est que je crains qu&amp;rsquo;il y ait aussi des CTO qui ont aussi cette méconnaissance de la donnée.&lt;/p&gt;&#xA;&lt;p&gt;La conséquence est qu&amp;rsquo;en cas de problème de performance, on ne fait qu&amp;rsquo;augmenter les ressources des instances.&#xA;Avec le cloud, la facture croît linéairement avec la taille de l&amp;rsquo;instance.&#xA;Si la croissance de la charge est exponentielle, il faudra scaler la base et la facture qui va avec. On se retrouve avec une facture exponentielle.&lt;/p&gt;&#xA;&lt;p&gt;Quand on n&amp;rsquo;arrive plus à s&amp;rsquo;en sortir, on va accuser l&amp;rsquo;outil ou le modèle, donc on va changer de SGBD ou aller vers du NoSQL. Spoiler : ça ne résoudra pas vos problèmes.&lt;/p&gt;&#xA;&lt;h1 id=&#34;on-oublie-le-passé&#34;&gt;On oublie le passé&lt;/h1&gt;&#xA;&lt;p&gt;Pendant un temps, j&amp;rsquo;ai voulu écrire un livre pour parler optimisation de requête, des erreurs courantes que je rencontre, etc.&lt;/p&gt;&#xA;&lt;p&gt;En regardant ma bibliothèque, elle est pleine de livres de ce genre. Ils ont pour la plupart entre 10 et 30 ans et le contenu est toujours d&amp;rsquo;actualité. A quoi servirait un énième livre s&amp;rsquo;il n&amp;rsquo;est pas connu ?&lt;/p&gt;&#xA;&lt;p&gt;J&amp;rsquo;ai un autre exemple en tête : les data warehouse (DWH). Ce terme devient de plus en plus galvaudé.&#xA;La construction d&amp;rsquo;un DWH est complexe, il faut passer par une phase de modélisation afin de stocker correctement les données. Cela permet de bonnes performances et facilite l&amp;rsquo;écriture&#xA;des requêtes analytiques.&lt;/p&gt;&#xA;&lt;p&gt;Maintenant, je croise régulièrement des &amp;ldquo;data warehouse&amp;rdquo; qui se résument à envoyer toutes les données dans un SGBD spécialisé (redshift, biquery &amp;hellip;). Sans travail de modélisation et avec des requêtes très mal écrites, parfois générées, car les utilisateurs ne savent pas faire du SQL.&lt;/p&gt;&#xA;&lt;p&gt;Ces services coûtent très cher et ne font pas de miracle s&amp;rsquo;il n&amp;rsquo;y a pas eu un travail approfondi de modélisation et d&amp;rsquo;optimisation.&lt;/p&gt;&#xA;&lt;p&gt;Pourtant, les livres sur les DWH et le SQL ont entre 10 et 30 ans. A cette époque, le cloud n&amp;rsquo;existait pas, les SSD non plus, les CPU avec plusieurs coeurs non plus.&#xA;Pourtant, on savait construire des DWH, faire des sites performants&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Il ne faudrait pas que le cloud nous fasse oublier tout cet héritage. Sinon, on risque de payer la dette technique et la perte de connaissance très cher, avec les intérêts en plus.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Il faut avoir en tête que même si le SQL a évolué, les SGBD gagnés en fonctionnalités, &lt;strong&gt;les principes fondateurs sont toujours justes&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;le-code-change-la-donnée-reste&#34;&gt;Le code change, la donnée reste&lt;/h1&gt;&#xA;&lt;p&gt;J&amp;rsquo;ai eu un super manager, ancien DBA, qui expliquait aux développeurs : tu n&amp;rsquo;es pas ici pour &amp;ldquo;produire du code&amp;rdquo; =&amp;gt; yeux écarquillés du développeur.&#xA;&amp;ldquo;tu es là pour produire et manipuler de la donnée.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;Lorsqu&amp;rsquo;il y avait une décision compliquée. Par exemple, prendre plus de temps pour revoir le code applicatif, faire une migration plus compliquée, plutôt qu&amp;rsquo;une solution&#xA;&amp;ldquo;quick win&amp;rdquo;. Ce même manager expliquait :&amp;quot;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;D&amp;rsquo;ici 5-10 ans, ton code aura été réécrit plusieurs fois, peut-être même dans un autre langage.&#xA;Nous, la donnée, dans 50 ans, elle sera toujours là. C&amp;rsquo;est notre devoir de nous assurer qu&amp;rsquo;elle sera toujours exploitable.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h1 id=&#34;il-faut-quelques-minutes-pour-prendre-une-mauvaise-décision-sur-une-base-de-donnée&#34;&gt;Il faut quelques minutes pour prendre une mauvaise décision sur une base de donnée&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;Et parfois plusieurs mois / années pour la corriger.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Il m&amp;rsquo;est arrivé de faire des audits où le modèle était catastrophique. Il avait évolué de solutions à court terme en d&amp;rsquo;autres solutions à court terme.&#xA;&amp;ldquo;On corrigera plus tard, il faut faire passer cette fonctionnalité dans le sprint&amp;rdquo;.&lt;/p&gt;&#xA;&lt;p&gt;Un DBA peut corriger le modèle de données à coup de grosses migrations (encore faut-il avoir un DBA, difficile si on ignore que ce métier existe&amp;hellip;).&#xA;Au-delà de ça, le problème va se poser autour : il faut réécrire une grosse partie du code applicatif (qui est souvent dans le même état que la base).&lt;/p&gt;&#xA;&lt;p&gt;Parfois, la complexité est quadratique ou exponentielle. Il vaut mieux tout jeter pour tout recommencer.&lt;/p&gt;&#xA;&lt;p&gt;On se retrouve face à plusieurs dilemmes :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Augmenter la taille des instances.&lt;/li&gt;&#xA;&lt;li&gt;Parfois, cette solution n&amp;rsquo;est pas suffisante. J&amp;rsquo;explique : &amp;ldquo;là, vous pouvez faire encore fois dix sur la taille de l&amp;rsquo;instance, mais vous ne pourrez jouer cette carte qu&amp;rsquo;une fois&amp;rdquo;. Notez que cette solution est inutile si le traitement ne peut pas être parallélisé.&lt;/li&gt;&#xA;&lt;li&gt;Tout jeter pour tout recommencer. Là aussi, le coût ou la perte peut être démentielle.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Alors qu&amp;rsquo;il aurait suffi des conseils d&amp;rsquo;un DBA à quelques moments de la vie du projet pour éviter de partir dans une mauvaise direction.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;On ne bâtit pas un château sur du sable&lt;/strong&gt;. J&amp;rsquo;ai une anecdote en tête, une personne de mon entourage m&amp;rsquo;a raconté une histoire d&amp;rsquo;un bâtiment qui avait été contrôlé au moment de la livraison :&lt;/p&gt;&#xA;&lt;p&gt;Un prélèvement avait été fait dans les murs et il n&amp;rsquo;y avait pas assez de ciment, le bâtiment, &lt;strong&gt;neuf&lt;/strong&gt;, pouvait s&amp;rsquo;écrouler. Il venait d&amp;rsquo;être totalement terminé, électricité, plomberie, menuiseries&amp;hellip; Tout était terminé.&#xA;Il a dû être rasé complètement. Autant il existe des assurances dans le bâtiment, mais pas pour le développement&amp;hellip;&#xA;Je pense que certaines sociétés ne survivent pas si la dette technique est trop importante.&lt;/p&gt;&#xA;&lt;h1 id=&#34;lusage-du-cloud&#34;&gt;L&amp;rsquo;usage du cloud&lt;/h1&gt;&#xA;&lt;p&gt;Le cloud a de nombreux avantages :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;On peut rapidement obtenir des bases de données avec une installation relativement propre.&lt;/li&gt;&#xA;&lt;li&gt;Le cloud provider vous obligera à rester sur des versions supportées.&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;Écologiquement&amp;rdquo;, cela permet de mutualiser des ressources physiques. Mais c&amp;rsquo;est aussi une faiblesse. L&amp;rsquo;accès facile à ces ressources peut aussi entrainer un gaspillage. On peut facilement déployer&#xA;une centaine d&amp;rsquo;instances. Là, où avec une infrastructure &lt;em&gt;on-premise&lt;/em&gt;, il faut concilier avec les ressources physiques à disposition : puissance des serveurs, puissance électrique, espace dans les baies&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;On paye ce qu&amp;rsquo;on consomme. On peut facilement identifier combien coute un service. Qu&amp;rsquo;une requête est responsable de 80% de la facture. Ce qui peut inciter à l&amp;rsquo;optimiser, le gain financier est immédiat. Encore faut-il qu&amp;rsquo;il y ait des personnes qui s&amp;rsquo;y intéressent.&#xA;Je n&amp;rsquo;ai pas l&amp;rsquo;impression qu&amp;rsquo;il y ait beaucoup de FinOps. S&amp;rsquo;il y en a, est-ce que ces derniers pensent à optimiser la base ?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Mais il y a aussi de vrais inconvénients :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Perte de souveraineté numérique. A cela s&amp;rsquo;ajoute des risques juridiques. Comment garantir que vos données ne sont pas stockées ailleurs ? Si vous avez choisi un service managé, comment en sortir si la législation vous impose d&amp;rsquo;être sur le sol Français ou d&amp;rsquo;un autre pays ?&lt;/li&gt;&#xA;&lt;li&gt;Perte de compétences.&lt;/li&gt;&#xA;&lt;li&gt;Dépendance à un cloud provider : encore que sur ce point, on voit émerger de nouvelles offres &amp;ldquo;cloud agnostique&amp;rdquo; : Des sociétés créent un cloud par-dessus un autre cloud.&#xA;Je pense notamment à &lt;a href=&#34;https://aiven.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aiven&lt;/a&gt;, &lt;a href=&#34;https://www.enterprisedb.com/docs/biganimal/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EDB BigAnimal&lt;/a&gt;, &lt;a href=&#34;https://www.crunchydata.com/products/crunchy-bridge&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Crunchy Bridge&lt;/a&gt; et j&amp;rsquo;en oublie certainement&amp;hellip;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;&#xA;&lt;li&gt;Les couts décollent quand l&amp;rsquo;infrastructure est importante. Certains commencent à quitter le cloud. Je pense notamment à Basecamp :&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://world.hey.com/dhh/why-we-re-leaving-the-cloud-654b47e0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Why we&amp;rsquo;re leaving the cloud&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://world.hey.com/dhh/we-stand-to-save-7m-over-five-years-from-our-cloud-exit-53996caa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;We stand to save $7m over five years from our cloud exit&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://world.hey.com/dhh/the-big-cloud-exit-faq-20274010&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Big Cloud Exit FAQ&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;ce-quil-faudrait-changer&#34;&gt;Ce qu&amp;rsquo;il faudrait changer&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Redonner de la valeur à la donnée : des sociétés rechignent à faire appel à des DBA ou prendre des contrats de supports sur leur base. Quel est le cout d&amp;rsquo;une indisponibilité de service, d&amp;rsquo;une corruption de donnée, d&amp;rsquo;une perte de la base ?&lt;/li&gt;&#xA;&lt;li&gt;Réinvestir le champ des compétences en base de donnée : SQL, modélisation&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. A ce sujet, j&amp;rsquo;aime beaucoup le titre de Markus Winand : &lt;a href=&#34;https://winand.at/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SQL Renaissance Ambassador&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;S&amp;rsquo;attarder un peu plus sur l&amp;rsquo;usage des ressources : la consommation du numérique est importante, si les serveurs et l&amp;rsquo;électricité étaient plus chers, on serait contraint d&amp;rsquo;optimiser.&lt;/li&gt;&#xA;&lt;li&gt;Surveiller les dépenses sur les bases. Que ça soit dans le cloud, mais également on-premise. Pour cela, il faut avoir des indicateurs de couts.&lt;/li&gt;&#xA;&lt;li&gt;Penser pas à faire appel à des DBA pour anticiper les problèmes et investiguer sur les problèmes de performance : J&amp;rsquo;ai audité des bases dans un état catastrophique, ça aurait pu être évité si un DBA était intervenu dans la phase de modélisation. Sur les problèmes de performance, il m&amp;rsquo;est déjà arrivé de diviser des factures de cloud par 10 ou de baisser la charge moyenne de 80% à 5% avec un suivi régulier.&lt;/li&gt;&#xA;&lt;li&gt;Il ne faut pas se résigner à payer de grosses factures cloud plutôt que d&amp;rsquo;investir dans de la compétence de DBA.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;pour-conclure&#34;&gt;Pour conclure&lt;/h1&gt;&#xA;&lt;p&gt;C&amp;rsquo;est un article moins technique par rapport à ce que vous avez l&amp;rsquo;habitude de lire sur mon blog.&#xA;Cependant, c&amp;rsquo;est un des plus importants que j&amp;rsquo;ai été amené à écrire.&#xA;Ca fait plus de dix ans que je fais du Postgres et je réalise que la tendance ne va pas dans la bonne direction.&#xA;J&amp;rsquo;espère qu&amp;rsquo;il y aura une prise de conscience pour un avenir plus durable des bases de données.&lt;/p&gt;&#xA;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34;&gt;&#xA;&lt;p&gt;Ainsi que dans le public, il est dans le &lt;a href=&#34;https://code.gouv.fr/data/sill.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Socle interministériel de logiciels libres&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:2&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/pgconfeu/status/1734860251390750980&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;720 personnes à la PGEurope 2023&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:3&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS EBS latency and IOPS: The surprising truth&lt;/a&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Ultimately, due to AWS’ opacity, there is simply no way to know how much throughput (from the physical disks and from the network that sits in-between) to expect for a given EBS volume. Provisioned IOPS only offer a partial solution to this issue, at a higher hourly cost.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:4&#34;&gt;&#xA;&lt;p&gt;Le Postgres actuel est très loin du Postgres avec lequel j&amp;rsquo;ai débuté :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Nouvelles fonctionnalités liées au standard SQL : JSONPath par exemple. &lt;a href=&#34;https://winand.at/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Markus Winand&lt;/a&gt; est l&amp;rsquo;auteur d&amp;rsquo;un super site à ce sujet: &lt;a href=&#34;https://modern-sql.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Modern SQL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Nouvelles fonctionnalités sur le moteur : parallélisme, partitionnement, nouveaux noeuds d&amp;rsquo;exécution, réplication logique&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;La conséquence est un nombre de paramètres qui augmente au fur et à mesure.&lt;/li&gt;&#xA;&lt;li&gt;De nouvelles extensions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:5&#34;&gt;&#xA;&lt;p&gt;Je n&amp;rsquo;ai pas travaillé avec ces offres, je n&amp;rsquo;ai pas de recul dessus. On peut néanmoins souligner que ces sociétés emploient des développeurs qui contribuent à Postgres.&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:6&#34;&gt;&#xA;&lt;p&gt;Il y a quelques années, un article était tiré d&amp;rsquo;une conférence.&lt;/p&gt;&#xA;&lt;p&gt;Le titre est particulièrement juste : &lt;a href=&#34;https://www.citusdata.com/blog/2018/03/19/postgres-database-constraints&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Database constraints in Postgres: The last line of defense&lt;/a&gt;.&#xA;Voici la vidéo de la conférence : &lt;a href=&#34;https://www.youtube.com/watch?v=hWh8QoV8z8k&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Constraints: a Developer&amp;rsquo;s Secret Weapon - Will Leinweber&lt;/a&gt;&#xA;et ses &lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2018/sessions/session/1835/slides/70/2018-03-15%20constraints%20a%20developers%20secret%20weapon%20pgday%20paris.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;slides&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/div&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>Optimisation du GROUP BY</title>
    <updated>2024-01-26T09:00:00Z</updated>
    <id>tag:blog.anayrat.info,2024-01-26:/2024/01/26/optimisation-du-group-by/</id>
    <link href="https://blog.anayrat.info/2024/01/26/optimisation-du-group-by/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Un commit a attiré mon attention lors de ma veille technique :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-diff&#34; data-lang=&#34;diff&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;commit 0452b461bc405e6d35d8a14c02813c15e28ae516&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Author:     Alexander Korotkov &amp;lt;akorotkov@postgresql.org&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;AuthorDate: Sun Jan 21 22:21:36 2024 +0200&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Commit:     Alexander Korotkov &amp;lt;akorotkov@postgresql.org&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CommitDate: Sun Jan 21 22:21:36 2024 +0200&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Explore alternative orderings of group-by pathkeys during optimization.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    When evaluating a query with a multi-column GROUP BY clause, we can minimize&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    sort operations or avoid them if we synchronize the order of GROUP BY clauses&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    with the ORDER BY sort clause or sort order, which comes from the underlying&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    query tree. Grouping does not imply any ordering, so we can compare&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    the keys in arbitrary order, and a Hash Agg leverages this. But for Group Agg,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    we simply compared keys in the order specified in the query. This commit&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    explores alternative ordering of the keys, trying to find a cheaper one.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    The ordering of group keys may interact with other parts of the query, some of&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    which may not be known while planning the grouping. For example, there may be&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    an explicit ORDER BY clause or some other ordering-dependent operation higher up&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    in the query, and using the same ordering may allow using either incremental&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    sort or even eliminating the sort entirely.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    The patch always keeps the ordering specified in the query, assuming the user&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    might have additional insights.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    This introduces a new GUC enable_group_by_reordering so that the optimization&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    may be disabled if needed.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Discussion: https://postgr.es/m/7c79e6a5-8597-74e8-0671-1c39d124c9d6%40sigaev.ru&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Author: Andrei Lepikhov, Teodor Sigaev&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Reviewed-by: Tomas Vondra, Claudio Freire, Gavin Flower, Dmitry Dolgov&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Reviewed-by: Robert Haas, Pavel Borisov, David Rowley, Zhihong Yu&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Reviewed-by: Tom Lane, Alexander Korotkov, Richard Guo, Alena Rybakina&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;On remarque le message du commit assez explicite en mentionnant les personnes impliquées (12 relecteurs!) ainsi que le lien vers la discussion :&#xA;&lt;a href=&#34;https://www.postgresql.org/message-id/flat/7c79e6a5-8597-74e8-0671-1c39d124c9d6%40sigaev.ru&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;POC: GROUP BY optimization&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Les travaux ont commencé en 2018! Il aura fallu 5 ans et demi pour aboutir à ce commit. C&amp;rsquo;est le fruit de nombreux échanges afin de parvenir à un consensus en prenant en compte les multiples idées.&lt;/p&gt;&#xA;&lt;p&gt;Pour tester ce patch, j&amp;rsquo;ai compilé Postgres depuis les sources. Prenons un exemple tout simple :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;insert&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;into&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;generate_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_000_000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;vacuum&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;analyze&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;On obtient une table de 422Mo et un index de 66Mo.&#xA;Vous noterez au passage que j&amp;rsquo;ai utilisé une nouveauté de Postgres 16 en utilisant des &amp;ldquo;underscore&amp;rdquo; dans le &lt;em&gt;generate_series&lt;/em&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Si on fait un &lt;code&gt;GROUP BY&lt;/code&gt; sur &lt;em&gt;c1,c2&lt;/em&gt;, on obtient un parcours d&amp;rsquo;index :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;explain (settings, analyze,buffers) select count(*),c1,c2 from t1 group by c1,c2 order by c1,c2;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                    QUERY PLAN&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--------------------------------------------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; GroupAggregate  (cost=0.43..235342.27 rows=100000 width=16) (actual time=3.605..3501.887 rows=1000 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Group Key: c1, c2&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Buffers: shared hit=10447&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   -&amp;gt;  Index Only Scan using t1_c1_c2_idx on t1  (cost=0.43..159340.96 rows=10000175 width=8) (actual time=0.070..1900.730 rows=10000000 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Heap Fetches: 0&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Buffers: shared hit=10447&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Settings: enable_group_by_reordering = &amp;#39;off&amp;#39;, random_page_cost = &amp;#39;1.1&amp;#39;, max_parallel_workers_per_gather = &amp;#39;0&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Planning:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Buffers: shared hit=1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Planning Time: 0.191 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Execution Time: 3502.036 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Vous remarquerez que j&amp;rsquo;ai volontairement désactivé la fonctionnalité dans un premier temps (enable_group_by_reordering=off). J&amp;rsquo;ai également désactivé la parallélisation pour plus de clarté.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;On a le plan attendu, le moteur va lire 10447 blocs avec un parcours &lt;em&gt;Index Only Scan&lt;/em&gt;. Le moteur va chercher le plan qui manipule le moins de blocs possible.&lt;/p&gt;&#xA;&lt;p&gt;En revanche, si on change l&amp;rsquo;ordre du group by :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;explain (settings, analyze,buffers) select count(*),c1,c2 from t1 group by c2,c1 order by c1,c2;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                          QUERY PLAN&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;------------------------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Sort  (cost=602422.32..602672.32 rows=100000 width=16) (actual time=5393.446..5393.503 rows=1000 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Sort Key: c1, c2&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Sort Method: quicksort  Memory: 79kB&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Buffers: shared hit=96 read=53959&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   -&amp;gt;  HashAggregate  (cost=514992.50..594117.50 rows=100000 width=16) (actual time=5392.351..5392.894 rows=1000 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Group Key: c2, c1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Batches: 1  Memory Usage: 3217kB&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Buffers: shared hit=96 read=53959&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         -&amp;gt;  Seq Scan on t1  (cost=0.00..154055.00 rows=10000000 width=8) (actual time=0.033..1186.171 rows=10000000 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;               Buffers: shared hit=96 read=53959&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Settings: enable_group_by_reordering = &amp;#39;off&amp;#39;, random_page_cost = &amp;#39;1.1&amp;#39;, max_parallel_workers_per_gather = &amp;#39;0&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Planning:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Buffers: shared hit=1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Planning Time: 0.189 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Execution Time: 5394.566 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Dans ce cas, le moteur va lire toute la table (&lt;em&gt;seqscan&lt;/em&gt;) et faire un tri, alors que le résultat est identique.&lt;/p&gt;&#xA;&lt;p&gt;Le moteur lit 422Mo de données contre 80Mo, soit 5 fois plus. Le résultat peut être désastreux suivant les performances du stockage.&#xA;Là, on a de la &amp;ldquo;chance&amp;rdquo;, mon instance est dans un ramdisk donc la requête n&amp;rsquo;est pas beaucoup plus lente.&#xA;Avec du stockage mécanique ou des disques cloud, le temps de réponse peut augmenter drastiquement.&lt;/p&gt;&#xA;&lt;p&gt;L&amp;rsquo;ordre des colonnes dans un group by est important, c&amp;rsquo;est une optimisation assez simple pour peu qu&amp;rsquo;on connaisse le schéma de la base et qu&amp;rsquo;on maitrise les requêtes exécutées sur le serveur.&lt;/p&gt;&#xA;&lt;p&gt;Malheureusement, avec les ORM, on peut perdre cette maitrise ou rater des corrections.&#xA;C&amp;rsquo;est là où cette fonctionnalité est intéressante. Voyons son effet :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;postgres=# set enable_group_by_reordering to on;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SET&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;postgres=# explain (settings, analyze,buffers) select count(*),c1,c2 from t1 group by c2,c1 order by c1,c2;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                    QUERY PLAN&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--------------------------------------------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; GroupAggregate  (cost=0.43..235338.33 rows=100000 width=16) (actual time=4.502..3658.168 rows=1000 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Group Key: c1, c2&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Buffers: shared hit=10447&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   -&amp;gt;  Index Only Scan using t1_c1_c2_idx on t1  (cost=0.43..159338.33 rows=10000000 width=8) (actual time=0.081..1923.553 rows=10000000 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Heap Fetches: 0&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Buffers: shared hit=10447&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Settings: random_page_cost = &amp;#39;1.1&amp;#39;, max_parallel_workers_per_gather = &amp;#39;0&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Planning:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Buffers: shared hit=1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Planning Time: 0.230 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Execution Time: 3658.337 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;On retrouve le premier plan bien plus performant.&lt;/p&gt;&#xA;&lt;p&gt;C&amp;rsquo;est une fonctionnalité assez simple qui devrait améliorer les temps d&amp;rsquo;exécutions de certaines requêtes dont la clause group by n&amp;rsquo;a pas été optimisée.&lt;/p&gt;&#xA;&lt;p&gt;C&amp;rsquo;est une demande assez récurrente d&amp;rsquo;améliorer le planificateur afin de gérer des cas en apparence simple. Il faut avoir en tête que le risque est de d&amp;rsquo;augmenter&#xA;les opérations de calculs dans le planificateur. Or, on veut que cette étape soit la plus rapide possible La réponse est souvent résumée à : &amp;ldquo;on ne veut pas alourdir le planificateur alors qu&amp;rsquo;on peut corriger la requête&amp;rdquo;.&lt;/p&gt;&#xA;&lt;p&gt;Cependant, ce type d&amp;rsquo;optimisation peut être acceptée si on sait que ça ne sera pas couteux pour le planificateur.&lt;/p&gt;&#xA;&lt;p&gt;Il n&amp;rsquo;y a plus qu&amp;rsquo;à espérer que cette fonctionnalité ne soit pas retirée d&amp;rsquo;ici la sortie de Postgres 17 :)&lt;/p&gt;&#xA;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34;&gt;&#xA;&lt;p&gt;Petite anecdote, pour ajouter cette fonctionnalité, l&amp;rsquo;auteur a fait évoluer le standard SQL : &lt;a href=&#34;http://peter.eisentraut.org/blog/2023/09/20/grouping-digits-in-sql&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Grouping digits in SQL&lt;/a&gt; .&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/div&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL compression du TOAST et toast_tuple_target</title>
    <updated>2022-02-14T07:00:00Z</updated>
    <id>tag:blog.anayrat.info,2022-02-14:/2022/02/14/postgresql-compression-du-toast-et-toast_tuple_target/</id>
    <link href="https://blog.anayrat.info/2022/02/14/postgresql-compression-du-toast-et-toast_tuple_target/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Quelques rappels sur le TOAST et présentation d&amp;rsquo;un changement apparu avec PostgreSQL 11.&lt;/p&gt;&#xA;&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;&#xA;  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table des matières&lt;/summary&gt;&#xA;  &lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#quest-ce-que-le-toast-&#34;&gt;Qu&amp;rsquo;est-ce que le TOAST ?&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#exemple-avec-le-jsonb&#34;&gt;Exemple avec le JSONB&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#paramétrage-avancé&#34;&gt;Paramétrage avancé&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#bonus&#34;&gt;Bonus&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;/details&gt;&#xA;&lt;h1 id=&#34;quest-ce-que-le-toast-&#34;&gt;Qu&amp;rsquo;est-ce que le TOAST ?&lt;/h1&gt;&#xA;&lt;p&gt;Vous êtes-vous déjà posé la question sur comment Postgres fait pour stocker des lignes dépassant la taille d&amp;rsquo;un bloc? Pour rappel, la taille par défaut d&amp;rsquo;un bloc est de 8Ko.&lt;/p&gt;&#xA;&lt;p&gt;Postgres utilise un mécanisme appelé TOAST pour &lt;a href=&#34;https://www.postgresql.org/docs/current/storage-toast.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Oversized-Attribute Storage Technique&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Lorsqu&amp;rsquo;un enregistrement devient trop gros pour être stocké dans un bloc, le moteur va le stocker &amp;ldquo;à part&amp;rdquo;, dans une table de toast.&#xA;L&amp;rsquo;enregistrement sera découpé en &lt;em&gt;chunks&lt;/em&gt;, ainsi la table principale (appelée &lt;em&gt;heap&lt;/em&gt;) contiendra un pointeur (&lt;em&gt;chunk_id&lt;/em&gt;) pointant vers le bon &lt;em&gt;chunk&lt;/em&gt; dans la table de toast.&lt;/p&gt;&#xA;&lt;p&gt;Ce &lt;em&gt;chunk&lt;/em&gt; sera stocké sur plusieurs lignes, pour un &lt;em&gt;chunk_id&lt;/em&gt; on peut avoir plusieurs lignes dans cette table de toast.&#xA;Ainsi, cette table de toast est composée de 3 colonnes:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;chunk_id&lt;/em&gt; : Numéro du chunk référencé dans la heap&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;chunk_seq&lt;/em&gt; : Numéro de chaque segment d&amp;rsquo;un chunk&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;chunk_data&lt;/em&gt; : Partie données de chaque segment&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La réalité est un peu plus complexe, en vrai le moteur va tenter d&amp;rsquo;éviter de stocker la donnée dans la table toast.&#xA;Si la ligne dépasse &lt;code&gt;TOAST_TUPLE_THRESHOLD&lt;/code&gt; (2Ko), il va tenter de compresser les colonnes pour essayer de faire rentrer la ligne dans le bloc.&#xA;Plus précisément, il faut que la taille soit inférieure à &lt;code&gt;TOAST_TUPLE_TARGET&lt;/code&gt; (2Ko par défaut, on va en reparler).&lt;/p&gt;&#xA;&lt;p&gt;Si on a de la chance, la ligne compressée rentre dans la heap. Sinon, il va tenter de compresser les colonnes,&#xA;de la plus grande à la plus petite et les stocker dans la partie toast jusqu&amp;rsquo;à ce que les colonnes restantes rentrent dans une ligne de la heap. &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&lt;p&gt;A noter également que si le gain en compression est trop faible, il considère qu&amp;rsquo;il est inutile de dépenser&#xA;de la ressource de calcul à tenter de compresser. Il stocke donc la donnée sans compression. &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&lt;p&gt;Avez-vous déjà prêté attention à la colonne &amp;ldquo;Storage&amp;rdquo; lorsque vous affichez les caractéristiques d&amp;rsquo;une table à l&amp;rsquo;aide de la méta commande &lt;code&gt;\d+ table&lt;/code&gt; ?&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;stackoverflow=# \d+ posts&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                   Table &amp;#34;public.posts&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Column     |  Type   | Collation | Nullable | Default | Storage  |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;---------------+---------+-----------+----------+---------+----------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; id            | integer |           | not null |         | plain    |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; posttypeid    | integer |           | not null |         | plain    |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; score         | integer |           |          |         | plain    |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; viewcount     | integer |           |          |         | plain    |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; body          | text    |           |          |         | extended |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Dans cet exemple, la colonne prend comme valeur &lt;em&gt;plain&lt;/em&gt; ou &lt;em&gt;extended&lt;/em&gt;. En réalité, il existe 4 valeurs possibles selon le type de donnée :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;plain&lt;/em&gt; : la colonne est stockée dans la heap uniquement et sans compression.&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;extended&lt;/em&gt; : la colonne peut être compressée et stockée dans le toast si nécessaire.&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;external&lt;/em&gt; : la colonne peut être stockée dans le toast mais uniquement sans compression. Parfois on peut utiliser ce mode pour avoir un gain en performance (évite la compression/décompression)&#xA;au prix d&amp;rsquo;une consommation plus importante de l&amp;rsquo;espace disque.&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;main&lt;/em&gt; : La colonne est stockée dans la heap uniquement mais contrairement au mode &lt;em&gt;plain&lt;/em&gt;, on autorise la compression.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Au premier abord, on peut penser que l&amp;rsquo;intérêt est surtout sur la possibilité de stocker&#xA;des lignes dépassant la taille d&amp;rsquo;un bloc et de compresser la donnée pour gagner de l&amp;rsquo;espace disque.&lt;/p&gt;&#xA;&lt;p&gt;Il y a un autre intérêt : lors d&amp;rsquo;une mise à jour d&amp;rsquo;une ligne, si les colonnes &amp;ldquo;toastées&amp;rdquo; ne sont pas modifiées, le moteur n&amp;rsquo;a pas besoin de modifier la table toast.&#xA;On va ainsi éviter de devoir décompresser et recompresser le toast et écrire tout ça dans des journaux de transaction.&lt;/p&gt;&#xA;&lt;p&gt;Nous allons voir qu&amp;rsquo;un autre avantage est que le moteur peut éviter de lire le toast si ce n&amp;rsquo;est pas nécessaire.&lt;/p&gt;&#xA;&lt;h1 id=&#34;exemple-avec-le-jsonb&#34;&gt;Exemple avec le JSONB&lt;/h1&gt;&#xA;&lt;p&gt;Pour étudier ça, on va utiliser le type JSONB. De manière générale, je déconseille l&amp;rsquo;usage de ce type :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;On perd les avantages d&amp;rsquo;avoir un schéma :&#xA;&lt;ul&gt;&#xA;&lt;li&gt;vérification des types&lt;/li&gt;&#xA;&lt;li&gt;contraintes d&amp;rsquo;intégrité&lt;/li&gt;&#xA;&lt;li&gt;pas de clés étrangères&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;L&amp;rsquo;écriture des requêtes devient plus complexe&lt;/li&gt;&#xA;&lt;li&gt;Absence des statistiques sur les clés d&amp;rsquo;un champ json&lt;/li&gt;&#xA;&lt;li&gt;Perte d&amp;rsquo;efficacité du stockage vu qu&amp;rsquo;on stocke les clés pour chaque ligne&lt;/li&gt;&#xA;&lt;li&gt;Pas de mise à jour partielle du JSONB. Si on modifie une clé on est obligé de &lt;em&gt;detoaster&lt;/em&gt; et &lt;em&gt;toaster&lt;/em&gt; tout le JSONB&lt;/li&gt;&#xA;&lt;li&gt;Pas de &lt;em&gt;detoast&lt;/em&gt; partiel : si on souhaite lire une seule clé du JSONB, on est contraint de &lt;em&gt;detoaster&lt;/em&gt; tout le JSONB &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Cependant, il y a quelques exceptions où le JSON peut être utile :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Lorsqu&amp;rsquo;on n&amp;rsquo;a pas besoin de chercher dans de multiples champs et qu&amp;rsquo;on récupère le json via une autre colonne. (Statistiques sur les clés du json inutiles).&lt;/li&gt;&#xA;&lt;li&gt;Et, lorsqu&amp;rsquo;il serait très difficile de faire rentrer le json dans un schéma relationnel. Certains cas impliqueraient d&amp;rsquo;avoir énormément de colonnes et la plupart à &lt;code&gt;NULL&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Par exemple, pour stocker des caractéristiques de produit où une version normalisée entrainerait l&amp;rsquo;usage de beaucoup de colonnes dont la plupart seraient à &lt;code&gt;NULL&lt;/code&gt;.&#xA;Imaginons que vous stockez des produits, une télévision aurait des caractéristiques spécifiques (type d&amp;rsquo;écran, taille etc). Une machine à laver aurait aussi d&amp;rsquo;autre caractéristiques spécifiques (vitesse essorage, poids accepté&amp;hellip;).&lt;/p&gt;&#xA;&lt;p&gt;On pourrait ainsi envisager d&amp;rsquo;avoir des colonnes &amp;ldquo;normales&amp;rdquo; comprenant le modèle, son prix, sa référence etc, et une colonne contenant toutes les caractéristiques.&#xA;On accèderait à la ligne via la référence et ainsi on récupèrerait toutes les caractéristiques du produit stockées dans le json.&lt;/p&gt;&#xA;&lt;p&gt;Je vais réutiliser la table des posts de Stackoverflow en déplaçant quelques colonnes dans une colonne de type jsonb (colonne &lt;em&gt;jsonfield&lt;/em&gt; dans cet exemple):&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;\d posts&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                            Unlogged table &amp;#34;public.posts&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        Column         |            Type             | Collation | Nullable | Default&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-----------------------+-----------------------------+-----------+----------+---------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; id                    | integer                     |           | not null |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; posttypeid            | integer                     |           | not null |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; acceptedanswerid      | integer                     |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; parentid              | integer                     |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; creationdate          | timestamp without time zone |           | not null |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; score                 | integer                     |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; viewcount             | integer                     |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; body                  | text                        |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; owneruserid           | integer                     |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; lasteditoruserid      | integer                     |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; lasteditordisplayname | text                        |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; lasteditdate          | timestamp without time zone |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; lastactivitydate      | timestamp without time zone |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; title                 | text                        |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; tags                  | text                        |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; answercount           | integer                     |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; commentcount          | integer                     |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; favoritecount         | integer                     |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; closeddate            | timestamp without time zone |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; communityowneddate    | timestamp without time zone |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; jsonfield             | jsonb                       |           |          |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Voici une requête toute simple d&amp;rsquo;agrégation :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;viewcount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;answercount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;commentcount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;favoritecount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;posts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                          QUERY PLAN&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-------------------------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Aggregate  (cost=10265135.77..10265135.78 rows=1 width=128) (actual time=170221.557..170221.558 rows=1 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Buffers: shared hit=1 read=9186137&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   I/O Timings: read=138022.290&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   -&amp;gt;  Seq Scan on posts  (cost=0.00..9725636.88 rows=53949888 width=16) (actual time=0.014..153665.913 rows=53949886 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Buffers: shared hit=1 read=9186137&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         I/O Timings: read=138022.290&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Planning Time: 0.240 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Execution Time: 170221.627 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;(8 rows)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;La requête lit 70 Go de données et met environ 2min 50s à s&amp;rsquo;exécuter.&lt;/p&gt;&#xA;&lt;p&gt;Maintenant la même requête, mais cette fois en utilisant les clés présentes dans le json.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;jsonfield&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ViewCount&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;jsonfield&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;AnswerCount&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;jsonfield&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;CommentCount&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;jsonfield&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;FavoriteCount&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;posts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           QUERY PLAN&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Aggregate  (cost=11883632.41..11883632.42 rows=1 width=128)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            (actual time=520917.028..520917.030 rows=1 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   Buffers: shared hit=241116554 read=13625756&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   -&amp;gt;  Seq Scan on posts  (cost=0.00..9725636.88 rows=53949888 width=570)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          (actual time=0.972..70569.365 rows=53949886 loops=1)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Buffers: shared read=9186138&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Planning Time: 0.118 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Execution Time: 520945.395 ms&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;(10 rows)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;La requête met environ 8min 40s à s&amp;rsquo;exécuter. En revanche le nombre de blocs lus semble un peu délirant :&lt;/p&gt;&#xA;&lt;p&gt;Le Seq Scan indique comme tout à l&amp;rsquo;heure 70Go. En revanche, le nœud parent indique plus de 1.9 To lus!&lt;/p&gt;&#xA;&lt;p&gt;Voici la taille de la table avec le paramétrage par défaut. Il faut savoir que pour certains enregistrements,&#xA;le moteur va, soit compresser la ligne dans la heap, soit la compresser et la placer dans le toast.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SELECT&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  pg_size_pretty(pg_relation_size(oid)) table_size,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  pg_size_pretty(pg_relation_size(reltoastrelid)) toast_size&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM pg_class&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WHERE relname = &amp;#39;posts&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; table_size | toast_size&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;------------+-----------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 70 GB      | 33 GB&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;(1 row)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Comment expliquer les 1.9 To lus ?&lt;/p&gt;&#xA;&lt;p&gt;Par curiosité, j&amp;rsquo;ai fait la même requête, mais avec une seule agrégation et j&amp;rsquo;obtiens environ 538 Go.&lt;/p&gt;&#xA;&lt;p&gt;On peut se poser plusieurs questions :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Comment savoir si le moteur va lire le toast ?&lt;/li&gt;&#xA;&lt;li&gt;Pourquoi un tel écart de temps d&amp;rsquo;exécution entre la version &amp;ldquo;colonne standard&amp;rdquo; et champ jsonb?&lt;/li&gt;&#xA;&lt;li&gt;A quoi correspondent les compteurs dans le nœud &lt;code&gt;Aggregate&lt;/code&gt; ?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Pour répondre à la première question, il suffit de lire la vue &lt;code&gt;pg_statio_user_tables&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Avant exécution de la requête :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;select relid,schemaname,relname,heap_blks_read,heap_blks_hit,toast_blks_read,toast_blks_hit from pg_statio_all_tables where relname in (&amp;#39;posts&amp;#39;,&amp;#39;pg_toast_26180851&amp;#39;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  relid   | schemaname |      relname      | heap_blks_read | heap_blks_hit | toast_blks_read | toast_blks_hit&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;----------+------------+-------------------+----------------+---------------+-----------------+----------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 26180851 | public     | posts             |      422018238 |      87673549 |       129785076 |      628153337&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 26180854 | pg_toast   | pg_toast_26180851 |      129785076 |     628153337 |                 |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;(2 rows)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Après :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  relid   | schemaname |      relname      | heap_blks_read | heap_blks_hit | toast_blks_read | toast_blks_hit&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;----------+------------+-------------------+----------------+---------------+-----------------+----------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 26180851 | public     | posts             |      431204376 |      87673549 |       134156898 |      686299551&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 26180854 | pg_toast   | pg_toast_26180851 |      134156898 |     686299551 |                 |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;(2 rows)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ce qui nous fait :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pg_size_pretty&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;431204376&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;87673549&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;422018238&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;87673549&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;bigint&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;heap_buffers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pg_size_pretty&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134156898&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;686299551&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;129785076&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;628153337&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;bigint&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toast_buffers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;heap_buffers&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toast_buffers&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------+---------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GB&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;477&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GB&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Le moteur va bien lire le toast. En revanche les compteurs laissent penser que le moteur va lire plusieurs fois le toast.&lt;/p&gt;&#xA;&lt;p&gt;Si je fais le même calcul, mais cette fois en effectuant l&amp;rsquo;agrégation que sur un seul champ, j&amp;rsquo;obtiens 119 Go (~ 477 Go / 4)&#xA;J&amp;rsquo;imagine que le moteur lit le toast pour chaque fonction.&lt;/p&gt;&#xA;&lt;p&gt;Ensuite, l&amp;rsquo;écart du temps d&amp;rsquo;exécution s&amp;rsquo;explique par plusieurs facteurs :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Le moteur va devoir lire et &lt;em&gt;detoaster&lt;/em&gt; (décompresser) le toast&lt;/li&gt;&#xA;&lt;li&gt;Faire des opérations supplémentaires sur le jsonb pour accéder à la valeur&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Avec la première requête, le moteur n&amp;rsquo;avait pas à lire le toast. D&amp;rsquo;une part, il a moins de données à lire,&#xA;d&amp;rsquo;autre part, il n&amp;rsquo;a pas à manipuler le json pour identifier la clé et extraire la valeur à calculer.&lt;/p&gt;&#xA;&lt;p&gt;Enfin, les compteurs du nœud aggregate doivent correspondre aux données décompressées pour chaque fonction qui va lire dans le json.&#xA;En effet, si on prend le total moins le &lt;em&gt;seqscan&lt;/em&gt; de la table, donc que la partie &lt;em&gt;toast&lt;/em&gt;, on a :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;468 Go pour un seul champ&lt;/li&gt;&#xA;&lt;li&gt;936 Go, le double pour deux champs&lt;/li&gt;&#xA;&lt;li&gt;1873 Go pour les 4 champs (donc environ 4 x 468 Go)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;C&amp;rsquo;est ce qui explique pourquoi on obtient une valeur aussi élevée.&lt;/p&gt;&#xA;&lt;h1 id=&#34;paramétrage-avancé&#34;&gt;Paramétrage avancé&lt;/h1&gt;&#xA;&lt;p&gt;Maintenant, on va encourager Postgres à placer le maximum de données dans le toast grâce à l&amp;rsquo;option &lt;em&gt;toast_tuple_target&lt;/em&gt; apparue avec la version 11 de Postgres.&lt;/p&gt;&#xA;&lt;p&gt;Cette option permet de manipuler le seuil à partir duquel les données sont stockée dans le &lt;em&gt;toast&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Par ailleurs, étant sous Postgres 14, j&amp;rsquo;en ai profité pour utiliser l&amp;rsquo;algorithme de compression lz4 (paramètre &lt;em&gt;default_toast_compression&lt;/em&gt;).&#xA;Cet algorithme offre un ratio de compression similaire à pglz, cependant, il est beaucoup plus rapide (Voir &lt;a href=&#34;https://www.postgresql.fastware.com/blog/what-is-the-new-lz4-toast-compression-in-postgresql-14&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;What is the new LZ4 TOAST compression in PostgreSQL 14, and how fast is it?&lt;/a&gt;).&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;posts_toast&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WITH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toast_tuple_target&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;posts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Voici la taille de la table obtenue.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SELECT&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  pg_size_pretty(pg_relation_size(oid)) table_size,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  pg_size_pretty(pg_relation_size(reltoastrelid)) toast_size&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM pg_class&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WHERE relname = &amp;#39;posts_toast&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; table_size | toast_size&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;------------+------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 59 GB      | 52 GB&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Au total, la table avec le toast fait grosso-modo la même taille. Dans l&amp;rsquo;exemple avec la première table,&#xA;il faut savoir que le moteur compresse aussi les données dans la heap.&lt;/p&gt;&#xA;&lt;p&gt;Rejouons notre requête d&amp;rsquo;agrégation :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;viewcount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;answercount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;commentcount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;favoritecount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;posts_toast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Cette fois la requête lit 59 Go de données et met 2min 17 secondes.&#xA;On a gagné environ 20% de temps d&amp;rsquo;exécution sur cet exemple.&lt;/p&gt;&#xA;&lt;p&gt;On pourrait gagner beaucoup plus si la partie stockée en toast était plus importante. Le volume de donnée à lire dans la heap serait beaucoup plus réduit.&lt;/p&gt;&#xA;&lt;p&gt;Par curiosité, j&amp;rsquo;ai aussi exécuté la requête qui fait l&amp;rsquo;agrégation depuis les données du champ json. J&amp;rsquo;obtiens un temps d&amp;rsquo;exécution de 7min 17s.&lt;/p&gt;&#xA;&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&lt;p&gt;Résumé en quelques chiffres :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Agrégation type standard, stockage standard : 2min 50s&lt;/li&gt;&#xA;&lt;li&gt;Agrégation type jsonb, stockage standard : 8min 40s&lt;/li&gt;&#xA;&lt;li&gt;Agrégation type standard, stockage avec &lt;em&gt;toast_tuple_target&lt;/em&gt; = 128 : 2min 17s&lt;/li&gt;&#xA;&lt;li&gt;Agrégation type jsonb, stockage avec &lt;em&gt;toast_tuple_target&lt;/em&gt; = 128 : 7min 17s&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;On constate que l&amp;rsquo;usage du JSON est bien plus couteux que d&amp;rsquo;utiliser les types standards. Le moteur doit faire plus d&amp;rsquo;opérations pour accéder à la valeur d&amp;rsquo;une clé json.&lt;/p&gt;&#xA;&lt;p&gt;Par ailleurs, il est obligé de décompresser les données dans le toast pour y accéder. Néanmoins, on peut aussi jouer avec le paramètre &lt;code&gt;toast_tuple_target&lt;/code&gt; pour pousser plus&#xA;d&amp;rsquo;informations dans le toast. Ainsi, dans certains cas, cela peut permettre de réduire la quantité de données lues en évitant de lire le toast.&lt;/p&gt;&#xA;&lt;h1 id=&#34;bonus&#34;&gt;Bonus&lt;/h1&gt;&#xA;&lt;p&gt;Comment souvent dans Postgres, tout évolue au fil des versions. Le TOAST n&amp;rsquo;échappe pas à cette règle.&#xA;Ainsi, quelques nouveautés pourraient apparaitre dans les prochaines versions :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Un premier patch a été proposé pour avoir plus de statistiques sur le toast : &lt;a href=&#34;https://commitfest.postgresql.org/37/3457/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pg_stat_toast&lt;/a&gt;.&#xA;L&amp;rsquo;idée, est d&amp;rsquo;avoir des statistiques sur la compression : gain compression, stockage inline ou séparé dans le toast&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;Un second patch appelé &lt;a href=&#34;https://commitfest.postgresql.org/37/3490/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pluggable toaster&lt;/a&gt;. Celui-ci est beaucoup plus important. Il propose d&amp;rsquo;étendre le &lt;em&gt;&amp;ldquo;toaster&amp;rdquo;&lt;/em&gt;.&#xA;L&amp;rsquo;idée serait de pouvoir proposer différents &lt;em&gt;&amp;ldquo;toaster&amp;rdquo;&lt;/em&gt; selon le type de donnée (notamment le JSONB).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34;&gt;&#xA;&lt;p&gt;Voir &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/access/heap/heaptoast.c;h=55bbe1d584760a849960871296dfbdd7447b2b67;hb=refs/heads/REL_14_STABLE#l160&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;heap_toast_insert_or_update&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:2&#34;&gt;&#xA;&lt;p&gt;Il existe deux algorithmes de compression supportés : &lt;em&gt;pglz&lt;/em&gt; (historique et intégré dans Postgres) et &lt;em&gt;lz4&lt;/em&gt; (depuis Postgres 14).&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Pour &lt;em&gt;pglz&lt;/em&gt;, voir &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/include/common/pg_lzcompress.h;h=3e53fbe97bd0a10e3fbf7ed4396924084f657868;hb=refs/heads/REL_14_STABLE#l25&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PGLZ_Strategy&lt;/a&gt;&#xA;et &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/common/pg_lzcompress.c;h=a30a2c2eb83a71725754d8dd680621a02e7557e9;hb=refs/heads/REL_14_STABLE#l223&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;strategy_default_data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Pour &lt;em&gt;lz4&lt;/em&gt;, il s&amp;rsquo;agit d&amp;rsquo;une librarie externe. Voir &lt;a href=&#34;https://github.com/lz4/lz4/blob/dev/lib/lz4.h#L145&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LZ4_compress_default&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:3&#34;&gt;&#xA;&lt;p&gt;Voir les slides de la conférence d&amp;rsquo;Oleg Bartunov et Nikita Glukhov : &lt;a href=&#34;http://www.sai.msu.su/~megera/postgres/talks/jsonb-nizhny-2021.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;json or not json that is the question&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/div&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>Cas d&#39;usages du partitionnement natif dans PostgreSQL</title>
    <updated>2021-09-01T07:00:00Z</updated>
    <id>tag:blog.anayrat.info,2021-09-01:/2021/09/01/cas-dusages-du-partitionnement-natif-dans-postgresql/</id>
    <link href="https://blog.anayrat.info/2021/09/01/cas-dusages-du-partitionnement-natif-dans-postgresql/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Après une période d&amp;rsquo;inactivité, je reprends l&amp;rsquo;écriture d&amp;rsquo;articles techniques sur Postgres. C&amp;rsquo;est aussi pour moi l&amp;rsquo;occasion de vous annoncer mon changement d&amp;rsquo;activité. Depuis courant 2021 je suis passé freelance pour permettre aux entreprises de bénéficier de mon expérience sur Postgres.&lt;/p&gt;&#xA;&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;&#xA;  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table des matières&lt;/summary&gt;&#xA;  &lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#histoire-du-partitionnement-dans-postgresql&#34;&gt;Histoire du partitionnement dans PostgreSQL&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#erreurs-courantes&#34;&gt;Erreurs courantes&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#il-faut-partitionner-dès-que-la-volumétrie-est-importante&#34;&gt;&amp;ldquo;Il faut partitionner dès que la volumétrie est importante&amp;rdquo;&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#il-faut-partitionner-pour-répartir-les-données-sur-plusieurs-disques&#34;&gt;&amp;ldquo;Il faut partitionner pour répartir les données sur plusieurs disques&amp;rdquo;&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#cas-dusages-du-partitionnement&#34;&gt;Cas d&amp;rsquo;usages du partitionnement&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionner-pour-gérer-la-rétention&#34;&gt;Partitionner pour gérer la rétention&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionner-pour-contrôler-la-fragmentation-des-index&#34;&gt;Partitionner pour contrôler la fragmentation des index&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionner-pour-faciliter-lexécution-de-requête-lorsque-la-cardinalité-est-faible&#34;&gt;Partitionner pour faciliter l&amp;rsquo;exécution de requête lorsque la cardinalité est faible&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionner-pour-obtenir-de-meilleures-statistiques&#34;&gt;Partitionner pour obtenir de meilleures statistiques&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionwise-join--partitionwise-aggregate&#34;&gt;partitionwise join &amp;amp; partitionwise aggregate&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#stockage-avec-tiering&#34;&gt;Stockage avec tiering&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;/details&gt;&#xA;&lt;h1 id=&#34;histoire-du-partitionnement-dans-postgresql&#34;&gt;Histoire du partitionnement dans PostgreSQL&lt;/h1&gt;&#xA;&lt;p&gt;PostgreSQL permet depuis très longtemps de partitionner des tables en exploitant l&amp;rsquo;héritage de table. Toutefois, cette méthode était assez lourde à mettre en oeuvre : elle impliquait de mettre en place soi-même des triggers pour rediriger les écritures (moins performant que le partitionnement natif), le temps de planification pouvait augmenter fortement au-delà d&amp;rsquo;une centaine de partitions&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;Le partitionnement natif est arrivé avec la version 10. C&amp;rsquo;est depuis cette version que le moteur est capable (entre autres) de diriger lui-même les écritures vers les bonnes tables, lire seulement les tables concernées, d&amp;rsquo;utiliser des algorithmes exploitant le partitionnement etc.&#xA;Il offre ainsi de meilleures performances et une facilité d&amp;rsquo;exploitation. On peut entre autres :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Partitionner :&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Par liste&lt;/li&gt;&#xA;&lt;li&gt;Par hashage&lt;/li&gt;&#xA;&lt;li&gt;Par intervalles&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Faire des partitionnements à plusieurs niveaux&lt;/li&gt;&#xA;&lt;li&gt;Partitionner sur plusieurs colonnes&lt;/li&gt;&#xA;&lt;li&gt;Utiliser des clés primaires et clés étrangères&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Toutes ces fonctionnalités sont intéressantes, mais on en vient à se poser une question toute bête : quand mettre en oeuvre le partitionnement?&lt;/p&gt;&#xA;&lt;p&gt;Je vais vous présenter plusieurs cas d&amp;rsquo;usages que j&amp;rsquo;ai pu rencontrer. Mais avant, voici quelques erreurs courantes sur le partitionnement.&lt;/p&gt;&#xA;&lt;h1 id=&#34;erreurs-courantes&#34;&gt;Erreurs courantes&lt;/h1&gt;&#xA;&lt;h2 id=&#34;il-faut-partitionner-dès-que-la-volumétrie-est-importante&#34;&gt;&amp;ldquo;Il faut partitionner dès que la volumétrie est importante&amp;rdquo;&lt;/h2&gt;&#xA;&lt;p&gt;Déjà, qu&amp;rsquo;est-ce qu&amp;rsquo;une volumétrie &amp;ldquo;importante&amp;rdquo;?&lt;/p&gt;&#xA;&lt;p&gt;Certains diront que c&amp;rsquo;est au-delà de plusieurs centaines de Go, d&amp;rsquo;autres au-delà du téraoctet, d&amp;rsquo;autres encore au-delà du pétaoctet&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;Il n&amp;rsquo;existe pas vraiment de réponse à cette question et globalement ça va dépendre du type d&amp;rsquo;activité : ratio INSERT/UPDATE/DELETE, type de SELECT (OLTP, OLAP&amp;hellip;).&#xA;Ca dépendra également du matériel. Il y a 10 ans, quand les serveurs n&amp;rsquo;avaient que quelques Go de RAM avec des disques mécaniques, il était probable qu&amp;rsquo;une base de quelques centaines de Go soit perçue comme une grosse base.&#xA;Maintenant il n&amp;rsquo;est pas rare de voir des serveurs avec plus d&amp;rsquo;un téraoctet de RAM, des disques NVMe.&lt;/p&gt;&#xA;&lt;p&gt;Ainsi, une base de quelques centaines de Go n&amp;rsquo;est plus considérée comme une grosse base. Mais plutôt comme une base de taille modeste.&lt;/p&gt;&#xA;&lt;p&gt;Petite anecdote, pour se rassurer, un client m&amp;rsquo;a questionné si Postgres était déjà utilisé pour des volumétries &amp;ldquo;importantes&amp;rdquo;. On parlait alors d&amp;rsquo;une base d&amp;rsquo;une quarantaine de Go sur un serveur qui disposait de 64Go de RAM. Toutes les lectures se faisaient depuis le cache&amp;hellip; :). J&amp;rsquo;ai pu le rassurer sur la taille de sa base qui était relativement modeste.&lt;/p&gt;&#xA;&lt;p&gt;Il peut tout à fait être superflu de partitionner une base de quelques To comme il peut être nécessaire de partitionner une base de quelques centaines de Go. Par exemple, si l&amp;rsquo;activité consiste juste à ajouter des lignes à des tables et que les requêtes se résument à de simple &lt;code&gt;WHERE colonne = 4&lt;/code&gt; qui retournent quelques lignes. Un simple Btree fera l&amp;rsquo;affaire. Et si la requête retourne un nombre assez important de lignes, il est possible d&amp;rsquo;utiliser les index BRIN ou les bloom filter.&lt;/p&gt;&#xA;&lt;p&gt;Les index BRIN présentent des bénéfices proches du partitionnement ou sharding en évitant la complexité de mise en oeuvre&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;il-faut-partitionner-pour-répartir-les-données-sur-plusieurs-disques&#34;&gt;&amp;ldquo;Il faut partitionner pour répartir les données sur plusieurs disques&amp;rdquo;&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;rsquo;idée serait de créer des partitions et des tablespaces sur différents disques afin de répartir les opérations d&amp;rsquo;entrées/sorties.&lt;/p&gt;&#xA;&lt;p&gt;Pour PostgreSQL, un tablespace n&amp;rsquo;est ni plus, ni moins qu&amp;rsquo;un chemin vers un répertoire. Il est tout à fait possible&#xA;de gérer le stockage au niveau du système d&amp;rsquo;exploitation et d&amp;rsquo;agréger plusieurs disques (en RAID10) par exemple.&#xA;Ensuite, il suffit de stocker la table sur le volume créé. Ainsi, on peut répartir les I/O sur un ensemble de disques.&lt;/p&gt;&#xA;&lt;p&gt;Dans ce cas, il n&amp;rsquo;est donc pas nécessaire de mettre en oeuvre le partitionnement. Toutefois, nous verrons un cas où il pourrait avoir du sens.&lt;/p&gt;&#xA;&lt;p&gt;Maintenant nous allons nous intéresser à des cas d&amp;rsquo;usage &amp;ldquo;légitimes&amp;rdquo; du partitionnement.&lt;/p&gt;&#xA;&lt;h1 id=&#34;cas-dusages-du-partitionnement&#34;&gt;Cas d&amp;rsquo;usages du partitionnement&lt;/h1&gt;&#xA;&lt;h2 id=&#34;partitionner-pour-gérer-la-rétention&#34;&gt;Partitionner pour gérer la rétention&lt;/h2&gt;&#xA;&lt;p&gt;A cause du modèle MVCC, la suppression massive de données entraine de la fragmentation dans les tables.&lt;/p&gt;&#xA;&lt;p&gt;Un cas d&amp;rsquo;usage possible est de partitionner par date. Supprimer les anciennes données revient à supprimer une partition complète. L&amp;rsquo;opération sera rapide et les tables ne seront pas fragmentées&lt;/p&gt;&#xA;&lt;h2 id=&#34;partitionner-pour-contrôler-la-fragmentation-des-index&#34;&gt;Partitionner pour contrôler la fragmentation des index&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;rsquo;ajout et modification de données dans une table fragmente les index au fil du temps. Pour faire simple, on ne peut pas récupérer l&amp;rsquo;espace libre dans un bloc tant qu&amp;rsquo;il n&amp;rsquo;est pas vide. Avec le temps les splits d&amp;rsquo;index créent du &amp;ldquo;vide&amp;rdquo; dans ce dernier et le seul moyen de récupérer cet espace est de reconstruire l&amp;rsquo;index.&lt;/p&gt;&#xA;&lt;p&gt;On appelle cela le &amp;ldquo;bloat&amp;rdquo;. Il y a eu de nombreuses améliorations sur les dernières versions de Postgres:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Version 12, on peut lire dans les &lt;a href=&#34;https://www.postgresql.org/docs/12/release-12.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Releases Notes&lt;/a&gt;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Improve performance and space utilization of btree indexes with many duplicates (Peter Geoghegan, Heikki Linnakangas)&lt;/p&gt;&#xA;&lt;p&gt;Previously, duplicate index entries were stored unordered within their duplicate groups. This caused overhead during index inserts, wasted space due to excessive page splits, and it reduced VACUUM&amp;rsquo;s ability to recycle entire pages. Duplicate index entries are now sorted in heap-storage order.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Version 13, on peut lire dans les &lt;a href=&#34;https://www.postgresql.org/docs/13/release-13.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Releases Notes&lt;/a&gt;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;More efficiently store duplicates in B-tree indexes (Anastasia Lubennikova, Peter Geoghegan)&lt;/p&gt;&#xA;&lt;p&gt;This allows efficient B-tree indexing of low-cardinality columns by storing duplicate keys only once. Users upgrading with pg_upgrade will need to use REINDEX to make an existing index use this feature.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Version 14, on peut lire dans les &lt;a href=&#34;https://www.postgresql.org/docs/14/release-14.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Releases Notes&lt;/a&gt;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Allow btree index additions to remove expired index entries to prevent page splits (Peter Geoghegan)&lt;/p&gt;&#xA;&lt;p&gt;This is particularly helpful for reducing index bloat on tables whose indexed columns are frequently updated.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Pour contrôler le bloat, on pourrait reconstruire l&amp;rsquo;index à intervalles réguliers (merci &lt;code&gt;REINDEX CONCURRENTLY&lt;/code&gt; arrivé en version 12). Cette solution serait contraignante, car il faudrait régulièrement reconstruire l&amp;rsquo;intégralité de l&amp;rsquo;index.&lt;/p&gt;&#xA;&lt;p&gt;Si la majorité des modifications sont faites sur les données récentes, par exemple: table de logs, commandes clients, rendez-vous&amp;hellip; On pourrait imaginer un partitionnement par mois. Ainsi, à chaque début de mois on part sur une table &amp;ldquo;neuve&amp;rdquo; et on peut ré-indexer la précédente table pour supprimer le bloat.&lt;/p&gt;&#xA;&lt;p&gt;On peut aussi en profiter pour faire un &lt;code&gt;CLUSTER&lt;/code&gt; sur la table pour avoir une bonne corrélation des données avec le stockage.&lt;/p&gt;&#xA;&lt;h2 id=&#34;partitionner-pour-faciliter-lexécution-de-requête-lorsque-la-cardinalité-est-faible&#34;&gt;Partitionner pour faciliter l&amp;rsquo;exécution de requête lorsque la cardinalité est faible&lt;/h2&gt;&#xA;&lt;p&gt;Petit à petit on va voir des cas d&amp;rsquo;usages un peu plus compliqués :)&lt;/p&gt;&#xA;&lt;p&gt;Prenons un exemple : une table de commande comprenant un statut de livraison, au bout de quelques années 99% des commandes sont livrées (on l&amp;rsquo;espère!) et très peu en cours de paiement ou livraison.&lt;/p&gt;&#xA;&lt;p&gt;Imaginons qu&amp;rsquo;on souhaite récupérer 100 commandes en cours de livraison. On va créer un index sur le statut et l&amp;rsquo;utiliser pour récupérer les enregistrements.&#xA;En étant un peu astucieux, on peut créer un index partiel sur ce statut particulier. Problème, cet index va se fragmenter assez vite au fur et à mesure que les commandes seront livrées.&lt;/p&gt;&#xA;&lt;p&gt;Dans ce cas on pourrait faire un partitionnement sur le statut. Ainsi, récupérer 100 commandes en cours de livraison revient à lire 100 enregistrements de la partition.&lt;/p&gt;&#xA;&lt;h2 id=&#34;partitionner-pour-obtenir-de-meilleures-statistiques&#34;&gt;Partitionner pour obtenir de meilleures statistiques&lt;/h2&gt;&#xA;&lt;p&gt;Pour déterminer le meilleur plan d&amp;rsquo;exécution, Postgres prend des décisions à partir des statistiques d&amp;rsquo;une table. Ces statistiques sont obtenues à partir d&amp;rsquo;un échantillon de la table (le &lt;code&gt;default_statistic_target&lt;/code&gt; qui vaut 100 par défaut).&lt;/p&gt;&#xA;&lt;p&gt;Par défaut le moteur va collecter 300 x &lt;code&gt;default_statistic_target&lt;/code&gt; lignes, soit 30 000 lignes. Avec une table de plusieurs centaines de millions de lignes, cet échantillon est parfois trop petit.&lt;/p&gt;&#xA;&lt;p&gt;On peut augmenter de manière drastique la taille de l&amp;rsquo;échantillon, mais cette approche présente quelques inconvénients:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ca alourdis le temps de planification&lt;/li&gt;&#xA;&lt;li&gt;Ca alourdis le &lt;code&gt;ANALYZE&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Parfois ce n&amp;rsquo;est pas suffisant si les données sont mal réparties. Par exemple si on prend quelques centaines de milliers de lignes sur une table qui comprend plusieurs centaines de millions, on peut rater les lignes dont le statut est en livraison.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Avec le partitionnement on pourrait avoir un même échantillon, mais par partition, ce qui permet de gagner en précision.&lt;/p&gt;&#xA;&lt;p&gt;Ce serait également utile quand on a des données corrélées entre colonnes. Je vais reprendre l&amp;rsquo;exemple des commandes. On a une année entière de commandes: toutes les commandes qui ont plus d&amp;rsquo;un mois sont livrées, celles du dernier mois sont livrées à 90% (10% sont en cours de livraison).&lt;/p&gt;&#xA;&lt;p&gt;Intuitivement, si je cherche une commande en cours de livraison il y a plus de 6 mois je ne devrais pas avoir de résultat. Inversement, si je cherche des commandes en cours de livraison sur le dernier mois, je devrais obtenir 10% de la table. Or, le moteur ne le sait pas, pour lui les commandes en cours de livraison sont réparties sur toute la table.&lt;/p&gt;&#xA;&lt;p&gt;Avec un partitionnement par date, il peut estimer qu&amp;rsquo;il n&amp;rsquo;y a pas de commande en cours de livraisons de plus d&amp;rsquo;un mois. Ce type d&amp;rsquo;approche permet surtout de réduire une erreur d&amp;rsquo;estimation dans un plan d&amp;rsquo;exécution.&lt;/p&gt;&#xA;&lt;p&gt;Voici un exemple avec cette table de commandes, &lt;code&gt;orders_p&lt;/code&gt; est la version partitionnée par mois de la table &lt;code&gt;orders&lt;/code&gt;. Les données étant identiques dans les deux tables.&lt;/p&gt;&#xA;&lt;p&gt;On peut remarquer que l&amp;rsquo;estimation est bien meilleure dans le cas où la table est partitionnée, le moteur ayant des statistiques par partition.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;&#xA;&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 3&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 6&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;19&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;22&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;25&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&#xA;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;EXPLAIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ANALYZE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_p&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;BETWEEN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-01-01&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-01-31&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;                                                  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PLAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;using&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_13_state_idx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_13&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;45&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Cond&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-01-01&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-01-31&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Planning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;120&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Execution&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;059&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;EXPLAIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ANALYZE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;BETWEEN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-01-01&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-01-31&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;                                                  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PLAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;---------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;using&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_state_idx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;44&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13168&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3978&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Cond&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-01-01&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-01-31&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Removed&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100161&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Planning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;188&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Execution&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;141&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;571&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Maintenant prenons la même requête sur le dernier mois:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;&#xA;&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 3&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 6&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;19&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;22&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;26&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&#xA;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;EXPLAIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ANALYZE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_p&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;BETWEEN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-07-01&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-07-31&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;                                                       &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PLAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;using&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_19_state_idx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_19&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;43&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2417&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;19215&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20931&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Cond&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-07-01&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-07-31&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Planning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;297&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Execution&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;618&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;EXPLAIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ANALYZE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;BETWEEN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-07-01&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-07-31&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;                                                     &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PLAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;using&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_state_idx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;44&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13168&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15008&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20931&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Cond&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-07-01&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2021-07-31&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Removed&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;79230&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Planning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;173&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Execution&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;146&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;326&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Ici aussi on peut remarquer que l&amp;rsquo;estimation est meilleure.&lt;/p&gt;&#xA;&lt;h2 id=&#34;partitionwise-join--partitionwise-aggregate&#34;&gt;partitionwise join &amp;amp; partitionwise aggregate&lt;/h2&gt;&#xA;&lt;p&gt;Un autre intérêt du partitionnement est de bénéficier de meilleurs algorithmes pour les jointures et agrégation.&lt;/p&gt;&#xA;&lt;p&gt;Le &lt;code&gt;partitionwise aggregate&lt;/code&gt; permet de faire une agregation ou un regroupement partition par partition. Un exemple vaut mieux qu&amp;rsquo;un long discours:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;&#xA;&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 4&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;16&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20&#xA;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;21&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&#xA;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;explain&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;analyze&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timing&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;off&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_p&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;                                                  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PLAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HashAggregate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;508361&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;508365&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;45&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;365&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;365&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Append&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;408317&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;35&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20008890&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20000000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_01&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1270&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_02&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1270&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[...]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_19&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;45308&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;04&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2941004&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2941004&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_20&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;131708&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;21&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8549421&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8549421&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Planning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;576&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Execution&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5273&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;217&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enable_partitionwise_aggregate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;explain&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;analyze&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timing&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;off&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_p&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;                                                  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PLAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line hl&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Append&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;29&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;408343&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;83&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1765&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;365&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HashAggregate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;29&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;05&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_01&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1270&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HashAggregate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;29&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;05&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_02&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_02&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1270&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[...]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HashAggregate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;60013&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;06&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;60013&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;37&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;31&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_19&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_19&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;45308&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;04&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2941004&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2941004&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HashAggregate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;174455&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;174455&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;55&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;24&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;24&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Scan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orders_20&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cost&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;131708&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;21&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8549421&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;actual&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8549421&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loops&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Planning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;461&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Execution&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4669&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;315&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;63&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Dans le premier cas l&amp;rsquo;agrégation se fait une fois pour toutes les tables, alors que dans le second exemple, on fait l&amp;rsquo;agrégation par partition.&#xA;On peut également remarquer que le coût total est inférieur dans le plan avec agrégation par partition.&lt;/p&gt;&#xA;&lt;p&gt;Le &lt;code&gt;partitionwise join&lt;/code&gt; fonctionne sur le même principe, on fait une jointure partition par partition. C&amp;rsquo;est utile pour joindre deux tables partitionnées.&lt;/p&gt;&#xA;&lt;h2 id=&#34;stockage-avec-tiering&#34;&gt;Stockage avec tiering&lt;/h2&gt;&#xA;&lt;p&gt;Enfin, un autre cas d&amp;rsquo;usage serait de vouloir stocker une partie de la table sur un stockage différent:&lt;/p&gt;&#xA;&lt;p&gt;On peut stocker une table partitionnée dans des tablespaces différents. Par exemple les données récentes sur un tablespace rapide sur SSD NVMe.&#xA;Puis les données plus rarement accédées sur un autre tablespace, avec des disques mécaniques moins couteux.&lt;/p&gt;&#xA;&lt;p&gt;Cette approche peut aussi avoir du sens à l&amp;rsquo;heure du cloud où le stockage est très onéreux.&lt;/p&gt;&#xA;&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&lt;p&gt;Voilà, je pense avoir fait le tour des principaux cas d&amp;rsquo;usages qui me venaient en tête.&lt;/p&gt;&#xA;&lt;p&gt;Evidemment, la mise en oeuvre du partitionnement implique une plus grande complexité (gestion des partitions&amp;hellip;)&#xA;et des limitations qu&amp;rsquo;il faudra étudier en amont.&lt;/p&gt;&#xA;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34;&gt;&#xA;&lt;p&gt;&amp;ldquo;BRIN indexes provide similar benefits to horizontal partitioning or sharding but without needing to explicitly declare partitions.&amp;rdquo; - &lt;a href=&#34;https://en.wikipedia.org/wiki/Block_Range_Index&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/Block_Range_Index&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/div&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>Mesurer facilement la latence I/O avec PostgreSQL 16</title>
    <updated>2023-09-02T16:30:00Z</updated>
    <id>tag:pgphil.ovh,2023-09-02:/traqueur_16_01.php</id>
    <link href="http://pgphil.ovh/traqueur_16_01.php" rel="alternate"></link>
    <summary type="html">Démonstration avec le traqueur d&#39;une nouvelle fonctionnalité PostgreSQL 16 facilitant le suivi des performances et le diagnostic des ralentissements</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>Mettre à jour PostgreSQL pour améliorer les performances</title>
    <updated>2023-05-21T09:00:00Z</updated>
    <id>tag:pgphil.ovh,2023-05-21:/migration_performance_14_15_01.php</id>
    <link href="http://pgphil.ovh/migration_performance_14_15_01.php" rel="alternate"></link>
    <summary type="html">Pagination, ex aequo...obtenez vos résultats triés bien plus rapidement avec PostgreSQL 15</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL inspire les autres SGBD ?</title>
    <updated>2023-04-12T09:00:00Z</updated>
    <id>tag:pgphil.ovh,2023-04-12:/oracle23c_ou_oracle23p_comme_postgresql.php</id>
    <link href="http://pgphil.ovh/oracle23c_ou_oracle23p_comme_postgresql.php" rel="alternate"></link>
    <summary type="html">Oracle 23c ou 23p comme PostgreSQL ?</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>CYCLE</title>
    <updated>2022-12-03T15:00:00Z</updated>
    <id>tag:pgphil.ovh,2022-12-03:/nocycle_15_01.php</id>
    <link href="http://pgphil.ovh/nocycle_15_01.php" rel="alternate"></link>
    <summary type="html">Nouveautés autour des requêtes hiérarchiques avec PostgreSQL 14 et versions supérieures</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>MERGE</title>
    <updated>2022-03-29T17:30:00Z</updated>
    <id>tag:pgphil.ovh,2022-03-29:/upsert_15_devel_01.php</id>
    <link href="http://pgphil.ovh/upsert_15_devel_01.php" rel="alternate"></link>
    <summary type="html">Introduction de la commande MERGE par PostgreSQL 15</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>Limitations du planner (optimiseur) de PostgreSQL</title>
    <updated>2022-03-06T18:45:00Z</updated>
    <id>tag:pgphil.ovh,2022-03-06:/limitations_planner_13_01.php</id>
    <link href="http://pgphil.ovh/limitations_planner_13_01.php" rel="alternate"></link>
    <summary type="html">Est-il toujours possible en 2022 de faire trébucher l&#39;optimiseur statistique de PostgreSQL ? Comment y remédier ?</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>[Infographie] PostgreSQL</title>
    <updated>2021-02-11T11:23:13Z</updated>
    <id>tag:blog.atolcd.com,2021-02-11:/infographie-postgresql/</id>
    <content type="html">&#xA;&lt;p&gt;PostgreSQL est un SGBD que nous affectionnons particulièrement chez Atol CD ! Retrouvez dans cette infographie quelques caractéristiques techniques, des chiffres-clé, son histoire mais aussi pourquoi nous l&amp;rsquo;aimons et notre Top5 des fonctionnalités côté développement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-gallery columns-1 is-cropped wp-block-gallery-1 is-layout-flex wp-block-gallery-is-layout-flex&#34;&gt;&lt;ul class=&#34;blocks-gallery-grid&#34;&gt;&lt;li class=&#34;blocks-gallery-item&#34;&gt;&lt;figure&gt;&lt;img fetchpriority=&#34;high&#34; decoding=&#34;async&#34; width=&#34;866&#34; height=&#34;2560&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-scaled.jpg&#34; alt=&#34;&#34; data-id=&#34;4477&#34; data-full-url=&#34;https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-scaled.jpg&#34; data-link=&#34;https://blog.atolcd.com/infographie-postgresql/infographie_postgresql/&#34; class=&#34;wp-image-4477&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-scaled.jpg 866w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-101x300.jpg 101w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-346x1024.jpg 346w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-768x2271.jpg 768w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-520x1536.jpg 520w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-693x2048.jpg 693w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-600x1774.jpg 600w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-945x2794.jpg 945w&#34; sizes=&#34;(max-width: 866px) 100vw, 866px&#34; /&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/infographie-postgresql/&#34;&gt;[Infographie] PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/infographie-postgresql/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=infographie-postgresql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PostgreSQL est un SGBD que nous affectionnons particulièrement chez Atol CD ! Retrouvez dans cette infographie quelques caractéristiques techniques, des chiffres-clé, son histoire mais aussi pourquoi nous l&amp;#8217;aimons et notre Top5 des fonctionnalités côté développement.&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/infographie-postgresql/&#34;&gt;[Infographie] PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Sortie de PostgreSQL 13</title>
    <updated>2020-09-24T05:54:57Z</updated>
    <id>tag:blog.atolcd.com,2020-09-24:/sortie-de-postgresql-13/</id>
    <content type="html">&#xA;&lt;p&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;&lt;img decoding=&#34;async&#34; class=&#34;alignnone size-full wp-image-4130&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2020/09/pg13.jpg&#34; alt=&#34;&#34; width=&#34;960&#34; height=&#34;540&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2020/09/pg13.jpg 960w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-300x169.jpg 300w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-768x432.jpg 768w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-600x338.jpg 600w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-945x532.jpg 945w&#34; sizes=&#34;(max-width: 960px) 100vw, 960px&#34; /&gt;Malgré des actualités plutôt moroses au Botswana concernant nos chers éléphants, il y en a un qui se porte bien et est encore plus fort à savoir PostgreSQL qui sort en version 13 stable ce jeudi 24 septembre 2020. &lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;Après seulement 3 versions Bêta et une RC le voilà dans les starting blocks pour débarquer sur vos serveurs ! Et comme à chaque nouvelle version son&lt;/span&gt; &lt;span style=&#34;font-weight: 400;&#34;&gt;lot de nouveautés&lt;/span&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;Un petit rappel qui peut parfois éviter bien des catastrophes, si vous avez prévu de migrer vers PostgreSQL 13, vous devriez jeter un oeil sur &lt;a href=&#34;https://www.postgresql.org/docs/13/release-13.html#id-1.11.6.5.4&#34;&gt;les potentielles incompatibilités avec les précédentes versions&lt;/a&gt;  (et aussi sur les versions intermédiaires si vous faite un gap de plusieurs versions d&amp;rsquo;un coup), il est toujours préférable d&amp;rsquo;identifier ces légers changements en amont plutôt qu&amp;rsquo;une fois en production. Mais rassurez-vous, dans cette version pas de quoi freiner significativement une migration.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;h1&gt;Partitionnement&lt;/h1&gt;&#xA;&lt;p&gt;Des améliorations sont ajoutées sur le partitionnement de tables, tant au niveau performance avec l&amp;rsquo;ajout de cas où une jointure directe entre partition peut être utilisée dans une requête, mais aussi de fonctionnalités telles que  la gestion des triggers avec le support de la clause BEFORE ou bien encore la réplication logique sans avoir besoin de publier chaque partition.&lt;/p&gt;&#xA;&lt;h1&gt;Index&lt;/h1&gt;&#xA;&lt;p&gt;Là aussi des améliorations de performances mais aussi des gains d&amp;rsquo;espace disque sur les index B-tree surtout pour ceux contenant des doublons, mais si vous passez par un pg_upgrade il voudra passer par un reindex pour bénéficier de ces changements.&lt;/p&gt;&#xA;&lt;h1&gt;Planificateur&lt;/h1&gt;&#xA;&lt;p&gt;Le planificateur de requête PostgreSQL a lui aussi eu le droit à quelques améliorations notamment au niveau des statistiques ce qui peut améliorer les plans d&amp;rsquo;exécution et donc les performances.&lt;/p&gt;&#xA;&lt;h1&gt;Performance générale&lt;/h1&gt;&#xA;&lt;p&gt;Les performances ne sont pas en reste dans cette nouvelle version, avec l&amp;rsquo;ajout du &lt;span style=&#34;font-weight: 400;&#34;&gt;tri incrémentiel ce qui accélère le tri des données dans certains cas,  sur les agrégations de hachage qui peuvent désormais utiliser le stockage sur disque dans le cadre de grands ensembles d&amp;rsquo;agrégation, sur la conversion de type entier vers texte.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;h1&gt;Vues système&lt;/h1&gt;&#xA;&lt;p&gt;De nouvelles vues système font leur apparition :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/progress-reporting.html#BASEBACKUP-PROGRESS-REPORTING&#34;&gt;pg_stat_progress_basebackup &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/progress-reporting.html#ANALYZE-PROGRESS-REPORTING&#34;&gt;pg_stat_progress_analyze &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/view-pg-shmem-allocations.html&#34;&gt;pg_shmem_allocations &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/monitoring-stats.html#MONITORING-PG-STAT-SLRU-VIEW&#34;&gt;pg_stat_slru&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;la vue &lt;a href=&#34;https://www.postgresql.org/docs/13/monitoring-stats.html#PG-STAT-ACTIVITY-VIEW&#34;&gt;pg_stat_activity&lt;/a&gt; se voit elle ajoutée une colonne leader_pid ce qui permet de retrouver rapidement tous les processus impliqués dans une requête parallèle.&lt;/p&gt;&#xA;&lt;h1&gt;Fonctionnalités&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ajout de la fonctionnalité &lt;a href=&#34;https://www.postgresql.org/docs/13/sql-select.html#SQL-LIMIT&#34;&gt;FETCH FIRST WITH TIES&lt;/a&gt; (vous trouverez &lt;a href=&#34;http://pgphil.ovh/topn_13_beta_01.php&#34;&gt;ici&lt;/a&gt; un exemple)&lt;/li&gt;&#xA;&lt;li&gt;Ajout de la fonction gen_random_uuid() utilisable sans activer d’extensions&lt;/li&gt;&#xA;&lt;li&gt;Ajout de la possibilité de renommer une colonne d&amp;rsquo;une vue :&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;ALTER VIEW [ IF EXISTS ] name RENAME [ COLUMN ] column_name TO new_column_name&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de la fonction .datetime() dans les jsonpath pour convertir automatique une chaîne en date ou horodatage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1&gt;Client psql&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de nouvelles commandes pour afficher la description de classe d&amp;rsquo;opérateur et famille d&amp;rsquo;opérateur&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a class=&#34;link&#34; title=&#34;Meta-Commands&#34; href=&#34;https://www.postgresql.org/docs/13/app-psql.html#APP-PSQL-META-COMMANDS&#34;&gt;&lt;code class=&#34;literal&#34;&gt;\dAc&lt;/code&gt;&lt;/a&gt;, &lt;code class=&#34;literal&#34;&gt;\dAf&lt;/code&gt;, &lt;code class=&#34;literal&#34;&gt;\dAo&lt;/code&gt;, et &lt;code class=&#34;literal&#34;&gt;\dAp&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Ajout du statut de la transaction dans le prompt &lt;br /&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;* dans une transaction&lt;/li&gt;&#xA;&lt;li&gt;! dans un échec de transaction&lt;/li&gt;&#xA;&lt;li&gt;? pour un état indéterminé de la transaction&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1&gt;Administration&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de la capacité de la commande VACUUM à traiter des index en parallèle&lt;/li&gt;&#xA;&lt;li&gt;la commande reindexdb peut aussi paralléliser les tâches&lt;/li&gt;&#xA;&lt;li&gt;introduction de la notion de « trusted extension » qui permet à un super utilisateur de définir les extensions qu’un utilisateur a le droit d&amp;rsquo;installer dans sa base de données en ayant le droit CREATE.&lt;/li&gt;&#xA;&lt;li&gt;Ajout pour pg_dump de l&amp;rsquo;option &amp;#8211;include-foreign-data pour inclure dans la sauvegarde les données de serveurs distants&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La liste des nouveautés dans cette version est grande, toutes les nouveautés n&amp;rsquo;ont pas été abordées mais vous pouvez bien sur les retrouver dans la &lt;a href=&#34;https://www.postgresql.org/docs/13/release-13.html&#34;&gt;note de version&lt;/a&gt;. Le focus a surtout été fait sur le côté utilisateur plutôt qu&amp;rsquo;administrateur de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-13/&#34;&gt;Sortie de PostgreSQL 13&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/sortie-de-postgresql-13/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sortie-de-postgresql-13" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Malgré des actualités plutôt moroses au Botswana concernant nos chers éléphants, il y en a un qui se porte bien et est encore plus fort à savoir PostgreSQL qui sort en version 13 stable ce jeudi 24 septembre 2020.  Après... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-13/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-13/&#34;&gt;Sortie de PostgreSQL 13&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Sortie de PostgreSQL 11</title>
    <updated>2018-10-19T13:12:39Z</updated>
    <id>tag:blog.atolcd.com,2018-10-19:/sortie-de-postgresql-11/</id>
    <content type="html">&lt;p&gt;Après seulement une release candidate (mais auparavant 4 version bêta), PostgreSQL 11 vient de sortir!!!! Et comme à chaque nouvelle version son lot de nouveautés que nous allons essayer de passer rapidement en revue.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-3169&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11.jpg&#34; alt=&#34;&#34; width=&#34;826&#34; height=&#34;540&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11.jpg 826w, https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11-300x196.jpg 300w, https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11-768x502.jpg 768w, https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11-600x392.jpg 600w&#34; sizes=&#34;(max-width: 826px) 100vw, 826px&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Amélioration de la parallélisation&lt;/h2&gt;&#xA;&lt;p&gt;Quoi de mieux que de commencer le tour des nouveautés par un sujet que l&amp;rsquo;on a abordé lors du &lt;a href=&#34;https://blog.atolcd.com/conference-la-parallelisation-au-service-de-loptimisation/&#34;&gt;PG Day France 2018&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 11 va encore plus loin dans la parallélisation avec :&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Création d&amp;rsquo;index B-tree en parallèle&lt;/li&gt;&#xA;&lt;li&gt;Parallélisation des UNION ALL&lt;/li&gt;&#xA;&lt;li&gt;Amélioration du Parallel hash join (paralléliser le remplissage d’une seule table de hachage, partagée) et parallelized sequential scans&lt;/li&gt;&#xA;&lt;li&gt;Parallélisation sur la création de vue matérialisée et table à partir des résultats d&amp;rsquo;une requête&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE .. AS, SELECT INTO et CREATE MATERIALIZED VIEW.&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout d&amp;rsquo;un paramètre de configuration du serveur « parallel_leader_participation » qui permet de contrôler si le processus leader participe à l&amp;rsquo;exécution des sous plans d&amp;rsquo;exécution&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Amélioration du partitionnement&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;La possibilité de partitionner une table par hashage de clé (en plus des autres)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE hash1 (col1 NUMERIC, col2 VARCHAR(10)) PARTITION BY HASH(col1);&#xD;&#xA;CREATE TABLE hash1a PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 0) ;&#xD;&#xA;CREATE TABLE hash1b PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 1) ;&#xD;&#xA;CREATE TABLE hash1c PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 2) ;&#xD;&#xA;CREATE TABLE hash1d PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 3) ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout possible d&amp;rsquo;une partition par défaut pour les données ne correspondant à aucune partition&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE table1d PARTITION OF table1 DEFAULT;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;La possibilité de créer des clés primaires, clés étrangères, index et triggers qui seront automatiquement applicables sur l&amp;rsquo;ensemble des partitions&lt;/li&gt;&#xA;&lt;li&gt;Support du changement automatique de partition en cas de mise à jour de la clé de partitionnement&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances lors des SELECT sur la lecture des partitions&lt;/li&gt;&#xA;&lt;li&gt;Support des upsert sur les tables partitionnées&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;INSERT  INTO  tablep1 (col1, col2) &#xD;&#xA;VALUES  (100,  &#39;update&#39;) &#xD;&#xA;ON  CONFLICT ON CONSTRAINT tablep1_pkey &#xD;&#xA;DO UPDATE SET col2=&#39;update&#39; ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Gestion des transactions dans les procédures stockées&lt;/h2&gt;&#xA;&lt;p&gt;PostgreSQL 11 introduit la possibilité de créer des procédures (en PL/pgSQL, PL/Perl, PL/Python, et PL/Tcl). Depuis de nombreuses années, il est possible dans PostgreSQL de créer des fonctions et bien ici ça y ressemble fortement, sauf que l&amp;rsquo;on ne retourne pas de résultats et que l&amp;rsquo;on peut gérer les transactions !&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE PROCEDURE transaction_test1()&#xD;&#xA;LANGUAGE plpgsql&#xD;&#xA;AS $$&#xD;&#xA;BEGIN&#xD;&#xA;  FOR i IN 0..9 LOOP&#xD;&#xA;    INSERT INTO table1 (col1) VALUES (i) ;&#xD;&#xA;    IF i % 2 = 0 THEN&#xD;&#xA;      COMMIT;&#xD;&#xA;    ELSE&#xD;&#xA;      ROLLBACK;&#xD;&#xA;    END IF;&#xD;&#xA;  END LOOP;&#xD;&#xA;END;&#xD;&#xA;$$;&lt;/pre&gt;&lt;p&gt;L&amp;rsquo;exécution de ces procédures se fait en utilisant la commande CALL&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CALL transaction_test1();&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Compilation JIT&lt;/h2&gt;&#xA;&lt;p&gt;PostgreSQL 11 introduit le support de la compilation Just-in-Time (JIT) pour optimiser l’exécution de code et d’autres opérations. Utilisant des composants du projet LLVM, l’introduction de JIT dans PostgreSQL accélère les requêtes utilisant des expressions, listes, agrégats, projections, ainsi que certaines opérations internes.&lt;/p&gt;&#xA;&lt;p&gt;Pour pouvoir utiliser la compilation JIT, vous devrez installer la dépendance LLVM puis activer la compilation JIT soit dans le fichier de configuration (jit = on), soit durant votre session en exécutant SET jit = on.&lt;/p&gt;&#xA;&lt;p&gt;La compilation JIT bénéficie surtout aux requêtes de longue durée et limitées par le processeur. Ce seront souvent des requêtes analytiques (OLAP). Pour les requêtes courtes, le surcoût apporté par la compilation JIT sera souvent supérieur au temps qu&amp;rsquo;elle permet de gagner.&lt;/p&gt;&#xA;&lt;h2&gt;Améliorations générales SQL&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Support de toutes les clauses (SQL:2011) dans les fonctions de fenêtrage ce qui permet maintenant l’utilisation de RANGE dans des clauses PRECEDING/FOLLOWING, GROUPS ou d’exclusion&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;WINDOW window_name AS ( &#xD;&#xA;  [ PARTITION BY expression [, ...] ]&#xD;&#xA;  [ ORDER BY expression [ ASC | DESC | USING operator ] [ NULLS { FIRST | LAST } ] [, ...] ]&#xD;&#xA;  [ frame_clause ]&#xD;&#xA;)&#xD;&#xA;&#xD;&#xA;frame_clause :&#xD;&#xA;{ RANGE | ROWS | GROUPS } frame_start [ frame_exclusion ]&#xD;&#xA;{ RANGE | ROWS | GROUPS } BETWEEN frame_start AND frame_end [ frame_exclusion ]&#xD;&#xA;&#xD;&#xA;frame_start / frame_end :&#xD;&#xA;&#xD;&#xA;UNBOUNDED PRECEDING&#xD;&#xA;offset PRECEDING&#xD;&#xA;CURRENT ROW&#xD;&#xA;offset FOLLOWING&#xD;&#xA;UNBOUNDED FOLLOWING&#xD;&#xA;&#xD;&#xA;frame_exclusion :&#xD;&#xA;&#xD;&#xA;EXCLUDE CURRENT ROW&#xD;&#xA;EXCLUDE GROUP&#xD;&#xA;EXCLUDE TIES&#xD;&#xA;EXCLUDE NO OTHERS&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de fonctions de hash sha-2 : sha224(), sha256(), sha384() et sha512()&lt;/li&gt;&#xA;&lt;li&gt;Ajout de fonctions de recherche plein texte : json(b)_to_tsvector() et websearch_to_tsquery()&lt;/li&gt;&#xA;&lt;li&gt;Ajout de l&amp;rsquo;opérateur ^@ identique à LIKE &amp;lsquo;mot%&amp;rsquo; mais plus efficace sur un index b-tree&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;text ^@ text&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Amélioration des index avec l&amp;rsquo;ajout du mot clef INCLUDE, qui permet d&amp;rsquo;indiquer une liste de colonnes qui seront incluses dans l&amp;rsquo;index comme des colonnes non clés. L&amp;rsquo;ajout de colonnes dans la création d&amp;rsquo;index permet alors l&amp;rsquo;utilisation de parcours d&amp;rsquo;index couvrants.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] nom ] ON [ ONLY ] nom_table [ USING méthode ]&#xD;&#xA;    ( { nom_colonne | ( expression ) } [ COLLATE collation ] [ classeop ] [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, ...] )&#xD;&#xA;    [ INCLUDE ( nom_colonne [, ...] ) ]&#xD;&#xA;    [ WITH ( parametre_stockage = valeur [, ... ] ) ]&#xD;&#xA;    [ TABLESPACE nom_espacelogique ]&#xD;&#xA;    [ WHERE prédicat ]&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Amélioration de l’ordre ALTER TABLE .. ADD COLUMN .. DEFAULT .. avec une valeur par défaut non NULL n’a plus besoin de réécrire entièrement la table lors de son exécution, ce qui entraîne une grosse amélioration des performances.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Authentification&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de l&amp;rsquo;authentification LDAP, mais celle ci n&amp;rsquo;est utilisée que pour valider les paires nom d&amp;rsquo;utilisateur/mot de passe. De ce fait, pour pouvoir utiliser LDAP comme méthode d&amp;rsquo;authentification, l&amp;rsquo;utilisateur doit préalablement exister dans la base.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;psql&lt;/h2&gt;&#xA;&lt;p&gt;Le client psql évolue lui aussi :&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout des commandes « quit » et « exit » dans le client psql&amp;#8230; (fini les personnes prisent de panique pour sortir de leur terminal ??? )&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://media.giphy.com/media/xTk9ZBWrma4PIC9y4E/giphy.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de la commande \gdesc pour afficher les noms et types de colonnes du résultat de la requête&lt;/li&gt;&#xA;&lt;li&gt;Ajout de variables pour les erreurs et activités des requêtes ERROR, SQLSTATE, ROW_COUNT, LAST_ERROR_MESSAGE, and LAST_ERROR_SQLSTATE.&lt;/li&gt;&#xA;&lt;li&gt;Ajout de la possibilité de tester l&amp;rsquo;existence d&amp;rsquo;une variable par exemple dans un if&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;\if :{?variable_name}&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Amélioration de la complétion dans l&amp;rsquo;écriture de requêtes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;En dehors de ces nouveautés en terme d&amp;rsquo;utilisation, cette nouvelle version apporte aussi des améliorations de performance et d&amp;rsquo;utilisation de mémoire.&lt;/p&gt;&#xA;&lt;p&gt;Et voilà, nous avons fini notre petit tour rapide des nouveautés de postgreSQL 11, mais ne vous inquiétez pas une version 12 est déjà en préparation pour le troisième trimestre 2019.&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-11/&#34;&gt;Sortie de PostgreSQL 11&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/sortie-de-postgresql-11/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sortie-de-postgresql-11" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Après seulement une release candidate (mais auparavant 4 version bêta), PostgreSQL 11 vient de sortir!!!! Et comme à chaque nouvelle version son lot de nouveautés que nous allons essayer de passer rapidement en revue. Amélioration de la parallélisation Quoi de... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-11/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-11/&#34;&gt;Sortie de PostgreSQL 11&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Pimp My PostgreSQL</title>
    <updated>2018-01-26T11:07:23Z</updated>
    <id>tag:blog.atolcd.com,2018-01-26:/pimp-my-postgresql/</id>
    <content type="html">&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignright wp-image-2934&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2018/01/pimp-my-postgresql.png&#34; alt=&#34;&#34; width=&#34;491&#34; height=&#34;290&#34; /&gt;Une question qui se pose souvent après l&amp;rsquo;installation d&amp;rsquo;une instance postgreSQL, c&amp;rsquo;est comment configurer ce fichier postgresql.conf. Dans le doute souvent, beaucoup de personnes conservent la configuration par défaut, ce qui ne va pas poser vraiment de problème pour une utilisation légère. Mais si on a une instance postgreSQL avec postGIS et des millions d&amp;rsquo;enregistrements, cela va rapidement se trouver problématique si on laisse les valeurs par défaut&amp;#8230;&lt;/p&gt;&#xA;&lt;p&gt;Pour les initiés qui installent régulièrement de nouvelles instances postgreSQL, se plonger dans les plus de 600 lignes du fichier de configuration par défaut ne les effraie pas. Mais on n&amp;rsquo;installe pas forcément tous les jours un nouveau serveur avec des caractéristiques différentes. Il faut donc soit se replonger pour une centième fois dans la documentation de postgres pour se rappeler à notre bonne mémoire les différents paramètres et les valeurs à adapter en fonction de la ram, disque, cpu&amp;#8230;&lt;/p&gt;&#xA;&lt;p&gt;En plus de devoir se rappeler les &lt;strong&gt;paramètres à modifier,&lt;/strong&gt; il faut aussi connaître les &lt;strong&gt;règles de calcul &lt;/strong&gt;pour les valeurs comme par exemple le « effective_cache_size » qui est préconisé à 75% de la ram total du serveur si celui-ci est dédié à postgres.&lt;/p&gt;&#xA;&lt;p&gt;Le but de cet article n&amp;rsquo;est pas de voir ni de détailler tous les paramètres de configuration possibles et inimaginables, mais de voir cela comme un mémo pour les initiés ou de s’interroger sur les &lt;strong&gt;paramètres qui seraient potentiellement à modifier en fonction du serveur&lt;/strong&gt; (et des applications qui l&amp;rsquo;utilisent) si l&amp;rsquo;on ne connait pas l&amp;rsquo;utilisation des paramètres de ce fichier postgresql.conf.&lt;/p&gt;&#xA;&lt;p&gt;Pour cela un petit outil a été conçu par Cybertec, qui permet de renseigner quelques caractéristiques et de voir évoluer en conséquence le fichier postgresql.conf notamment en fonction de la ram du serveur, du nombre de cpu, de la taille de la base&amp;#8230; etc.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;alignnone size-full wp-image-2925&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator.png&#34; alt=&#34;&#34; width=&#34;1005&#34; height=&#34;993&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator.png 1005w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-300x296.png 300w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-768x759.png 768w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-945x934.png 945w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-600x593.png 600w&#34; sizes=&#34;auto, (max-width: 1005px) 100vw, 1005px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cela ne remplace pas une connaissance aguerrie de postgreSQL et de sa configuration mais ça permet de se faire une idée des paramètres à adapter en fonction de son serveur et de ses besoins.&lt;/p&gt;&#xA;&lt;p&gt;Cet outil est disponible en ligne à cette adresse : &lt;a href=&#34;http://pgconfigurator.cybertec.at/&#34;&gt;http://pgconfigurator.cybertec.at/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/pimp-my-postgresql/&#34;&gt;Pimp My PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/pimp-my-postgresql/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pimp-my-postgresql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Une question qui se pose souvent après l&amp;#8217;installation d&amp;#8217;une instance postgreSQL, c&amp;#8217;est comment configurer ce fichier postgresql.conf. Dans le doute souvent, beaucoup de personnes conservent la configuration par défaut, ce qui ne va pas poser vraiment de problème pour une... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/pimp-my-postgresql/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/pimp-my-postgresql/&#34;&gt;Pimp My PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Sortie de PostgreSQL 10</title>
    <updated>2017-10-05T13:28:32Z</updated>
    <id>tag:blog.atolcd.com,2017-10-05:/sortie-de-postgresql-10/</id>
    <content type="html">&lt;p&gt;Aujourd&amp;rsquo;hui, c&amp;rsquo;est la sortie de &lt;strong&gt;PostgreSQL 10&lt;/strong&gt;!!!! Première révolution, la numérotation des versions : on passe de 9.4&amp;#8230;9.6 pour les versions majeures à 10, 11, 12&amp;#8230; Ce point est important car un changement de version majeure implique une migration des données. Une opération beaucoup plus lourde que la seule mise à jour des exécutables !&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-2788&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/10/postgresql-10.jpg&#34; alt=&#34;&#34; width=&#34;558&#34; height=&#34;337&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/10/postgresql-10.jpg 558w, https://blog.atolcd.com/wp-content/uploads/2017/10/postgresql-10-300x181.jpg 300w&#34; sizes=&#34;auto, (max-width: 558px) 100vw, 558px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Voici quelques détails sur cette&lt;strong&gt; nouvelle version 10&lt;/strong&gt; et ce qu&amp;rsquo;elle apporte :&lt;/p&gt;&#xA;&lt;h2&gt;Performance et partitionnement&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Le partitionnement de table est maintenant un attribut de la table :&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE table_name ( ... )&#xD;&#xA;[ PARTITION BY { RANGE | LIST } ( { column_name | ( expression ) }&#xD;&#xA;&#xD;&#xA;CREATE TABLE table_name&#xD;&#xA;PARTITION OF parent_table [ (&#xD;&#xA;) ] FOR VALUES partition_bound_spec&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;PostgreSQL 10 va plus loin dans la parallélisation avec le parallélisme des Index-Only Scan, Index Scan, Bitmap Heap Scan, Merge Join / Gather Merge, Subplan-Related Improvements&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances pour les agrégats et jointures avec &lt;code&gt;postgres_fdw&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances de l&amp;rsquo;analyseur de requête&lt;/li&gt;&#xA;&lt;li&gt;Apparition des statistiques multi-colonnes&lt;/li&gt;&#xA;&lt;li&gt;Amélioration du plan d’exécution des requêtes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Réplication et scalabilité&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Réplication logique : légère et basée sur les WAL, répliquant les objets individuellement via les commandes PUBLICATION (primaire) et SUBSCRIPTION (secondaire)&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE PUBLICATION financials FOR TABLE ONLY loans, ONLY fines;&lt;/pre&gt;&lt;br /&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE SUBSCRIPTION financials&#xD;&#xA;CONNECTION &#39;dbname=libdata user=postgres host=172.17.0.2&#39;&#xD;&#xA;PUBLICATION financials;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;QUORUM replication : avec ANY et FIRST pour synchronous_standby_names;&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;synchronous_standby_names = ANY 2(node1,node2,node3);&#xD;&#xA;synchronous_standby_names = FIRST 2(node1,node2);&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Suppression automatique à la fin de la session des slots de réplication temporaires&lt;/li&gt;&#xA;&lt;li&gt;Amélioration de libpq permettant des connexions a de multiples systèmes&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances de la réplication physique&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Administration&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Support de la compression pour pg_receivewal&lt;/li&gt;&#xA;&lt;li&gt;Ajout d&amp;rsquo;informations sur les Background processes et Wait Events dans pg_stat_activity&lt;/li&gt;&#xA;&lt;li&gt;Ajout de fonctions qui remontent à l&amp;rsquo;utilisateur des informations sur le status de transaction. L&amp;rsquo;usage principal de ces fonctions est de déterminer les transactions commitées entre deux snapshots.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;txid_status(bigint)&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Fonctionnalités SQL et développeurs&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Gestion de colonne Identity qui vise à remplacer l&amp;rsquo;utilisation du type serial et qui est conforme au standard SQL&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE test_new (&#xD;&#xA;    id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,&#xD;&#xA;    payload text&#xD;&#xA;);&lt;/pre&gt;&lt;p&gt;plus d&amp;rsquo;informations sur ce sujet &lt;a href=&#34;https://blog.2ndquadrant.com/postgresql-10-identity-columns/&#34;&gt;ici par exemple&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Possibilité de renommer la valeur d&amp;rsquo;une énumération&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TYPE langage AS ENUM (&#39;SQL&#39;, &#39;JAVA&#39;, &#39;HTML&#39;) ;&#xD;&#xA;ALTER TYPE langage RENAME VALUE &#39;HTML&#39; TO &#39;HTML5&#39; ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout des triggers AFTER STATEMENT qui peuvent avoir accès à l’ensemble des lignes modifiées, avant et après changement, à travers une pseudo-variable de type table&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TRIGGER nom_trigger AFTER DELETE ON nom_table&#xD;&#xA;REFERENCING OLD TABLE AS OLD&#xD;&#xA;FOR EACH STATEMENT&#xD;&#xA;EXECUTE PROCEDURE nom_procedure();&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de la fonction xmltable qui produit une table basée sur la valeur XML donnée.&lt;/li&gt;&#xA;&lt;li&gt;Supprimer des éléments d&amp;rsquo;un JSONB&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;SELECT &#39;{&#34;a&#34;:1 , &#34;b&#34;:2, &#34;c&#34;:3}&#39;::jsonb - &#39;{a,c}&#39;::text[] ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Il est possible de créer des indexes full text sur une colonne JSON ou JSONB&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE INDEX bookdata_fts ON bookdata&#xD;&#xA;USING gin (( to_tsvector(&#39;english&#39;,bookdata) ));&#xD;&#xA;&#xD;&#xA;SELECT bookdata -&amp;gt; &#39;title&#39;&#xD;&#xA;FROM bookdata&#xD;&#xA;WHERE to_tsvector(&#39;english&#39;,bookdata) @@ to_tsquery(&#39;duke&#39;);&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Sécurité&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Authentification SCRAM plus sécurisée que md5&lt;/li&gt;&#xA;&lt;li&gt;Création de nouveau rôle pour le monitoring évitant ainsi d&amp;rsquo;être super utilisateur&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;pg_read_all_settings : Lit toutes les variables de configuration, y compris celles normalement visibles des seuls super-utilisateurs.&#xD;&#xA;pg_read_all_stats : Lit toutes les vues pg_stat_* et utilise plusieurs extensions relatives aux statistiques, y compris celles normalement visibles des seuls super-utilisateurs.&#xD;&#xA;pg_stat_scan_tables : Exécute des fonctions de monitoring pouvant prendre des verrous verrous ACCESS SHARE sur les tables, potentiellement pour une longue durée.&#xD;&#xA;pg_monitor : Lit et exécute plusieurs vues et fonctions de monitoring. Ce rôle est membre de pg_read_all_settings, pg_read_all_stats et pg_stat_scan_tables.&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de politiques restrictive dans les politiques de sécurité pour l&amp;rsquo;accès aux lignes et plus seulement de politiques permissives&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE POLICY admin_local_only ON passwd AS RESTRICTIVE TO admin&#xD;&#xA;    USING (pg_catalog.inet_client_addr() IS NULL);&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Autres fonctionnalités&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;file_fdw peut maintenant utiliser les programmes&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE FOREIGN TABLE&#xD;&#xA;   test(a int, b text)&#xD;&#xA;   SERVER csv&#xD;&#xA;   OPTIONS (program &#39;gunzip -c /tmp/data.czv.gz&#39;);&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;support des collations ICU&lt;/li&gt;&#xA;&lt;li&gt;Ajout d&amp;rsquo;un module amcheck permettant de vérifier cohérence / corruption d&amp;rsquo;un index B-Tree&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE EXTENSION amcheck ;&#xD;&#xA;   SELECT bt_index_check(&#39;idx1_check1&#39;) ;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Modifications entrainant une incompatibilité ascendante&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;“xlog” et “clog” qui deviennent respectivement “wal” et “xact”.&lt;/li&gt;&#xA;&lt;li&gt;fin du support du protocole client/serveur 1.0 (clients datant d’avant la version 6.3)&lt;/li&gt;&#xA;&lt;li&gt;changement de valeurs par défaut pour pg_basebackup&lt;/li&gt;&#xA;&lt;li&gt;fin du support des TIMESTAMP avec floating point.&lt;/li&gt;&#xA;&lt;li&gt;Le module contrib/tsearch2 a été supprimé qui permettait une comptabilité avec les fonction de recherche full text avant la version 8.3&lt;/li&gt;&#xA;&lt;li&gt;fin du support de la commande pg_dump pour les bases de données plus anciennes que la version 8.0&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Et voilà, nous avons fini notre petit tour rapide des nouveautés de postgreSQL 10 mais une version 11 est déjà prévue pour dans 12 mois !&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-10/&#34;&gt;Sortie de PostgreSQL 10&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/sortie-de-postgresql-10/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sortie-de-postgresql-10" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Aujourd&amp;#8217;hui, c&amp;#8217;est la sortie de PostgreSQL 10!!!! Première révolution, la numérotation des versions : on passe de 9.4&amp;#8230;9.6 pour les versions majeures à 10, 11, 12&amp;#8230; Ce point est important car un changement de version majeure implique une migration des... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-10/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/sortie-de-postgresql-10/&#34;&gt;Sortie de PostgreSQL 10&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Nouveau module d’export de données pour REMOcRA</title>
    <updated>2017-05-12T13:52:26Z</updated>
    <id>tag:blog.atolcd.com,2017-05-12:/nouveau-module-dexport-de-donnees-remocra/</id>
    <content type="html">&lt;h1&gt;Objectif du module&lt;/h1&gt;&#xA;&lt;p&gt;Le SDIS du Var ne disposait pas jusqu&amp;rsquo;à ce jour, à travers la plate-forme collaborative &lt;a href=&#34;http://sdis.atolcd.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;REMOcRA&lt;/a&gt;, d&amp;rsquo;une méthode simple pour exporter le contenu de la base de données auprès de ses partenaires. Les demandes étant de plus en plus récurrentes, le SDIS du Var a décidé &lt;strong&gt;de faire évoluer l&amp;rsquo;application pour l&amp;rsquo;enrichir d&amp;rsquo;un module dédié aux exports&lt;/strong&gt; et a confié à Atol Conseils et Développements sa réalisation en veillant à respecter les besoins suivants :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;En tant qu&amp;rsquo;administrateur de l&amp;rsquo;extranet, être en mesure de réaliser facilement des exports de données en se basant sur des modèles administrables. Ce module devait être en mesure de produire des fichiers tabulaires ou des fichiers géographiques.&lt;/li&gt;&#xA;&lt;li&gt;En tant que partenaire, être en mesure d&amp;rsquo;exporter soit même les données mises à disposition par le SDIS sur un territoire autorisé.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1&gt;Comment ça marche ?&lt;/h1&gt;&#xA;&lt;h2&gt;Un fonctionnement basé sur des modèles d&amp;rsquo;exports&lt;/h2&gt;&#xA;&lt;p&gt;Le mécanisme d&amp;rsquo;export repose sur des modèles. Ces derniers peuvent être référencés directement par les administrateurs de la plate-forme REMOcRA grâce à des fichiers de définition de modèle (format XML) déposés fia FTP dans un sous-dossier de REMOcRA.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-large wp-image-2626&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-1024x220.png&#34; alt=&#34;&#34; width=&#34;676&#34; height=&#34;145&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-1024x220.png 1024w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-300x64.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-768x165.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-945x203.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-600x129.png 600w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1.png 1067w&#34; sizes=&#34;auto, (max-width: 676px) 100vw, 676px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Le fichier XML précise principalement la requête SQL à utiliser pour filtrer et formater les données à la bonne structure. L&amp;rsquo;attribut spatial du nœud racine permet de préciser si l&amp;rsquo;export est de type tabulaire (CSV) ou géographique (Esri Shapefile). Dans le cas d&amp;rsquo;un export géographique, la colonne « wkt » contenant la géométrie encodée en WKT est exploitée.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-2627&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2.png&#34; alt=&#34;&#34; width=&#34;822&#34; height=&#34;341&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2.png 822w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2-300x124.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2-768x319.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2-600x249.png 600w&#34; sizes=&#34;auto, (max-width: 822px) 100vw, 822px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Le référencement des modèles est réalisé directement depuis l&amp;rsquo;interface en exécutant depuis REMOcRA le traitement « Référencer les modèles d&amp;rsquo;export de données » disponible dans la catégorie d&amp;rsquo;applications « Divers »&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-2628&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3.png&#34; alt=&#34;&#34; width=&#34;968&#34; height=&#34;288&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3.png 968w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-300x89.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-768x228.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-945x281.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-600x179.png 600w&#34; sizes=&#34;auto, (max-width: 968px) 100vw, 968px&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Un traitement spécifique intégrant le filtrage spatial des données&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-large wp-image-2629&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-1024x525.png&#34; alt=&#34;&#34; width=&#34;676&#34; height=&#34;347&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-1024x525.png 1024w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-300x154.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-768x394.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-945x484.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-600x307.png 600w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4.png 1167w&#34; sizes=&#34;auto, (max-width: 676px) 100vw, 676px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;La réalisation d&amp;rsquo;un export de données depuis le système REMOcRA se base sur le mécanisme suivant :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;L&amp;rsquo;utilisateur de profil « administrateur » dispose d&amp;rsquo;un nouveau traitement intitulé « Exporter les données à partir d&amp;rsquo;un modèle ». Ce dernier permet de réaliser des exports de données en s&amp;rsquo;appuyant sur la liste de modèles.&lt;/li&gt;&#xA;&lt;li&gt;Après avoir choisi son modèle, la demande d&amp;rsquo;export formulée par l&amp;rsquo;utilisateur est stockée en file d&amp;rsquo;attente. Une tâche planifiée vérifie régulièrement la présence de demandes en attente&lt;/li&gt;&#xA;&lt;li&gt;Lors de l’exécution de la tâche planifiée, le moteur ETL exécute les demandes d&amp;rsquo;export en attente en s&amp;rsquo;appuyant sur les informations contenues dans le modèle pour générer un fichier CSV (dans le cas de données non géographiques) ou des fichiers de formes (fichiers ESRI Shapefile).&lt;/li&gt;&#xA;&lt;li&gt;A l&amp;rsquo;issu du traitement, les fichiers produits sont compressés au format ZIP et un lien de téléchargement est fourni dans un mél envoyé au demandeur du traitement.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; class=&#34;aligncenter size-full wp-image-2630&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5.png&#34; alt=&#34;&#34; width=&#34;962&#34; height=&#34;367&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5.png 962w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-300x114.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-768x293.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-945x361.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-600x229.png 600w&#34; sizes=&#34;auto, (max-width: 962px) 100vw, 962px&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Une mutualisation des connaissances !&lt;/h2&gt;&#xA;&lt;p&gt;Le SDIS du Var (83), à l&amp;rsquo;initiative de la plate-forme collaborative métier REMOcRA, a décidé de faire bénéficier ses confrères de sa démarche en redistribuant gratuitement l&amp;rsquo;outil et ce module sous licence Creative Commons.&lt;br /&gt;&#xA;Dans cette démarche open source, la solution et le nouveau module sont disponibles sur Github pour installation et test à tous les SDIS sur &lt;a href=&#34;https://github.com/atolcd/sdis-remocra&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/atolcd/sdis-remocra&lt;/a&gt;. Pour plus d&amp;rsquo;information sur la solution REMOcRA, consulter &lt;a href=&#34;http://sdis.atolcd.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;http://sdis.atolcd.com&lt;/a&gt;&lt;br /&gt;&#xA;&lt;em&gt;REMOcRA est cofinancé par l’Union européenne. L’Europe s’engage avec le Fonds européen de développement régional.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/&#34;&gt;Nouveau module d&amp;rsquo;export de données pour REMOcRA&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=nouveau-module-dexport-de-donnees-remocra" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Objectif du module Le SDIS du Var ne disposait pas jusqu&amp;#8217;à ce jour, à travers la plate-forme collaborative REMOcRA, d&amp;#8217;une méthode simple pour exporter le contenu de la base de données auprès de ses partenaires. Les demandes étant de plus... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a href=&#34;https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/&#34;&gt;Nouveau module d&amp;rsquo;export de données pour REMOcRA&lt;/a&gt; est apparu en premier sur &lt;a href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Nouveau dans pg13: Colonne leader_pid dans pg_stat_activity</title>
    <updated>2020-03-08T05:33:26Z</updated>
    <id>tag:rjuju.github.io,2020-03-08:/postgresqlfr/2020/03/08/nouveau-dans-pg13-leader_pid.html</id>
    <content type="html">&lt;h3 id=&#34;nouvelle-colonne-leader_pid-dans-la-vue-pg_stat_activity&#34;&gt;Nouvelle colonne leader_pid dans la vue pg_stat_activity&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Étonnamment, depuis que les requêtes parallèles ont été ajoutées dans&#xA;PostgreSQL 9.6, il était impossible de savoir à quel processus client était lié&#xA;un worker parallèle.  Ainsi, comme &lt;a href=&#34;https://twitter.com/g_lelarge/status/1209486212190343168&#34;&gt;Guillaume l’a fait&#xA;remarquer&lt;/a&gt;, it makes&#xA;il est assez difficile de construire des outils simples permettant&#xA;d’échantillonner les événements d’attente liés à tous les processus impliqués&#xA;dans une requête.  Une solution simple à ce problème est d’exporter&#xA;l’information de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;lock group leader&lt;/code&gt; disponible dans le processus client au&#xA;niveau SQL :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit b025f32e0b5d7668daec9bfa957edf3599f4baa8&#xA;Author: Michael Paquier &amp;lt;michael@paquier.xyz&amp;gt;&#xA;Date:   Thu Feb 6 09:18:06 2020 +0900&#xA;&#xA;Add leader_pid to pg_stat_activity&#xA;&#xA;This new field tracks the PID of the group leader used with parallel&#xA;query.  For parallel workers and the leader, the value is set to the&#xA;PID of the group leader.  So, for the group leader, the value is the&#xA;same as its own PID.  Note that this reflects what PGPROC stores in&#xA;shared memory, so as leader_pid is NULL if a backend has never been&#xA;involved in parallel query.  If the backend is using parallel query or&#xA;has used it at least once, the value is set until the backend exits.&#xA;&#xA;Author: Julien Rouhaud&#xA;Reviewed-by: Sergei Kornilov, Guillaume Lelarge, Michael Paquier, Tomas&#xA;Vondra&#xA;Discussion: https://postgr.es/m/CAOBaU_Yy5bt0vTPZ2_LUM6cUcGeqmYNoJ8-Rgto+c2+w3defYA@mail.gmail.com&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Avec cette modification, il est maintenant très simple de trouver tous les&#xA;processus impliqués dans une requête parallèle.  Par exemple :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;=#&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;  &lt;span class=&#34;n&#34;&gt;array_agg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;members&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_stat_activity&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;IS&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;GROUP&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;       &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;members&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-------------------+------------+---------------&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;      &lt;span class=&#34;mi&#34;&gt;31630&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32269&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32268&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Attention toutefois, comme indiqué dans le message de commit, si la colonne&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;leader_pid&lt;/code&gt; à la même valeur que la colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pid&lt;/code&gt;, cela ne veut pas forcément&#xA;dire que le processus client est actuellement en train d’effectuer une requête&#xA;parallèle, car une fois que le champ est positionné il n’est jamais&#xA;réinitialisé.  De plus, pour éviter tout surcoût, aucun verrou supplémentaire&#xA;n’est maintenu lors de l’affichage de ces données.  Cela veut dire que chaque&#xA;ligne est traitée indépendamment.  Ainsi, bien que cela soit fort peu probable,&#xA;vous pouvez obtenir des données incohérentes dans certaines circonstances,&#xA;comme par exemple un worker paralèlle pointant vers un pid qui est déjà&#xA;déconnecté.&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2020/03/08/nouveau-dans-pg13-leader_pid.html&#34;&gt;Nouveau dans pg13: Colonne leader_pid dans pg_stat_activity&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on March 08, 2020.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2020/03/08/nouveau-dans-pg13-leader_pid.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>pg qualstats 2: Suggestion d&#39;index globale</title>
    <updated>2020-01-06T12:23:29Z</updated>
    <id>tag:rjuju.github.io,2020-01-06:/postgresqlfr/2020/01/06/pg_qualstats-2-suggestion-index-globale.html</id>
    <content type="html">&lt;p&gt;Parvenir à une suggestion d’index de qualité peut être une tâche complexe.&#xA;Cela nécessite à la fois une connaissance des requêtes applicatives et des&#xA;spécificités de la base de données.  Avec le temps de nombreux projets ont&#xA;essayé de résoudre ce problème, l’un d’entre eux étant &lt;a href=&#34;https://powa.readthedocs.io/&#34;&gt;PoWA version&#xA;3&lt;/a&gt;, avec l’aide de &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/pg_qualstats.html&#34;&gt;pg_qualstats&#xA;extension&lt;/a&gt;.&#xA;Cet outil donne de plutôt bonnes suggestions d’index, mais il est nécessaire&#xA;d’installer et configurer PoWA, alors que certains utilisateurs aimeraient&#xA;n’avoir que la suggestion d’index globale.  Pour répondre à ce besoin de&#xA;simplicité, l’algorithme utilisé dans PoWA est maintenant disponible dans&#xA;pg_qualstats version 2, sans avoir besoin d’utiliser des composants&#xA;additionnels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: La fonction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_qualstats_index\_advisor()&lt;/code&gt; a été changée pour retourner&#xA;du &lt;strong&gt;json&lt;/strong&gt; plutôt que du &lt;strong&gt;jsonb&lt;/strong&gt;, afin de conserver la compatibilité avec PostgreSQL&#xA;9.3.  Les requêtes d’exemples sont donc également modifiées pour utiliser&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;json_array_elements()&lt;/code&gt; plutôt que &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;jsonb_array_elements()&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;quest-ce-que-pg_qualstats&#34;&gt;Qu’est-ce que pg_qualstats&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Une manière simple d’expliquer ce qu’est pg_qualstats serait de dire qu’il&#xA;s’agit d’une extension similaire à&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/pgstatstatements.html&#34;&gt;pg_stat_statements&lt;/a&gt;&#xA;mais travaillant au niveaux des prédicats.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cette extension sauvegarde des statistiques utiles pour les clauses &lt;strong&gt;WHERE&lt;/strong&gt;&#xA;et &lt;strong&gt;JOIN&lt;/strong&gt; : à quelle table et quelle colonne un prédicat fait référénce, le&#xA;nombre de fois qu’un prédicat a été utilisé, le nombre d’exécutions de&#xA;l’opérateur sous-jacent, si le prédicat provient d’un parcours d’index ou non,&#xA;la sélectivité, la valeur des constantes et bien plus encore.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il est possible de déduire beaucoup de choses depuis ces informations.  Par&#xA;exemple, si vous examinez les prédicats qui contiennent des références à des&#xA;tables différentes, vous pouvez trouver quelles tables sont jointes ensembles,&#xA;et à quel point les conditions de jointures sont sélectives.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;suggestion-globale-&#34;&gt;Suggestion Globale ?&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Comment je l’ai mentionné, la suggestion d’index globale ajoutée dans&#xA;pg_qualstats 2 utilise la même approche que celle de PoWA, ainsi cet article&#xA;peut servir à décrire le fonctionnement des deux outils.  La seule différence&#xA;est que vous obtiendrez probablement une suggestion de meilleure qualité avec&#xA;PoWA, puisque plus de prédicats seront disponibles, et que vous pourrez&#xA;également choisir sur quel intervalle de temps vous souhaitez effectuer une&#xA;suggestion d’index manquants.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La chose importante à retenir ici est qu’il s’agit d’une suggestion effectuée&#xA;de manière &lt;strong&gt;globale&lt;/strong&gt;, c’est-à-dire en prenant en compte tous les prédicats&#xA;intéressant en même temps.  Cette approche est différente de toutes les autres&#xA;dont j’ai connaissance, qui ne prennent en compte qu’une seule requête à la&#xA;fois.  Selon moi, une approche globale est meilleure, car il est possible de&#xA;réduire le nombre total d’index, en maximisant l’efficacité des index&#xA;multi-colonnes.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;comment-marche-la-suggestion-globale&#34;&gt;Comment marche la suggestion globale&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;La première étape consiste à récupérer tous les prédicats qui pourraient&#xA;bénéficier de nouveaux index.  C’est particulièrement facile à obtenir avec&#xA;pg_qualstats.  En filtrant les prédicats venant d’un parcours séquentiel,&#xA;exécutés de nombreuses fois et qui filtrent de nombreuses lignes (à la fois en&#xA;nombre et en pourcentage), vous obtenez une liste parfaite de prédicats qui&#xA;auraient très probablement besoin d’un index (ou alors dans certains cas une&#xA;liste des requêtes mal écrites).  Voyons regardons par exemple le cas d’une&#xA;applications qui utiliserait ces 4 prédicats:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/global_advisor_1_quals.png&#34;&gt;&lt;img src=&#34;/images/global_advisor_1_quals.png&#34; alt=&#34;Liste de tous les prédicats&#xA;trouvés&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ensuite, il faut construire l’ensemble entier des chemins de toutes les&#xA;prédicats joints par un AND logique, qui contiennent d’autres prédicats, qui&#xA;peuvent être eux-meme également joints par des AND logiques.  En utilisants les&#xA;même 4 prédicats vus précédemments, nous obtenons ces chemins :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/global_advisor_2_graphs.png&#34;&gt;&lt;img src=&#34;/images/global_advisor_2_graphs.png&#34; alt=&#34;Construction de tous les chemins de prédicats&#xA;possibles&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois tous les chemins construits, il suffit d’obtenir le meilleur chemin&#xA;pour trouver le meilleur index à suggérer.  Le classement de ces chemins est&#xA;pour le moment fait en donnant un poids à chaque nœud de chaque chemin qui&#xA;correspond au nombre de prédicats simple qu’il contient, et en additionnant le&#xA;poids pour chaque chemin.  C’est une approche très simple, et qui permet de&#xA;favoriser un nombre minimal d’index qui optimisent le plus de requêtes&#xA;possible.  Avec nos exemple, nous obtenons :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/global_advisor_3_weighted.png&#34;&gt;&lt;img src=&#34;/images/global_advisor_3_weighted.png&#34; alt=&#34;Ajout d&#39;un poids à tous les chemins et choix du score le plus&#xA;haut&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bien évidemment, d’autres approches de classement pourraient être utilisée pour&#xA;prendre en compte d’autres paramètres, et potentiellement obtenir une meilleur&#xA;suggestion.  Par exemple, en prenant en compte également le nombre d’exécution&#xA;ou la sélectivité des prédicats.  Si le ratio de lecture/écriture pour chaque&#xA;table est connu (ce qui est disponible avec l’extension&#xA;&lt;a href=&#34;https://github.com/powa-team/powa-archivist&#34;&gt;powa-archivist&lt;/a&gt;), il serait&#xA;également possible d’adapter le classement pour limiter la suggestion d’index&#xA;pour les tables qui ne sont accédées presque exclusivement en écriture.  Avec&#xA;cet algorithme, ces ajustements seraient relativement simples à faire.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois que le meilleur chemin est trouvé, on peut générer l’ordre de création&#xA;de l’index !  Comme l’ordre des colonnes peut être important, l’ordre est&#xA;généré en récupérant les colonnes de chaque nœud par poids croissant.  Avec&#xA;notre exemple, l’index suivant est généré :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Une fois que l’index est trouvé, on supprime simplement les prédicats contenus&#xA;de la liste globale de prédicats et on reprendre de zéro jusqu’à ce qu’il n’y&#xA;ait plus de prédicats.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;un-peu-plus-de-détails-et-mise-en-garde&#34;&gt;Un peu plus de détails et mise en garde&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Bien évidemment, il s’agit ici d’une version simplifiée de l’algorithme de&#xA;suggestion, car d’autres informations sont nécessaires.  Par exemple, la liste&#xA;des prédicats est en réalité ajustée avec les &lt;a href=&#34;https://www.postgresql.org/docs/current/indexes-opclass.html&#34;&gt;classes d’opérateurs et méthode&#xA;d’acces&lt;/a&gt; en&#xA;fonction du type de la colonne et de sont opérateur, afin de s’assurer&#xA;d’obtenir des index valides.  Si plusieurs méthodes d’accès aux index sont&#xA;trouvées pour un même meilleur chemin, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;btree&lt;/code&gt; sera choisi en priorité.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cela nous amène à un autre détail : cette approche est principalement pensée&#xA;pour les index &lt;strong&gt;btree&lt;/strong&gt;, pour lesqules l’ordre des colonnes est critiques.&#xA;D’autres méthodes d’accès ne requièrent pas un ordre spécifique pour les&#xA;colonnes, et pour ces méthodes d’accès il est possible qu’une suggestion plus&#xA;optimale soit possible si l’ordre des colonnes n’était pas pris en compte.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Un autre point important est que les classes d’opérateurs et méthodes d’accès&#xA;ne sont pas gérés en dur mais récupérés à l’exécution en utilisant les&#xA;catalogues locaux.  Par conséquent, vous pouvez obtenir des résultats&#xA;différents (et potentiellement meilleurs) si vous faites en sorte d’avoir&#xA;toutes les classes d’opérateur additionelles disponibles quand vous utilisez la&#xA;suggestion d’index globale.  Cela pourrait être les extensions &lt;strong&gt;btree_gist&lt;/strong&gt;&#xA;et &lt;strong&gt;btree_gist&lt;/strong&gt;, mais également d’autres méthodes d’accès aux index.  Il est&#xA;également possible que certain types / opérateurs n’aient pas de méthode&#xA;d’accès associée dans les catalogues.  Dans ce cas, ces prédicats sont&#xA;retournées séparément dans une liste de prédicats non optimisables&#xA;automatiquement, et pour lequel une analyse manuelle est nécessaire.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Enfin, comme pg_qualstats ne traite pas les prédicats composés d’expressions,&#xA;l’outil ne peut pas suggérer d’index sur des expressions, par exemple en cas&#xA;d’utilisateur de recherche plein texte.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;exemple-dutilisation&#34;&gt;Exemple d’utilisation&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Une simple fonction est fournie, avec des paramètres facultatifs, qui retourne&#xA;une valeur de type json :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;OR&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;REPLACE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FUNCTION&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_qualstats_index_advisor&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;min_filter&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;min_selectivity&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;forbidden_am&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;{}&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;RETURNS&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Les noms de paramètres sont parlants :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;min_filter&lt;/code&gt;: combien de lignes le prédicat doit-il filtrer en moyenne pour&#xA;être pris en compte par la suggestion globale, par défaut &lt;strong&gt;1000&lt;/strong&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;min_selectivity&lt;/code&gt;: quelle doit être la sélectivité moyenne d’un prédicat&#xA;pour qu’il soit pris en compte par la suggestion globale, par défaut&#xA;&lt;strong&gt;30%&lt;/strong&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;forbidden_am&lt;/code&gt;: liste des méthodes d’accès aux index à ignorer.  Aucune par&#xA;défaut, bien que pour les version 9.6 et inférieures &lt;strong&gt;les index hash sont&#xA;ignoré en interne&lt;/strong&gt;, puisque ceux-ci ne sont sur que depuis la version 10.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple simple, tirés des tests de non régression de pg_qualstats :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pgqs&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;a&#39;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generate_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id2&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id3&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;INSERT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;INTO&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;line &#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generate_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_qualstats_reset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ILIKE&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;moh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;COUNT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pgqs&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Et voici ce que la fonction retourne :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json_array_elements&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;pg_qualstats_index_advisor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min_filter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&#39;indexes&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;ORDER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;COLLATE&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;C&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;                               &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;---------------------------------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;CREATE INDEX ON public.adv USING btree (id1)&#34;&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;CREATE INDEX ON public.adv USING btree (val, id1, id2, id3)&#34;&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;CREATE INDEX ON public.pgqs USING btree (id)&#34;&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json_array_elements&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;pg_qualstats_index_advisor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min_filter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&#39;unoptimised&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;ORDER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;COLLATE&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;C&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;        &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-----------------&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;adv.val ~~* ?&#34;&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;La &lt;a href=&#34;https://github.com/powa-team/pg_qualstats/&#34;&gt;version 2 de pg_qualstats&lt;/a&gt;&#xA;n’est pas encore disponible en version stable, mais n’hésitez pas à la tester&#xA;et &lt;a href=&#34;https://github.com/powa-team/pg_qualstats/issues&#34;&gt;rapporter tout problème que vous pourriez&#xA;rencontrer&lt;/a&gt; !&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2020/01/06/pg_qualstats-2-suggestion-index-globale.html&#34;&gt;pg qualstats 2: Suggestion d&#39;index globale&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on January 06, 2020.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2020/01/06/pg_qualstats-2-suggestion-index-globale.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>PoWA 4: Nouveau daemon powa-collector</title>
    <updated>2019-12-10T18:54:17Z</updated>
    <id>tag:rjuju.github.io,2019-12-10:/postgresqlfr/2019/12/10/powa-4-nouveau-powa-collector.html</id>
    <content type="html">&lt;p&gt;Cet article fait partie d’une série d’article sur &lt;a href=&#34;http://powa.readthedocs.io/&#34;&gt;la beta de PoWA&#xA;4&lt;/a&gt;, et décrit le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon&#xA;powa-collector&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;nouveau-daemon-powa-collector&#34;&gt;Nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon powa-collector&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Ce daemon remplace le précédent &lt;em&gt;background worker&lt;/em&gt; lorsque le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html&#34;&gt;mode&#xA;remote&lt;/a&gt; est utilisé.&#xA;Il s’agit d’un simple daemon écrit en python, qui s’occupera de toutes les&#xA;étapes nécessaires pour effectuer des &lt;em&gt;snapshots distants&lt;/em&gt;.  Il est &lt;a href=&#34;https://pypi.org/project/powa-collector/&#34;&gt;disponible&#xA;sur pypi&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Comme je l’ai expliqué dans mon &lt;a href=&#34;/postgresql/2019/05/17/powa-4-with-remote-mode-beta-is-available.html&#34;&gt;précédent article introduistant PoWA 4&lt;/a&gt;, ce&#xA;daemon est nécessaire  pour la configuration d’un mode remote, en gardant cette&#xA;architecture à l’esprit :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_remote.svg&#34;&gt;&lt;img src=&#34;/images/powa_4_remote.svg&#34; alt=&#34;Architecture de PoWA 4 en mode distant&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sa configuration est très simple.  Il vous suffit tout simplement de renommer&#xA;le fichier &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa-collector.conf.sample&lt;/code&gt; fourni, et d’adapter &lt;a href=&#34;https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING&#34;&gt;l’URI de&#xA;connexion&lt;/a&gt;&#xA;pour décrire comment se connecter sur votre &lt;em&gt;serveur repository&lt;/em&gt; dédié, et&#xA;c’est fini.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une configuration typique devrait ressembler à :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-conf&#34; data-lang=&#34;conf&#34;&gt;{&#xA;    &lt;span class=&#34;s2&#34;&gt;&#34;repository&#34;&lt;/span&gt;: {&#xA;        &lt;span class=&#34;s2&#34;&gt;&#34;dsn&#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&#34;postgresql://powa_user@server_dns:5432/powa&#34;&lt;/span&gt;,&#xA;    },&#xA;    &lt;span class=&#34;s2&#34;&gt;&#34;debug&#34;&lt;/span&gt;: &lt;span class=&#34;n&#34;&gt;true&lt;/span&gt;&#xA;}&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;La liste des &lt;em&gt;serveur distants&lt;/em&gt;, leur configuration ainsi que tout le reste qui&#xA;est nécessaire pour le bon fonctionnement sera automatiquement récupéré depuis&#xA;le &lt;em&gt;serveur repository&lt;/em&gt; que vous ave déjà configuré.  Une fois démarré, il&#xA;démarrera un thread dédié par &lt;em&gt;serveur distant&lt;/em&gt; déclaré, et maintiendra une&#xA;&lt;strong&gt;connexion persistente&lt;/strong&gt; sur ce &lt;em&gt;serveur distant&lt;/em&gt;.  Chaque thread effectuera&#xA;un &lt;em&gt;snapshot distant&lt;/em&gt;, exportant les données sur le &lt;em&gt;serveur repository&lt;/em&gt; en&#xA;utilisant les nouvelles &lt;em&gt;fonctions sources&lt;/em&gt;.  Chaque thread ouvrira et fermera&#xA;une connexion sur le &lt;em&gt;serveur repository&lt;/em&gt; lors de l’exécution du &lt;em&gt;snapshot&#xA;distant&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bien évidemment, ce daemon a besoin de pouvoir se connecter sur tous les&#xA;&lt;em&gt;serveurs distants&lt;/em&gt; déclarés ainsi que le &lt;em&gt;serveur repository&lt;/em&gt;.  La table&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_servers&lt;/code&gt;, qui stocke la liste des &lt;em&gt;serveurs distants&lt;/em&gt;, a un champ pour&#xA;stocker les nom d’utilisateur et mot de passe pour se connecter aux &lt;em&gt;serveur&#xA;distants&lt;/em&gt;.  Stocker un mot de passe en clair dans cette table est une hérésie,&#xA;si l’on considère l’aspect sécurité.  Ainsi, comme indiqué dans la&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/security.html#connection-on-remote-servers&#34;&gt;section sécurité de&#xA;PoWA&lt;/a&gt;,&#xA;vous pouve stocker un mot de passe NULL et &lt;a href=&#34;https://www.postgresql.org/docs/current/auth-methods.html&#34;&gt;utiliser à la place n’importe&#xA;laquelle des autres méthodes d’authentification supportées par la&#xA;libpq&lt;/a&gt; (fichier&#xA;.pgpass, certificat…).  C’est très fortement recommandé pour toute&#xA;installation sérieuse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La connexion persistente sur le &lt;em&gt;serveur repository&lt;/em&gt; est utilisée pour&#xA;superviser la daemon :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;pour vérifier  que le daemon est bien démarré&lt;/li&gt;&#xA;  &lt;li&gt;pour communiquer au travers de l’UI en utilisant un &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/protocol.html&#34;&gt;protocole simple&lt;/a&gt;&#xA;afin d’effectuer des actions diverses (recharger la configuration, vérifier&#xA;le status d’un thread dédié à un &lt;em&gt;serveur distant&lt;/em&gt;…)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Il est à noter que vous pouvez également demander au daemon de recharger sa&#xA;configuration en envoyant un SIGHUP au processus du daemon.  Un rechargement&#xA;est nécessaire pour toute modification effectuée sur la liste des serveurs&#xA;distants (ajout ou suppression d’un &lt;em&gt;serveur distant&lt;/em&gt;, ou mise à jour d’un&#xA;existant).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez également noter que, par choix,&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;powa-collector&lt;/a&gt;&#xA;n’effectuera pas de &lt;em&gt;snapshot local&lt;/em&gt;.  Si vous voulez utiliser PoWA pour le&#xA;&lt;em&gt;serveur repository&lt;/em&gt;, il vous faudra activer le &lt;em&gt;background worker&lt;/em&gt; original.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;nouvelle-page-de-configuration&#34;&gt;Nouvelle page de configuration&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;La page de configuration est maintenant modifiée pour donner toutes les&#xA;informations nécessaires sur le status du background worker, le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;powa-collector&#xA;daemon&lt;/a&gt;&#xA;(incluant tous ses threads dédiés) ainsi que la liste des &lt;em&gt;serveurs distants&lt;/em&gt;&#xA;déclarés.  Voici un exemple de cette nouvelle page racine de configuration :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_configuration_page.png&#34;&gt;&lt;img src=&#34;/images/powa_4_configuration_page.png&#34; alt=&#34;Nouvelle page de&#xA;configuration&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon&#xA;powa-collector&lt;/a&gt;&#xA;est utilisé, le status de chaque serveur distant sera récupéré en utilisant le&#xA;protocole de communication.  Si le collecteur rencontre des erreurs (lors de la&#xA;connexion à un &lt;em&gt;serveur distant&lt;/em&gt;, durant un &lt;em&gt;snapshot&lt;/em&gt; par exemple), celles-ci&#xA;seront également affichées ici.  À noter également que ces erreurs seront&#xA;également affichées en haut de chaque page de toutes les pages de l’UI, afin&#xA;d’être sûr de ne pas les rater.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;De plus, la section configuration a maintenant une hiérarchie, et vous pourrez&#xA;voir la liste des extensions ainsi que la configuration actuelle de PostgreSQL&#xA;pour le serveur &lt;strong&gt;local&lt;/strong&gt; ou &lt;strong&gt;distant&lt;/strong&gt; en cliquant sur le serveur de votre&#xA;choix!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il y a également un nouveau bouton &lt;strong&gt;Reload collector&lt;/strong&gt; sur le bandeau&#xA;d’en-tête qui, comme on pourrait s’y attendre, demandera au collecteur de&#xA;recharger sa configuration.  Cela peut être utile si vous avez déclarés de&#xA;nouveaux serveurs mais n’ave pas d’accès au serveur sur lequel le collecteur&#xA;s’exécute.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette article est le dernier de la séurie concernant la nouvelle version de&#xA;PoWA.  Il est toujours en beta, n’hésitez donc pas à le tester, &lt;a href=&#34;https://powa.readthedocs.io/en/latest/support.html#support&#34;&gt;rapporter&#xA;tout bug rencontré&lt;/a&gt;&#xA;ou donner tout autre retour!&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/12/10/powa-4-nouveau-powa-collector.html&#34;&gt;PoWA 4: Nouveau daemon powa-collector&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on December 10, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/12/10/powa-4-nouveau-powa-collector.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>PoWA 4: nouveautés dans powa-archivist !</title>
    <updated>2019-06-05T14:26:17Z</updated>
    <id>tag:rjuju.github.io,2019-06-05:/postgresqlfr/2019/06/05/powa-4-nouveaute-dans-powa-archivist.html</id>
    <content type="html">&lt;p&gt;Cet article fait partie d’une série d’article sur &lt;a href=&#34;http://powa.readthedocs.io/&#34;&gt;la beta de PoWA&#xA;4&lt;/a&gt;, et décrit les changements présents dans&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/index.html&#34;&gt;powa-archivist&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour plus d’information sur cette version 4, vous pouvez consulter &lt;a href=&#34;/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html&#34;&gt;l’article&#xA;de présentation général&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;aperçu-rapide&#34;&gt;Aperçu rapide&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Tout d’abord, il faut savoir qu’il n’y a pas d’upgrade possible depuis la v3&#xA;vers la v4, il est donc nécessaire d’effectuer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;DROP EXTENSION powa&lt;/code&gt; si vous&#xA;utilisiez déjà PoWA sur vos serveurs.  Cela est du au fait que la v4 apporte&#xA;&lt;strong&gt;de très nombreux&lt;/strong&gt; changements dans la partie SQL de l’extension, ce qui en&#xA;fait le changement le plus significatif dans la suite PoWA pour cette nouvelle&#xA;version.  Au moment où j’écris cet article, la quantité de changements apportés&#xA;dans cette extension est :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-diff&#34; data-lang=&#34;diff&#34;&gt; CHANGELOG.md       |   14 +&#xA; powa--4.0.0dev.sql | 2075 +++++++++++++++++++++-------&#xA; powa.c             |   44 +-&#xA; 3 files changed, 1629 insertions(+), 504 deletions(-)&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;L’absence d’upgrade ne devrait pas être un problème en pratique.  PoWA est un&#xA;outil pour analyser les performances, il est fait pour avoir des données avec&#xA;une grande précision mais un historique très limité.  Si vous cherchez une&#xA;solution de supervision généraliste pour conserver des mois de données, PoWA&#xA;n’est définitivement pas l’outil qu’il vous faut.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;configurer-la-liste-des-serveurs-distants&#34;&gt;Configurer la liste des &lt;em&gt;serveurs distants&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;En ce qui concerne les changements à proprement parler, le premier petit&#xA;changement est que le &lt;a href=&#34;https://www.postgresql.org/docs/current/bgworker.html&#34;&gt;background&#xA;worker&lt;/a&gt; n’est plus&#xA;nécessaire pour le fonctionnement de powa-archivist, car il n’est pas utilisé&#xA;pour le mode distant.  Cela signifie qu’un redémarrage de PostgreSQL n’est plus&#xA;nécessaire pour installer PoWA.  Bien évidemment, un redémarrage est toujours&#xA;nécessaire si vous souhaitez utiliser le mode local, en utilisant le background&#xA;worker, or si vous voulez installer des extensions additionelles qui&#xA;nécessitent elles-même un redémarrage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ensuite, comme PoWA requiert un peu de configuration (fréquence des snapshot,&#xA;rétention des données et ainsi de suite), certaines nouvelles tables sont&#xA;ajouter pour permettre de configurer tout ça.  La nouvelle table &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_servers&lt;/code&gt;&#xA;stocke la configuration de toutes les instances distantes dont les données&#xA;doivent être stockées sur cette instance.  Cette &lt;em&gt;instance PoWA locale&lt;/em&gt; est&#xA;appelée un &lt;strong&gt;serveur repository&lt;/strong&gt; (qui devrait typiquement être dédiée à&#xA;stocker des données PoWA), en opposition aux &lt;strong&gt;instances distantes&lt;/strong&gt; qui sont&#xA;les instances que vous voulez monitorer.  Le contenu de cette table est tout ce&#xA;qu’il y a de plus simple :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powa_servers&lt;/span&gt;&#xA;                              &lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_servers&#34;&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;   &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;                 &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-----------+----------+-----------+----------+------------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;            &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nextval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&#39;powa_servers_id_seq&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;regclass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;hostname&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;alias&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;port&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;username&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;password&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;dbname&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;frequency&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;300&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;powa_coalesce&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;retention&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interval&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;1 day&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;interval&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Si vous avez déjà utilisé PoWA, vous devriez reconnaître la plupart des options&#xA;de configuration qui sont maintenant stockées ici.  Les nouvelles options sont&#xA;utilisées pour décrire comment se connecter aux &lt;em&gt;instances distances&lt;/em&gt;, et&#xA;peuvent fournir un alias à afficher sur l’UI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Vous avez également probablement remarqué une colonne &lt;strong&gt;password&lt;/strong&gt;.  Stocker un&#xA;mot de passe en clair dans cette table est une hérésie pour n’importe qui&#xA;désirant un minimum de sécurité.  Ainsi, comme mentionné dans la &lt;a href=&#34;https://powa.readthedocs.io/en/latest/security.html#connection-on-remote-servers&#34;&gt;section&#xA;sécurité de la documentation de PoWA&#xA;&lt;/a&gt;,&#xA;vous pouvez stocker NULL pour le champ password et à la place utiliser&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/auth-methods.html&#34;&gt;n’importe laquelle des autres méthodes d’authentification supportée par la&#xA;libpq&lt;/a&gt;&#xA;(fichier .pgpass, certificat…).  Une authentification plus sécurisée est&#xA;chaudement recommandée pour toute installation sérieuse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une autre table, la table &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_snapshot_metas&lt;/code&gt;, est également ajoutée pour&#xA;stocker quelques métadonnées concernant les informations de snapshot pour&#xA;chaque &lt;em&gt;serveur distant&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;                                   &lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_snapshot_metas&#34;&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;                &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;--------------+--------------------------+-----------+----------+---------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;                  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;coalesce_seq&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;bigint&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;snapts&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;-infinity&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;aggts&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;-infinity&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;purgets&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;-infinity&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;errors&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Il s’agit tout simplement d’un compteur pour compter le nombre de snapshots&#xA;effectués, un timestamp pour chaque type d’événement survenu (snapshot,&#xA;aggrégation et purge) et un tableau de chaîne de caractères pour stocker toute&#xA;erreur survenant durant le snapshot, afin que l’UI pour l’afficher.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;api-sql-pour-configurer-les-serveurs-distants&#34;&gt;API SQL pour configurer les &lt;em&gt;serveurs distants&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Bien que ces tables soient très simples, une &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html#configure-powa-and-stats-extensions-on-each-remote-server&#34;&gt;API SQL basique est disponible&#xA;pour déclarer de nouveaux serveurs et les&#xA;configurer&lt;/a&gt;.&#xA;6 fonctions de bases sont disponibles :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_register_server()&lt;/code&gt;, pour déclarer un nouveau &lt;em&gt;servuer distant&lt;/em&gt;, ainsi&#xA;que la liste des extensions qui y sont disponibles&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_configure_server()&lt;/code&gt; pour mettre à jour un des paramètres pour le&#xA;&lt;em&gt;serveur distant&lt;/em&gt; spécifié (en utilisant un paramètre JSON, où la clé est&#xA;le nom du paramètre à changer et la valeur la nouvelle valeur à utiliser)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_deactivate_server()&lt;/code&gt; pour désactiver les snapshots pour le &lt;em&gt;serveur&#xA;distant&lt;/em&gt; spécifiqué (ce qui concrètement positionnera le paramètre&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;frequency&lt;/code&gt; à &lt;strong&gt;-1&lt;/strong&gt;)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_delete_and_purge_server()&lt;/code&gt; pour supprimer le &lt;em&gt;serveur distant&lt;/em&gt;&#xA;spécifié de la liste des serveurs et supprimer toutes les données associées&#xA;aux snapshots&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_activate_extension()&lt;/code&gt;, pour déclarer qu’une nouvelle extension est&#xA;disponible sur le &lt;em&gt;serveur distant&lt;/em&gt; spécifié&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_deactivate_extension()&lt;/code&gt;, pour spécifier qu’une extension n’est plus&#xA;disponible sur le &lt;em&gt;serveur distant&lt;/em&gt; spécifié&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Toute action plus compliquée que ça devra être effectuée en utilisant des&#xA;requêtes SQL.  Heureusement, il ne devrait pas y avoir beaucoup d’autres&#xA;besoins, et les tables sont vraiment très simple donc cela ne devrait pas poser&#xA;de soucis.  &lt;a href=&#34;https://github.com/powa-team/powa-archivist/issues&#34;&gt;N’hésitez cependant pas à demander de nouvelles&#xA;fonctions&lt;/a&gt; si vous aviez&#xA;d’autres besoins.  Veuillez également noter que l’UI ne vous permet pas&#xA;d’appeler ces fonctions, puisque celle-ci est pour le moment &lt;strong&gt;entièrement en&#xA;lecture seule&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;effectuer-des-snapshots-distants&#34;&gt;Effectuer des &lt;em&gt;snapshots distants&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Puisque les métriques sont maintenant stockées sur une instance PostgreSQL&#xA;différente, nous avons énormément changé la façon dont les &lt;em&gt;snapshots&lt;/em&gt;&#xA;(récupérer les données fournies par une &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/index.html&#34;&gt;extensions&#xA;statistique&lt;/a&gt;&#xA;et les stockées dans le catalogue PoWA &lt;a href=&#34;/postgresqlfr/2019/04/06/minimiser-le-surcout-de-stockage-par-ligne.html&#34;&gt;de manière à optimiser le stockage&lt;/a&gt;) sont&#xA;effectués.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La liste de toutes les extensions statistiques, ou &lt;em&gt;sources de données&lt;/em&gt;, qui&#xA;sont disponibles sur un &lt;strong&gt;serveur&lt;/strong&gt; (soit &lt;em&gt;distant&lt;/em&gt; soit &lt;em&gt;local&lt;/em&gt;) et pour&#xA;lesquelles un &lt;em&gt;snapshot&lt;/em&gt; devrait être effectué est stockée dans une table&#xA;appelée &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_functions&lt;/code&gt;:&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;               &lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_functions&#34;&lt;/span&gt;&#xA;     &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;----------------+---------+-----------+----------+---------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;module&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;operation&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;function_name&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;query_source&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;added_manually&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;boolean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;true&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;enabled&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;boolean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;true&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;priority&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;numeric&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Un nouveau champ &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;query_source&lt;/code&gt; a été rajouté.  Celui-ci fournit le nom de la&#xA;&lt;em&gt;fonction source&lt;/em&gt;, nécessaire pour la compatibilité d’une &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/index.html&#34;&gt;extension&#xA;statistique&lt;/a&gt;&#xA;avec les snapshots distants.  Cette fonction est utilisée pour exporter les&#xA;compteurs fournis par cette extension sur un serveur différent, dans une &lt;em&gt;table&#xA;transitoire&lt;/em&gt; dédiée.  La fonction de &lt;em&gt;snapshot&lt;/em&gt; effectuera alors le &lt;em&gt;snapshot&lt;/em&gt;&#xA;en utilisant automatiquement ces données exportées plutôt que celles fournies&#xA;par l’extension statististique locale quand le mode distant est utilisé.  Il&#xA;est à noter que l’export de ces compteurs ainsi que le snapshot distant est&#xA;effectué automatiquement par le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon&#xA;powa-collector&lt;/a&gt;&#xA;que je présenterai dans un autre article.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple montant comment PoWA effectue un &lt;em&gt;snapshot distant&lt;/em&gt; d’une&#xA;liste de base données.  Comme vous allez le voir, c’est très simple ce qui&#xA;signifie qu’il est également très simple d’ajouter cette même compatibilité&#xA;pour une nouvelle extension statistique.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La &lt;em&gt;table transitoire&lt;/em&gt;:&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;   &lt;span class=&#34;n&#34;&gt;Unlogged&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_databases_src_tmp&#34;&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;---------+---------+-----------+----------+---------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Pour de meilleurs performances, toutes les &lt;em&gt;tables transitoires&lt;/em&gt; sont &lt;strong&gt;non&#xA;journalisées (unlogged)&lt;/strong&gt;, puisque leur contenu n’est nécessaire que durant un&#xA;&lt;em&gt;snapshot&lt;/em&gt; et sont supprimées juste après.  Dans cet examlple, la &lt;em&gt;table&#xA;transitoire&lt;/em&gt; ne stocke que l’identifiant du serveur distant correspondant à ces&#xA;données, l’oid ainsi que le nom de chacune des bases de données présentes sur&#xA;le &lt;em&gt;serveur distant&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Et la &lt;em&gt;fonction source&lt;/em&gt; :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;OR&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;REPLACE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FUNCTION&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;powa_databases_src&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_srvid&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;OUT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;OUT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;RETURNS&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SETOF&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;record&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;LANGUAGE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plpgsql&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;BEGIN&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;IF&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_srvid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;THEN&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;RETURN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_database&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;ELSE&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;RETURN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powa_databases_src_tmp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;_srvid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;END&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IF&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;END&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Cette fonction retourne simplement le contenu de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_database&lt;/code&gt; si les données&#xA;locales sont demandées (l’identifiant de serveur &lt;strong&gt;0&lt;/strong&gt; est toujours le serveur&#xA;local), ou alors le contenu de la &lt;em&gt;table transitoire&lt;/em&gt; pour le serveur distant&#xA;spécifié.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La &lt;em&gt;fonction de snapshot&lt;/em&gt; peut alors facilement effectuer n’importe quel&#xA;traitement avec ces données pour le &lt;em&gt;serveur distant&lt;/em&gt; voulu.  Dans le cas de la&#xA;fonction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_databases_snapshot()&lt;/code&gt;, il s’agit simplement de synchroniser la&#xA;liste des bases de données, et de stocker le timestamp de suppression si une&#xA;base de données qui existait précédemment n’est plus listée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour plus de détails, vous pouvez consulter la documentation concernant&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/development.html&#34;&gt;l’ajout d’une source de données dans&#xA;PoWA&lt;/a&gt;,&#xA;qui a été mise à jour pour les spécificités de la version 4.&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/06/05/powa-4-nouveaute-dans-powa-archivist.html&#34;&gt;PoWA 4: nouveautés dans powa-archivist !&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on June 05, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/06/05/powa-4-nouveaute-dans-powa-archivist.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>PoWA 4 apporte un mode remote, disponible en beta !</title>
    <updated>2019-05-17T11:04:17Z</updated>
    <id>tag:rjuju.github.io,2019-05-17:/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html</id>
    <content type="html">&lt;p&gt;&lt;a href=&#34;http://powa.readthedocs.io/&#34;&gt;PoWA 4&lt;/a&gt; est disponible en beta.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;nouveau-mode-remote-&#34;&gt;Nouveau mode remote !&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html&#34;&gt;nouveau mode remote&lt;/a&gt;&#xA;est la plus grosse fonctionnalité ajoutée dans PoWA 4, bien qu’il y ait eu&#xA;d’autres améliorations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Je vais décrire ici ce que ce nouveau mode implique ainsi que ce qui a changé&#xA;sur l’&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-web/index.html&#34;&gt;UI&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si de plus amples détails sur le reste des changements apportés dans PoWA 4&#xA;vous intéresse, je publierai bientôt d’autres articles sur le sujet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour les plus pressés, n’hésitez pas à aller directement sur la &lt;a href=&#34;https://dev-powa.anayrat.info/&#34;&gt;démo v4 de&#xA;PoWA&lt;/a&gt;, très gentiment hébergée par &lt;a href=&#34;http://blog.anayrat.info/&#34;&gt;Adrien&#xA;Nayrat&lt;/a&gt;.  Aucun authentification n’est requise,&#xA;cliquez simplement sur “Login”.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;pourquoi-un-mode-remote-est-il-important&#34;&gt;Pourquoi un mode remote est-il important&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette fonctionnalité a probablement été la plus fréquemment demandée depuis que&#xA;PoWA a été publié, en 2014.  Et c’est pour de bonnes raisons, car un mode local&#xA;a quelques inconvénients.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tout d’abord, voyons comment se présentait l’architecture avec les versions 3&#xA;et antérieures.  Imaginons une instance contenant 2 bases de données (db1 et&#xA;db2), ainsi qu’&lt;strong&gt;une base de données dédiée à PoWA&lt;/strong&gt;.  Cette base de données&#xA;dédiée contient à la fois les &lt;em&gt;extensions statistiques&lt;/em&gt; nécessaires pour&#xA;récupérer compteurs de performances actuels ainsi que pour &lt;strong&gt;les stocker&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_local.svg&#34;&gt;&lt;img src=&#34;/images/powa_4_local.svg&#34; alt=&#34;Architecture en mode local&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Un &lt;em&gt;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/configuration.html#background-worker-configuration&#34;&gt;background&#xA;worker&lt;/a&gt;&lt;/em&gt;&#xA;est démarré par PoWA, qui est responsable d’effectuer des &lt;em&gt;snapshots&lt;/em&gt; et de les&#xA;stocker dans la base powa dédiée à intervalle réguliers.  Ensuite, en utilisant&#xA;powa-web, vous pouvez consulter l’activité de n’importe laquelle des bases de&#xA;données &lt;strong&gt;locales&lt;/strong&gt; en effectuant des requêtes sur les données stockées dans la&#xA;base dédié, et potentiellement en se connectant sur l’une des autres bases de&#xA;données locales lorsque les données complètes sont nécessaires, par exemple&#xA;lorsque l’outil de suggestion d’index est utilisé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Avec la version 4, l’architecture avec une configuration distante change de&#xA;manière significative:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_remote.svg&#34;&gt;&lt;img src=&#34;/images/powa_4_remote.svg&#34; alt=&#34;Architecture en mode distant&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Vous pouvez voir qu’une base de donnée powa dédiée est toujours nécessaire,&#xA;mais &lt;strong&gt;uniquement pour les extensions statistiques&lt;/strong&gt;.  Les données sont&#xA;maintenant stockées sur une instance différente.  Ensuite, le &lt;em&gt;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/configuration.html#background-worker-configuration&#34;&gt;background&#xA;worker&lt;/a&gt;&lt;/em&gt;&#xA;est remplacé par un &lt;strong&gt;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;nouveau daemon&#xA;collecteur&lt;/a&gt;&lt;/strong&gt;,&#xA;qui lit les métriques de performance depuis les &lt;em&gt;serveurs distants&lt;/em&gt;, et les&#xA;stocke sur le &lt;em&gt;serveur repository&lt;/em&gt; dédié.  Powa-web pourra présenter les&#xA;données en se connectant sur le &lt;em&gt;serveur repository&lt;/em&gt;, ainsi que sur les&#xA;&lt;strong&gt;serveurs distants&lt;/strong&gt; lorsque des données complètes sont nécessaires.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En résumé, avec le nouveau mode distant ajouté dans cette version 4&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;un redémarrage de PostgreSQL n’est plus nécessaire pour installer&#xA;powa-archivist&lt;/li&gt;&#xA;  &lt;li&gt;il n’y a plus de surcoût du au fait de stocker et requêter les données sur&#xA;le même serveur PostgreSQL que vos serveurs de productions (il y a toujours&#xA;certaines partie de l’UI qui nécessitent d’effectuer des requêtes sur le&#xA;serveur d’origine, par exemple pour montrer des plans avec EXPLAIN, mais le&#xA;surcoût est négligeable)&lt;/li&gt;&#xA;  &lt;li&gt;il est maintenant possible d’utiliser PoWA sur un &lt;strong&gt;serveur en&#xA;hot-standby&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;L’UI vous accueillera donc maintenant avec une page initiale afin de choisir&#xA;lequel des serveurs stockés sur la base de données cible vous voulez&#xA;travailler :&#xA;&lt;a href=&#34;/images/powa_4_all_servers.png&#34;&gt;&lt;img src=&#34;/images/powa_4_all_servers.png&#34; alt=&#34;Choix des serveurs&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La principale raison pour laquelle il a fallu tellement de temps pour apporter&#xA;ce mode distant est parce que cela apporte beaucoup de complexité, nécessitant&#xA;une réécriture majeure de PoWA.  Nous voulions également ajouter d’abord&#xA;d’autres fonctionnalités, comme la &lt;strong&gt;suggestion globale d’index&lt;/strong&gt;, avec une&#xA;&lt;strong&gt;validation grâce à &lt;a href=&#34;http://hypopg.readthedocs.io/&#34;&gt;hypopg&lt;/a&gt;&lt;/strong&gt; introduit avec&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/releases/v3.0.0.html&#34;&gt;PoWA 3&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;changements-dans-powa-web&#34;&gt;Changements dans &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-web/index.html&#34;&gt;powa-web&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;L’&lt;em&gt;interface graphique&lt;/em&gt; est le composant qui a le plus de changements visibles&#xA;dans cette version 4.  Voici les plus changements les plus importants.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;compatibilité-avec-le-mode-distant&#34;&gt;Compatibilité avec le mode distant&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Le changement le plus important est bien évidemment le support pour le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html&#34;&gt;nouveau&#xA;mode remote&lt;/a&gt;.  En&#xA;conséquence, la première page affichée est maintenant une page de &lt;strong&gt;sélection&#xA;de serveur&lt;/strong&gt;, affichant tous les &lt;em&gt;serveurs distants&lt;/em&gt; enregistrés.  Après avoir&#xA;choisi le &lt;em&gt;serveur distant&lt;/em&gt; voulu (ou le &lt;em&gt;serveur local&lt;/em&gt; si vous n’utilisez pas&#xA;le mode distant), toutes les autres pages seront similaires à celles&#xA;disponibles jusqu’à la version 3, mais afficheront les données pour un &lt;em&gt;serveur&#xA;distant&lt;/em&gt; spécifique uniquement, et bien entendu en récupérant les données&#xA;depuis la &lt;strong&gt;base de données repository&lt;/strong&gt;, avec en plus de nouvelles&#xA;informations décrites ci-dessous.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez notez que puisque les données sont maintenant stockées sur un &lt;em&gt;serveur&#xA;repository&lt;/em&gt; dédié quand le mode remote est utilisé, la majorité de l’UI est&#xA;utilisable sans se connecter au &lt;em&gt;serveur distant&lt;/em&gt; sélectionné.  Toutefois,&#xA;powa-web nécessite toujours de pouvoir se connecter sur le &lt;em&gt;serveur distant&lt;/em&gt;&#xA;quand les données originales sont nécessaires (par exemple, pour la suggestion&#xA;d’index ou pour montrer des plans avec &lt;strong&gt;EXPLAIN&lt;/strong&gt;).  Les &lt;a href=&#34;https://powa.readthedocs.io/en/latest/security.html#connection-on-remote-servers&#34;&gt;mêmes considérations&#xA;et possibilités concernant&#xA;l’authentification&lt;/a&gt;&#xA;que pour le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon powa-collector&#xA;&lt;/a&gt;&#xA;(qui sera décrit dans un prochain article) s’appliquent ici.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;pg_track_settings-support&#34;&gt;&lt;a href=&#34;https://github.com/rjuju/pg_track_settings/&#34;&gt;pg_track_settings&lt;/a&gt; support&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Quand cette extension est correctement configurée, un nouveau widget timeline&#xA;apparaîtra, placé entre chaque graph et son aperçu, affichant différents types&#xA;de changements enregistrés si ceux-ci ont été détectés sur l’intervalle de&#xA;temps sélectionné.  Sur les pages par base de données et par requête, la liste&#xA;sera également filtrée en fonction de la base de données sélectionnée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La même timeline sera affichée sur chacun des graphs de chacune des pages, afin&#xA;de facilement vérifier si ces changements ont eu un impact visible en utilisant&#xA;les différents graphs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez noter que les détails des changements sont affichés au survol de la&#xA;souris.  Vous pouvez également cliquer sur n’importe lequel des événements de&#xA;la timeline pour figer l’affichage, et tracer une ligne verticale sur le graph&#xA;associé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple d’un tel changement de configuration en action :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/pg_track_settings_powa4.png&#34;&gt;&lt;img src=&#34;/images/pg_track_settings_powa4.png&#34; alt=&#34;Changements de configuration détectés&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez également noter qu’il est nécessaire d’avoir au minimum la version&#xA;2.0.0 de &lt;a href=&#34;https://github.com/rjuju/pg_track_settings/&#34;&gt;pg_track_settings&lt;/a&gt;, et&#xA;que l’extension doit être installée &lt;strong&gt;à la fois sur les &lt;em&gt;serveurs distants&lt;/em&gt;&#xA;ainsi que sur le &lt;em&gt;serveur repository&lt;/em&gt;.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;nouveaux-graphs-disponibles&#34;&gt;Nouveaux graphs disponibles&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Quand&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/pg_stat_kcache.html&#34;&gt;pg_stat_kcache&lt;/a&gt;&#xA;est configuré, ses informations n’étaient auparavant affichées que sur la page&#xA;par requête.  Les informations sont maintenant également affichées sur les&#xA;pages par serveur et par base, dans deux nouveaux graphs :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;dans le graph &lt;strong&gt;Block Access&lt;/strong&gt;, où les métriques &lt;strong&gt;OS cache&lt;/strong&gt; et &lt;strong&gt;disk&#xA;read&lt;/strong&gt; remplaceront la métrique &lt;strong&gt;read&lt;/strong&gt;&lt;/li&gt;&#xA;  &lt;li&gt;dans un nouveau graph &lt;strong&gt;System Resources&lt;/strong&gt; (qui est également ajouté dans&#xA;la page &lt;em&gt;par requête&lt;/em&gt;), montrant les &lt;a href=&#34;/postgresql/2018/07/17/pg_stat_kcache-2-1-is-out.html&#34;&gt;metrics ajoutées dans pg_stat_kcache&#xA;2.1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Voici un example de ce nouveau graph &lt;strong&gt;System Resources&lt;/strong&gt; :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/pg_stat_kcache_system_resources_powa4.png&#34;&gt;&lt;img src=&#34;/images/pg_stat_kcache_system_resources_powa4.png&#34; alt=&#34;Ressources système&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il y avait également un graph &lt;strong&gt;Wait Events&lt;/strong&gt; (disponible quand &lt;a href=&#34;https://powa.readthedocs.io/en/v4/components/stats_extensions/pg_wait_sampling.html&#34;&gt;l’extension&#xA;pg_wait_sampling&lt;/a&gt;&#xA;est configuée) disponible uniquement sur la page par requête.  Ce graph est&#xA;maintenant disponible sur les pages par serveur et par base également.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;documentation-des-métriques-et-liens-vers-la-documentation&#34;&gt;Documentation des métriques et liens vers la documentation&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Certaines métriques affichées sur l’interface sont assez parlante, mais&#xA;certaines autres peuvent être un peu obscures.  Jusqu’à maintenant, il n’y&#xA;avait malheureusement aucune documentation pour les métriques.  Le problème est&#xA;maintenant réglé, et tous les graphs ont une &lt;em&gt;icône d’information&lt;/em&gt;, qui&#xA;affichent une description des métriques utilisée dans le graph au survol de la&#xA;souris.  Certains graphs incluent également un lien vers la &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/index.html&#34;&gt;documentation PoWA&#xA;de extension&#xA;statistiques&lt;/a&gt;&#xA;pour les utilisateurs qui désirent en apprendre plus à leur sujet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_metrics_doc.png&#34;&gt;&lt;img src=&#34;/images/powa_4_metrics_doc.png&#34; alt=&#34;Documentation des métriques&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;et-des-correctifs-de-bugs-divers&#34;&gt;Et des correctifs de bugs divers&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Certains problèmes de longues dates ont également été rapportés :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;la boîte affichée au survol d’un graph montant les valeurs des métriques&#xA;avait une position verticale incorrecte&lt;/li&gt;&#xA;  &lt;li&gt;la sélection temporelle en utilisant l’aperçu des graphs ne montrait pas un&#xA;aperçu correct après avoir appliqué la sélection&lt;/li&gt;&#xA;  &lt;li&gt;les erreurs lors de la création d’index hypothétiques ou dans certains cas&#xA;leur affichage n’était pas correctement gérés sur plusieurs pages&lt;/li&gt;&#xA;  &lt;li&gt;les filtres des tableaux n’était pas réappliqués quand l’intervalle de&#xA;temps sélectionné était changé&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Si un de ces problèmes vous a un jour posé problème, vous serez ravi&#xA;d’apprendre qu’ils sont maintenant tous corrigés !&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette 4ème version de PoWA représente un temps de développement très important,&#xA;de nombreuses améliorations sur la documentation et beaucoup de tests.  Nous&#xA;somme maintenant assez satisfaits, mais il est possible que nous ayons ratés&#xA;certains bugs.  Si vous vous intéressez à ce projet, j’espère que vous&#xA;essaierez de tester cette beta, et si besoin n’hésitez pas à &lt;a href=&#34;https://powa.readthedocs.io/en/latest/support.html#support&#34;&gt;nous remonter un&#xA;bug&lt;/a&gt;!&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html&#34;&gt;PoWA 4 apporte un mode remote, disponible en beta !&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on May 17, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>Nouveauté pg12: Statistiques sur les erreurs de checkums</title>
    <updated>2019-04-18T11:02:26Z</updated>
    <id>tag:rjuju.github.io,2019-04-18:/postgresqlfr/2019/04/18/nouveau-dans-pg12-statistiques-erreurs-checksums.html</id>
    <content type="html">&lt;h3 id=&#34;data-checksums&#34;&gt;Data checksums&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Ajoutés dans &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=96ef3b8ff1c&#34;&gt;PostgreSQL&#xA;9.3&lt;/a&gt;,&#xA;les &lt;a href=&#34;https://www.postgresql.org/docs/current/app-initdb.html#APP-INITDB-DATA-CHECKSUMS&#34;&gt;data&#xA;checksums&lt;/a&gt;&#xA;peuvent aider à détecter les corruptions de données survenant sur votre&#xA;stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les checksums sont activés si l’instance a été initialisée en utilisant &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;initdb&#xA;--data-checksums&lt;/code&gt; (ce qui n’est pas le comportement par défaut), ou s’ils ont&#xA;été activés après en utilisant la nouvelle utilitaire&#xA;activated afterwards with the new&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/devel/app-pgchecksums.html&#34;&gt;pg_checksums&lt;/a&gt;&#xA;également &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=ed308d783790&#34;&gt;ajouté dans PostgreSQL&#xA;12&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Quand les checksums sont ativés, ceux-ci sont écrits à chaque fois qu’un bloc&#xA;de données est écrit sur disque, et vérifiés à chaque fois qu’un bloc est lu&#xA;depuis le disque (ou depuis le cache du système d’exploitation).  Si la&#xA;vérification échoue, une erreur est remontée dans les logs.  Si le bloc était&#xA;lu par un processus client, la requête associée échouera bien évidemment, mais&#xA;si le bloc était lu par une opération&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/protocol-replication.html#id-1.10.5.9.7.1.8.1.12&#34;&gt;BASE_BACKUP&lt;/a&gt;&#xA;(tel que pg_basebackup), la commande continuera à s’exécuter.  Bien que les&#xA;data checksums ne détecteront qu’un sous ensemble des problèmes possibles, ils&#xA;ont tout de même une certaine utilisé, surtout si vous ne faites pas confiance&#xA;à votre stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Jusqu’à PostgreSQL 11, les erreurs de validation de checksum ne pouvaient être&#xA;trouvées qu’en cherchant dans les logs, ce qui n’est clairement pas pratique si&#xA;vous voulez monitorer de telles erreurs.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;nouveaux-compteurs-disponibles-dans-pg_stat_database&#34;&gt;Nouveaux compteurs disponibles dans pg_stat_database&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Pour rendre la supervision des erreurs de checksum plus simple, et pour aider&#xA;les utilisateurs à réagir dès qu’un tel problème survient, PostgreSQL 12 ajoute&#xA;de nouveaux compteurs dans la vue &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_database&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit 6b9e875f7286d8535bff7955e5aa3602e188e436&#xA;Author: Magnus Hagander &amp;lt;magnus@hagander.net&amp;gt;&#xA;Date:   Sat Mar 9 10:45:17 2019 -0800&#xA;&#xA;Track block level checksum failures in pg_stat_database&#xA;&#xA;This adds a column that counts how many checksum failures have occurred&#xA;on files belonging to a specific database. Both checksum failures&#xA;during normal backend processing and those created when a base backup&#xA;detects a checksum failure are counted.&#xA;&#xA;Author: Magnus Hagander&#xA;Reviewed by: Julien Rouhaud&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit 77bd49adba4711b4497e7e39a5ec3a9812cbd52a&#xA;Author: Magnus Hagander &amp;lt;magnus@hagander.net&amp;gt;&#xA;Date:   Fri Apr 12 14:04:50 2019 +0200&#xA;&#xA;    Show shared object statistics in pg_stat_database&#xA;&#xA;    This adds a row to the pg_stat_database view with datoid 0 and datname&#xA;    NULL for those objects that are not in a database. This was added&#xA;    particularly for checksums, but we were already tracking more satistics&#xA;    for these objects, just not returning it.&#xA;&#xA;    Also add a checksum_last_failure column that holds the timestamptz of&#xA;    the last checksum failure that occurred in a database (or in a&#xA;    non-dataabase file), if any.&#xA;&#xA;    Author: Julien Rouhaud &amp;lt;rjuju123@gmail.com&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit 252b707bc41cc9bf6c55c18d8cb302a6176b7e48&#xA;Author: Magnus Hagander &amp;lt;magnus@hagander.net&amp;gt;&#xA;Date:   Wed Apr 17 13:51:48 2019 +0200&#xA;&#xA;    Return NULL for checksum failures if checksums are not enabled&#xA;&#xA;    Returning 0 could falsely indicate that there is no problem. NULL&#xA;    correctly indicates that there is no information about potential&#xA;    problems.&#xA;&#xA;    Also return 0 as numbackends instead of NULL for shared objects (as no&#xA;    connection can be made to a shared object only).&#xA;&#xA;    Author: Julien Rouhaud &amp;lt;rjuju123@gmail.com&amp;gt;&#xA;    Reviewed-by: Robert Treat &amp;lt;rob@xzilla.net&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Ces compteurs reflèteront les erreurs de validation de checksum à la fois pour&#xA;les processus clients et pour l’activité&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/protocol-replication.html#id-1.10.5.9.7.1.8.1.12&#34;&gt;BASE_BACKUP&lt;/a&gt;,&#xA;par base de données.&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;n&#34;&gt;rjuju&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_stat_database&lt;/span&gt;&#xA;                        &lt;span class=&#34;k&#34;&gt;View&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;pg_catalog.pg_stat_database&#34;&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-----------------------+--------------------------+-----------+----------+---------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;datid&lt;/span&gt;                 &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;                      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt;               &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;                     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;p&#34;&gt;[...]&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;checksum_failures&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;bigint&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;checksum_last_failure&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;p&#34;&gt;[...]&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;stats_reset&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;La colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;checksum_failures&lt;/code&gt; montrera un nombre cumulé d’erreurs, et la&#xA;colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;checksum_last_failure&lt;/code&gt; montrera l’horodatage de la dernière erreur de&#xA;validation sur la base de données (NULL si aucune erreur n’est jamais&#xA;survenue).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour éviter toute confusion (merci à Robert Treat pour l’avoir signalé), ces&#xA;deux colonnes retourneront toujours NULL si les data checkums ne sont pas&#xA;activés, afin qu’on ne puisse pas croire que les checksums sont toujours&#xA;vérifiés avec succès.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Comme effet de bord, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_database&lt;/code&gt;  montrera maintenant également les&#xA;statistiques disponibles pour les objets partagés (tels que la table&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_database&lt;/code&gt; par exemple), dans une nouvelle ligne pour laquelle &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;datid&lt;/code&gt; vaut&#xA;&lt;strong&gt;0&lt;/strong&gt;, et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;datname&lt;/code&gt; vaut &lt;strong&gt;NULL&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;del&gt;Une sonde dédiée est également &lt;a href=&#34;https://github.com/OPMDG/check_pgactivity/issues/226&#34;&gt;déjà&#xA;planifiée&lt;/a&gt; dans&#xA;&lt;a href=&#34;https://opm.readthedocs.io/probes/check_pgactivity.html&#34;&gt;check_pgactivity&lt;/a&gt; !&lt;/del&gt;&#xA;Une sonde dédiée est également &lt;a href=&#34;https://github.com/OPMDG/check_pgactivity/commit/0e8b516e95e4364470d4e205aebc9fe68bbcfd23&#34;&gt;déjà&#xA;disponible&lt;/a&gt;&#xA;dans &lt;a href=&#34;https://opm.readthedocs.io/probes/check_pgactivity.html&#34;&gt;check_pgactivity&lt;/a&gt; !&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/04/18/nouveau-dans-pg12-statistiques-erreurs-checksums.html&#34;&gt;Nouveauté pg12: Statistiques sur les erreurs de checkums&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on April 18, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/04/18/nouveau-dans-pg12-statistiques-erreurs-checksums.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>Mettre en place une streaming replication avec PostgreSQL 10</title>
    <updated>2018-03-13T06:28:00Z</updated>
    <id>tag:blog.raveland.tech,2018-03-13:/post/postgresql_sr_fr/</id>
    <link href="https://blog.raveland.tech/post/postgresql_sr_fr/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Dans ce post, je vais vous expliquer comment mettre en place une &lt;em&gt;streaming replication&lt;/em&gt; avec PostgreSQL 10. Par contre, je n&amp;rsquo;expliquerais pas comment installer PostgreSQL donc je suppose que cela est déjà le cas.&lt;/p&gt;</summary>
    <author>
      <name>blog.raveland.tech</name>
    </author>
  </entry>
  <entry>
    <title>OpenBSD / PostgreSQL / Authentification</title>
    <updated>2017-11-29T11:31:53Z</updated>
    <id>tag:blog.raveland.tech,2017-11-29:/post/openbsd_pg/</id>
    <link href="https://blog.raveland.tech/post/openbsd_pg/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Si vous êtes un utilisateur d&amp;rsquo;OpenBSD et de PostgreSQL, vous pouvez utiliser l&amp;rsquo;authentification BSD pour vous authentifier sur vos bases.&#xA;Nous allons voir comment faire cela.&lt;/p&gt;</summary>
    <author>
      <name>blog.raveland.tech</name>
    </author>
  </entry>
  <entry>
    <title>Postgresql et la réplication logique</title>
    <updated>2017-11-27T08:32:06Z</updated>
    <id>tag:blog.raveland.tech,2017-11-27:/post/postgresql_lr/</id>
    <link href="https://blog.raveland.tech/post/postgresql_lr/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cet article va tester la nouvelle fonctionnalité disponible depuis PostgreSQL 10.0 : la réplication logique.&lt;/p&gt;&#xA;&lt;p&gt;Pour en savoir plus, l&amp;rsquo;excellente &lt;a href=&#34;https://docs.postgresql.fr/10/logical-replication.html&#34;&gt;documentation de PostgreSQL&lt;/a&gt;&lt;/p&gt;</summary>
    <author>
      <name>blog.raveland.tech</name>
    </author>
  </entry>
</feed>