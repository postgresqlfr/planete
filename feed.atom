<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>Planète PostgreSQL</title>
  <id>https://planete.postgresql.fr/</id>
  <updated>2023-09-07T16:32:45Z</updated>
  <subtitle>L&#39;actualité de PostgreSQL de français</subtitle>
  <link href="https://planete.postgresql.fr/"></link>
  <author>
    <name>PostgreSQL.fr</name>
    <email>contact@postgresql.fr</email>
  </author>
  <entry>
    <title>Mesurer facilement la latence I/O avec PostgreSQL 16</title>
    <updated>2023-09-02T16:30:00Z</updated>
    <id>tag:pgphil.ovh,2023-09-02:/traqueur_16_01.php</id>
    <link href="http://pgphil.ovh/traqueur_16_01.php" rel="alternate"></link>
    <summary type="html">Démonstration avec le traqueur d&#39;une nouvelle fonctionnalité PostgreSQL 16 facilitant le suivi des performances et le diagnostic des ralentissements</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>Mettre à jour PostgreSQL pour améliorer les performances</title>
    <updated>2023-05-21T09:00:00Z</updated>
    <id>tag:pgphil.ovh,2023-05-21:/migration_performance_14_15_01.php</id>
    <link href="http://pgphil.ovh/migration_performance_14_15_01.php" rel="alternate"></link>
    <summary type="html">Pagination, ex aequo...obtenez vos résultats triés bien plus rapidement avec PostgreSQL 15</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL inspire les autres SGBD ?</title>
    <updated>2023-04-12T09:00:00Z</updated>
    <id>tag:pgphil.ovh,2023-04-12:/oracle23c_ou_oracle23p_comme_postgresql.php</id>
    <link href="http://pgphil.ovh/oracle23c_ou_oracle23p_comme_postgresql.php" rel="alternate"></link>
    <summary type="html">Oracle 23c ou 23p comme PostgreSQL ?</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>CYCLE</title>
    <updated>2022-12-03T15:00:00Z</updated>
    <id>tag:pgphil.ovh,2022-12-03:/nocycle_15_01.php</id>
    <link href="http://pgphil.ovh/nocycle_15_01.php" rel="alternate"></link>
    <summary type="html">Nouveautés autour des requêtes hiérarchiques avec PostgreSQL 14 et versions supérieures</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>MERGE</title>
    <updated>2022-03-29T17:30:00Z</updated>
    <id>tag:pgphil.ovh,2022-03-29:/upsert_15_devel_01.php</id>
    <link href="http://pgphil.ovh/upsert_15_devel_01.php" rel="alternate"></link>
    <summary type="html">Introduction de la commande MERGE par PostgreSQL 15</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>Limitations du planner (optimiseur) de PostgreSQL</title>
    <updated>2022-03-06T18:45:00Z</updated>
    <id>tag:pgphil.ovh,2022-03-06:/limitations_planner_13_01.php</id>
    <link href="http://pgphil.ovh/limitations_planner_13_01.php" rel="alternate"></link>
    <summary type="html">Est-il toujours possible en 2022 de faire trébucher l&#39;optimiseur statistique de PostgreSQL ? Comment y remédier ?</summary>
    <author>
      <name>pgphil.ovh</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #104</title>
    <updated>2023-09-01T13:36:00Z</updated>
    <id>tag:sebastien.lardiere.net,2023-09-01:/blog/index.php/post/2023/09/01/PostgreSQL-Hebdo-104</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2023/09/01/PostgreSQL-Hebdo-104" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/postgresql-v16-cool-new-features/&#34;&gt;Postgres v16: 14 Cool New Features&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.loxodata.com/post/postgresql-16-rc1/&#34;&gt;PostgreSQL 16 en RC1&lt;/a&gt; : la publication de PostgreSQL 16 approche ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.crunchydata.com/blog/top-10-postgres-management-tasks&#34;&gt;Top 10 Postgres Management Tasks&lt;/a&gt; : Quelques conseils pertinents pour les administrateurs souhaitant maitriser leurs instances PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.percona.com/blog/streamline-the-sql-code-guide-to-pgformatter/&#34;&gt;Streamline the SQL Code: Guide to pgFormatter&lt;/a&gt; : pgformatter est un excellent outil pour aider à la lecture et la compréhension des requêtes SQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ubuntu.com/blog/postgresql-high-availability&#34;&gt;PostgreSQL high availability made charmingly easy&lt;/a&gt; : Un outil pour faciliter le déploiement d&#39;une stack PostgreSQL complète ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.timescale.com/blog/best-practices-for-picking-postgresql-data-types/&#34;&gt;Best Practices for Picking PostgreSQL Data Types&lt;/a&gt; : quels types de données faut-il choisir pour l&#39;extension timescaledb ?&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.depesz.com/2023/09/01/waiting-for-postgresql-17-add-to_bin-and-to_oct/&#34;&gt;Waiting for PostgreSQL 17 – Add to_bin() and to_oct()&lt;/a&gt; : l&#39;usage de ces fonctions n&#39;est pas si fréquent, mais c&#39;est aussi l&#39;occasion de montrer que le développement de la version 17 a déjà commencé ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #103</title>
    <updated>2023-07-21T13:17:00Z</updated>
    <id>tag:sebastien.lardiere.net,2023-07-21:/blog/index.php/post/2023/07/21/PostgreSQL-Hebdo-103</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2023/07/21/PostgreSQL-Hebdo-103" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dataegret.com/2023/06/please-welcome-pg_index_watch-a-utility-for-dealing-with-index-bloat-on-frequently-updated-tables/&#34;&gt;Please welcome Pg_index_watch – a utility for dealing with index bloat on frequently updated tables&lt;/a&gt; puis &lt;a href=&#34;https://dataegret.com/2023/07/automated-index-bloat-management-how-pg_index_watch-keeps-postgresql-indexes-lean/&#34;&gt;Automated index bloat management: How pg_index_watch keeps PostgreSQL indexes lean&lt;/a&gt; : comment gérer la fragmentation des index ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kmoppel.github.io/2023-07-04-til-in-is-not-the-same-as-any/&#34;&gt;TIL - IN is not the same as ANY&lt;/a&gt; : les deux opérateurs produisent le même résultat, mais pas de la même manière ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/darold/ora2pg/releases/tag/v24.0&#34;&gt;Ora2Pg 24.0 have been released&lt;/a&gt; : comme nouveauté, notons le support de MS-SQL-Server !&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/subqueries-and-performance-in-postgresql/&#34;&gt;Subqueries and performance in PostgreSQL&lt;/a&gt; : de l&#39;utilisation des sous-requêtes et des CTEs ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.architecture-performance.fr/ap_blog/postgresql-features-matrix-gpt-optimized/&#34;&gt;&lt;/a&gt; : une matrice des fonctionnalités de PostgreSQL générée à l&#39;aide de ChatGPT ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://twitter.com/samokhvalov/status/1679953049899642880&#34; title=&#34;https://twitter.com/samokhvalov/status/1679953049899642880&#34;&gt;https://twitter.com/samokhvalov/sta...&lt;/a&gt; : un tweet plein de bons conseils ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.citusdata.com/blog/2023/07/18/citus-12-schema-based-sharding-for-postgres/&#34;&gt;Citus 12: Schema-based sharding for PostgreSQL&lt;/a&gt; : Citus est un outil pour faire grandir votre architecture de base de données ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.percona.com/blog/how-to-measure-the-network-impact-on-postgresql-performance/&#34;&gt;How To Measure the Network Impact on PostgreSQL Performance&lt;/a&gt; : cet aspect de l&#39;analyse de la performance est trop souvent ignoré, et pourtant, il est important ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #102</title>
    <updated>2023-07-03T14:48:00Z</updated>
    <id>tag:sebastien.lardiere.net,2023-07-03:/blog/index.php/post/2023/07/03/PostgreSQL-Hebdo-102</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2023/07/03/PostgreSQL-Hebdo-102" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lwn.net/SubscriberLink/934940/67531dfd296a5ba1/&#34;&gt;PostgreSQL reconsiders its process-based model&lt;/a&gt; : résumé des discussions à propos d&#39;une refonte en profondeur de PostgreSQL, d&#39;un modèle basé sur des processus vers un modèle basé sur des threads ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.crunchydata.com/blog/performance-tips-for-postgres-fdw&#34;&gt;Performance Tips for Postgres FDW&lt;/a&gt; : quelques bonnes pratiques pour l&#39;efficacité des accès distants aux données ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.rustprooflabs.com/2023/06/postgres15-explain-buffer-temp-timings&#34;&gt;Postgres 15: Explain Buffer now with Temp Timings&lt;/a&gt; : À partir de la version 15, les temps d&#39;IO des fichiers temporaires sont visibles dans les plans d&#39;exécutions ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://jkatz05.com/post/postgres/vectors-json-postgresql/&#34;&gt;Vectors are the new JSON in PostgreSQL&lt;/a&gt;: à propos de l&#39;utilisation de vecteurs dans PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-16-beta-2-released-2665/&#34;&gt;PostgreSQL 16 Beta 2 Released!&lt;/a&gt; : deuxième beta de la version 16 de PostgreSQL, à tester !&#xA;&lt;ul&gt;&#xA;&lt;li&gt;en français : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-16-beta2/&#34; title=&#34;https://www.loxodata.com/post/postgresql-16-beta2/&#34;&gt;https://www.loxodata.com/post/postg...&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #101</title>
    <updated>2023-06-12T13:43:00Z</updated>
    <id>tag:sebastien.lardiere.net,2023-06-12:/blog/index.php/post/2023/06/12/PostgreSQL-Hebdo-101</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2023/06/12/PostgreSQL-Hebdo-101" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pgvis.org/&#34;&gt;Simple Visualisations For PostgreSQL&lt;/a&gt; : un outil facilitant la visualisation du résultat d&#39;une requête ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-16-beta-1-released-2643/&#34;&gt;PostgreSQL 16 Beta 1 Released!&lt;/a&gt; : testez la prochaine version de PostgreSQL, les paquets pour Debian et Redhat sont déjà prêts. Traduction en français : &lt;a href=&#34;https://www.loxodata.com/post/postgresql-16-beta1/&#34;&gt;PostgreSQL 16 bêta 1&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rhaas.blogspot.com/2023/05/do-i-really-need-that-backuplabel-file.html&#34;&gt;Do I Really Need That backup_label File?&lt;/a&gt; : pas toujours évident de savoir pourquoi telle bonne pratique est essentielle, mais il est souvent préférable de suivre les recomandations données par la documentation ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.keithf4.com/posts/2023-05-30-new-hugo-new-partman/&#34;&gt;New Site, New Partman&lt;/a&gt; : l&#39;extension de gestion des tables partitionnées évolue ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.crunchydata.com/blog/pgbackrest-file-bundling-and-block-incremental-backup&#34;&gt;pgBackRest File Bundling and Block Incremental Backup&lt;/a&gt; : L&#39;outil de sauvegarde pgBackRest continue d&#39;innover et de proposer de nouvelles options pour améliorer l&#39;exploitation des sauvegardes de PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog-postgresql.verite.pro/2023/06/11/caracteres-icu.html&#34;&gt;Classification des caractères avec ICU&lt;/a&gt; : l&#39;utilisation d&#39;ICI à la place de la libc pour les collations ouvrent de nombreuses possibilités ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kmoppel.github.io/2023-06-07-til-filling-prepared-statement-placeholders-automatically-with-pgbadger/&#34;&gt;TIL - Filling prepared statement placeholders automatically with pgbadger&lt;/a&gt; : l&#39;outil pgbadger est un très bon outil pour extraire des informations des logs de PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/what-is-a-schema-in-postgresql/&#34;&gt;What is a schema in PostgreSQL?&lt;/a&gt; : le schema est un objet mal connu, bien que très souvent utilisé ;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #100</title>
    <updated>2023-05-12T13:48:00Z</updated>
    <id>tag:sebastien.lardiere.net,2023-05-12:/blog/index.php/post/2023/05/12/PostgreSQL-Hebdo-100</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2023/05/12/PostgreSQL-Hebdo-100" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://philbooth.me/blog/nine-ways-to-shoot-yourself-in-the-foot-with-postgresql&#34;&gt;Nine ways to shoot yourself in the foot with PostgreSQL&lt;/a&gt; : Toujours bon à prendre, ces conseils peuvent guider dans la compréhension de qui ne va pas avec notre usage de PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.softwareandbooz.com/in-defense-of-postgresql-mvcc-and-vacuuming/&#34;&gt;https://www.softwareandbooz.com/in-defense-of-postgresql-mvcc-and-vacuuming/&lt;/a&gt; : Il est vrai que les sujets des VACUUM et de la fragmentation est ennuyeux, mais en réalité tout à fait gérable, au regard des avantages apportés par MVCC ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-153-148-1311-1215-and-1120-released-2637/&#34;&gt;PostgreSQL 15.3, 14.8, 13.11, 12.15, and 11.20 Released!&lt;/a&gt; : Mettez à jour vos instances PostgreSQL !&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/forcing-a-join-order-in-postgresql/&#34;&gt;Forcing a join order in PostgreSQL&lt;/a&gt; : forcer les plans d&#39;exécution n&#39;est pas toujours une bonne idée, mais c&#39;est parfois nécessaire. Attention à la dette technique que cela introduit ;&lt;/li&gt;&#xA;&lt;li&gt;Publication de &lt;a href=&#34;https://www.pgbouncer.org/changelog.html#pgbouncer-119x&#34;&gt;PgBouncer 1.19.0&lt;/a&gt; : avec, en autres, un nouveau paramètre &lt;code&gt;auth_dbname&lt;/code&gt;, pour simplifier la gestion de l&#39;authentification ;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&lt;p&gt;À venir dans PostgreSQL 16 :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/lz4-zstd-pg_dump-compression-postgresql-16/&#34;&gt;LZ4 and ZSTD pg_dump compression&lt;/a&gt; : des algorithmes de compression plus efficace pour les sauvegardes logiques ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mydbops.wordpress.com/2023/05/07/postgresql-16-brings-load-balancing-support-in-libpq-psql/&#34;&gt;PostgreSQL 16 brings Load Balancing Support in libpq (psql)&lt;/a&gt; : ce qui était déjà possible en Java le devient pour tous les clients utilisant la libpq ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/message-id/0048141b-9a6d-23da-13d3-ba4e55d6a0c5@postgresql.org&#34;&gt;PostgreSQL 16 Beta 1 release date&lt;/a&gt; : le 25 mai !&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL Hebdo #99</title>
    <updated>2023-04-24T08:18:00Z</updated>
    <id>tag:sebastien.lardiere.net,2023-04-24:/blog/index.php/post/2023/04/24/PostgreSQL-Hebdo-99</id>
    <link href="http://sebastien.lardiere.net/blog/index.php/post/2023/04/24/PostgreSQL-Hebdo-99" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lu ces dernières semaines :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dev.to/ftisiot/postgresqlr-jsonb-cheatsheet-complete-fast-lookup-guide-2ba1&#34;&gt;PostgreSQL® JSONB Cheatsheet: Complete and Fast Lookup Guide&lt;/a&gt; : un aperçu du type de données jsonb et des méthodes associées, à connaître pour être efficace ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.dylanpaulus.com/posts/postgres-is-a-graph-database/&#34;&gt;Postgres: The Graph Database You Didn&#39;t Know You Had&lt;/a&gt; : PostgreSQL sait déjà faire des graphes avec des requêtes récursives ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://peter.eisentraut.org/blog/2023/04/18/postgresql-and-sql-2023&#34;&gt;PostgreSQL and SQL:2023&lt;/a&gt; : suite au précédent billet sur le même sujet, la liste des fonctionnalités présentes ou non dans PostgreSQL ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://event-driven.io/en/postgres_superpowers/&#34;&gt;Postgres Superpowers in Practice&lt;/a&gt; : beaucoup de possibilités offertes par PostgreSQL et ses extensions méritent le détour, car cela peut faciliter grandement une utilisation riche des données ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kmoppel.github.io/2023-04-18-can-there-be-too-many-partitions/&#34;&gt;Can there be too many partitions?&lt;/a&gt; : peut-on utiliser un grand nombre de partitions ? il semble que oui, c&#39;est possible ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://makina-corpus.com/sig-cartographie/structurer-donnees-geographiques-maniere-arborescente-postgresql-ltree&#34;&gt;Structurer des données géographiques de manière arborescente avec PostgreSQL et ltree&lt;/a&gt; : utiliser les extensions disponibles avec PostgreSQL permet d&#39;exploiter au mieux nos données ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.thenile.dev/blog/things-dbs-dont-do&#34;&gt;Things DBs Don&#39;t Do - But Should&lt;/a&gt; : nos bases de données ne savent pas tout faire (ça n&#39;est d&#39;ailleurs pas souhaitables), mais que pourraient-elles faire de mieux à l&#39;avenir, afin de servir encore mieux les interêts de nos utilisateurs ?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&lt;p&gt;À venir dans PostgreSQL 16 :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/explain-generic-plan-postgresql-16/&#34;&gt;EXPLAIN (GENERIC_PLAN): New in PostgreSQL 16&lt;/a&gt; : à partir de la version 16 de PostgreSQL, en cours de développement, on a la possibilité d&#39;analyser un plan d&#39;exécution générique ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://bdrouvot.github.io/2023/04/19/postgres-16-highlight-logical-decoding-on-standby/&#34;&gt;Postgres 16 highlight: Logical decoding on standby&lt;/a&gt; : la réplication logique devient possible à partir d&#39;un secondaire « physique » ;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cybertec-postgresql.com/en/underscores-in-numeric-constants-in-postgresql-16/&#34;&gt;Underscores in numeric constants in PostgreSQL 16&lt;/a&gt; : la notation standard des nombres évolue, et PostgreSQL aussi !&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Sébastien Lardière</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 16 en RC1</title>
    <updated>2023-08-31T13:30:00Z</updated>
    <id>tag:www.loxodata.com,2023-08-31:/post/postgresql-16-rc1/</id>
    <link href="http://www.loxodata.com/post/postgresql-16-rc1/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le PostgreSQL Global Development Group a annoncé la publication de la première&#xA;Release Candidate de PostgreSQL 16. En tant que Release Candidate, la version&#xA;de PostgreSQL 16 RC1 sera quasiment identique à la publication initiale de&#xA;PostgreSQL 16, cependant, des corrections pourront être appliquées avant la&#xA;mise à disposition de la version finale de PostgreSQL 16.&lt;/p&gt;&#xA;&lt;p&gt;La date de publication pour la version finale de PostgreSQL 16 est prévue au 14&#xA;septembre 2023. Consulter la section &lt;a href=&#34;#planning-des-publications&#34;&gt;Planning des publications&lt;/a&gt;&#xA;pour plus de détails.&lt;/p&gt;&#xA;&lt;h1 id=&#34;mise-à-jour-vers-la-rc1-de-postgresql-16&#34;&gt;Mise à jour vers la RC1 de PostgreSQL 16&lt;/h1&gt;&#xA;&lt;p&gt;Pour mettre à jour votre version de PostgreSQL depuis une précédente version de&#xA;PostgreSQL, vous pouvez utiliser la même stratégie que pour mettre à jour vers&#xA;toute version majeure de PostgreSQL (par exemple avec la commande &lt;code&gt;pg_upgrade&lt;/code&gt;&#xA;ou &lt;code&gt;pg_dump&lt;/code&gt;/&lt;code&gt;pg_restore&lt;/code&gt;).&lt;/p&gt;&#xA;&lt;p&gt;Pour plus d&amp;rsquo;information, consultez la section &lt;a href=&#34;https://www.postgresql.org/docs/16/upgrading.html&#34;&gt;mise à jour&lt;/a&gt;&#xA;de la documentation officielle : &lt;a href=&#34;https://www.postgresql.org/docs/16/upgrading.html&#34;&gt;https://www.postgresql.org/docs/16/upgrading.html&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;changements-depuis-la-bêta-3&#34;&gt;Changements depuis la bêta 3&lt;/h1&gt;&#xA;&lt;p&gt;Plusieurs corrections ont été apportées à PostgreSQL 16 suite aux remontées&#xA;d&amp;rsquo;utilisateurs ayant testé la bêta 3.&lt;/p&gt;&#xA;&lt;p&gt;La principale concerne la correction d&amp;rsquo;un problème de performance lors de chargements parallèles sur une table unique à l&amp;rsquo;aide de la commande &lt;code&gt;COPY&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Pour la liste complète des corrections, veuillez consulter la page des&#xA;&lt;a href=&#34;https://wiki.postgresql.org/wiki/PostgreSQL_16_Open_Items#resolved_before_16rc1&#34;&gt;tickets&lt;/a&gt; ouverts.&lt;/p&gt;&#xA;&lt;h1 id=&#34;planning-des-publications&#34;&gt;Planning des publications&lt;/h1&gt;&#xA;&lt;p&gt;Il s&amp;rsquo;agit de la première Release Candidate de la version 16. Sauf à découvrir un&#xA;problème imposant un nouveau délai ou une nouvelle Release Candidate, PostgreSQL&#xA;16 devrait être publiée le 14 septembre 2023.&lt;/p&gt;&#xA;&lt;p&gt;Pour plus d&amp;rsquo;information, veuillez consulter la page &lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;Beta Testing&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;liens&#34;&gt;Liens&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;Téléchargement&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;Information sur le Bêta Testing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;Note de publication de PostgreSQL 16&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://wiki.postgresql.org/wiki/PostgreSQL_16_Open_Items&#34;&gt;Problèmes connus de PostgreSQL 16&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/featurematrix/#configuration-management&#34;&gt;Matrice de fonctionnalités&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/account/submitbug/&#34;&gt;Soumettre un bogue&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://twitter.com/postgresql&#34;&gt;Suivre @postgresql sur Twitter&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/donate/&#34;&gt;Faire un don&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 15.4, 14.9, 13.12, 12.16, 11.21 et 16 bêta 3</title>
    <updated>2023-08-17T13:30:00Z</updated>
    <id>tag:www.loxodata.com,2023-08-17:/post/postgresql-16-beta3-and-fix/</id>
    <link href="http://www.loxodata.com/post/postgresql-16-beta3-and-fix/" rel="alternate"></link>
    <summary type="html">&lt;h1 id=&#34;publication-des-mises-à-jour-de-postgresql-154-149-1312-1216-1121-et-de-postgresql-16-bêta-3&#34;&gt;Publication des mises à jour de PostgreSQL 15.4, 14.9, 13.12, 12.16, 11.21 et de PostgreSQL 16 bêta 3&lt;/h1&gt;&#xA;&lt;p&gt;Le PostgreSQL Global Development Group a annoncé la publication d&amp;rsquo;une mise à jour&#xA;pour toutes les versions supportées de PostgreSQL, incluant les versions 15.4,&#xA;14.9, 13.12, 12.16 et 11.21 ainsi que la bêta 3 de PostgreSQL 16.&#xA;Cette publication inclut le correctif de deux failles de sécurité et de plus de 40&#xA;bugs reportés ces derniers mois.&lt;/p&gt;&#xA;&lt;p&gt;Si vous utilisez des index BRIN pour vérifier les valeurs NULL, vous aurez&#xA;besoin de &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-reindex.html&#34;&gt;réindexer&lt;/a&gt;&#xA;ces derniers après la mise à jour. Sur PostgreSQL 12 et supérieur, vous pouvez&#xA;utiliser &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-reindex.html&#34;&gt;&lt;code&gt;REINDEX CONCURRENTLY&lt;/code&gt;&lt;/a&gt;&#xA;pour ne pas bloquer les écritures sur les index concernés et leur table, par&#xA;exemple :&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;REINDEX INDEX CONCURRENTLY your_index_name;&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;Pour plus de détails, se référer à la &lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;note de version&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;notice-de-dépréciation-de-postgresql-11&#34;&gt;Notice de dépréciation de PostgreSQL 11&lt;/h2&gt;&#xA;&lt;p&gt;PostgreSQL 11 ne recevra plus de correctifs à partir du 9 novembre 2023. Si vous&#xA;utilisez cette version sur un environnement de production, nous vous recommandons&#xA;de mettre à jour vers une version plus récente et supportée de PostgreSQL.&#xA;Merci de consulter notre &lt;a href=&#34;https://www.postgresql.org/support/versioning/&#34;&gt;politique de gestion de version&lt;/a&gt;&#xA;pour plus de détails.&lt;/p&gt;&#xA;&lt;h2 id=&#34;failles-de-sécurité&#34;&gt;Failles de sécurité&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/support/security/CVE-2023-39417/&#34;&gt;CVE-2023-39417&lt;/a&gt;: Les &lt;code&gt;@substitutions@&lt;/code&gt; entre guillements dans les scripts d&amp;rsquo;extension permettent l&amp;rsquo;injection SQL.&lt;/p&gt;&#xA;&lt;p&gt;Versions supportées vulnérables : 11 - 15. L&amp;rsquo;équipe de sécurité ne teste&#xA;pas les versions non supportées, mais ce problème est assez ancien.&lt;/p&gt;&#xA;&lt;p&gt;Un &lt;a href=&#34;https://www.postgresql.org/docs/current/extend-extensions.html&#34;&gt;script d&amp;rsquo;extension&lt;/a&gt;&#xA;est vulnérable s&amp;rsquo;il utilise &lt;code&gt;@extowner@&lt;/code&gt;, &lt;code&gt;@extschema@&lt;/code&gt; ou &lt;code&gt;@extschema&lt;/code&gt;:&amp;hellip;@ à&#xA;l&amp;rsquo;intérieur d&amp;rsquo;une construction de guillemets (guillemets dollars, &lt;code&gt;&#39;&#39;&lt;/code&gt;, ou &lt;code&gt;&amp;quot;&amp;quot;&lt;/code&gt;).&#xA;Aucune extension incluse n&amp;rsquo;est vulnérable. Les utilisations vulnérables&#xA;apparaissent dans un exemple de documentation et dans des extensions non incluses.&#xA;Par conséquent, la condition préalable à l&amp;rsquo;attaque est qu&amp;rsquo;un administrateur ait&#xA;installé des fichiers d&amp;rsquo;une extension vulnérable, fiable et non incluse. Sous&#xA;réserve de cette condition préalable, cela permet à un attaquant ayant les&#xA;privilèges &lt;code&gt;CREATE&lt;/code&gt; au niveau de la base de données d&amp;rsquo;exécuter du code arbitraire&#xA;en tant que super-utilisateur de démarrage. PostgreSQL bloquera cette attaque&#xA;dans le serveur principal, il n&amp;rsquo;est donc pas nécessaire de modifier les&#xA;extensions individuelles.&lt;/p&gt;&#xA;&lt;p&gt;Le projet PostgreSQL remercie Micah Gate, Valerie Woolard, Tim Carey-Smith, et&#xA;Christoph Berg pour avoir rapporté ce problème.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/support/security/CVE-2023-39418/&#34;&gt;CVE-2023-39418&lt;/a&gt;: &lt;code&gt;MERGE&lt;/code&gt; ne vérifie pas les règles de sécurité de lignes sur &lt;code&gt;UPDATE&lt;/code&gt; ou &lt;code&gt;SELECT&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Versions supportées vulnérables : 15.&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 15 a introduit la commande &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-merge.html&#34;&gt;&lt;code&gt;MERGE&lt;/code&gt;&lt;/a&gt;&#xA;qui échoue à la vérification des règles de sécurité sur de nouvelles lignes pour&#xA;un &lt;code&gt;UPDATE&lt;/code&gt; ou &lt;code&gt;SELECT&lt;/code&gt;. Si des règles sur &lt;code&gt;UPDATE&lt;/code&gt; ou &lt;code&gt;SELECT&lt;/code&gt; interdisent des&#xA;lignes que des règles sur &lt;code&gt;INSERT&lt;/code&gt; autorisent, alors un utilisateur peut stocker&#xA;ces lignes. Les autres conséquences dépendent de l&amp;rsquo;application. Ceci n&amp;rsquo;affecte&#xA;que les bases de données pour lesquelles une règle de sécurité de&#xA;niveau ligne a été créée avec l&amp;rsquo;instruction &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-createpolicy.html&#34;&gt;CREATE POLICY&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Le projet PostgreSQL remercie Dean Rasheed pour avoir rapporté ce problème.&lt;/p&gt;&#xA;&lt;h2 id=&#34;note-sur-la-bêta-3-de-postgresql-16&#34;&gt;Note sur la bêta 3 de PostgreSQL 16&lt;/h2&gt;&#xA;&lt;p&gt;Cette publication marque la disponibilité de la bêta 3 de PostgreSQL 16 et rapproche&#xA;la communauté d&amp;rsquo;une possible mise à disposition globale vers la fin du troisième&#xA;trimestre.&lt;/p&gt;&#xA;&lt;p&gt;Dans l&amp;rsquo;esprit de la communauté open source PostgreSQL, nous vous&#xA;encourageons fortement à tester les nouvelles fonctionnalités de&#xA;PostgreSQL dans vos systèmes de bases de données. Ceci afin de nous&#xA;aider à éliminer les bogues et autres problèmes qui pourraient encore&#xA;exister. Bien que nous ne vous conseillions pas de faire fonctionner&#xA;PostgreSQL 16 bêta 3 dans vos environnements de production, nous vous&#xA;encourageons à trouver des moyens de faire fonctionner votre charge&#xA;applicative typique avec cette publication bêta.&lt;/p&gt;&#xA;&lt;p&gt;Vos tests et vos commentaires aideront la communauté à s&amp;rsquo;assurer que&#xA;PostgreSQL 16 respecte nos standards de stabilité et de fiabilité, pour&#xA;continuer à proposer la base de données open source la plus avancée au monde. Regardez&#xA;plus en détails le &lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;processus de bêta test&lt;/a&gt;&#xA;pour savoir comment vous pouvez y contribuer :&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;https://www.postgresql.org/developer/beta/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Vous trouverez plus d&amp;rsquo;informations sur toutes les fonctionnalités de PostgreSQL&#xA;16 et les changements dans la &lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;note de version&lt;/a&gt; :&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;https://www.postgresql.org/docs/16/release-16.html&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;correction-de-bogues-et-améliorations&#34;&gt;Correction de bogues et améliorations&lt;/h2&gt;&#xA;&lt;p&gt;Cette mise à jour corrige plus de 40 bogues reportés ces derniers mois. Les&#xA;problèmes listés ci-dessous affecte PostgreSQL 15. Certains de ces problèmes&#xA;peuvent aussi affecter d&amp;rsquo;autres versions de PostgreSQL.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Correction de la gestion des valeurs &lt;code&gt;NULL&lt;/code&gt; dans les index &lt;a href=&#34;https://www.postgresql.org/docs/current/brin-intro.html&#34;&gt;&lt;code&gt;BRIN&lt;/code&gt;&lt;/a&gt;.&#xA;Ce correctif ne s&amp;rsquo;applique pas sur des index &lt;code&gt;BRIN&lt;/code&gt; déjà existant &amp;ndash; vous&#xA;devrez procéder à un &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-reindex.html&#34;&gt;&lt;code&gt;REINDEX&lt;/code&gt;&lt;/a&gt; pour corriger tous les index utilisés pour rechercher valeurs &lt;code&gt;NULL&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;Ne pas laisser une base de données corrompue lorsqu&amp;rsquo;un &lt;code&gt;DROP DATABASE&lt;/code&gt; est&#xA;interrompu ;&lt;/li&gt;&#xA;&lt;li&gt;Plusieurs corrections d&amp;rsquo;index partitionnés ;&lt;/li&gt;&#xA;&lt;li&gt;Correction de &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-alterextension.html&#34;&gt;&lt;code&gt;ALTER EXTENSION ... SET SCHEMA&lt;/code&gt;&lt;/a&gt; pour déclencher&#xA;une erreur si l&amp;rsquo;extension contient des objets en dehors du schéma de&#xA;cette dernière ;&lt;/li&gt;&#xA;&lt;li&gt;Correction de la gestion de dépendance des méthodes d&amp;rsquo;accès des tables ;&lt;/li&gt;&#xA;&lt;li&gt;Ne pas utiliser d&amp;rsquo;index uniques partiels pour la vérification d&amp;rsquo;unicité&#xA;dans le planificateur ;&lt;/li&gt;&#xA;&lt;li&gt;Gestion correcte des sous-requêtes dans les expressions de règles RLS et vues&#xA;de sécurité à l&amp;rsquo;instanciation des actions de règles ;&lt;/li&gt;&#xA;&lt;li&gt;Correction des conditions de concurrence dans la détection de conflit pour le mode d&amp;rsquo;isolation de transaction &lt;code&gt;SERIALIZABLE&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;Correction d&amp;rsquo;erreurs intermittentes lors de la mise à jour d&amp;rsquo;un champ d&amp;rsquo;une colonne composite qui nécessite un &lt;a href=&#34;https://www.postgresql.org/docs/current/storage-toast.html&#34;&gt;TOASTing hors ligne&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;Correction de plusieurs fuites mémoire survenues pendant la durée de vie d&amp;rsquo;une requête ;&lt;/li&gt;&#xA;&lt;li&gt;Autoriser les fractions de secondes en paramètre de la méthode &lt;a href=&#34;https://www.postgresql.org/docs/current/functions-json.html#FUNCTIONS-SQLJSON-PATH-OPERATORS&#34;&gt;&lt;code&gt;jsonpath datetime()&lt;/code&gt;&lt;/a&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;Augmentation de la limite des tokens dans &lt;code&gt;pg_hba.conf&lt;/code&gt; et &lt;code&gt;pg_ident.conf&lt;/code&gt; à 10240 octets ;&lt;/li&gt;&#xA;&lt;li&gt;Une erreur de mémoire insuffisante provenant du compilateur JIT provoquera désormais une erreur &lt;code&gt;FATAL&lt;/code&gt; PostgreSQL au lieu d&amp;rsquo;une exception C++ ;&lt;/li&gt;&#xA;&lt;li&gt;Autoriser &lt;code&gt;VACUUM&lt;/code&gt; à continuer après avoir détecté certains types de corruption d&amp;rsquo;index B-tree. Bien que cette correction permette à &lt;code&gt;VACUUM&lt;/code&gt; de continuer, il reste nécessaire de corriger l&amp;rsquo;index corrompu avec &lt;code&gt;REINDEX&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;Éviter le double rejeu des transactions préparées lors de la récupération après un crash ;&lt;/li&gt;&#xA;&lt;li&gt;S&amp;rsquo;assurer qu&amp;rsquo;un checkpoint appelle &lt;code&gt;fsync&lt;/code&gt; sur une table nouvellement créée mais vide ;&lt;/li&gt;&#xA;&lt;li&gt;Rendre silencieux les erreurs &amp;ldquo;missing contrecord&amp;rdquo; pour éviter de journaliser des messages inexacts de &lt;code&gt;pg_waldump&lt;/code&gt; et &lt;code&gt;walsender&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;Correction de la fonction &lt;a href=&#34;https://www.postgresql.org/docs/current/fuzzystrmatch.html&#34;&gt;fuzzystrmatch&lt;/a&gt; &lt;a href=&#34;https://www.postgresql.org/docs/current/fuzzystrmatch.html#id-1.11.7.26.6&#34;&gt;Soundex &lt;code&gt;difference()&lt;/code&gt;&lt;/a&gt; pour gérer correctement les entrées vides ;&lt;/li&gt;&#xA;&lt;li&gt;Plusieurs corrections pour &lt;a href=&#34;https://www.postgresql.org/docs/current/intarray.html&#34;&gt;intarray&lt;/a&gt;, y compris l&amp;rsquo;interdiction des paramètres d&amp;rsquo;entrée de type tableaux de dépasser la limite de type dans un index GiST ;&lt;/li&gt;&#xA;&lt;li&gt;Correction de &lt;code&gt;pg_dump&lt;/code&gt; pour gérer correctement les corps de fonctions en SQL standard (&lt;code&gt;BEGIN ATOMIC&lt;/code&gt;) qui requièrent des dépendances au moment du parsing sur des index uniques.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Pour la liste complète de changements disponibles, se référer à la &lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;note de version&lt;/a&gt;/&lt;/p&gt;&#xA;&lt;h2 id=&#34;correctifs-sur-la-bêta-3-de-postgresql-16&#34;&gt;Correctifs sur la bêta 3 de PostgreSQL 16&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de la commande &lt;code&gt;\drg&lt;/code&gt; à &lt;code&gt;psql&lt;/code&gt; pour afficher des informations sur les&#xA;permissions de rôles ;&lt;/li&gt;&#xA;&lt;li&gt;Ajout de l&amp;rsquo;identifiant de timeline aux noms de fichiers générés avec &lt;code&gt;pg_waldump --save-fullpage&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;Correction d&amp;rsquo;un crash après la survenue d&amp;rsquo;un deadlock dans un worker parallèle&#xA;de &lt;code&gt;VACUUM&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Consulter la &lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;note de version&lt;/a&gt;&#xA;pour une liste complète de nouvelles fonctionnalités ou changements :&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;https://www.postgresql.org/docs/16/release-16.html&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;mise-à-jour&#34;&gt;Mise à jour&lt;/h2&gt;&#xA;&lt;p&gt;Toutes les mises à jour PostgreSQL sont cumulatives. Comme toutes les publications&#xA;de versions mineures, les utilisateurs ne sont pas obligés de sauvegarder et&#xA;restaurer leur bases de données ou d&amp;rsquo;utiliser &lt;code&gt;pg_upgrade&lt;/code&gt; pour appliquer cette&#xA;mise à jour ; il vous suffit de stopper PostgreSQL et mettre à jour les&#xA;binaires.&lt;/p&gt;&#xA;&lt;p&gt;Si vous utilisez des index BRIN pour vérifier les valeurs NULL, vous aurez&#xA;besoin de &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-reindex.html&#34;&gt;réindexer&lt;/a&gt;&#xA;ces derniers après la mise à jour. Sur PostgreSQL 12 et supérieur, vous pouvez&#xA;utiliser &lt;a href=&#34;https://www.postgresql.org/docs/current/sql-reindex.html&#34;&gt;&lt;code&gt;REINDEX CONCURRENTLY&lt;/code&gt;&lt;/a&gt;&#xA;pour ne pas bloquer les écritures sur les index concernés et leur tables, par&#xA;exemple :&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;REINDEX INDEX CONCURRENTLY your_index_name;&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;Les utilisateurs qui ont omis une ou plusieurs mises à jour mineures devront&#xA;effectuer des étapes supplémentaires ; se référer aux notes de versions&#xA;précédentes pour plus de détails.&lt;/p&gt;&#xA;&lt;p&gt;Pour plus de détails, se référer à la &lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;note de version&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;mise-à-jour-vers-la-bêta-3-de-postgresql-16&#34;&gt;Mise à jour vers la bêta 3 de PostgreSQL 16&lt;/h2&gt;&#xA;&lt;p&gt;Pour mettre à jour votre version de PostgreSQL depuis une&#xA;précédente version de PostgreSQL (bêta ou non) vers la version bêta 3 de PostgreSQL 16, vous&#xA;pouvez utiliser la même stratégie que pour mettre à jour vers toute version&#xA;majeure de PostgreSQL (par exemple avec la commande &lt;code&gt;pg_upgrade&lt;/code&gt; ou &lt;code&gt;pg_dump&lt;/code&gt;/&lt;code&gt;pg_restore&lt;/code&gt;).&#xA;Pour plus d&amp;rsquo;information, consultez la section &lt;a href=&#34;https://www.postgresql.org/docs/16/static/upgrading.html&#34;&gt;mise à jour&lt;/a&gt;&#xA;de la documentation officielle.&lt;/p&gt;&#xA;&lt;h2 id=&#34;tests-pour-le-débogage-et-la-compatibilité&#34;&gt;Tests pour le débogage et la compatibilité&lt;/h2&gt;&#xA;&lt;p&gt;La stabilité de chaque publication de PostgreSQL dépend de vous, la&#xA;communauté. En testant la version à venir avec votre charge et vos outils de&#xA;tests, vous pourrez nous aider à trouver les bogues et régressions avant la&#xA;publication de PostgreSQL 16.&lt;/p&gt;&#xA;&lt;p&gt;Étant donné qu&amp;rsquo;il s&amp;rsquo;agit d&amp;rsquo;une version bêta, des changements mineurs dans le&#xA;comportement de la base de données, des détails et des APIs sont toujours&#xA;possibles. Vos retours et tests aideront à déterminer les ajustements finaux&#xA;des nouvelles fonctionnalités.&lt;/p&gt;&#xA;&lt;p&gt;La qualité des tests aide à déterminer le moment de la publication&#xA;finale.&lt;/p&gt;&#xA;&lt;p&gt;Une liste des &lt;a href=&#34;https://wiki.postgresql.org/wiki/PostgreSQL_16_Open_Items&#34;&gt;problèmes ouverts&lt;/a&gt;&#xA;est publiquement disponible dans le wiki de PostgreSQL. Vous pouvez&#xA;&lt;a href=&#34;https://www.postgresql.org/account/submitbug/&#34;&gt;rapporter des bogues&lt;/a&gt;&#xA;en utilisant le formulaire présent sur le site web de PostgreSQL :&#xA;&lt;a href=&#34;https://www.postgresql.org/account/submitbug/&#34;&gt;https://www.postgresql.org/account/submitbug/&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;liens&#34;&gt;Liens&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;Téléchargement&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/release/&#34;&gt;Note de publication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/security/&#34;&gt;Sécurité&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/support/versioning/&#34;&gt;Gestion des versions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;Information sur le Bêta Testing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;Note de publication de PostgreSQL 16 Bêta&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://wiki.postgresql.org/wiki/PostgreSQL_16_Open_Items&#34;&gt;Problèmes connus de PostgreSQL 16&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://twitter.com/postgresql&#34;&gt;Suivre @postgresql sur Twitter&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/donate/&#34;&gt;Faire un don&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 16 bêta 2</title>
    <updated>2023-06-30T08:00:00Z</updated>
    <id>tag:www.loxodata.com,2023-06-30:/post/postgresql-16-beta2/</id>
    <link href="http://www.loxodata.com/post/postgresql-16-beta2/" rel="alternate"></link>
    <summary type="html">&lt;h1 id=&#34;postgresql-16-bêta-2-publiée&#34;&gt;PostgreSQL 16 Bêta 2 publiée&lt;/h1&gt;&#xA;&lt;p&gt;Le PostgreSQL Global Development Group annonce la disponibilité de la&#xA;deuxième bêta de PostgreSQL 16 en &lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;téléchargement&lt;/a&gt;.&#xA;Cette publication contient un aperçu des fonctionnalités qui seront disponibles&#xA;dans la version finale de PostgreSQL 16. Des modifications peuvent toutefois&#xA;intervenir d&amp;rsquo;ici là.&lt;/p&gt;&#xA;&lt;p&gt;Vous pouvez trouver des informations sur toutes les fonctionnalités et les&#xA;changements de PostgreSQL 16 dans les &lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;notes de version&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Dans l&amp;rsquo;esprit de la communauté open source PostgreSQL, nous vous&#xA;encourageons fortement à tester les nouvelles fonctionnalités de&#xA;PostgreSQL dans vos systèmes de bases de données. Ceci afin de nous&#xA;aider à éliminer les bogues et autres problèmes qui pourraient encore&#xA;exister. Bien que nous ne vous conseillions pas de faire fonctionner&#xA;PostgreSQL 16 bêta 2 dans vos environnements de production, nous vous&#xA;encourageons à trouver des moyens de faire fonctionner votre charge&#xA;applicative typique avec cette publication bêta.&lt;/p&gt;&#xA;&lt;p&gt;Vos tests et vos commentaires aideront la communauté à s&amp;rsquo;assurer que&#xA;PostgreSQL 16 respecte nos standards de stabilité et de fiabilité, pour&#xA;continuer à proposer la base de données open source la plus avancée au monde. Regardez&#xA;plus en détails le &lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;processus de bêta test&lt;/a&gt;&#xA;pour savoir comment vous pouvez y contribuer.&lt;/p&gt;&#xA;&lt;h1 id=&#34;mise-à-jour-vers-la-bêta-2-de-postgresql-16&#34;&gt;Mise à jour vers la bêta 2 de PostgreSQL 16&lt;/h1&gt;&#xA;&lt;p&gt;Pour mettre à jour votre version de PostgreSQL depuis une&#xA;précédente version de PostgreSQL (bêta ou non) vers la version bêta 2 de PostgreSQL 16, vous&#xA;pouvez utiliser la même stratégie que pour mettre à jour vers toute version&#xA;majeure de PostgreSQL (par exemple avec la commande &lt;code&gt;pg_upgrade&lt;/code&gt; ou &lt;code&gt;pg_dump&lt;/code&gt;/&lt;code&gt;pg_restore&lt;/code&gt;).&#xA;Pour plus d&amp;rsquo;information, consultez la section &lt;a href=&#34;https://www.postgresql.org/docs/16/static/upgrading.html&#34;&gt;mise à jour&lt;/a&gt;&#xA;de la documentation officielle.&lt;/p&gt;&#xA;&lt;h1 id=&#34;changements-depuis-la-bêta-1&#34;&gt;Changements depuis la bêta 1&lt;/h1&gt;&#xA;&lt;p&gt;Les corrections et modifications apportées à la version bêta 2 de PostgreSQL 16&#xA;incluent :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;le fournisseur de collation par défaut sélectionné par &lt;code&gt;initdb&lt;/code&gt; est remis à&#xA;nouveau vers &lt;code&gt;libc&lt;/code&gt; ;&lt;/li&gt;&#xA;&lt;li&gt;le comportement de sélection de la locale &lt;code&gt;C&lt;/code&gt; avec &lt;code&gt;libicu&lt;/code&gt; est délégué à&#xA;nouveau à &lt;code&gt;libicu&lt;/code&gt;. Sur les plateformes ICU 64 et au dessus, la locale C est&#xA;obsolète, et ICU fournit son propre mécanisme pour sélectionner une locale ou&#xA;générer une erreur ;&lt;/li&gt;&#xA;&lt;li&gt;plusieurs corrections liés à l&amp;rsquo;optimisation des jointures ;&lt;/li&gt;&#xA;&lt;li&gt;correction du code source B-tree lié aux changements introduits par le&#xA;décodage logique depuis les standbys ;&lt;/li&gt;&#xA;&lt;li&gt;correction de risque dans la consultation du cache lors de la recherche de&#xA;privilèges &lt;code&gt;MAINTAIN&lt;/code&gt; sur des partitions parentes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La &lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;note de publication&lt;/a&gt;&#xA;contient la liste complète des fonctionnalités nouvelles et modifiées.&lt;/p&gt;&#xA;&lt;h2 id=&#34;tests-pour-le-débogage-et-la-compatibilité&#34;&gt;Tests pour le débogage et la compatibilité&lt;/h2&gt;&#xA;&lt;p&gt;La stabilité de chaque publication de PostgreSQL dépend de vous, la&#xA;communauté. En testant la version à venir avec votre charge et vos outils de&#xA;tests, vous pourrez nous aider à trouver les bogues et régressions avant la&#xA;publication de PostgreSQL 16.&lt;/p&gt;&#xA;&lt;p&gt;Étant donné qu&amp;rsquo;il s&amp;rsquo;agit d&amp;rsquo;une version bêta, des changements mineurs dans le&#xA;comportement de la base de données, des détails et des APIs sont toujours&#xA;possibles. Vos retours et tests aideront à déterminer les ajustements finaux&#xA;des nouvelles fonctionnalités.&lt;/p&gt;&#xA;&lt;p&gt;La qualité des tests aide à déterminer le moment de la publication&#xA;finale.&lt;/p&gt;&#xA;&lt;p&gt;Une liste des &lt;a href=&#34;https://wiki.postgresql.org/wiki/PostgreSQL_16_Open_Items&#34;&gt;problèmes ouverts&lt;/a&gt;&#xA;est publiquement disponible dans le wiki de PostgreSQL. Vous pouvez&#xA;&lt;a href=&#34;https://www.postgresql.org/account/submitbug/&#34;&gt;rapporter des bogues&lt;/a&gt;&#xA;en utilisant le formulaire présent sur le site web de PostgreSQL :&#xA;&lt;a href=&#34;https://www.postgresql.org/account/submitbug/&#34;&gt;https://www.postgresql.org/account/submitbug/&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;planning-bêta&#34;&gt;Planning Bêta&lt;/h2&gt;&#xA;&lt;p&gt;Il s&amp;rsquo;agit de la deuxième publication bêta de la version 16. Le projet&#xA;PostgreSQL publiera autant de bêtas que nécessaires pour tester. Celles-ci&#xA;seront suivies par une ou plusieurs publications de version candidate,&#xA;jusqu&amp;rsquo;à la publication de la version finale à la fin de l&amp;rsquo;année 2023.&lt;/p&gt;&#xA;&lt;p&gt;Pour plus d&amp;rsquo;information,&#xA;veuillez consulter la page &lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;Beta Testing&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;lien&#34;&gt;Lien&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;Téléchargement&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;Information sur le Bêta Testing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;Note de publication de PostgreSQL 16 Bêta&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://wiki.postgresql.org/wiki/PostgreSQL_16_Open_Items&#34;&gt;Problème connu de PostgreSQL 16&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/featurematrix/#configuration-management&#34;&gt;Matrice fonctionnelle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/account/submitbug/&#34;&gt;Soumettre un bogue&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 16 bêta 1</title>
    <updated>2023-06-12T09:00:00Z</updated>
    <id>tag:www.loxodata.com,2023-06-12:/post/postgresql-16-beta1/</id>
    <link href="http://www.loxodata.com/post/postgresql-16-beta1/" rel="alternate"></link>
    <summary type="html">&lt;h1 id=&#34;postgresql-16-bêta-1-publiée&#34;&gt;PostgreSQL 16 Bêta 1 publiée&lt;/h1&gt;&#xA;&lt;p&gt;Le PostgreSQL Global Development Group annonce la disponibilité de la&#xA;première bêta de PostgreSQL 16 en &lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;téléchargement&lt;/a&gt;.&#xA;Cette publication contient un aperçu des fonctionnalités qui seront disponibles&#xA;dans la version finale de PostgreSQL 16. Des modifications peuvent toutefois&#xA;intervenir d&amp;rsquo;ici là.&lt;/p&gt;&#xA;&lt;p&gt;Vous pouvez trouver des informations sur toutes les fonctionnalités et les&#xA;changements de PostgreSQL 16 dans les &lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;notes de version&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Dans l&amp;rsquo;esprit de la communauté open source PostgreSQL, nous vous&#xA;encourageons fortement à tester les nouvelles fonctionnalités de&#xA;PostgreSQL dans vos systèmes de base de données. Ceci afin de nous&#xA;aider à éliminer les bogues et autres problèmes qui pourraient&#xA;exister. Bien que nous ne vous conseillions pas de faire fonctionner&#xA;PostgreSQL 16 Bêta 1 dans vos environnements de production, nous vous&#xA;encourageons à trouver des moyens de faire fonctionner votre charge&#xA;applicative typique avec cette publication bêta.&lt;/p&gt;&#xA;&lt;p&gt;Vos tests et vos commentaires aideront la communauté à s&amp;rsquo;assurer que&#xA;PostgreSQL 16 respecte nos standards de stabilité et fiablité.&lt;/p&gt;&#xA;&lt;h2 id=&#34;principales-fonctionnalités-de-postgresql-16&#34;&gt;Principales fonctionnalités de PostgreSQL 16&lt;/h2&gt;&#xA;&lt;h3 id=&#34;performance&#34;&gt;Performance&lt;/h3&gt;&#xA;&lt;p&gt;PostgreSQL 16 inclut des améliorations de performance dans l&amp;rsquo;exécution des&#xA;requêtes. Cette version ajoute plus de parallélisme dans les requêtes, notamment&#xA;en permettant aux jointures &lt;code&gt;FULL&lt;/code&gt; et &lt;code&gt;RIGHT&lt;/code&gt; de s&amp;rsquo;exécuter en parallèle, ainsi&#xA;que l&amp;rsquo;exécution parallèle des fonctions d&amp;rsquo;agrégation &lt;code&gt;string_agg&lt;/code&gt; et &lt;code&gt;array_agg&lt;/code&gt;.&#xA;De plus, PostgreSQL 16 peut utiliser les tris incrémentaux dans les requêtes&#xA;&lt;code&gt;SELECT DISTINCT&lt;/code&gt;. Il y a aussi plusieurs optimisations pour les &lt;a href=&#34;https://www.postgresql.org/docs/16/sql-expressions.html#SYNTAX-WINDOW-FUNCTIONS&#34;&gt;focntions de fenêtrage&lt;/a&gt;,&#xA;des améliorations dans les recherches pour les partitions &lt;code&gt;RANGE&lt;/code&gt; et &lt;code&gt;LIST&lt;/code&gt;, et&#xA;le support des &amp;ldquo;anti-joins&amp;rdquo; dans les requêtes &lt;code&gt;RIGHT&lt;/code&gt; et &lt;code&gt;OUTER&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 16 peut également améliorer les performances du chargement parallèle&#xA;de données en masse en utilisant &lt;code&gt;COPY&lt;/code&gt; jusqu&amp;rsquo;à 300%.&lt;/p&gt;&#xA;&lt;p&gt;Cette version introduit également le support de l&amp;rsquo;accélération CPU utilisant&#xA;SIMD pour les architectures x86 et ARM, incluant des optimisations pour le&#xA;traitement des chaînes ASCII et JSON, et les recherches dans les tableaux et&#xA;les sous-transactions. De plus, PostgreSQL 16 introduit le &lt;a href=&#34;https://www.postgresql.org/docs/16/libpq-connect.html#LIBPQ-CONNECT-LOAD-BALANCE-HOSTS&#34;&gt;load balancing&lt;/a&gt;&#xA;dans &lt;code&gt;libpq&lt;/code&gt;, la bibliothèque client de PostgreSQL.&lt;/p&gt;&#xA;&lt;h3 id=&#34;améliorations-de-la-réplication-logique&#34;&gt;Améliorations de la réplication logique&lt;/h3&gt;&#xA;&lt;p&gt;La réplication logique permet aux utilisateurs de PostgreSQL de diffuser des&#xA;données en temps réel vers d&amp;rsquo;autres systèmes PostgreSQL ou d&amp;rsquo;autres systèmes&#xA;externes qui implémentent le protocole logique. Jusqu&amp;rsquo;à PostgreSQL 16, les&#xA;utilisateurs ne pouvaient créer des éditeurs de réplication logique que sur&#xA;les instances primaires. PostgreSQL 16 ajoute la possibilité d&amp;rsquo;effectuer le&#xA;décodage logique sur une instance standby, donnant aux utilisateurs plus d&amp;rsquo;options&#xA;pour distribuer leur charge de travail, par exemple, utiliser une instance standby&#xA;qui est moins occupée qu&amp;rsquo;une instance primaire pour répliquer logiquement les&#xA;changements.&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 16 inclut également plusieurs améliorations de performance pour la&#xA;réplication logique. Cela inclut la possibilité pour l&amp;rsquo;abonné d&amp;rsquo;appliquer de&#xA;grosses transactions en parallèle, d&amp;rsquo;utiliser des index autres que le &lt;code&gt;PRIMARY KEY&lt;/code&gt;&#xA;pour effectuer des recherches pendant les opérations &lt;code&gt;UPDATE&lt;/code&gt; ou &lt;code&gt;DELETE&lt;/code&gt;, et&#xA;de permettre aux tables d&amp;rsquo;être copiées en utilisant le format binaire pendant&#xA;l&amp;rsquo;initialisation.&lt;/p&gt;&#xA;&lt;h3 id=&#34;expérience-développeur&#34;&gt;Expérience développeur&lt;/h3&gt;&#xA;&lt;p&gt;PostgreSQL 16 continue d&amp;rsquo;implémenter le standard &lt;a href=&#34;https://www.postgresql.org/docs/16/functions-json.html&#34;&gt;SQL/JSON&lt;/a&gt;&#xA;pour manipuler les données &lt;a href=&#34;https://www.postgresql.org/docs/16/datatype-json.html&#34;&gt;JSON&lt;/a&gt;,&#xA;incluant le support des constructeurs &lt;code&gt;SQL/JSON&lt;/code&gt; (par exemple &lt;code&gt;JSON_ARRAY()&lt;/code&gt;,&#xA;&lt;code&gt;JSON_ARRAYAGG()&lt;/code&gt; et &lt;code&gt;al&lt;/code&gt;), et les fonctions d&amp;rsquo;identité (&lt;code&gt;IS JSON&lt;/code&gt;). Cette&#xA;version ajoute également la fonction d&amp;rsquo;agrégation standard SQL &lt;a href=&#34;https://www.postgresql.org/docs/16/functions-aggregate.html#id-1.5.8.27.5.2.4.1.1.1.1&#34;&gt;ANY_VALUE&lt;/a&gt;,&#xA;qui renvoie n&amp;rsquo;importe quelle valeur arbitraire de l&amp;rsquo;ensemble des agrégats.&#xA;Pour plus de commodité, PostgreSQL 16 vous permet maintenant de spécifier des&#xA;entiers non décimaux, tels que &lt;code&gt;0xff&lt;/code&gt;, &lt;code&gt;0o777&lt;/code&gt;, et &lt;code&gt;0b101010&lt;/code&gt;, et d&amp;rsquo;utiliser&#xA;des underscores comme séparateurs de milliers, tels que &lt;code&gt;5_432&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Cette version ajoute au client &lt;a href=&#34;https://www.postgresql.org/docs/16/app-psql.html&#34;&gt;psql&lt;/a&gt;&#xA;la prise en charge du protocole de requête étendu. Les utilisateurs peuvent&#xA;exécuter une requête, par exemple &lt;code&gt;SELECT $1 + $2&lt;/code&gt;, et utiliser la commande&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/16/app-psql.html#APP-PSQL-META-COMMAND-BIND&#34;&gt;\bind&lt;/a&gt;&#xA;pour substituer les variables.&lt;/p&gt;&#xA;&lt;h3 id=&#34;sécurité&#34;&gt;Sécurité&lt;/h3&gt;&#xA;&lt;p&gt;PostgreSQL 16 continue à offrir aux utilisateurs la possibilité d&amp;rsquo;accorder des&#xA;accès privilégiés aux fonctionnalités sans nécessiter de superutilisateur avec&#xA;de nouveaux &lt;a href=&#34;https://www.postgresql.org/docs/16/predefined-roles.html&#34;&gt;rôles prédéfinis&lt;/a&gt;.&#xA;Ceux-ci incluent &lt;code&gt;pg_maintain&lt;/code&gt;, qui permet l&amp;rsquo;exécution d&amp;rsquo;opérations telles que&#xA;&lt;code&gt;VACUUM&lt;/code&gt;, &lt;code&gt;ANALYZE&lt;/code&gt;, &lt;code&gt;REINDEX&lt;/code&gt;, et d&amp;rsquo;autres, et &lt;code&gt;pg_create_subscription&lt;/code&gt;, qui&#xA;permet aux utilisateurs de créer un abonnement de réplication logique. De plus,&#xA;à partir de cette version, les abonnés à la réplication logique exécutent les&#xA;transactions sur une table en tant que propriétaire de la table, et non en tant&#xA;que superutilisateur.&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 16 vous permet maintenant d&amp;rsquo;utiliser des expressions régulières dans&#xA;les fichiers &lt;a href=&#34;https://www.postgresql.org/docs/16/auth-pg-hba-conf.html&#34;&gt;pg_hba.conf&lt;/a&gt;&#xA;et &lt;a href=&#34;https://www.postgresql.org/docs/16/auth-username-maps.html&#34;&gt;pg_ident.conf&lt;/a&gt;&#xA;pour faire correspondre les noms d&amp;rsquo;utilisateurs et de bases de données. De plus,&#xA;PostgreSQL 16 ajoute la possibilité d&amp;rsquo;inclure d&amp;rsquo;autres fichiers dans &lt;code&gt;pg_hba.conf&lt;/code&gt;&#xA;et &lt;code&gt;pg_ident.conf&lt;/code&gt;. PostgreSQL 16 ajoute également le support du mot-clé &lt;a href=&#34;https://www.postgresql.org/docs/16/functions-info.html#id-1.5.8.32.3.4.2.2.24.1.1.1&#34;&gt;SYSTEM_USER&lt;/a&gt;&#xA;du standard SQL, qui renvoie le nom d&amp;rsquo;utilisateur et la méthode d&amp;rsquo;authentification&#xA;utilisés pour établir une session.&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 16 ajoute également le support de la délégation des identifiants Kerberos,&#xA;qui permet aux extensions telles que &lt;code&gt;postgres_fdw&lt;/code&gt; et &lt;code&gt;dblink&lt;/code&gt; d&amp;rsquo;utiliser les&#xA;identifiants authentifiés pour se connecter à d&amp;rsquo;autres services. Cette version&#xA;ajoute également plusieurs nouveaux paramètres de connexion orientés sécurité&#xA;pour les clients. Il s&amp;rsquo;agit notamment de &lt;a href=&#34;https://www.postgresql.org/docs/16/libpq-connect.html#LIBPQ-CONNECT-REQUIRE-AUTH&#34;&gt;require_auth&lt;/a&gt;,&#xA;qui permet à un client de spécifier les méthodes d&amp;rsquo;authentification qu&amp;rsquo;il est&#xA;prêt à accepter de la part du serveur. Vous pouvez maintenant définir &lt;code&gt;sslrootcert&lt;/code&gt;&#xA;à &lt;code&gt;system&lt;/code&gt; pour demander à PostgreSQL d&amp;rsquo;utiliser l&amp;rsquo;autorité de certification (&lt;code&gt;CA&lt;/code&gt;)&#xA;de confiance fournie par le système d&amp;rsquo;exploitation du client.&lt;/p&gt;&#xA;&lt;h3 id=&#34;supervision-et-administration&#34;&gt;Supervision et administration&lt;/h3&gt;&#xA;&lt;p&gt;PostgreSQL 16 ajoute plusieurs nouvelles fonctionnalités de supervision, y&#xA;compris la nouvelle vue &lt;a href=&#34;https://www.postgresql.org/docs/16/monitoring-stats.html#MONITORING-PG-STAT-IO-VIEW&#34;&gt;pg_stat_io&lt;/a&gt;&#xA;qui fournit des informations sur les statistiques d&amp;rsquo;entrées-sorties. Cette&#xA;version fournit également un horodatage pour la dernière fois qu&#39;&lt;a href=&#34;https://www.postgresql.org/docs/16/monitoring-stats.html#MONITORING-PG-STAT-ALL-TABLES-VIEW&#34;&gt;une table ou un index a été scanné&lt;/a&gt;.&#xA;L&amp;rsquo;algorithme de normalisation utilisé pour &lt;code&gt;pg_stat_activity&lt;/code&gt; a également été&#xA;amélioré.&lt;/p&gt;&#xA;&lt;p&gt;Cette version inclut des améliorations de la stratégie de freeze des pages, ce&#xA;qui améliore les performances du vacuuming et d&amp;rsquo;autres opérations de maintenance.&#xA;PostgreSQL 16 améliore également le support général des collations de texte,&#xA;qui fournissent des règles sur la façon dont le texte est trié. PostgreSQL 16&#xA;définit ICU comme fournisseur de collation par défaut, et ajoute également le&#xA;support des collations prédéfinies &lt;code&gt;unicode&lt;/code&gt; et &lt;code&gt;ucs_basic&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 16 ajoute des options de compression supplémentaires à &lt;code&gt;pg_dump&lt;/code&gt;,&#xA;incluant le support des compressions &lt;code&gt;lz4&lt;/code&gt; et &lt;code&gt;zstd&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;autres-changements-notables&#34;&gt;Autres changements notables&lt;/h3&gt;&#xA;&lt;p&gt;PostgreSQL 16 supprime l&amp;rsquo;option &lt;code&gt;promote_trigger_file&lt;/code&gt; pour permettre la promotion&#xA;d&amp;rsquo;un standby. Les utilisateurs doivent utiliser la commande &lt;code&gt;pg_ctl promote&lt;/code&gt; ou&#xA;la fonction &lt;code&gt;pg_promote()&lt;/code&gt; pour promouvoir un standby.&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 16 a introduit le système de construction Meson, qui remplacera à&#xA;terme Autoconf. Cette version ajoute également les fondations du support de&#xA;fonctionnalités de développement qui seront améliorées dans les versions futures.&#xA;Cela inclut une option au développeur pour activer &lt;code&gt;DirectIO&lt;/code&gt; et la possibilité&#xA;d&amp;rsquo;utiliser la réplication logique pour répliquer de manière bidirectionnelle&#xA;entre deux tables lorsque &lt;code&gt;origin=none&lt;/code&gt; est spécifié dans l&amp;rsquo;abonné.&lt;/p&gt;&#xA;&lt;p&gt;Pour les installations Windows, PostgreSQL 16 supporte maintenant une version&#xA;minimale de Windows 10.&lt;/p&gt;&#xA;&lt;h2 id=&#34;fonctionnalités-supplémentaires&#34;&gt;Fonctionnalités supplémentaires&lt;/h2&gt;&#xA;&lt;p&gt;De nombreuses autres fonctionnalités et améliorations ont été ajoutées&#xA;à PostgreSQL. En fonction des cas d&amp;rsquo;usages, leur importance peut&#xA;paraître plus ou moins grande que celles mentionnées ci-dessus.&lt;/p&gt;&#xA;&lt;p&gt;Vous pouvez consulter les&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/devel/release-15.html&#34;&gt;notes de publications&lt;/a&gt;&#xA;pour une liste complète des nouveautés et changements :&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;https://www.postgresql.org/docs/16/release-16.html&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;tests-pour-le-débogage-et-la-compatibilité&#34;&gt;Tests pour le débogage et la compatibilité&lt;/h2&gt;&#xA;&lt;p&gt;La stabilité de chaque publication de PostgreSQL dépend de vous, la&#xA;communauté. En testant la version à venir avec votre charge et vos outils de&#xA;tests, vous pourrez nous aider à trouver les bogues et régressions avant la&#xA;publication de PostgreSQL 16.&lt;/p&gt;&#xA;&lt;p&gt;Étant donné qu&amp;rsquo;il s&amp;rsquo;agit d&amp;rsquo;une version bêta, des changements mineurs dans le&#xA;comportement de la base de données, des détails et des APIs sont toujours&#xA;possibles. Vos retours et tests aideront à déterminer les ajustements finaux&#xA;des nouvelles fonctionnalités.&lt;/p&gt;&#xA;&lt;p&gt;La qualité des tests aide à déterminer le moment de la publication&#xA;finale.&lt;/p&gt;&#xA;&lt;p&gt;Une liste des &lt;a href=&#34;https://wiki.postgresql.org/wiki/PostgreSQL_16_Open_Items&#34;&gt;problèmes ouverts&lt;/a&gt;&#xA;est publiquement disponible dans le wiki de PostgreSQL. Vous pouvez&#xA;&lt;a href=&#34;https://www.postgresql.org/account/submitbug/&#34;&gt;rapporter des bogues&lt;/a&gt;&#xA;en utilisant le formulaire présent sur le site web de PostgreSQL :&#xA;&lt;a href=&#34;https://www.postgresql.org/account/submitbug/&#34;&gt;https://www.postgresql.org/account/submitbug/&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;planning-bêta&#34;&gt;Planning Bêta&lt;/h2&gt;&#xA;&lt;p&gt;Il s&amp;rsquo;agit de la première publication bêta de la version 16. Le projet&#xA;PostgreSQL publiera autant de bêtas que nécessaires pour tester. Celles-ci&#xA;seront suivies par une ou plusieurs publications de versions candidates,&#xA;jusqu&amp;rsquo;à la publication de la version finale à la fin de l&amp;rsquo;année 2023.&lt;/p&gt;&#xA;&lt;p&gt;Pour plus d&amp;rsquo;information,&#xA;veuillez consulter la page &lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;Beta Testing&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;lien&#34;&gt;Lien&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;Téléchargement&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/developer/beta/&#34;&gt;Information sur le Bêta Testing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/16/release-16.html&#34;&gt;Note de publication de PostgreSQL 16 Bêta&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://wiki.postgresql.org/wiki/PostgreSQL_16_Open_Items&#34;&gt;Problème connu de PostgreSQL 16&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/about/featurematrix/#configuration-management&#34;&gt;Matrice fonctionnelle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/account/submitbug/&#34;&gt;Soumettre un bogue&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>Retour sur le pgDay Paris 2023</title>
    <updated>2023-04-03T15:00:00Z</updated>
    <id>tag:www.loxodata.com,2023-04-03:/post/pgday-paris-2023/</id>
    <link href="http://www.loxodata.com/post/pgday-paris-2023/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Les 22 et 23 mars derniers s&amp;rsquo;est tenue la 7e édition du pgDay Paris 2023.&#xA;LOXODATA était, cette année encore, sponsor &lt;em&gt;&amp;ldquo;partner&amp;rdquo;&lt;/em&gt; de l&amp;rsquo;évènement.&#xA;Cette édition s&amp;rsquo;est déroulée au sein de l&amp;rsquo;espace Saint Martin, dans le 3e&#xA;arrondissement de Paris, qui dispose d&amp;rsquo;un bel auditorium.&lt;/p&gt;&#xA;&lt;p&gt;L&amp;rsquo;une des nouveautés de cette édition était l&amp;rsquo;introduction d&amp;rsquo;une journée de&#xA;formations payantes précédant la journée de conférence, sur le même modèle que&#xA;la &lt;em&gt;PGConf.EU&lt;/em&gt;.&#xA;Lors de l&amp;rsquo;inscription, il suffisait de choisir la formation d&amp;rsquo;une journée ou&#xA;l&amp;rsquo;une des deux formations proposée pour chaque demi-journée.&lt;/p&gt;&#xA;&lt;p&gt;LOXODATA a dispensé une formation le matin, et une autre l&amp;rsquo;après-midi.&lt;/p&gt;&#xA;&lt;p&gt;Autre nouveauté de cette année, une seconde salle permettait de compléter le&#xA;programme des conférences.&lt;br&gt;&#xA;Cette année, c&amp;rsquo;était aussi le retour des conférences filmées, mais uniquement&#xA;pour celles se déroulant dans l&amp;rsquo;auditorium.&lt;/p&gt;&#xA;&lt;p&gt;Le programme complet est sur le site du &lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/&#34;&gt;pgDay Paris 2023&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;les-formations&#34;&gt;Les formations&lt;/h2&gt;&#xA;&lt;p&gt;Les sujets des formations étaient aussi variés que :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Bien démarrer avec votre instance PostgreSQL, par Patrick Francelle et&#xA;Stéphane Schildknecht, LOXODATA&lt;/li&gt;&#xA;&lt;li&gt;Disaster recovery avec pgBackRest, assurée par Philippe Viegas et Stéphane&#xA;Schildknecht, LOXODATA&lt;/li&gt;&#xA;&lt;li&gt;Tout ce que vous avez toujours voulu savoir sur les pools de connexions&#xA;(sans jamais oser le demander) ; Frédéric Delacourt, Data Bene&lt;/li&gt;&#xA;&lt;li&gt;CREATE EXTENSION, la votre de préférence ; Cédric Villemain, Data Bene&lt;/li&gt;&#xA;&lt;li&gt;Troubleshooting Postgres ; Jean-Sébastien Defontenay et Sébastien Sire, EDB&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;les-conférences&#34;&gt;Les conférences&lt;/h2&gt;&#xA;&lt;p&gt;Le programme de la journée de conférences comportait douze sessions en anglais,&#xA;réparties entre l&amp;rsquo;auditorium et une autre salle plus petite. Parmi ces&#xA;conférences, on pouvait retrouver plusieurs présentations non techniques.&lt;/p&gt;&#xA;&lt;p&gt;Cette journée était particulière, marquée par des mouvements sociaux et des&#xA;perturbations des transports, et plusieurs personnes ont été contraintes&#xA;d&amp;rsquo;annuler leur participation. Malgré tout, une centaine de personnes ont pu&#xA;participer, mais quelques ajustements de programme ont également été nécessaires.&lt;br&gt;&#xA;La couverture médiatique de l&amp;rsquo;évènement aurait aussi mérité d&amp;rsquo;être un peu plus fournie.&lt;/p&gt;&#xA;&lt;p&gt;Après l&amp;rsquo;introduction faite par Karen Jex, la keynote d&amp;rsquo;ouverture s&amp;rsquo;est déroulée&#xA;dans l&amp;rsquo;auditorium. Magali Milbergue s&amp;rsquo;est retrouvée promue à la tâche délicate&#xA;de lancer la journée, suite à l&amp;rsquo;annulation contrainte de l&amp;rsquo;intervenante prévue.&#xA;Elle nous a présenté un sujet peu abordé dans ce genre de conférence :&#xA;l&amp;rsquo;importance des relations humaines dans nos métiers.&lt;br&gt;&#xA;En particulier, elle nous a rappelé que si nous pensons parfois être neutres,&#xA;nous sommes soumis à des biais liés à notre origine, ou simplement à l&amp;rsquo;état&#xA;actuel de la société. Quelques biais énumérés : le sexisme, le racisme, le validisme.&#xA;Elle nous a ensuite indiqué que nous aimons en général les sciences « dures »,&#xA;mais que les sciences sociales sont nécessaires dans nos métiers, avant de nous&#xA;inviter à nous autoéduquer sur tous ces sujets.&lt;/p&gt;&#xA;&lt;p&gt;À partir de ce point, il fallait choisir parmi les deux tracks de conférences&#xA;pour dix des douze sessions de la journée.&lt;/p&gt;&#xA;&lt;p&gt;La première session dans la petite salle était présentée par Francesco Tisiot&#xA;avec &lt;code&gt;Fix your strings!&lt;/code&gt;. Cela concernait l&amp;rsquo;utilisation appropriée des types&#xA;caractère avec PostgreSQL. En partant de la mauvaise écriture de son nom, il&#xA;nous a entraîné dans la modélisation d&amp;rsquo;une base avec différents cas d&amp;rsquo;usage,&#xA;l&amp;rsquo;utilisation des types appropriés pour bénéficier de la validation des données&#xA;et effectuer la normalisation de nos modèles de données afin de pouvoir en faire&#xA;une exploitation.&lt;/p&gt;&#xA;&lt;p&gt;David Christensen, nous a ensuite proposé &lt;code&gt;How to Tame a Mastodon: Lessons for PostgreSQL at Scale&lt;/code&gt;&#xA;ou comment gérer de grosses instances PostgreSQL (gros volume de données,&#xA;beaucoup de transactions et de nombreux réplicas). Il nous a partagé ses conseils&#xA;sur la gestion des verrous lors de l&amp;rsquo;ajout de colonnes, contraintes, index, le&#xA;partitionnement de grosses tables et l&amp;rsquo;espace occupé dans une table par les&#xA;données selon leur type et la place potentiellement perdue.&lt;/p&gt;&#xA;&lt;p&gt;Après la pause déjeuner, on retrouve Boriss Mejias qui va assurer le spectacle&#xA;comme à son habitude sur un sujet bien connu :&#xA;&lt;code&gt;Understanding MVCC, Vacuum, and how to monitor it with the pg_catalog&lt;/code&gt;.&#xA;Il nous rappelle ainsi le principe de MVCC avec PostgreSQL et les transactions,&#xA;les tâches de maintenance associées &lt;code&gt;VACUUM&lt;/code&gt; et &lt;code&gt;autovacuum&lt;/code&gt; et les vues du&#xA;catalogue système pour superviser tous ces aspects.&lt;/p&gt;&#xA;&lt;p&gt;La suite logique fut d&amp;rsquo;aller assister à la présentation de Chelsea Dole&#xA;&lt;code&gt;Managing Your Tuple Graveyard&lt;/code&gt;. Chelsea nous présente aussi le principe de&#xA;MVCC mais sur la gestion des tuples, et comment gérer le bloat associé, comment&#xA;le quantifier, l&amp;rsquo;interpréter selon le volume d&amp;rsquo;une table donnée : selon la&#xA;taille d&amp;rsquo;une table, le taux de bloat admis ne sera pas le même, et comment&#xA;finalement pallier le bloat par des tâches de maintenance, mais également par&#xA;la mise en place de patterns appropriés d&amp;rsquo;accès aux données.&lt;/p&gt;&#xA;&lt;p&gt;Stefan Fercot s&amp;rsquo;est ensuite affairé à nous présenter les principes de la&#xA;restauration avec PostgreSQL et les différentes cibles possibles, les outils&#xA;tels que &lt;code&gt;pg_waldump&lt;/code&gt; pour parcourir les WAL à la recherche de la cible voulue.&#xA;Un petit clin d&amp;rsquo;oeil a été fait à Sébastien Lardière et ses dernières contributions&#xA;sur l&#39;&lt;a href=&#34;https://www.loxodata.fr/post/timelineid/&#34;&gt;identifiant de timeline&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;En parallèle de ces trois sessions de l&amp;rsquo;après-midi, d&amp;rsquo;autres sessions avaient&#xA;lieu également.&lt;/p&gt;&#xA;&lt;p&gt;Après le déjeuner, Daniel Westermann nous a parlé de sa découverte de la&#xA;communauté PostgreSQL en 2013 lorsqu&amp;rsquo;il a eu besoin de résoudre un problème de&#xA;performance. Une fois passée la surprise des outils de communication, notamment&#xA;les listes de diffusion et leurs règles d&amp;rsquo;utilisation, il nous a donné quelques&#xA;conseils avant de consulter la communauté, ainsi que quelques points d&amp;rsquo;entrée&#xA;pour contribuer, ce qu&amp;rsquo;il nous a encouragé à faire.&lt;/p&gt;&#xA;&lt;p&gt;La conférence suivante est aussi une suite logique. Melih Mutlu nous a parlé de&#xA;ses 6 premiers mois de contribution à la communauté PostgreSQL. En voulant&#xA;participer au code, il a cherché s&amp;rsquo;il y avait des bugs à corriger. Il a lui&#xA;aussi été surpris des outils et méthodes utilisés par la communauté. Au final,&#xA;l&amp;rsquo;accueil des nouveaux arrivants n&amp;rsquo;est pas toujours facile même si les personnes&#xA;sont accueillantes et bienveillantes.&lt;/p&gt;&#xA;&lt;p&gt;Sur l&amp;rsquo;avant-dernière conférence de la journée, Elizabeth Garrett Christensen&#xA;nous a fait une introduction à PostGIS. Après une introduction sur différents&#xA;systèmes existants, elle se concentre sur PostGIS, un certain nombre de&#xA;fonctionnalités et d&amp;rsquo;outils, ainsi que quelques exemples de choses possibles.&lt;/p&gt;&#xA;&lt;p&gt;Pour la conférence de fin, nous avons eu le plaisir de voir Sarah&#xA;Haïm-Lubczanski nous parler de son métier en tant qu&amp;rsquo;architecte de documentation&#xA;technique. Bien que la documentation de PostgreSQL soit très bien perçue, elle&#xA;comporte un certain nombre de points qui pourraient être grandement améliorés en&#xA;utilisant les dernières bonnes pratiques sur l&amp;rsquo;écriture d&amp;rsquo;une documentation&#xA;accessible pour tous.&lt;/p&gt;&#xA;&lt;p&gt;Puis, Karen Jex conclut la journée avec le mot de la fin.&lt;/p&gt;&#xA;&lt;p&gt;Au final, cette journée de conférence fut un peu différente des autres années,&#xA;à la fois par une participation malheureusement moins importante, mais aussi&#xA;par des conférences qui laissaient la place à des sujets moins techniques et à&#xA;des intervenants moins connus.&lt;/p&gt;&#xA;&lt;h2 id=&#34;le-programme&#34;&gt;Le programme&lt;/h2&gt;&#xA;&lt;p&gt;La liste complète des conférences :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4330-talkception-why-non-technical-talks-in-tech-events-are-so-important/&#34;&gt;Talkception : why non-technical talks in tech events are so important&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4366-postgresql-and-software-engineers/&#34;&gt;PostgreSQL and Software Engineers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4322-fix-your-strings/&#34;&gt;Fix Your Strings!&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4346-upgrade-postgres/&#34;&gt;Upgrade Postgres!&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4387-how-to-tame-a-mastodon-lessons-for-postgresql-at-scale/&#34;&gt;How to Tame a Mastodon: Lessons for PostgreSQL at Scale&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4259-working-effectively-with-support-the-community/&#34;&gt;Working effectively with (-support-) the community&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4379-understanding-mvcc-vacuum-and-how-to-monitor-it-with-the-pg_catalog/&#34;&gt;Understanding MVCC, Vacuum, and how to monitor it with the pg_catalog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4310-managing-your-tuple-graveyard/&#34;&gt;Managing your tuple graveyard&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4337-takeaways-from-the-first-6-months-of-hacking-on-postgres/&#34;&gt;Takeaways from the First 6 Months of Hacking on Postgres&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4384-postgis-for-newbies/&#34;&gt;PostGIS for Newbies&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4247-explore-the-postgresql-recovery-process-and-its-targets/&#34;&gt;Explore the PostgreSQL recovery process and its targets&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.eu/events/pgdayparis2023/schedule/session/4303-documentation-lets-make-it-better-now-together/&#34;&gt;Documentation : Let’s make it better, now, together!&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>Memento PostgreSQL 15</title>
    <updated>2023-03-27T09:38:00Z</updated>
    <id>tag:www.loxodata.com,2023-03-27:/post/refcard2023/</id>
    <link href="http://www.loxodata.com/post/refcard2023/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Depuis quelques années, nous produisons et diffusons la version papier&#xA;de notre memento sur PostgreSQL. Ce memento est adapté à chaque version,&#xA;au fur et à mesure de leurs publications.&lt;/p&gt;&#xA;&lt;p&gt;La version 15 de PostgreSQL ayant été publiée l&amp;rsquo;automne dernier, nous&#xA;mettons à disposition ce memento mis à jour.&lt;/p&gt;&#xA;&lt;p&gt;Ce document reprend, sur deux triptryques, l&amp;rsquo;ensemble des utilitaires&#xA;et commandes qui nous semblent essentiels pour travailler avec&#xA;PostgreSQL. Nous vous proposons de le retrouver ici sous la forme d&amp;rsquo;un&#xA;fichier PDF, disponible en deux langues : &lt;a href=&#34;http://www.loxodata.com/downloads/files/RefCard_Fr_PostgreSQL15.pdf&#34; download=&#34;RefCard_Fr_PostgreSQL15.pdf&#34;&gt;version française&lt;/a&gt;&#xA;, ou : &lt;a href=&#34;http://www.loxodata.com/downloads/files/RefCard_En_PostgreSQL15.pdf&#34; download=&#34;RefCard_En_PostgreSQL15.pdf&#34;&gt;version anglaise&lt;/a&gt;&#xA;.&lt;/p&gt;&#xA;&lt;p&gt;Il suffit de l&amp;rsquo;imprimer en recto-verso et de le plier en 3, ou, tout&#xA;simplement, de conserver et consulter le fichier PDF.&lt;/p&gt;&#xA;&lt;p&gt;Si vous avez des remarques ou des suggestions, vous pouvez nous écrire&#xA;à l&amp;rsquo;adresse &lt;a href=&#34;mailto:contact@loxodata.com&#34;&gt;contact@loxodata.com&lt;/a&gt;, nous serons heureux de faire évoluer&#xA;ce memento.&lt;/p&gt;</summary>
    <author>
      <name>Loxodata</name>
    </author>
  </entry>
  <entry>
    <title>Chiffrement sous PostgreSQL : mais sous quelles conditions ?</title>
    <updated>2023-08-02T10:02:56Z</updated>
    <id>tag:blog.capdata.fr,2023-08-02:/index.php/chiffrement-des-donnees-sous-postgresql/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10163&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10163&amp;#038;title=Chiffrement%20sous%20PostgreSQL%20%3A%20mais%20sous%20quelles%20conditions%20%3F&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=Chiffrement%20sous%20PostgreSQL%20%3A%20mais%20sous%20quelles%20conditions%20%3F&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10163&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone size-medium wp-image-10165&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/07/cle-300x199.png&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;199&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/07/cle-300x199.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/07/cle.png 373w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Lorsque l&amp;#8217;on parle sécurité des données sur une instance PostgreSQL, nous avons le choix entre le chiffrement &amp;#8220;at rest&amp;#8221; avec TDE (cf &lt;a href=&#34;https://blog.capdata.fr/index.php/transparent-data-encryption-pour-postgresql/&#34;&gt;cet article&lt;/a&gt;), ou bien l&amp;#8217;utilisation de l&amp;#8217;extension, bien connue des DBA PostgreSQL, &lt;strong&gt;pgcrypto&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Cette extension permet de disposer de fonctions de chiffrement via méthode de hashage et dite de &amp;#8220;salage&amp;#8221; pour générer des valeurs aléatoires.&lt;/p&gt;&#xA;&lt;p&gt;Dans cet article, nous allons effectuer une étude comparative sur les différents algorithmes de cryptage, en portant notre attention sur les temps d&amp;#8217;exécution liés au chiffrage, mais aussi les problématiques de stockage que cela peut engendrer.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Etat des lieux&lt;/h2&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Afin d&amp;#8217;effectuer les différents tests, nous partons sur une petite configuration machine, à savoir, une EC2 AWS t2.micro, avec 1 CPU et 1 Go de RAM.&lt;/p&gt;&#xA;&lt;p&gt;Cette VM héberge une instance de bases de données PostgreSQL version 13.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres@~]$ cat /proc/cpuinfo | egrep -i &#39;model|Mhz|core&#39;&#xD;&#xA;model : 79&#xD;&#xA;model name : Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz&#xD;&#xA;cpu MHz : 2299.980&#xD;&#xA;core id : 0&#xD;&#xA;cpu cores : 1&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres@ ~]$ cat /proc/meminfo | grep -i Total&#xD;&#xA;MemTotal: 834212 kB&#xD;&#xA;SwapTotal: 0 kB&#xD;&#xA;VmallocTotal: 34359738367 kB&#xD;&#xA;HugePages_Total: 0&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Nous savons que ce n&amp;#8217;est pas avec une telle configuration que nous pouvons nous attendre à pas des performances impressionnantes, mais nous aurons au moins de quoi se faire une idée sur les caractéristiques du chiffrement.&lt;/p&gt;&#xA;&lt;p&gt;Pour notre jeu de données, nous nous appuyons sur le site &amp;#8220;DVD Rental&amp;#8221; proposant une base de données fictive de location de DVDs (oui oui cela doit encore exister cette catégorie de société ! ) (DVD Rental sur &lt;a href=&#34;https://www.postgresqltutorial.com/postgresql-getting-started/postgresql-sample-database/&#34;&gt;ce site&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;p&gt;Les tables comportent des données assez représentatives de ce que l&amp;#8217;on souhaite faire pour notre étude.&lt;/p&gt;&#xA;&lt;p&gt;Les tables proposées pour cette base sont les suivantes&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [dvdrental]  select schemaname,tablename, pg_size_pretty(pg_relation_size(schemaname::varchar||&#39;.&#39;||tablename::varchar)) as Size_table, pg_size_pretty(pg_indexes_size(schemaname::varchar||&#39;.&#39;||tablename::varchar)) as Size_index from pg_tables where schemaname not in (&#39;pg_catalog&#39;,&#39;information_schema&#39;) order by 2 desc;&#xD;&#xA;&#xD;&#xA;------------+---------------+------------+------------&#xD;&#xA;public      | store         | 8192 bytes | 32 kB&#xD;&#xA;public      | staff         | 8192 bytes | 16 kB&#xD;&#xA;public      | rental        | 1200 kB    | 1120 kB&#xD;&#xA;public      | payment       | 864 kB     | 920 kB&#xD;&#xA;public      | language      | 8192 bytes | 16 kB&#xD;&#xA;public      | inventory     | 200 kB     | 208 kB&#xD;&#xA;public      | film_category | 48 kB      | 40 kB&#xD;&#xA;public      | film_actor    | 240 kB     | 216 kB&#xD;&#xA;public      | film          | 432 kB     | 200 kB&#xD;&#xA;public      | customer      | 72 kB      | 112 kB&#xD;&#xA;public      | country       | 8192 bytes | 16 kB&#xD;&#xA;public      | city          | 40 kB      | 48 kB&#xD;&#xA;public      | category      | 8192 bytes | 16 kB&#xD;&#xA;public      | address       | 64 kB      | 64 kB&#xD;&#xA;public      | actor         | 16 kB      | 32 kB&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Si l&amp;#8217;on souhaite avoir la liste des clients et leurs informations personnelles, y compris leur adresse, nous formulons la requête SQL suivante sur notre outil PostgreSQL client.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;div&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [dvdrental]  select c.customer_id,c.first_name,c.last_name,c.email,c.create_date,a.address,a.district,a.phone from customer c inner join address a on (c.address_id=a.address_id);&#xD;&#xA;&#xD;&#xA;customer_id  | first_name  | last_name    | email                                    | create_date | address                                | district             | phone&#xD;&#xA;-------------+-------------+--------------+------------------------------------------+-------------+----------------------------------------+----------------------+--------------&#xD;&#xA;524          | Jared       | Ely          | jared.ely@sakilacustomer.org             | 2006-02-14  | 1003 Qinhuangdao Street                | West Java            | 35533115997&#xD;&#xA;1            | Mary        | Smith        | mary.smith@sakilacustomer.org            | 2006-02-14  | 1913 Hanoi Way                         | Nagasaki             | 28303384290&#xD;&#xA;2            | Patricia    | Johnson      | patricia.johnson@sakilacustomer.org      | 2006-02-14  | 1121 Loja Avenue                       | California           | 838635286649&#xD;&#xA;3            | Linda       | Williams     | linda.williams@sakilacustomer.org        | 2006-02-14  | 692 Joliet Street                      | Attika               | 448477190408&#xD;&#xA;4            | Barbara     | Jones        | barbara.jones@sakilacustomer.org         | 2006-02-14  | 1566 Inegl Manor                       | Mandalay             | 705814003527&#xD;&#xA;5            | Elizabeth   | Brown        | elizabeth.brown@sakilacustomer.org       | 2006-02-14  | 53 Idfu Parkway                        | Nantou               | 10655648674&#xD;&#xA;6            | Jennifer    | Davis        | jennifer.davis@sakilacustomer.org        | 2006-02-14  | 1795 Santiago de Compostela Way        | Texas                | 860452626434&#xD;&#xA;7            | Maria       | Miller       | maria.miller@sakilacustomer.org          | 2006-02-14  | 900 Santiago de Compostela Parkway     | Central Serbia       | 716571220373&#xD;&#xA;8            | Susan       | Wilson       | susan.wilson@sakilacustomer.org          | 2006-02-14  | 478 Joliet Way                         | Hamilton             | 657282285970&#xD;&#xA;9            | Margaret    | Moore        | margaret.moore@sakilacustomer.org        | 2006-02-14  | 613 Korolev Drive                      | Masqat               | 380657522649&#xD;&#xA;10           | Dorothy     | Taylor       | dorothy.taylor@sakilacustomer.org        | 2006-02-14  | 1531 Sal Drive                         | Esfahan              | 648856936185&#xD;&#xA;11           | Lisa        | Anderson     | lisa.anderson@sakilacustomer.org         | 2006-02-14  | 1542 Tarlac Parkway                    | Kanagawa             | 635297277345&#xD;&#xA;12           | Nancy       | Thomas       | nancy.thomas@sakilacustomer.org          | 2006-02-14  | 808 Bhopal Manor                       | Haryana              | 465887807014&#xD;&#xA;13           | Karen       | Jackson      | karen.jackson@sakilacustomer.org         | 2006-02-14  | 270 Amroha Parkway                     | Osmaniye             | 695479687538&#xD;&#xA;14           | Betty       | White        | betty.white@sakilacustomer.org           | 2006-02-14  | 770 Bydgoszcz Avenue                   | California           | 517338314235&#xD;&#xA;15           | Helen       | Harris       | helen.harris@sakilacustomer.org          | 2006-02-14  | 419 Iligan Lane                        | Madhya Pradesh       | 990911107354&#xD;&#xA;16           | Sandra      | Martin       | sandra.martin@sakilacustomer.org         | 2006-02-14  | 360 Toulouse Parkway                   | England              | 949312333307&#xD;&#xA;17           | Donna       | Thompson     | donna.thompson@sakilacustomer.org        | 2006-02-14  | 270 Toulon Boulevard                   | Kalmykia             | 407752414682&#xD;&#xA; .......&#xD;&#xA;&#xD;&#xA;(599 rows)&#xD;&#xA;&#xD;&#xA;Time: 5.196 ms &lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;Les données nous sont renvoyées en clair avec nom, prénom, adresse et téléphone des personnes.&lt;/div&gt;&#xA;&lt;div&gt;La question que l&amp;#8217;on sera amené à se poser est, combien cela va ma couter de &amp;#8220;sécuriser&amp;#8221; ces données afin que ces champs ne soient pas lisibles via un simple &amp;#8220;SELECT &amp;#8221; sans algorithme de chiffrage ?&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&#xA;&lt;h2&gt;Mise en place&lt;/h2&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Comme évoqué ci-dessus, nous utiliserons l&amp;#8217;extension &amp;#8220;pgcrypto&amp;#8221; pour réaliser nos différents tests de chiffrement.&lt;/p&gt;&#xA;&lt;p&gt;Nous avons la version 1.3 de pgcrypto sur une instance PostgreSQL 13&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [dvdrental]  \dx&#xD;&#xA;Name      | Version | Schema     | Description&#xD;&#xA;----------+---------+------------+------------------------------&#xD;&#xA;pgcrypto  | 1.3     | public     | cryptographic functions&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;p&gt;Les données que nous nous proposons de traiter seront extraits de la requête avec jointure interne entre la table des clients (customer) et la table des adresses clients (address).&lt;/p&gt;&#xA;&lt;p&gt;Le plan d&amp;#8217;exécution de cette requête est assez simple. 2 lectures séquentielles sont effectuées directement sur les tables heap customer et address dans la mesure ou aucune clause where n&amp;#8217;est indiquée.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [dvdrental]  explain (analyze, verbose) select c.customer_id,c.first_name,c.last_name,c.email,c.create_date,a.address,a.district,a.phone from customer c inner join address a on (c.address_id=a.address_id);&#xD;&#xA;&#xD;&#xA;QUERY PLAN&#xD;&#xA;---------------------------------------------------------------------------------------------------------------------------------------------------&#xD;&#xA;Hash Join (cost=21.57..38.14 rows=599 width=94) (actual time=0.978..2.295 rows=599 loops=1)&#xD;&#xA;Output: c.customer_id, c.first_name, c.last_name, c.email, c.create_date, a.address, a.district, a.phone&#xD;&#xA;Inner Unique: true&#xD;&#xA;Hash Cond: (c.address_id = a.address_id)&#xD;&#xA;- Seq Scan on public.customer c (cost=0.00..14.99 rows=599 width=55) (actual time=0.009..0.433 rows=599 loops=1)&#xD;&#xA;Output: c.customer_id, c.store_id, c.first_name, c.last_name, c.email, c.address_id, c.activebool, c.create_date, c.last_update, c.active&#xD;&#xA;- Hash (cost=14.03..14.03 rows=603 width=45) (actual time=0.958..0.961 rows=603 loops=1)&#xD;&#xA;Output: a.address, a.district, a.phone, a.address_id&#xD;&#xA;Buckets: 1024 Batches: 1 Memory Usage: 56kB&#xD;&#xA;- Seq Scan on public.address a (cost=0.00..14.03 rows=603 width=45) (actual time=0.007..0.477 rows=603 loops=1)&#xD;&#xA;Output: a.address, a.district, a.phone, a.address_id&#xD;&#xA;Planning Time: 0.271 ms&#xD;&#xA;Execution Time: 2.705 ms&#xD;&#xA;(13 rows)&#xD;&#xA;&#xD;&#xA;Time: 3.476 ms&lt;/pre&gt;&#xA;&lt;p&gt;Pour cette simple requête, nous n&amp;#8217;avons besoin que de 3 millisecondes pour trier les données, avec un coût de 38, et ramener les 599 lignes.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Cryptage classique&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Le cryptage classique consiste à utiliser les fonctions simples &amp;#8220;encrypt / decrypt&amp;#8221;.&lt;br /&gt;&#xA;Ces 2 fonctions utilisent une clé de cryptage que l&amp;#8217;on passe à chacun des champs cryptés lors des ordres INSERT et SELECT.&lt;/p&gt;&#xA;&lt;p&gt;Tout d&amp;#8217;abord on crée les 2 tables vides, copies des tables &amp;#8220;customer&amp;#8221; et &amp;#8220;address&amp;#8221;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;CREATE TABLE IF NOT EXISTS public.customer_encrypt&#xD;&#xA;(&#xD;&#xA;customer_id integer,&#xD;&#xA;store_id smallint ,&#xD;&#xA;first_name bytea ,&#xD;&#xA;last_name bytea ,&#xD;&#xA;email bytea,&#xD;&#xA;address_id smallint,&#xD;&#xA;activebool boolean,&#xD;&#xA;create_date date,&#xD;&#xA;last_update timestamp without time zone,&#xD;&#xA;active integer,&#xD;&#xA;CONSTRAINT customer_pkey_crypt PRIMARY KEY (customer_id)&#xD;&#xA;)&#xD;&#xA;TABLESPACE pg_default;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;CREATE TABLE IF NOT EXISTS public.address_encrypt&#xD;&#xA;(&#xD;&#xA;address_id integer,&#xD;&#xA;address bytea,&#xD;&#xA;address2 character varying(50),&#xD;&#xA;district character varying(20),&#xD;&#xA;city_id smallint,&#xD;&#xA;postal_code character varying(10),&#xD;&#xA;phone bytea,&#xD;&#xA;last_update timestamp without time zone,&#xD;&#xA;CONSTRAINT address_key_crypt PRIMARY KEY (address_id)&#xD;&#xA;)&#xD;&#xA;TABLESPACE pg_default;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Puis on y insère les données à partir des tables sources &amp;#8220;customer&amp;#8221; et &amp;#8220;address&amp;#8221;. Pour cela, nous utilisons la fonction &amp;#8220;encrypt&amp;#8221; avec la clé &amp;#8220;capdata2023&amp;#8221; et l&amp;#8217;algorithme aes.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;insert into public.customer_encrypt&#xD;&#xA;select customer_id,&#xD;&#xA;store_id,&#xD;&#xA;encrypt(c.first_name::bytea,&#39;capdata2023&#39;,&#39;aes&#39;),&#xD;&#xA;encrypt(c.last_name::bytea,&#39;capdata2023&#39;,&#39;aes&#39;),&#xD;&#xA;encrypt(c.email::bytea,&#39;capdata2023&#39;,&#39;aes&#39;),&#xD;&#xA;address_id,&#xD;&#xA;activebool,&#xD;&#xA;create_date,&#xD;&#xA;last_update,&#xD;&#xA;active&#xD;&#xA;from customer c;&#xD;&#xA;INSERT 0 599&#xD;&#xA;Time: 5.297 ms&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;insert into public.address_encrypt&#xD;&#xA;select address_id,&#xD;&#xA;encrypt(address::bytea,&#39;capdata2023&#39;,&#39;aes&#39;),&#xD;&#xA;address2,&#xD;&#xA;district,&#xD;&#xA;city_id,&#xD;&#xA;postal_code,&#xD;&#xA;encrypt(phone::bytea,&#39;capdata2023&#39;,&#39;aes&#39;),&#xD;&#xA;last_update&#xD;&#xA;from address;&#xD;&#xA;INSERT 0 603&#xD;&#xA;Time: 4.616 ms&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Les données dans les tables sont bien chiffrées comme le montre le simple SELECT suivant&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [dvdrental]  select * from customer_encrypt limit 10;&#xD;&#xA;&#xD;&#xA;customer_id  | store_id | first_name                         | last_name                          | email                                                                                              | address_id | activebool | create_date | last_update | active&#xD;&#xA;-------------+----------+------------------------------------+------------------------------------+----------------------------------------------------------------------------------------------------+------------+------------+-------------+-------------------------+--------&#xD;&#xA;524          | 1        | \x18a7f8f4ba98111a01f63aef09773202 | \xdf4bcb77c652d6291c34ec7788cbe881 | \xa536a4f46d1bcc00f7183b46b68da712d70a0f419c1e58d778a4e9a3771828d7                                 | 530 | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&#xD;&#xA;1            | 1        | \x4f49ec91c5f38f8d3f751e42966f5695 | \x7c78e265d6e86fc17cdc78ebf1b41dd3 | \xac61ff9165a035a68a821c3959f5867a218fed8e350853e14d0c0a7dcf49b6d5                                 | 5   | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&#xD;&#xA;2            | 1        | \x541dec9d2a1688ff55fe0730e184548b | \x15200a194b068c59b0431271cf6f3c12 | \x7c9b39f5896ac24d8bedc08427adbfe1d5c22379d66dfd2881d3bdabe9b5cae60c329724424be9c6bcfe08cffc356c3c | 6   | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&#xD;&#xA;3            | 1        | \x4f1dd6b1d35f3024eb7c6cbf5c600269 | \x47d3a708ba137f5b9a0b873df5a7e340 | \x9297172b1a299f013db248a00d7414c7ea1378fbefc143e3f1f632c431ecf8597b5307f415eb82f672b15449c93c297e | 7   | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&#xD;&#xA;4            | 2        | \x84554c6f4c26d2f9c0b832b311263883 | \x6eff33a47393acf9d178afa9553ffae4 | \xe912cb073583fb399c92379d3529b18cf39754828ed28e02e31e3b8c9b523d2c02a18bfebc210bab193d8489cdd11914 | 8   | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&#xD;&#xA;5            | 1        | \xca5601a262cbc84669558ba7199f5960 | \x99fc3b33675cb5de00c92447f6f7e8ed | \xae7ea0ea5204c1df2e596af38b53a2da84cce415ae4ba5645df6dba7826e868a26eb59af5e79a7f8a4d55abc1382499b | 9   | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&#xD;&#xA;6            | 2        | \xb5f9f526337e730b25f4c4f7dab8eb91 | \x52bba94e13cc36be9f1094c1bae22c47 | \x50c4a57f06048c579897fce47603945db4d7143f6deaa5d801c447f23edde371565e24c4bc53e272e0ebf32ace80fbd5 | 10  | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&#xD;&#xA;7            | 1        | \xac6e41d9fb3a3eaefd0775e5b646a730 | \xb8ba78ad82aff0a50717301716e59013 | \xad3cec70e819240d7f7ddd6066364332f0c6b504d15b6627516deb13fe591bd2                                 | 11  | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&#xD;&#xA;8            | 2        | \x8aeb1a151900c8c2b3ac52c3a9c78a42 | \xea0c5c0e6546ffc8da1ef4f04f5addea | \x5eac14927a3c464e8cd88122d02271333e7235e8d212e1c2722a6b3804ba1672                                 | 12  | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&#xD;&#xA;9            | 2        | \x9248a51a98b10f1c0499f37604e2caa3 | \x254b523f8e750e100218947a2f838585 | \x706c681ae5692ba107cb51c3f54b1ef2699c1e463b68b8fbc48f8f9f15c86a45d456498740e41097f99f46c80837dcbf | 13  | t | 2006-02-14 | 2013-05-26 14:49:45.738 | 1&lt;/pre&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;p&gt;Pour déchiffrer les données de notre requête SQL avec jointure entre les clients et leurs adresses, nous devons appeler la fonction &amp;#8220;decrypt&amp;#8221; pour chaque champ, avec la clé de chiffrage associée. Afin de lire correctement la valeur, utiliser la fonction &amp;#8220;convert_from&amp;#8221; pour transformer l&amp;#8217;information de façon lisible.&lt;/p&gt;&#xA;&lt;p&gt;Ce qui donne la requête suivante :&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5433) [dvdrental]  select c.customer_id,&#xD;&#xA;convert_from(decrypt(c.first_name,&#39;capdata2023&#39;,&#39;aes&#39;),&#39;UTF8&#39;) as first_name,&#xD;&#xA;convert_from(decrypt(c.last_name,&#39;capdata2023&#39;,&#39;aes&#39;),&#39;UTF8&#39;) as last_name,&#xD;&#xA;convert_from(decrypt(c.email,&#39;capdata2023&#39;,&#39;aes&#39;),&#39;UTF8&#39;) as email,&#xD;&#xA;c.create_date,&#xD;&#xA;convert_from(decrypt(a.address,&#39;capdata2023&#39;,&#39;aes&#39;),&#39;UTF8&#39;) as adresse,&#xD;&#xA;a.district,&#xD;&#xA;convert_from(decrypt(a.phone,&#39;capdata2023&#39;,&#39;aes&#39;),&#39;UTF8&#39;) as telephone&#xD;&#xA;from customer_encrypt c&#xD;&#xA;inner join address_encrypt a&#xD;&#xA;on (c.address_id=a.address_id);&#xD;&#xA;&#xD;&#xA;customer_id  | first_name  | last_name    | email                                    | create_date | adresse                                | district             | telephone&#xD;&#xA;-------------+-------------+--------------+------------------------------------------+-------------+----------------------------------------+----------------------+--------------&#xD;&#xA;524          | Jared       | Ely          | jared.ely@sakilacustomer.org             | 2006-02-14  | 1003 Qinhuangdao Street                | West Java            | 35533115997&#xD;&#xA;1            | Mary        | Smith        | mary.smith@sakilacustomer.org            | 2006-02-14  | 1913 Hanoi Way                         | Nagasaki             | 28303384290&#xD;&#xA;2            | Patricia    | Johnson      | patricia.johnson@sakilacustomer.org      | 2006-02-14  | 1121 Loja Avenue                       | California | 838635286649&#xD;&#xA;3            | Linda       | Williams     | linda.williams@sakilacustomer.org        | 2006-02-14  | 692 Joliet Street                      | Attika | 448477190408&#xD;&#xA;4            | Barbara     | Jones        | barbara.jones@sakilacustomer.org         | 2006-02-14  | 1566 Inegl Manor                       | Mandalay | 705814003527&#xD;&#xA;5            | Elizabeth   | Brown        | elizabeth.brown@sakilacustomer.org       | 2006-02-14  | 53 Idfu Parkway                        | Nantou | 10655648674&#xD;&#xA;6            | Jennifer    | Davis        | jennifer.davis@sakilacustomer.org        | 2006-02-14  | 1795 Santiago de Compostela Way        | Texas | 860452626434&#xD;&#xA;7            | Maria       | Miller       | maria.miller@sakilacustomer.org          | 2006-02-14  | 900 Santiago de Compostela Parkway     | Central Serbia | 716571220373&#xD;&#xA;8            | Susan       | Wilson       | susan.wilson@sakilacustomer.org          | 2006-02-14  | 478 Joliet Way                         | Hamilton | 657282285970&#xD;&#xA;9            | Margaret    | Moore        | margaret.moore@sakilacustomer.org        | 2006-02-14  | 613 Korolev Drive                      | Masqat | 380657522649&#xD;&#xA;10           | Dorothy     | Taylor       | dorothy.taylor@sakilacustomer.org        | 2006-02-14  | 1531 Sal Drive                         | Esfahan | 648856936185&#xD;&#xA;11           | Lisa        | Anderson     | lisa.anderson@sakilacustomer.org         | 2006-02-14  | 1542 Tarlac Parkway                    | Kanagawa | 635297277345&#xD;&#xA;12           | Nancy       | Thomas       | nancy.thomas@sakilacustomer.org          | 2006-02-14  | 808 Bhopal Manor                       | Haryana | 465887807014&#xD;&#xA;13           | Karen       | Jackson      | karen.jackson@sakilacustomer.org         | 2006-02-14  | 270 Amroha Parkway                     | Osmaniye | 695479687538&#xD;&#xA;14           | Betty       | White        | betty.white@sakilacustomer.org           | 2006-02-14  | 770 Bydgoszcz Avenue                   | California | 517338314235&#xD;&#xA;15           | Helen       | Harris       | helen.harris@sakilacustomer.org          | 2006-02-14  | 419 Iligan Lane                        | Madhya Pradesh | 990911107354&#xD;&#xA;16           | Sandra      | Martin       | sandra.martin@sakilacustomer.org         | 2006-02-14  | 360 Toulouse Parkway                   | England | 949312333307&#xD;&#xA;17           | Donna       | Thompson     | donna.thompson@sakilacustomer.org        | 2006-02-14  | 270 Toulon Boulevard                   | Kalmykia | 407752414682&#xD;&#xA;&#xD;&#xA; ...&#xD;&#xA;&#xD;&#xA;(599 rows)&#xD;&#xA;&#xD;&#xA;Time: 5.064 ms&lt;/pre&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;pre&gt;&lt;/pre&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;Le temps d&amp;#8217;exécution de cette requête est d&amp;#8217;un peu plus de 5 millisecondes, nous sommes donc très proches de ce qui a été relevé sur les tables originales.&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;h3&gt;Chiffrement PGP symétrique&lt;/h3&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&#xA;&lt;p&gt;Le chiffrement PGP (Pretty Good Privacy) utilise des standards liés à OpenPGP (RFC 2440).&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div&gt;Le procédé consiste à utiliser un message chiffré PGP en deux parties.&lt;br /&gt;&#xA;&amp;#8211; Un paquet est envoyé avec la clé de session (clé symétrique ou bien une clé publique)&lt;br /&gt;&#xA;&amp;#8211; Paquet contenant les données chiffrées avec la clé de session.&lt;br /&gt;&#xA;Avec un chiffrement à clé symétrique, le mot de passe est envoyé crypté avec l’algorithme String2key (S2K).&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;Si une clé de session choisie par l&amp;#8217;utilisateur, elle sera également chiffrée suivant le même algorithme.&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;Enfin les données sont formatées avec un hachage SHA1, et sont préfixées avec un bloc d’octets pris au hasard.&lt;br /&gt;&#xA;Puis elles sont chiffrées avec la clé de session.&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;L&amp;#8217;étape de création de tables de tests et insertion des données à partir des tables sources &amp;#8220;customer&amp;#8221; et &amp;#8220;address&amp;#8221; est également nécessaire pour notre exemple.&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;CREATE TABLE IF NOT EXISTS public.customer_pgp_sym&#xD;&#xA;(&#xD;&#xA;customer_id integer,&#xD;&#xA;store_id smallint , &#xD;&#xA;first_name bytea , &#xD;&#xA;last_name bytea , &#xD;&#xA;email bytea, &#xD;&#xA;address_id smallint, &#xD;&#xA;activebool boolean, &#xD;&#xA;create_date date, &#xD;&#xA;last_update timestamp without time zone, &#xD;&#xA;active integer,&#xD;&#xA;CONSTRAINT customer_pkey_sym PRIMARY KEY (customer_id) &#xD;&#xA;)&#xD;&#xA;TABLESPACE pg_default;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;CREATE TABLE IF NOT EXISTS public.address_pgp_sym&#xD;&#xA;(&#xD;&#xA;address_id integer, &#xD;&#xA;address bytea,&#xD;&#xA;address2 character varying(50),&#xD;&#xA;district character varying(20),&#xD;&#xA;city_id smallint,&#xD;&#xA;postal_code character varying(10), &#xD;&#xA;phone bytea,&#xD;&#xA;last_update timestamp without time zone,&#xD;&#xA;CONSTRAINT address_key_sym PRIMARY KEY (address_id)&#xD;&#xA;)&#xD;&#xA;TABLESPACE pg_default;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;Insertion des données. Nous utilisons un algorithme &amp;#8220;aes256&amp;#8221; avec compression et clé de session.&lt;/div&gt;&#xA;&lt;div&gt;La clé de cryptage est toujours &amp;#8216;capdata2023&amp;#8217;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;insert into public.customer_pgp_sym_256&#xD;&#xA;select customer_id,&#xD;&#xA;store_id,&#xD;&#xA;pgp_sym_encrypt(c.first_name,&#39;capdata2023&#39;,&#39;cipher-algo=aes256, compress-algo=1, sess-key=1&#39;),&#xD;&#xA;pgp_sym_encrypt(c.last_name,&#39;capdata2023&#39;,&#39;cipher-algo=aes256, compress-algo=1, sess-key=1&#39;),&#xD;&#xA;pgp_sym_encrypt(c.email,&#39;capdata2023&#39;,&#39;cipher-algo=aes256, compress-algo=1, sess-key=1&#39;),&#xD;&#xA;address_id,&#xD;&#xA;activebool,&#xD;&#xA;create_date,&#xD;&#xA;last_update,&#xD;&#xA;active&#xD;&#xA;from customer c;&#xD;&#xA;&#xD;&#xA;INSERT 0 599&#xD;&#xA;Time: 1822.944 ms (00:01.823)&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;insert into public.address_pgp_sym_256&#xD;&#xA;select address_id,&#xD;&#xA;pgp_sym_encrypt(address,&#39;capdata2023&#39;,&#39;cipher-algo=aes256, compress-algo=1, sess-key=1&#39;),&#xD;&#xA;address2,&#xD;&#xA;district,&#xD;&#xA;city_id,&#xD;&#xA;postal_code,&#xD;&#xA;pgp_sym_encrypt(phone,&#39;capdata2023&#39;,&#39;cipher-algo=aes256, compress-algo=1, sess-key=1&#39;),&#xD;&#xA;last_update&#xD;&#xA;from address;&#xD;&#xA;&#xD;&#xA;INSERT 0 603&#xD;&#xA;Time: 1244.807 ms (00:01.245)&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Nous dépassons la seconde à chaque opération d&amp;#8217;insertions dans les nouvelles tables !!&lt;/p&gt;&#xA;&lt;p&gt;Si l&amp;#8217;on souhaite décrypter les champs , nous utilisons la fonction &amp;#8220;pgp_sym_decrypt&amp;#8221; et notre clé de cryptage.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;&#xD;&#xA;select c.customer_id,&#xD;&#xA;pgp_sym_decrypt(c.first_name,&#39;capdata2023&#39;) as first_name,&#xD;&#xA;pgp_sym_decrypt(c.last_name,&#39;capdata2023&#39;) as last_name,&#xD;&#xA;pgp_sym_decrypt(c.email,&#39;capdata2023&#39;) as email,&#xD;&#xA;c.create_date,&#xD;&#xA;pgp_sym_decrypt(a.address,&#39;capdata2023&#39;) as adresse,&#xD;&#xA;a.district,&#xD;&#xA;pgp_sym_decrypt(a.phone,&#39;capdata2023&#39;) as telephone&#xD;&#xA;from customer_pgp_sym_256 c&#xD;&#xA;inner join address_pgp_sym_256 a&#xD;&#xA;on (c.address_id=a.address_id);&#xD;&#xA;&#xD;&#xA;customer_id  | first_name  | last_name    | email                                    | create_date | adresse                                | district             | telephone&#xD;&#xA;-------------+-------------+--------------+------------------------------------------+-------------+----------------------------------------+----------------------+--------------&#xD;&#xA;524          | Jared       | Ely          | jared.ely@sakilacustomer.org             | 2006-02-14  | 1003 Qinhuangdao Street                | West Java            | 35533115997&#xD;&#xA;1            | Mary        | Smith        | mary.smith@sakilacustomer.org            | 2006-02-14  | 1913 Hanoi Way                         | Nagasaki             | 28303384290&#xD;&#xA;2            | Patricia    | Johnson      | patricia.johnson@sakilacustomer.org      | 2006-02-14  | 1121 Loja Avenue                       | California           | 838635286649&#xD;&#xA;3            | Linda       | Williams     | linda.williams@sakilacustomer.org        | 2006-02-14  | 692 Joliet Street                      | Attika               | 448477190408&#xD;&#xA;4            | Barbara     | Jones        | barbara.jones@sakilacustomer.org         | 2006-02-14  | 1566 Inegl Manor                       | Mandalay             | 705814003527&#xD;&#xA;5            | Elizabeth   | Brown        | elizabeth.brown@sakilacustomer.org       | 2006-02-14  | 53 Idfu Parkway                        | Nantou               | 10655648674&#xD;&#xA;6            | Jennifer    | Davis        | jennifer.davis@sakilacustomer.org        | 2006-02-14  | 1795 Santiago de Compostela Way        | Texas                | 860452626434&#xD;&#xA;7            | Maria       | Miller       | maria.miller@sakilacustomer.org          | 2006-02-14  | 900 Santiago de Compostela Parkway     | Central Serbia       | 716571220373&#xD;&#xA;8            | Susan       | Wilson       | susan.wilson@sakilacustomer.org          | 2006-02-14  | 478 Joliet Way                         | Hamilton             | 657282285970&#xD;&#xA;9            | Margaret    | Moore        | margaret.moore@sakilacustomer.org        | 2006-02-14  | 613 Korolev Drive                      | Masqat               | 380657522649&#xD;&#xA;10           | Dorothy     | Taylor       | dorothy.taylor@sakilacustomer.org        | 2006-02-14  | 1531 Sal Drive                         | Esfahan              | 648856936185&#xD;&#xA;11           | Lisa        | Anderson     | lisa.anderson@sakilacustomer.org         | 2006-02-14  | 1542 Tarlac Parkway                    | Kanagawa             | 635297277345&#xD;&#xA;12           | Nancy       | Thomas       | nancy.thomas@sakilacustomer.org          | 2006-02-14  | 808 Bhopal Manor                       | Haryana              | 465887807014&#xD;&#xA;13           | Karen       | Jackson      | karen.jackson@sakilacustomer.org         | 2006-02-14  | 270 Amroha Parkway                     | Osmaniye             | 695479687538&#xD;&#xA;14           | Betty       | White        | betty.white@sakilacustomer.org           | 2006-02-14  | 770 Bydgoszcz Avenue                   | California           | 517338314235&#xD;&#xA;15           | Helen       | Harris       | helen.harris@sakilacustomer.org          | 2006-02-14  | 419 Iligan Lane                        | Madhya Pradesh       | 990911107354&#xD;&#xA;16           | Sandra      | Martin       | sandra.martin@sakilacustomer.org         | 2006-02-14  | 360 Toulouse Parkway                   | England              | 949312333307&#xD;&#xA;&#xD;&#xA;&#xD;&#xA; .....&#xD;&#xA;&#xD;&#xA;(599 rows)&#xD;&#xA;&#xD;&#xA;Time: 2887.341 ms (00:02.887)&lt;/pre&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;Ici, nous dépassons les 2 secondes pour renvoyer les données déchiffrées.  Dans le plan d&amp;#8217;exécution de cette requête, on peut voir un coût global multiplié par 3 quasiment, et un temps global sur l&amp;#8217;opération de jointure entre les 2 tables de plus de 2800 millisecondes.&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------&#xD;&#xA;Hash Join (cost=37.57..84.63 rows=599 width=177) (actual time=7.387..2886.456 rows=599 loops=1)&#xD;&#xA;Output: c.customer_id, pgp_sym_decrypt(c.first_name, &#39;capdata2023&#39;::text), pgp_sym_decrypt(c.last_name, &#39;capdata2023&#39;::text), pgp_sym_decrypt(c.email, &#39;capdata2023&#39;::text), c.create_date, pgp_sym_decrypt(a.address, &#39;capdata2023&#39;::text), a.district, pgp_sym_decrypt(a.phone, &#39;capdata2023&#39;::text)&#xD;&#xA;Inner Unique: true&#xD;&#xA;Hash Cond: (c.address_id = a.address_id)&#xD;&#xA;- Seq Scan on public.customer_pgp_sym_256 c (cost=0.00..37.99 rows=599 width=370) (actual time=0.007..0.833 rows=599 loops=1)&#xD;&#xA;Output: c.customer_id, c.store_id, c.first_name, c.last_name, c.email, c.address_id, c.activebool, c.create_date, c.last_update, c.active&#xD;&#xA;- Hash (cost=30.03..30.03 rows=603 width=253) (actual time=1.186..1.189 rows=603 loops=1)&#xD;&#xA;Output: a.address, a.district, a.phone, a.address_id&#xD;&#xA;Buckets: 1024 Batches: 1 Memory Usage: 179kB&#xD;&#xA;- Seq Scan on public.address_pgp_sym_256 a (cost=0.00..30.03 rows=603 width=253) (actual time=0.006..0.516 rows=603 loops=1)&#xD;&#xA;Output: a.address, a.district, a.phone, a.address_id&#xD;&#xA;Planning Time: 0.200 ms&#xD;&#xA;Execution Time: 2887.108 ms&#xD;&#xA;(13 rows)&#xD;&#xA;&#xD;&#xA;Time: 2887.897 ms (00:02.888)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Chiffrement PGP avec pair de clés publique/privée&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;C’est la méthode la plus complexe à mettre en place, mais aussi la plus optimale en termes de sécurité.&lt;br /&gt;&#xA;Le procédé s’appuie également sur OpenPGP, mais utilise, en plus, une clé publique côté serveur de bases de données. Cette clé publique est utilisée pour chiffrer la donnée.&lt;br /&gt;&#xA;C’est au déchiffrage que la clé privée est envoyée depuis l’application pour contrôle, et qui sera utilisée pour lire les champs enregistrés.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h4&gt;Gestion des clés RSA&lt;/h4&gt;&#xA;&lt;p&gt;Avant d’utiliser les clés publiques et clés privées, il faut les déclarer sur la machine hébergeant la base de données.&lt;/p&gt;&#xA;&lt;p&gt;Pour l’installation, nous utilisons l’utilitaire « &lt;strong&gt;gpg&lt;/strong&gt; ». Lancer la création de clés via l’option « &lt;strong&gt;full-generate-keys&lt;/strong&gt; » pour choisir les options de clés. Nous choisissons des clés RSA signées, avec un codage sur 2048 bits. La période de validité des clés est de 2 ans.&lt;/p&gt;&#xA;&lt;p&gt;Si vous lancez cette commande avec un compte &amp;#8220;non root&amp;#8221;, exécuter l&amp;#8217;option &lt;strong&gt;&amp;#8211;pinentry-mode=loopback&lt;/strong&gt;, sinon vous n&amp;#8217;aurez pas les permissions de&lt;br /&gt;&#xA;modifications des clés éventuellement déjà créées.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres@ ~]$ gpg --full-generate-key --pinentry-mode=loopback&#xD;&#xA;gpg (GnuPG) 2.2.20; Copyright (C) 2020 Free Software Foundation, Inc.&#xD;&#xA;This is free software: you are free to change and redistribute it.&#xD;&#xA;There is NO WARRANTY, to the extent permitted by law.&#xD;&#xA;&#xD;&#xA;Please select what kind of key you want:&#xD;&#xA;(1) RSA and RSA (default)&#xD;&#xA;(2) DSA and Elgamal&#xD;&#xA;(3) DSA (sign only)&#xD;&#xA;(4) RSA (sign only)&#xD;&#xA;(14) Existing key from card&#xD;&#xA;Your selection? 1&#xD;&#xA;RSA keys may be between 1024 and 4096 bits long.&#xD;&#xA;What keysize do you want? (2048) 2048&#xD;&#xA;Requested keysize is 2048 bits&#xD;&#xA;Please specify how long the key should be valid.&#xD;&#xA;0 = key does not expire&#xD;&#xA; = key expires in n days&#xD;&#xA;w = key expires in n weeks&#xD;&#xA;m = key expires in n months&#xD;&#xA;y = key expires in n years&#xD;&#xA;Key is valid for? (0) 2y&#xD;&#xA;Key expires at Wed 09 Jul 2025 02:28:18 PM UTC&#xD;&#xA;Is this correct? (y/N) y&#xD;&#xA;&#xD;&#xA;GnuPG needs to construct a user ID to identify your key.&#xD;&#xA;&#xD;&#xA;Real name: capdata&#xD;&#xA;Email address: &#xD;&#xA;Comment: capdata gpg PG test&#xD;&#xA;You selected this USER-ID:&#xD;&#xA;&amp;quot;capdata (capdata gpg PG test) &amp;quot;&#xD;&#xA;&#xD;&#xA;Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? O&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;pub rsa2048 2023-07-10 [SC] [expires: 2025-07-09]&#xD;&#xA;50B8DAB80C7E568169DCF9A7A38D290FAA943D45&#xD;&#xA;uid capdata (capdata gpg PG test) &#xD;&#xA;sub rsa2048 2023-07-10 [E] [expires: 2025-07-09]&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Vérifications&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres@~]$ gpg --list-keys --keyid-format short&#xD;&#xA;gpg: checking the trustdb&#xD;&#xA;gpg: marginals needed: 3 completes needed: 1 trust model: pgp&#xD;&#xA;gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u&#xD;&#xA;gpg: next trustdb check due at 2025-07-09&#xD;&#xA;/var/lib/pgsql/.gnupg/pubring.kbx&#xD;&#xA;---------------------------------&#xD;&#xA;pub rsa2048/AA943D45 2023-07-10 [SC] [expires: 2025-07-09]&#xD;&#xA;50B8DAB80C7E568169DCF9A7A38D290FAA943D45&#xD;&#xA;uid [ultimate] capdata (capdata gpg PG test) &#xD;&#xA;sub rsa2048/1756306E 2023-07-10 [E] [expires: 2025-07-09]&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;et&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres@~]$ gpg --list-secret-keys --keyid-format short&#xD;&#xA;/var/lib/pgsql/.gnupg/pubring.kbx&#xD;&#xA;---------------------------------&#xD;&#xA;sec rsa2048/AA943D45 2023-07-10 [SC] [expires: 2025-07-09]&#xD;&#xA;50B8DAB80C7E568169DCF9A7A38D290FAA943D45&#xD;&#xA;uid [ultimate] capdata (capdata gpg PG test) &#xD;&#xA;ssb rsa2048/1756306E 2023-07-10 [E] [expires: 2025-07-09]&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Exporter la clé publique et la clé privée&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres@~]$ gpg --armor --export &#39;capdata&#39;&#xD;&#xA;-----BEGIN PGP PUBLIC KEY BLOCK-----&#xD;&#xA;&#xD;&#xA;mQENBGSsFaoBCADMenKoGzxL7hZ1gkVHUrY4UXA34ckuZn6yOeSwb/mrY/HdXVtz&#xD;&#xA;MO+cCCmJyp0rS3WoWAM+2bcstpAOgJaRzjZMbbKx9P0BocwbahwMbEgGY9J10l6S&#xD;&#xA;KT79khDmLrkLuXxiDl3IzsqatqMYIphrdNMZmUYIo5YegX/zcrgY2b3+xRdiPLnk&#xD;&#xA;WOmh/hJqzHd9GnTGCDa5jkUrme0DhBHJOBuAyh1abWGHHCrYlrs2guA1iYUMiq3P&#xD;&#xA;RD8dkIP5vEZO9XBPWRe0S41Et8kuocn0AlABW0VcA0GenMeviLk/xME2Cpnme9Fr&#xD;&#xA;0FDUxVQYi6vFXuf530G5f9QQnIYsQL26DVa1ABEBAAG0OmNhcGRhdGEgKGNhcGRh&#xD;&#xA;dGEgZ3BnIFBHIHRlc3QpIDxlcmFtaUBjYXBkYXRhLW9zbW96aXVtLmNvbT6JAVQE&#xD;&#xA;EwEIAD4WIQRQuNq4DH5WgWnc+aejjSkPqpQ9RQUCZKwVqgIbAwUJA8JnAAULCQgH&#xD;&#xA;AgYVCgkICwIEFgIDAQIeAQIXgAAKCRCjjSkPqpQ9ReqCB/97Fk6gWWYSfHQoQrH4&#xD;&#xA;N7Rlf1tNN0M5N7gmO6qZQVZzR5qiV1y3ahAIBPyIcQla9Nb3ry1NE5QayZ1FyEnu&#xD;&#xA;vTTVF2CWq0yXtes3Sv7Q2DrzoiENVwOeGSxqsx/IqfY8iFL6m3hXwXC51JNraLFh&#xD;&#xA;sTP617LKvfSETr+UFpkctdAfgmxlzJ7cUHF+m0lr7OsN9e5XZ8S9CwInFX6GJPDS&#xD;&#xA;j/CpUr4l/fdZa5H/1pc+gFBDWoaZYquqoYXM2YHOkPp9RZ12uejbRaIn/SlYKutE.......&#xD;&#xA;......&#xD;&#xA;mkx5lbcQlsaWj8PKM56mCgKF&#xD;&#xA;=U1rR&#xD;&#xA;-----END PGP PUBLIC KEY BLOCK-----&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;et&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[postgres@~]$ gpg --armor --export-secret-key &#39;capdata&#39;&#xD;&#xA;-----BEGIN PGP PRIVATE KEY BLOCK-----&#xD;&#xA;&#xD;&#xA;lQOYBGSsFaoBCADMenKoGzxL7hZ1gkVHUrY4UXA34ckuZn6yOeSwb/mrY/HdXVtz&#xD;&#xA;MO+cCCmJyp0rS3WoWAM+2bcstpAOgJaRzjZMbbKx9P0BocwbahwMbEgGY9J10l6S&#xD;&#xA;KT79khDmLrkLuXxiDl3IzsqatqMYIphrdNMZmUYIo5YegX/zcrgY2b3+xRdiPLnk&#xD;&#xA;WOmh/hJqzHd9GnTGCDa5jkUrme0DhBHJOBuAyh1abWGHHCrYlrs2guA1iYUMiq3P&#xD;&#xA;RD8dkIP5vEZO9XBPWRe0S41Et8kuocn0AlABW0VcA0GenMeviLk/xME2Cpnme9Fr&#xD;&#xA;0FDUxVQYi6vFXuf530G5f9QQnIYsQL26DVa1ABEBAAEAB/4poUVeJdtfDxxZ9LmD&#xD;&#xA;lZqdOTFaYzjZHkttoD1H0ahYZUr8+VCQ0XX7A6tnTw20HpMYAME6Zst1Cj8mgLYG&#xD;&#xA;/d+OrGfM9Nac4jLCoxYOTm5UhLa4v6l64vRc3kPcBUet1Cf3c7rS0w0rNgNa+tIi&#xD;&#xA;0IBZDhxUzm9WCyIAb8r83jnhGCSTaAeCBOqHnXE+JgUOdf15k1oVxYZdS73mpoNT&#xD;&#xA;aLXmmJbC7JFC74j40oP4brbUzzWo0mZo0R394ZG0booBJM2BDH4ydrSvGWbsreSF&#xD;&#xA;jo31xkHqsLOPHDlJvdVnbWVSuyjk0oL2bKWgXTz9oT1YxiaN32WRgM6cMXvXHZka&#xD;&#xA;TxhhBADa3SQQjK5+QXRYcTZjnMZ+E15AIk/DklYC1/Q/TYtKKD3w7oaoc7M8sPsq&#xD;&#xA;w7gzTMc9kAKb7NlG4x+v4+Ab5RuV08osS7ZPu3H3gZyPgjjyjwZEKG0pnMJdDfwr&#xD;&#xA;eWqhIdc35gd8FGiNHgoeFVS9pAA5TBB3W+mgR3x9Jdj/Q8htlQQA7yxwQ3/1bYyj&#xD;&#xA;ejd1Hvihq4YtvMyA7pJSkv5ptqyA/qiM6jkjH4WVL4Qew+IrmHOCfVyEjebIQgF......&#xD;&#xA;......&#xD;&#xA;5YLh06oFmkx5lbcQlsaWj8PKM56mCgKF&#xD;&#xA;=fYKN&#xD;&#xA;-----END PGP PRIVATE KEY BLOCK-----&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;La suite consistera à créer les tables pour accueillir ces données chiffrées, et insérer les données à partir des données sources.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;CREATE TABLE IF NOT EXISTS public.customer_pgp_pub&#xD;&#xA;(&#xD;&#xA;customer_id integer,&#xD;&#xA;store_id smallint , &#xD;&#xA;first_name bytea , &#xD;&#xA;last_name bytea , &#xD;&#xA;email bytea, &#xD;&#xA;address_id smallint, &#xD;&#xA;activebool boolean, &#xD;&#xA;create_date date, &#xD;&#xA;last_update timestamp without time zone, &#xD;&#xA;active integer,&#xD;&#xA;CONSTRAINT customer_pkey_pub PRIMARY KEY (customer_id) &#xD;&#xA;)&#xD;&#xA;TABLESPACE pg_default;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;CREATE TABLE IF NOT EXISTS public.address_pgp_pub&#xD;&#xA;(&#xD;&#xA;address_id integer, &#xD;&#xA;address bytea,&#xD;&#xA;address2 character varying(50),&#xD;&#xA;district character varying(20),&#xD;&#xA;city_id smallint,&#xD;&#xA;postal_code character varying(10), &#xD;&#xA;phone bytea,&#xD;&#xA;last_update timestamp without time zone,&#xD;&#xA;CONSTRAINT address_key_pub PRIMARY KEY (address_id)&#xD;&#xA;)&#xD;&#xA;TABLESPACE pg_default;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Lors de l&amp;#8217;étape d&amp;#8217;insertion de données, nous devons renseigner la clé publique, et utiliser, sur chaque champ, la fonction &amp;#8220;pgp_pub_encrypt&amp;#8221; !&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;insert into public.customer_pgp_pub&#xD;&#xA;select customer_id,&#xD;&#xA;store_id,&#xD;&#xA;pgp_pub_encrypt(c.first_name, keys.pubkey),&#xD;&#xA;pgp_pub_encrypt(c.last_name,keys.pubkey),&#xD;&#xA;pgp_pub_encrypt(c.email,keys.pubkey),&#xD;&#xA;address_id,&#xD;&#xA;activebool,&#xD;&#xA;create_date,&#xD;&#xA;last_update,&#xD;&#xA;active&#xD;&#xA;from customer c&#xD;&#xA;cross join (select dearmor(&#39;-----BEGIN PGP PUBLIC KEY BLOCK-----&#xD;&#xA;&#xD;&#xA;mQENBGSsFaoBCADMenKoGzxL7hZ1gkVHUrY4UXA34ckuZn6yOeSwb/mrY/HdXVtz&#xD;&#xA;MO+cCCmJyp0rS3WoWAM+2bcstpAOgJaRzjZMbbKx9P0BocwbahwMbEgGY9J10l6S&#xD;&#xA;KT79khDmLrkLuXxiDl3IzsqatqMYIphrdNMZmUYIo5YegX/zcrgY2b3+xRdiPLnk&#xD;&#xA;WOmh/hJqzHd9GnTGCDa5jkUrme0DhBHJOBuAyh1abWGHHCrYlrs2guA1iYUMiq3P&#xD;&#xA;RD8dkIP5vEZO9XBPWRe0S41Et8kuocn0AlABW0VcA0GenMeviLk/xME2Cpnme9Fr&#xD;&#xA;0FDUxVQYi6vFXuf530G5f9QQnIYsQL26DVa1ABEBAAG0OmNhcGRhdGEgKGNhcGRh&#xD;&#xA;dGEgZ3BnIFBHIHRlc3QpIDxlcmFtaUBjYXBkYXRhLW9zbW96aXVtLmNvbT6JAVQE&#xD;&#xA;EwEIAD4WIQRQuNq4DH5WgWnc+aejjSkPqpQ9RQUCZKwVqgIbAwUJA8JnAAULCQgH&#xD;&#xA;AgYVCgkICwIEFgIDAQIeAQIXgAAKCRCjjSkPqpQ9ReqCB/97Fk6gWWYSfHQoQrH4.....&#xD;&#xA;....&#xD;&#xA;vrti5S7AxozOn3jUfUawgKGHRhY2/Sm06+dmThnV3O3jRqAJcerTcFyL5YLh06oF&#xD;&#xA;mkx5lbcQlsaWj8PKM56mCgKF&#xD;&#xA;=U1rR&#xD;&#xA;-----END PGP PUBLIC KEY BLOCK-----&#39;) As pubkey) &#xD;&#xA;As keys;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;INSERT 0 599&#xD;&#xA;Time: 159.320 ms&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;insert into public.address_pgp_pub&#xD;&#xA;select address_id,&#xD;&#xA;pgp_pub_encrypt(address,keys.pubkey),&#xD;&#xA;address2,&#xD;&#xA;district,&#xD;&#xA;city_id,&#xD;&#xA;postal_code,&#xD;&#xA;pgp_pub_encrypt(phone,keys.pubkey),&#xD;&#xA;last_update&#xD;&#xA;from address&#xD;&#xA;cross join (select dearmor(&#39;-----BEGIN PGP PUBLIC KEY BLOCK-----&#xD;&#xA;&#xD;&#xA;mQENBGSsFaoBCADMenKoGzxL7hZ1gkVHUrY4UXA34ckuZn6yOeSwb/mrY/HdXVtz&#xD;&#xA;MO+cCCmJyp0rS3WoWAM+2bcstpAOgJaRzjZMbbKx9P0BocwbahwMbEgGY9J10l6S&#xD;&#xA;KT79khDmLrkLuXxiDl3IzsqatqMYIphrdNMZmUYIo5YegX/zcrgY2b3+xRdiPLnk&#xD;&#xA;WOmh/hJqzHd9GnTGCDa5jkUrme0DhBHJOBuAyh1abWGHHCrYlrs2guA1iYUMiq3P&#xD;&#xA;RD8dkIP5vEZO9XBPWRe0S41Et8kuocn0AlABW0VcA0GenMeviLk/xME2Cpnme9Fr&#xD;&#xA;0FDUxVQYi6vFXuf530G5f9QQnIYsQL26DVa1ABEBAAG0OmNhcGRhdGEgKGNhcGRh&#xD;&#xA;dGEgZ3BnIFBHIHRlc3QpIDxlcmFtaUBjYXBkYXRhLW9zbW96aXVtLmNvbT6JAVQE&#xD;&#xA;EwEIAD4WIQRQuNq4DH5WgWnc+aejjSkPqpQ9RQUCZKwVqgIbAwUJA8JnAAULCQgH&#xD;&#xA;AgYVCgkICwIEFgIDAQIeAQIXgAAKCRCjjSkPqpQ9ReqCB/97Fk6gWWYSfHQoQrH4&#xD;&#xA;N7Rlf1tNN0M5N7gmO6qZQVZzR5qiV1y3ahAIBPyIcQla9Nb3ry1NE5QayZ1FyEnu&#xD;&#xA;....&#xD;&#xA;vrti5S7AxozOn3jUfUawgKGHRhY2/Sm06+dmThnV3O3jRqAJcerTcFyL5YLh06oF&#xD;&#xA;mkx5lbcQlsaWj8PKM56mCgKF&#xD;&#xA;&#xD;&#xA;=U1rR&#xD;&#xA;&#xD;&#xA;-----END PGP PUBLIC KEY BLOCK-----&#39;) As pubkey)&amp;amp;amp;amp;amp;nbsp;&#xD;&#xA;&#xD;&#xA; As keys;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;INSERT 0 599&#xD;&#xA;Time: 159.320 ms&lt;/pre&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;Les insertions sont plutôt rapides vis-à-vis du PGP symétriques avec le chiffrage en aes256.&lt;/div&gt;&#xA;&lt;div&gt;La restitution des données déchiffrées est permise grâce à la clé privée renseignée.&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&lt;/div&gt;&#xA;&lt;div&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;select c.customer_id,&#xD;&#xA;pgp_pub_decrypt(c.first_name,keys.pubkey) as first_name,&#xD;&#xA;pgp_pub_decrypt(c.last_name,keys.pubkey) as last_name,&#xD;&#xA;pgp_pub_decrypt(c.email,keys.pubkey) as email,&#xD;&#xA;c.create_date,&#xD;&#xA;pgp_pub_decrypt(a.address,keys.pubkey) as adresse,&#xD;&#xA;a.district,&#xD;&#xA;pgp_pub_decrypt(a.phone,keys.pubkey) as telephone&#xD;&#xA;from customer_pgp_pub c&#xD;&#xA;inner join address_pgp_pub a&#xD;&#xA;on (c.address_id=a.address_id)&#xD;&#xA;cross join (SELECT dearmor(&#39;-----BEGIN PGP PRIVATE KEY BLOCK-----&#xD;&#xA;&#xD;&#xA;lQOYBGSsFaoBCADMenKoGzxL7hZ1gkVHUrY4UXA34ckuZn6yOeSwb/mrY/HdXVtz&#xD;&#xA;MO+cCCmJyp0rS3WoWAM+2bcstpAOgJaRzjZMbbKx9P0BocwbahwMbEgGY9J10l6S&#xD;&#xA;KT79khDmLrkLuXxiDl3IzsqatqMYIphrdNMZmUYIo5YegX/zcrgY2b3+xRdiPLnk&#xD;&#xA;WOmh/hJqzHd9GnTGCDa5jkUrme0DhBHJOBuAyh1abWGHHCrYlrs2guA1iYUMiq3P&#xD;&#xA;RD8dkIP5vEZO9XBPWRe0S41Et8kuocn0AlABW0VcA0GenMeviLk/xME2Cpnme9Fr&#xD;&#xA;0FDUxVQYi6vFXuf530G5f9QQnIYsQL26DVa1ABEBAAEAB/4poUVeJdtfDxxZ9LmD&#xD;&#xA;lZqdOTFaYzjZHkttoD1H0ahYZUr8+VCQ0XX7A6tnTw20HpMYAME6Zst1Cj8mgLYG&#xD;&#xA;/d+OrGfM9Nac4jLCoxYOTm5UhLa4v6l64vRc3kPcBUet1Cf3c7rS0w0rNgNa+tIi&#xD;&#xA;0IBZDhxUzm9WCyIAb8r83jnhGCSTaAeCBOqHnXE+JgUOdf15k1oVxYZdS73mpoNT&#xD;&#xA;aLXmmJbC7JFC74j40oP4brbUzzWo0mZo0R394ZG0booBJM2BDH4ydrSvGWbsreSF&#xD;&#xA;jo31xkHqsLOPHDlJvdVnbWVSuyjk0oL2bKWgXTz9oT1YxiaN32WRgM6cMXvXHZka&#xD;&#xA;TxhhBADa3SQQjK5+QXRYcTZjnMZ+E15AIk/DklYC1/Q/TYtKKD3w7oaoc7M8sPsq&#xD;&#xA;w7gzTMc9kAKb7NlG4x+v4+Ab5RuV08osS7ZPu3H3gZyPgjjyjwZEKG0pnMJdDfwr.....&#xD;&#xA;.....&#xD;&#xA;&#xD;&#xA;Nd51J9eivrti5S7AxozOn3jUfUawgKGHRhY2/Sm06+dmThnV3O3jRqAJcerTcFyL&#xD;&#xA;5YLh06oFmkx5lbcQlsaWj8PKM56mCgKF&#xD;&#xA;=fYKN&#xD;&#xA;-----END PGP PRIVATE KEY BLOCK-----&#39;) As pubkey) As keys;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;customer_id  | first_name  | last_name    | email                                    | create_date | adresse                                | district             | telephone&#xD;&#xA;-------------+-------------+--------------+------------------------------------------+-------------+----------------------------------------+----------------------+--------------&#xD;&#xA;524          | Jared       | Ely          | jared.ely@sakilacustomer.org              | 2006-02-14 | 1003 Qinhuangdao Street                | West Java            | 35533115997&#xD;&#xA;1            | Mary        | Smith        | mary.smith@sakilacustomer.org             | 2006-02-14 | 1913 Hanoi Way                         | Nagasaki             | 28303384290&#xD;&#xA;2            | Patricia    | Johnson      | patricia.johnson@sakilacustomer.org       | 2006-02-14 | 1121 Loja Avenue                       | California           | 838635286649&#xD;&#xA;3            | Linda       | Williams     | linda.williams@sakilacustomer.org         | 2006-02-14 | 692 Joliet Street                      | Attika               | 448477190408&#xD;&#xA;4            | Barbara     | Jones        | barbara.jones@sakilacustomer.org          | 2006-02-14 | 1566 Inegl Manor                       | Mandalay             | 705814003527&#xD;&#xA;5            | Elizabeth   | Brown        | elizabeth.brown@sakilacustomer.org        | 2006-02-14 | 53 Idfu Parkway                        | Nantou               | 10655648674&#xD;&#xA;6            | Jennifer    | Davis        | jennifer.davis@sakilacustomer.org         | 2006-02-14 | 1795 Santiago de Compostela Way        | Texas                | 860452626434&#xD;&#xA;7            | Maria       | Miller       | maria.miller@sakilacustomer.org           | 2006-02-14 | 900 Santiago de Compostela Parkway     | Central Serbia       | 716571220373&#xD;&#xA;8            | Susan       | Wilson       | susan.wilson@sakilacustomer.org           | 2006-02-14 | 478 Joliet Way                         | Hamilton             | 657282285970&#xD;&#xA;9            | Margaret    | Moore        | margaret.moore@sakilacustomer.org         | 2006-02-14 | 613 Korolev Drive                      | Masqat               | 380657522649&#xD;&#xA;10           | Dorothy     | Taylor       | dorothy.taylor@sakilacustomer.org         | 2006-02-14 | 1531 Sal Drive                         | Esfahan              | 648856936185&#xD;&#xA;11           | Lisa        | Anderson     | lisa.anderson@sakilacustomer.org          | 2006-02-14 | 1542 Tarlac Parkway                    | Kanagawa             | 635297277345&#xD;&#xA;12           | Nancy       | Thomas       | nancy.thomas@sakilacustomer.org           | 2006-02-14 | 808 Bhopal Manor                       | Haryana              | 465887807014&#xD;&#xA;13           | Karen       | Jackson      | karen.jackson@sakilacustomer.org          | 2006-02-14 | 270 Amroha Parkway                     | Osmaniye             | 695479687538&#xD;&#xA;14           | Betty       | White        | betty.white@sakilacustomer.org            | 2006-02-14 | 770 Bydgoszcz Avenue                   | California           | 517338314235&#xD;&#xA;15           | Helen       | Harris       | helen.harris@sakilacustomer.org           | 2006-02-14 | 419 Iligan Lane                        | Madhya Pradesh       | 990911107354&#xD;&#xA;16           | Sandra      | Martin       | sandra.martin@sakilacustomer.org          | 2006-02-14 | 360 Toulouse Parkway                   | England              | 949312333307&#xD;&#xA;......&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;(599 rows)&#xD;&#xA;&#xD;&#xA;Time: 11351.879 ms (00:11.352)&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Des données relevées en 11 secondes. Concernant le plan d&amp;#8217;exécution, , le coût global de notre jointure double vis à vis du chiffrement symétrique (on passe à 175), et un temps d&amp;#8217;exécution bien plus long (11400 millisecondes pour la jointure).&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;Hash Join (cost=74.57..175.63 rows=599 width=177) (actual time=21.263..11498.855 rows=599 loops=1)&#xD;&#xA;Output: c.customer_id, pgp_pub_decrypt(c.first_name, \************************************&#xD;&#xA;Inner Unique: true&#xD;&#xA;Hash Cond: (c.address_id = a.address_id)&#xD;&#xA;- Seq Scan on public.customer_pgp_pub c (cost=0.00..91.99 rows=599 width=1030) (actual time=0.006..1.294 rows=599 loops=1)&#xD;&#xA;Output: c.customer_id, c.store_id, c.first_name, c.last_name, c.email, c.address_id, c.activebool, c.create_date, c.last_update, c.active&#xD;&#xA;- Hash (cost=67.03..67.03 rows=603 width=695) (actual time=1.806..1.809 rows=603 loops=1)&#xD;&#xA;Output: a.address, a.district, a.phone, a.address_id&#xD;&#xA;Buckets: 1024 Batches: 1 Memory Usage: 440kB&#xD;&#xA;- Seq Scan on public.address_pgp_pub a (cost=0.00..67.03 rows=603 width=695) (actual time=0.004..0.556 rows=603 loops=1)&#xD;&#xA;Output: a.address, a.district, a.phone, a.address_id&#xD;&#xA;Planning Time: 0.536 ms&#xD;&#xA;Execution Time: 11499.672 ms&#xD;&#xA;(13 rows)&#xD;&#xA;&#xD;&#xA;Time: 11501.474 ms (00:11.501)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h3&gt;Interprétation des résultats.&lt;/h3&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Une fois ces tests effectués, nous pouvons en tirer des conclusions.&lt;/p&gt;&#xA;&lt;h4&gt;stockage&lt;/h4&gt;&#xA;&lt;p&gt;Concernant l&amp;#8217;espace disque de chacune de ces tables, nous voyons de grandes différences&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;(postgres@[local]:5433) [dvdrental] select tablename , pg_size_pretty(pg_table_size(tablename::varchar)) as SizeMo from pg_tables where tablename like &#39;custo%&#39; or tablename like &#39;addre%&#39; order by tablename,2;&#xD;&#xA;tablename             | sizemo&#xD;&#xA;----------------------+--------&#xD;&#xA;address               | 88 kB&#xD;&#xA;address_encrypt       | 104 kB&#xD;&#xA;address_pgp_pub       | 520 kB&#xD;&#xA;address_pgp_sym_256   | 224 kB&#xD;&#xA;customer              | 96 kB&#xD;&#xA;customer_encrypt      | 120 kB&#xD;&#xA;customer_pgp_pub      | 720 kB&#xD;&#xA;customer_pgp_sym_256  | 288 kB&#xD;&#xA;(10 rows)&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;-&amp;gt; Le chiffrement simple demande donc 20% de stockage en plus par rapport aux tables d&amp;#8217;origine.&lt;/p&gt;&#xA;&lt;p&gt;-&amp;gt; Avec le cryptage symétrique et compression algo aes256, cela double le volume disque vis-à-vis du cryptage classique.&lt;/p&gt;&#xA;&lt;p&gt;-&amp;gt; Enfin le chiffrement avec clé publique nécessite des tables 5 à 6 fois plus volumineuses que celles d&amp;#8217;origine.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h4&gt;Les temps d&amp;#8217;exécution&lt;/h4&gt;&#xA;&lt;p&gt;Comme nous avons pu le constater au cours de ce test, le chiffrement engendre des temps de réponses bien plus importants sur notre requête test.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;-&amp;gt; Pour le cryptage simple, un temps d&amp;#8217;exécution en insertion et sélection quasi identique. Mais l&amp;#8217;échantillon de données n&amp;#8217;est pas forcément le plus représentatif car celui-ci est plutôt restreint.&lt;/p&gt;&#xA;&lt;p&gt;-&amp;gt; Pour le cryptage symétrique avec compression algo aes256,  temps d&amp;#8217;exécution de l&amp;#8217;insertion et de la sélection beaucoup plus longs que le chiffrement classique. Nous passons de 5 millisecondes au SELECT et INSERT à plus de 1000 millisecondes pour l&amp;#8217;INSERT et plus de 2800 millisecondes pour le SELECT.&lt;/p&gt;&#xA;&lt;p&gt;-&amp;gt; Pour le cryptage avec clé publique/clé privée, à l&amp;#8217;insertion, c&amp;#8217;est plutôt rapide (quelques centaines de millisecondes).&lt;br /&gt;&#xA;Au select, nous dépassons les 10 secondes, pour une requête qui met 5 millisecondes sans aucun chiffrage.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Nous devons prendre en compte le fait que pour notre test, nous travaillons sur une VM extrêmement sous dimensionnée (ec2 type t2 micro).&lt;br /&gt;&#xA;Cependant, nous n&amp;#8217;avons sélectionné que quelques centaines de lignes dans nos tables, ce qui représente un échantillon faible.&lt;/p&gt;&#xA;&lt;p&gt;Qu&amp;#8217;en serait-il sur des tables de plus 100 millions de lignes ? La manipulation de données chiffrées volumineuses exigerait, sans aucun doute, plus de ressources en terme de CPU et RAM.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://s.w.org/images/core/emoji/14.0.0/72x72/1f642.png&#34; alt=&#34;🙂&#34; class=&#34;wp-smiley&#34; style=&#34;height: 1em; max-height: 1em;&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Emmanuel Rami&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pruning-de-partitions-sous-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;7 décembre 2020&#34;&gt;&amp;#8220;Pruning&amp;#8221; de partitions sous PostgreSQL ou comment bien élaguer !&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-13-les-nouveautes-interessantes/&#34; rel=&#34;bookmark&#34; title=&#34;30 octobre 2020&#34;&gt;PostgreSQL 13 : présentation&lt;/a&gt; (Emmanuel RAMI) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/quelles-solutions-de-chiffrement-de-donnees-pour-mysql-mariadb/&#34; rel=&#34;bookmark&#34; title=&#34;18 mars 2022&#34;&gt;Quelles solutions de chiffrement de données pour MySQL / MariaDB&lt;/a&gt; (David Baffaleuf) [MySQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/nouveautes-pg_stat_statements-avec-postgresql-15/&#34; rel=&#34;bookmark&#34; title=&#34;16 mars 2023&#34;&gt;Nouveautés pg_stat_statements avec PostgreSQL 15&lt;/a&gt; (David Baffaleuf) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/sql-server-retrouver-les-tables-dont-les-stats-ne-sont-plus-compilees-en-automatique/&#34; rel=&#34;bookmark&#34; title=&#34;28 janvier 2010&#34;&gt;Retrouver les tables dont les stats ne sont plus compilées en automatique&lt;/a&gt; (David Baffaleuf) [SQL Server]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 3.141 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10163&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10163&amp;#038;title=Chiffrement%20sous%20PostgreSQL%20%3A%20mais%20sous%20quelles%20conditions%20%3F&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=Chiffrement%20sous%20PostgreSQL%20%3A%20mais%20sous%20quelles%20conditions%20%3F&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10163&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/chiffrement-des-donnees-sous-postgresql/&#34;&gt;Chiffrement sous PostgreSQL : mais sous quelles conditions ?&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/chiffrement-des-donnees-sous-postgresql/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lorsque l&amp;#8217;on parle sécurité des données sur une instance PostgreSQL, nous avons le choix entre le chiffrement &amp;#8220;at rest&amp;#8221; avec TDE (cf cet article), ou bien l&amp;#8217;utilisation de l&amp;#8217;extension, bien connue des DBA PostgreSQL, pgcrypto. Cette extension permet de disposer&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/chiffrement-des-donnees-sous-postgresql/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/chiffrement-des-donnees-sous-postgresql/&#34;&gt;Chiffrement sous PostgreSQL : mais sous quelles conditions ?&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>PGO : opérateurs kubernetes pour PostgreSQL, la suite !</title>
    <updated>2023-06-06T12:21:23Z</updated>
    <id>tag:blog.capdata.fr,2023-06-06:/index.php/pgo-operateurs-kubernetes-pour-postgresql-la-suite/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10150&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10150&amp;#038;title=PGO%20%3A%20op%C3%A9rateurs%20kubernetes%20pour%20PostgreSQL%2C%20la%20suite%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PGO%20%3A%20op%C3%A9rateurs%20kubernetes%20pour%20PostgreSQL%2C%20la%20suite%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10150&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;Salut à toutes et tous ! Cette semaine la suite de notre petit tour des opérateurs Kubernetes pour PostgreSQL, et après &lt;a href=&#34;https://blog.capdata.fr/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/&#34;&gt;kubegres&lt;/a&gt;, c&amp;#8217;est au tour de &lt;a href=&#34;https://access.crunchydata.com/documentation/postgres-operator/v5/&#34;&gt;PGO &lt;/a&gt;de CrunchyData. &lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/06/pgo2.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/06/pgo2.png&#34; alt=&#34;&#34; width=&#34;954&#34; height=&#34;717&#34; class=&#34;aligncenter size-full wp-image-10154&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/06/pgo2.png 954w, https://blog.capdata.fr/wp-content/uploads/2023/06/pgo2-300x225.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/06/pgo2-768x577.png 768w&#34; sizes=&#34;(max-width: 954px) 100vw, 954px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Quelques infos générales sur l&amp;#8217;opérateur PGO&lt;/h2&gt;&#xA;&lt;p&gt;Comparé à Kubegres, PGO semble plus complet dans le sens où il intègre de base un réplica par défaut, mais aussi la possibilité de backuper directement avec &lt;a href=&#34;https://pgbackrest.org/&#34;&gt;pgBackRest&lt;/a&gt; dans des repositories locaux ou cloud, un pod &lt;a href=&#34;https://www.pgbouncer.org/&#34;&gt;pgBouncer&lt;/a&gt;, et un exporter pour &lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt;. &lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/06/pgo1-1.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/06/pgo1-1.png&#34; alt=&#34;&#34; width=&#34;1074&#34; height=&#34;660&#34; class=&#34;aligncenter size-full wp-image-10156&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/06/pgo1-1.png 1074w, https://blog.capdata.fr/wp-content/uploads/2023/06/pgo1-1-300x184.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/06/pgo1-1-1024x629.png 1024w, https://blog.capdata.fr/wp-content/uploads/2023/06/pgo1-1-768x472.png 768w&#34; sizes=&#34;(max-width: 1074px) 100vw, 1074px&#34; /&gt;&lt;/a&gt;&lt;br /&gt;&#xA;&lt;center&gt;(source : &lt;a href=&#34;https://access.crunchydata.com/documentation/postgres-operator/v5/architecture/overview/&#34;&gt;https://access.crunchydata.com/documentation/postgres-operator/v5/architecture/overview/&lt;/a&gt;)&lt;/center&gt;&lt;/p&gt;&#xA;&lt;p&gt;Comme pour kubegres, l&amp;#8217;operateur PGO encapsule à l&amp;#8217;intérieur de ses &lt;em&gt;deployments &lt;/em&gt;des objets de base Kubernetes tels que des StatefulSets pour les pods primaire et replicas, des Services, des PV et PVC pour le stockage, etc&amp;#8230; comme nous allons le voir lors du deploiement de notre premier cluster. &lt;/p&gt;&#xA;&lt;h2&gt;Installation de l&amp;#8217;opérateur PGO&lt;/h2&gt;&#xA;&lt;p&gt;Première chose à faire avant de créer notre premier cluster, déployer l&amp;#8217;opérateur PGO. Il est possible de le faire au choix soit via &lt;a href=&#34;https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/&#34;&gt;Kustomize &lt;/a&gt;soit via &lt;a href=&#34;https://helm.sh/&#34;&gt;Helm&lt;/a&gt;. CrunchyData propose &lt;a href=&#34;https://github.com/CrunchyData/postgres-operator-examples/fork&#34;&gt;un repo git à cloner&lt;/a&gt; et qui contient déjà les fichiers de configuration de base, que nous pourrons modifier au besoin pour customiser notre déploiement. Une fois le git cloné sur notre github Capdata, nous pouvons commencer à récupérer les fichiers en local et regarder le contenu des fichiers de définition. Nous utiliserons Kustomize pour l&amp;#8217;exemple :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ git clone --depth=1 &amp;quot;https://github.com/Capdata/postgres-operator-examples.git&amp;quot;&#xD;&#xA;Cloning into &#39;postgres-operator-examples&#39;...&#xD;&#xA;remote: Enumerating objects: 140, done.&#xD;&#xA;remote: Counting objects: 100% (140/140), done.&#xD;&#xA;remote: Compressing objects: 100% (105/105), done.&#xD;&#xA;remote: Total 140 (delta 33), reused 81 (delta 26), pack-reused 0&#xD;&#xA;Receiving objects: 100% (140/140), 150.57 KiB | 3.01 MiB/s, done.&#xD;&#xA;Resolving deltas: 100% (33/33), done.&#xD;&#xA;&#xD;&#xA;$ cd postgres-operator-examples/kustomize&#xD;&#xA;&#xD;&#xA;$ tree -a install/namespace/&#xD;&#xA;install/namespace/&#xD;&#xA;├── kustomization.yaml&#xD;&#xA;└── namespace.yaml&#xD;&#xA;&#xD;&#xA;$ tree -a install/default/&#xD;&#xA;install/default/&#xD;&#xA;├── kustomization.yaml&#xD;&#xA;└── selectors.yaml&#xD;&#xA;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;L&amp;#8217;apply de ~kustomize/install/namespace/namespace.yaml va créer un namespace dédié &lt;em&gt;postgres-operator&lt;/em&gt;: &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;apiVersion: v1&#xD;&#xA;kind: Namespace&#xD;&#xA;metadata:&#xD;&#xA;  name: postgres-operator&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Puis ~kustomize/install/default va créer le reste de l&amp;#8217;opérateur:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl apply --kustomize=kustomize/install/namespace&#xD;&#xA;namespace/postgres-operator created&#xD;&#xA;&#xD;&#xA;$ kubectl apply --server-side --kustomize=kustomize/install/default&#xD;&#xA;customresourcedefinition.apiextensions.k8s.io/pgupgrades.postgres-operator.crunchydata.com serverside-applied&#xD;&#xA;customresourcedefinition.apiextensions.k8s.io/postgresclusters.postgres-operator.crunchydata.com serverside-applied&#xD;&#xA;serviceaccount/pgo serverside-applied&#xD;&#xA;serviceaccount/postgres-operator-upgrade serverside-applied&#xD;&#xA;clusterrole.rbac.authorization.k8s.io/postgres-operator serverside-applied&#xD;&#xA;clusterrole.rbac.authorization.k8s.io/postgres-operator-upgrade serverside-applied&#xD;&#xA;clusterrolebinding.rbac.authorization.k8s.io/postgres-operator serverside-applied&#xD;&#xA;clusterrolebinding.rbac.authorization.k8s.io/postgres-operator-upgrade serverside-applied&#xD;&#xA;deployment.apps/pgo serverside-applied&#xD;&#xA;deployment.apps/pgo-upgrade serverside-applied&#xD;&#xA;&#xD;&#xA;$ kubectl get all --namespace=postgres-operator&#xD;&#xA;NAME                               READY   STATUS    RESTARTS   AGE&#xD;&#xA;pod/pgo-774db98dbc-htm5d           1/1     Running   0          74m&#xD;&#xA;pod/pgo-upgrade-785dd6dc4c-cw2ld   1/1     Running   0          74m&#xD;&#xA;&#xD;&#xA;NAME                          READY   UP-TO-DATE   AVAILABLE   AGE&#xD;&#xA;deployment.apps/pgo           1/1     1            1           74m&#xD;&#xA;deployment.apps/pgo-upgrade   1/1     1            1           74m&#xD;&#xA;&#xD;&#xA;NAME                                     DESIRED   CURRENT   READY   AGE&#xD;&#xA;replicaset.apps/pgo-774db98dbc           1         1         1       74m&#xD;&#xA;replicaset.apps/pgo-upgrade-785dd6dc4c   1         1         1       74m&#xD;&#xA;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h2&gt;Création d&amp;#8217;un premier cluster PGO&lt;/h2&gt;&#xA;&lt;p&gt;Maintenant que notre opérateur est installé, c&amp;#8217;est le moment de s&amp;#8217;intéresser au paramétrage du futur cluster. Tout se trouve dans ~kustomize/postgres:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ tree -a postgres/&#xD;&#xA;postgres/&#xD;&#xA;├── kustomization.yaml&#xD;&#xA;└── postgres.yaml&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Le coeur de notre cluster se trouve dans postgresl.yaml :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;apiVersion: postgres-operator.crunchydata.com/v1beta1&#xD;&#xA;kind: PostgresCluster&#xD;&#xA;metadata:&#xD;&#xA;  name: hippo&#xD;&#xA;spec:&#xD;&#xA;  image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres:ubi8-15.2-0&#xD;&#xA;  postgresVersion: 15&#xD;&#xA;  instances:&#xD;&#xA;    - name: instance1&#xD;&#xA;      dataVolumeClaimSpec:&#xD;&#xA;        accessModes:&#xD;&#xA;        - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;        resources:&#xD;&#xA;          requests:&#xD;&#xA;            storage: 1Gi&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.41-4&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        volume:&#xD;&#xA;          volumeClaimSpec:&#xD;&#xA;            accessModes:&#xD;&#xA;            - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;            resources:&#xD;&#xA;              requests:&#xD;&#xA;                storage: 1Gi&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Comme pour Kubegres, l&amp;#8217;opérateur PGO nous permet de créer un nouveau type d&amp;#8217;objet dans Kubernetes :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;kind: PostgresCluster&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Le nom du cluster par défaut est &amp;#8216;&lt;em&gt;hippo&lt;/em&gt;&amp;#8216; mais nous pourrons le changer sans problème. Pour les pods (primaire, réplicas, pgBackRest), les images sont précisées ainsi que les volumes qui sont rattachés via des abstractions de PVC appelées soit &amp;#8220;&lt;em&gt;dataVolumeClaimSpec&lt;/em&gt;&amp;#8221; pour les pods PostgreSQL soit &amp;#8220;&lt;em&gt;VolumeClaimSpec&lt;/em&gt;&amp;#8221; pour la partie sauvegarde. &lt;/p&gt;&#xA;&lt;p&gt;Nous pouvons compléter le fichier de définition par défaut avec quelques customisations:&lt;br /&gt;&#xA;&amp;#8211; Ajouter des quotas de ressources CPU et mémoire via &lt;em&gt;instances.resources.limits&lt;/em&gt;&lt;br /&gt;&#xA;&amp;#8211; Ajouter un réplica&lt;br /&gt;&#xA;&amp;#8211; Renommer notre cluster &amp;#8216;&lt;em&gt;pgcluster1&lt;/em&gt;&amp;#8216;&lt;br /&gt;&#xA;&amp;#8211; Et enfin ajouter un nodePort pour exposer notre cluster au monde extérieur :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;apiVersion: postgres-operator.crunchydata.com/v1beta1&#xD;&#xA;kind: PostgresCluster&#xD;&#xA;metadata:&#xD;&#xA;  name: pgcluster1&#xD;&#xA;spec:&#xD;&#xA;  image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres:ubi8-15.2-0&#xD;&#xA;  postgresVersion: 15&#xD;&#xA;  instances:&#xD;&#xA;    - name: postgresdb1&#xD;&#xA;      replicas: 2&#xD;&#xA;      resources:&#xD;&#xA;        limits:&#xD;&#xA;          cpu: &amp;quot;0.5&amp;quot;&#xD;&#xA;          memory: 1Gi&#xD;&#xA;      dataVolumeClaimSpec:&#xD;&#xA;        accessModes:&#xD;&#xA;        - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;        resources:&#xD;&#xA;          requests:&#xD;&#xA;            storage: 1Gi&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.41-4&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        volume:&#xD;&#xA;          volumeClaimSpec:&#xD;&#xA;            accessModes:&#xD;&#xA;            - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;            resources:&#xD;&#xA;              requests:&#xD;&#xA;                storage: 1Gi&#xD;&#xA;  service:&#xD;&#xA;    metadata:&#xD;&#xA;      annotations:&#xD;&#xA;        annotation1: &amp;quot;mdnodeport1&amp;quot;&#xD;&#xA;      labels:&#xD;&#xA;        label1: &amp;quot;32000&amp;quot;&#xD;&#xA;    type: NodePort&#xD;&#xA;    nodePort: 32000&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Pour la configuration des sauvegardes, nous verrons un peu plus tard. Dans l&amp;#8217;immédiat, créons notre cluster:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl apply -k kustomize/postgres/&#xD;&#xA;postgrescluster.postgres-operator.crunchydata.com/pgcluster1 created&#xD;&#xA;&#xD;&#xA;$ kubectl get all --namespace=postgres-operator&#xD;&#xA;NAME                                READY   STATUS    RESTARTS   AGE&#xD;&#xA;pod/pgcluster1-postgresdb1-55pl-0   4/4     Running   0          11s&#xD;&#xA;pod/pgcluster1-postgresdb1-9w2w-0   4/4     Running   0          11s&#xD;&#xA;pod/pgcluster1-repo-host-0          2/2     Running   0          11s&#xD;&#xA;pod/pgo-774db98dbc-tshp6            1/1     Running   0          68s&#xD;&#xA;pod/pgo-upgrade-785dd6dc4c-ntwkd    1/1     Running   0          68s&#xD;&#xA;&#xD;&#xA;NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE&#xD;&#xA;service/pgcluster1-ha          NodePort    10.102.232.74   &amp;lt;none&amp;gt;        5432:32000/TCP   51m&#xD;&#xA;service/pgcluster1-ha-config   ClusterIP   None            &amp;lt;none&amp;gt;        &amp;lt;none&amp;gt;           51m&#xD;&#xA;service/pgcluster1-pods        ClusterIP   None            &amp;lt;none&amp;gt;        &amp;lt;none&amp;gt;           51m&#xD;&#xA;service/pgcluster1-primary     ClusterIP   None            &amp;lt;none&amp;gt;        5432/TCP         51m&#xD;&#xA;service/pgcluster1-replicas    ClusterIP   10.106.148.50   &amp;lt;none&amp;gt;        5432/TCP         51m&#xD;&#xA;&#xD;&#xA;NAME                          READY   UP-TO-DATE   AVAILABLE   AGE&#xD;&#xA;deployment.apps/pgo           1/1     1            1           69s&#xD;&#xA;deployment.apps/pgo-upgrade   1/1     1            1           68s&#xD;&#xA;&#xD;&#xA;NAME                                     DESIRED   CURRENT   READY   AGE&#xD;&#xA;replicaset.apps/pgo-774db98dbc           1         1         1       68s&#xD;&#xA;replicaset.apps/pgo-upgrade-785dd6dc4c   1         1         1       68s&#xD;&#xA;&#xD;&#xA;NAME                                           READY   AGE&#xD;&#xA;statefulset.apps/pgcluster1-postgresdb1-55pl   1/1     11s&#xD;&#xA;statefulset.apps/pgcluster1-postgresdb1-9w2w   1/1     11s&#xD;&#xA;statefulset.apps/pgcluster1-repo-host          1/1     11s&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il se peut qu&amp;#8217;il y ait des problèmes de quota mémoire / CPU disponible, les pods vont rester en Pending, et la suppression / recréation des objets ne suffit pas. La suppression du namespace se bloque en Terminating il a fallu que je déroule la &lt;a href=&#34;https://www.ibm.com/docs/en/cloud-private/3.2.0?topic=console-namespace-is-stuck-in-terminating-state&#34;&gt;procédure de suppression du namespace à la main&lt;/a&gt; pour repartir de zéro. &lt;/p&gt;&#xA;&lt;p&gt;Bref notre déploiement nous a donc créé 3 nouveaux pods et 3 StatefulSets (primaire, réplica et pgBackRest), 4 services ClusterIP et notre nodePort. &lt;/p&gt;&#xA;&lt;p&gt;Pour nous y connecter, nous avons besoin de récupérer &lt;a href=&#34;https://access.crunchydata.com/documentation/postgres-operator/5.3.1/tutorial/connect-cluster/&#34;&gt;le secret&lt;/a&gt; qui a été créé à l&amp;#8217;initialisation du cluster. Jetons un coup d&amp;#8217;oeil au secret dans sa globalité pour voir ce qu&amp;#8217;il contient:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl get secret --namespace=postgres-operator pgcluster1-pguser-pgcluster1 -o json&#xD;&#xA;{&#xD;&#xA;    &amp;quot;apiVersion&amp;quot;: &amp;quot;v1&amp;quot;,&#xD;&#xA;    &amp;quot;data&amp;quot;: {&#xD;&#xA;        &amp;quot;dbname&amp;quot;: &amp;quot;cGdjbHVzdGVyMQ==&amp;quot;,&#xD;&#xA;        &amp;quot;host&amp;quot;: &amp;quot;cGdjbHVzdGVyMS1wcmltYXJ5LnBvc3RncmVzLW9wZXJhdG9yLnN2Yw==&amp;quot;,&#xD;&#xA;        &amp;quot;jdbc-uri&amp;quot;: &amp;quot;amRiYzpwb3N0Z3Jlc3FsOi8vcGdjbHVzdGVyMS1wcmltYXJ5LnBvc3RncmVzLW9wZXJhdG9yLnN2Yzo1NDMyL3BnY2x1c3RlcjE/cGFzc3dvcmQ9UHBybiUzQnZ1WDlrSiU1RE1WQnZwd3QzTk5wJTJBJnVzZXI9cGdjbHVzdGVyMQ==&amp;quot;,&#xD;&#xA;        &amp;quot;password&amp;quot;: &amp;quot;UHBybjt2dVg5a0pdTVZCdnB3dDNOTnAq&amp;quot;,&#xD;&#xA;        &amp;quot;port&amp;quot;: &amp;quot;NTQzMg==&amp;quot;,&#xD;&#xA;        &amp;quot;uri&amp;quot;: &amp;quot;cG9zdGdyZXNxbDovL3BnY2x1c3RlcjE6UHBybjt2dVg5a0olNURNVkJ2cHd0M05OcCUyQUBwZ2NsdXN0ZXIxLXByaW1hcnkucG9zdGdyZXMtb3BlcmF0b3Iuc3ZjOjU0MzIvcGdjbHVzdGVyMQ==&amp;quot;,&#xD;&#xA;        &amp;quot;user&amp;quot;: &amp;quot;cGdjbHVzdGVyMQ==&amp;quot;,&#xD;&#xA;        &amp;quot;verifier&amp;quot;: &amp;quot;U0NSQU0tU0hBLTI1NiQ0MDk2Olo3OTNBUVIwU0xZUVBDY3BXNkRaSXc9PSRWUWdlc0VlSGVvVnpnakc4emkyRGJJNmlpemo1ZnJGWmN2K3c3NzZScVhVPTpDT1JDVStoQU1IeDBkRzBKaGU3dllwUTdFWTB4QzZ5RzJUUE5NWFV5MTlRPQ==&amp;quot;&#xD;&#xA;    },&#xD;&#xA;    &amp;quot;kind&amp;quot;: &amp;quot;Secret&amp;quot;,&#xD;&#xA;    &amp;quot;metadata&amp;quot;: {&#xD;&#xA;        &amp;quot;creationTimestamp&amp;quot;: &amp;quot;2023-06-05T11:39:32Z&amp;quot;,&#xD;&#xA;        &amp;quot;labels&amp;quot;: {&#xD;&#xA;            &amp;quot;postgres-operator.crunchydata.com/cluster&amp;quot;: &amp;quot;pgcluster1&amp;quot;,&#xD;&#xA;            &amp;quot;postgres-operator.crunchydata.com/pguser&amp;quot;: &amp;quot;pgcluster1&amp;quot;,&#xD;&#xA;            &amp;quot;postgres-operator.crunchydata.com/role&amp;quot;: &amp;quot;pguser&amp;quot;&#xD;&#xA;        },&#xD;&#xA;        &amp;quot;name&amp;quot;: &amp;quot;pgcluster1-pguser-pgcluster1&amp;quot;,&#xD;&#xA;        &amp;quot;namespace&amp;quot;: &amp;quot;postgres-operator&amp;quot;,&#xD;&#xA;        &amp;quot;ownerReferences&amp;quot;: [&#xD;&#xA;            {&#xD;&#xA;                &amp;quot;apiVersion&amp;quot;: &amp;quot;postgres-operator.crunchydata.com/v1beta1&amp;quot;,&#xD;&#xA;                &amp;quot;blockOwnerDeletion&amp;quot;: true,&#xD;&#xA;                &amp;quot;controller&amp;quot;: true,&#xD;&#xA;                &amp;quot;kind&amp;quot;: &amp;quot;PostgresCluster&amp;quot;,&#xD;&#xA;                &amp;quot;name&amp;quot;: &amp;quot;pgcluster1&amp;quot;,&#xD;&#xA;                &amp;quot;uid&amp;quot;: &amp;quot;80bbee62-0602-4012-9c06-dcd23ca7723b&amp;quot;&#xD;&#xA;            }&#xD;&#xA;        ],&#xD;&#xA;        &amp;quot;resourceVersion&amp;quot;: &amp;quot;169451&amp;quot;,&#xD;&#xA;        &amp;quot;uid&amp;quot;: &amp;quot;fe833c97-0585-4910-95ca-fb1c7774d5b2&amp;quot;&#xD;&#xA;    },&#xD;&#xA;    &amp;quot;type&amp;quot;: &amp;quot;Opaque&amp;quot;&#xD;&#xA;}&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;On a donc la possibilité de récupérer le user et le mot de passe :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ export PGUSER=$(kubectl get secret --namespace=postgres-operator pgcluster1-pguser-pgcluster1 -o jsonpath={.data.user} | base64 -d)&#xD;&#xA;$ export PGPASSWORD=$(kubectl get secret --namespace=postgres-operator pgcluster1-pguser-pgcluster1 -o jsonpath={.data.password} | base64 -d)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Et tester la connexion (noter que l&amp;#8217;adresse IP est celle du node, ie &lt;em&gt;kubectl describe nodes&lt;/em&gt;):&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ psql -h 192.168.59.101 -p 32000 -c &amp;quot;select version();&amp;quot;&#xD;&#xA;                                                 version&#xD;&#xA;---------------------------------------------------------------------------------------------------------&#xD;&#xA; PostgreSQL 15.2 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-16), 64-bit&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h2&gt;Bascules et haute disponibilité&lt;/h2&gt;&#xA;&lt;p&gt;Lançons une connexion en boucle sur le nodePort pour récupérer l&amp;#8217;IP de l&amp;#8217;instance primaire et voir ce qui se passe en cas de bascule. &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ while(true); do psql -h 192.168.59.101 -p 32000 -c &amp;quot;select inet_server_addr();&amp;quot;; sleep 1; done&#xD;&#xA; inet_server_addr&#xD;&#xA;------------------&#xD;&#xA; 172.17.0.7&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA; inet_server_addr&#xD;&#xA;------------------&#xD;&#xA; 172.17.0.7&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA;(...)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Pour tester la bascule, nous allons carrément supprimer le StatefulSet de l&amp;#8217;instance primaire, il faut commencer par récupérer son nom, puis on supprime :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl -n postgres-operator get pods \&#xD;&#xA;  --selector=postgres-operator.crunchydata.com/role=master \&#xD;&#xA;  -o jsonpath=&#39;{.items[*].metadata.labels.postgres-operator\.crunchydata\.com/instance}&#39;&#xD;&#xA;pgcluster1-postgresdb1-9w2w&#xD;&#xA;&#xD;&#xA;$ kubectl delete statefulset --namespace=postgres-operator pgcluster1-postgresdb1-9w2w&#xD;&#xA;statefulset.apps &amp;quot;pgcluster1-postgresdb1-9w2w&amp;quot; deleted&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;La connexion en boucle indique que l&amp;#8217;on a bien changé d&amp;#8217;IP:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;(...)&#xD;&#xA; inet_server_addr&#xD;&#xA;------------------&#xD;&#xA; 172.17.0.7&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA; inet_server_addr&#xD;&#xA;------------------&#xD;&#xA; 172.17.0.7&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA; inet_server_addr&#xD;&#xA;------------------&#xD;&#xA; 172.17.0.6&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA; inet_server_addr&#xD;&#xA;------------------&#xD;&#xA; 172.17.0.6&#xD;&#xA;(1 row)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;&amp;#8230; et minikube a détecté la perte du StatefulSet &lt;em&gt;pgcluster1-postgresdb1-9w2w&lt;/em&gt; et l&amp;#8217;a recréé en arrière plan:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl get statefulset --namespace=postgres-operator&#xD;&#xA;NAME                          READY   AGE&#xD;&#xA;pgcluster1-postgresdb1-55pl   1/1     96m&#xD;&#xA;pgcluster1-postgresdb1-9w2w   1/1     11s&#xD;&#xA;pgcluster1-repo-host          1/1     96m&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Il existe un certain nombre d&amp;#8217;options complémentaires notamment de l&amp;#8217;anti-affinité pour éviter que les pods ne tournent sur les mêmes nodes, voir la &lt;a href=&#34;https://access.crunchydata.com/documentation/postgres-operator/5.3.1/tutorial/high-availability/&#34;&gt;documentation &lt;/a&gt;pour plus de détails.&lt;/p&gt;&#xA;&lt;h2&gt;Mise en place des backups via pgbackrest&lt;/h2&gt;&#xA;&lt;p&gt;Bien qu&amp;#8217;il soit possible de sauvegarder directement sur AWS S3, Azure ou GCP, pour l&amp;#8217;exemple nous avons déployé un volume Kubernetes simple.&lt;br /&gt;&#xA;Pour ajouter une planification et une rétention il faut rajouter quelques propriétés à &lt;em&gt;spec.backups.pgbackrest&lt;/em&gt; :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;  backups:&#xD;&#xA;    pgbackrest:&#xD;&#xA;      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.41-4&#xD;&#xA;        global:&#xD;&#xA;&#x9;  repo1-retention-full: &amp;quot;14&amp;quot;&#xD;&#xA;          repo1-retention-full-type: time&#xD;&#xA;      repos:&#xD;&#xA;      - name: repo1&#xD;&#xA;        volume:&#xD;&#xA;          volumeClaimSpec:&#xD;&#xA;            accessModes:&#xD;&#xA;            - &amp;quot;ReadWriteOnce&amp;quot;&#xD;&#xA;            resources:&#xD;&#xA;              requests:&#xD;&#xA;                storage: 1Gi&#xD;&#xA;&#x9;schedules:&#xD;&#xA;&#x9;  full: &amp;quot;50 15 * * *&amp;quot;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl apply -k kustomize/postgres/&#xD;&#xA;postgrescluster.postgres-operator.crunchydata.com/pgcluster1 configured&#xD;&#xA;&#xD;&#xA;$ kubectl get cronjobs --namespace=postgres-operator&#xD;&#xA;NAME                    SCHEDULE       SUSPEND   ACTIVE   LAST SCHEDULE   AGE&#xD;&#xA;pgcluster1-repo1-full   50 15 * * *    False     0        &amp;lt;none&amp;gt;          106s&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Kubernetes a créé un cronjob associé. Sachant que les backups peuvent être aussi différentiels ou incrémentaux selon la stratégie de sauvegarde envisagée.&lt;br /&gt;&#xA;La rétention quant à elle peut être indiquée en jours (&lt;em&gt;time&lt;/em&gt;) ou en nombre de sauvegardes (&lt;em&gt;count&lt;/em&gt;). Grâce à pgBackRest, PGO permettra ensuite d&amp;#8217;utiliser les backups pour soit cloner les bases vers une autre cluster, soit le restaurer à un point dans le temps vers un nouveau cluster (pour comparer les données ou récupérer des lignes supprimées par erreur par exemple), ou restaurer in-place. Le sujet est assez long et cela pourra faire l&amp;#8217;objet d&amp;#8217;un futur épisode, mais globalement la puissance de feu de pgBackRest au service de la restaurabilité donne un atout supplémentaire à PGO par rapport à ses concurrents. &lt;/p&gt;&#xA;&lt;h2&gt;Conclusion&lt;/h2&gt;&#xA;&lt;p&gt;Dans cette première approche de PGO, nous n&amp;#8217;avons fait qu&amp;#8217;effleurer la surface des possibilités de cet opérateur, qui semble aller plus loin que ses concurrents avec:&lt;br /&gt;&#xA;&amp;#8211; La sauvegarde et restauration via pgBackRest intégré, et la possibilité de sauvegarder directement dans le cloud.&lt;br /&gt;&#xA;&amp;#8211; Intégration avec Promotheus.&lt;br /&gt;&#xA;&amp;#8211; Intégration avec pgBouncer.&lt;br /&gt;&#xA;&amp;#8211; Déployable directement via des standards tels que Kustomize ou Helm.&lt;br /&gt;&#xA;&amp;#8211; Gestion des secrets intégrée.&lt;br /&gt;&#xA;etc&amp;#8230; Sûrement que d&amp;#8217;autres articles pour approfondir PGO viendront compléter celui-ci, en attendant bonne lecture et à bientôt sur le blog Cap Data !&lt;br /&gt;&#xA;&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;26 avril 2023&#34;&gt;Kubegres : l&amp;#8217;opérateur Kubernetes clé en main pour PostgreSQL&lt;/a&gt; (David Baffaleuf) [ContainerDevopsPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/&#34; rel=&#34;bookmark&#34; title=&#34;29 mars 2023&#34;&gt;PostgreSQL sur la solution Kubernetes locale Minikube&lt;/a&gt; (Emmanuel RAMI) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/comparatif-des-gestionnaires-de-vip-dans-un-cluster-patroni-episode-2-vip-manager/&#34; rel=&#34;bookmark&#34; title=&#34;11 mars 2022&#34;&gt;Comparatif des gestionnaires de VIP dans un cluster Patroni : épisode 2 (VIP-MANAGER)&lt;/a&gt; (David Baffaleuf) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-comparatif-entre-barman-et-pgbackrest/&#34; rel=&#34;bookmark&#34; title=&#34;4 février 2020&#34;&gt;PostgreSQL : Comparatif entre Barman et pgBackRest&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/comparatif-des-gestionnaires-de-vip-dans-un-cluster-patroni-episode-1-keepalived/&#34; rel=&#34;bookmark&#34; title=&#34;6 mars 2022&#34;&gt;Comparatif des gestionnaires de VIP dans un cluster Patroni : épisode 1 (KEEPALIVED)&lt;/a&gt; (David Baffaleuf) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 2.818 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10150&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10150&amp;#038;title=PGO%20%3A%20op%C3%A9rateurs%20kubernetes%20pour%20PostgreSQL%2C%20la%20suite%20%21&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PGO%20%3A%20op%C3%A9rateurs%20kubernetes%20pour%20PostgreSQL%2C%20la%20suite%20%21&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10150&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pgo-operateurs-kubernetes-pour-postgresql-la-suite/&#34;&gt;PGO : opérateurs kubernetes pour PostgreSQL, la suite !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/pgo-operateurs-kubernetes-pour-postgresql-la-suite/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Salut à toutes et tous ! Cette semaine la suite de notre petit tour des opérateurs Kubernetes pour PostgreSQL, et après kubegres, c&amp;#8217;est au tour de PGO de CrunchyData. Quelques infos générales sur l&amp;#8217;opérateur PGO Comparé à Kubegres, PGO semble&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/pgo-operateurs-kubernetes-pour-postgresql-la-suite/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/pgo-operateurs-kubernetes-pour-postgresql-la-suite/&#34;&gt;PGO : opérateurs kubernetes pour PostgreSQL, la suite !&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>Cybertec Migrator : une alternative à ora2pg ?</title>
    <updated>2023-05-10T08:49:33Z</updated>
    <id>tag:blog.capdata.fr,2023-05-10:/index.php/cybertec-migrator-une-alternative-a-ora2pg/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10089&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10089&amp;#038;title=Cybertec%20Migrator%20%3A%20une%20alternative%20%C3%A0%20ora2pg%20%3F&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=Cybertec%20Migrator%20%3A%20une%20alternative%20%C3%A0%20ora2pg%20%3F&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10089&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;Connue pour de nombreux produits développés pour PostgreSQL, &lt;a href=&#34;https://www.cybertec-postgresql.com/en/&#34;&gt;Cybertec&lt;/a&gt; a récemment mis à jour son outil de migration de base de données du moteur Oracle vers le moteur PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Dans cet article, je vais vous expliquer la mise en place de l&amp;#8217;outil, son installation, et vous montrer pas à pas comment migrer une base de données depuis Oracle vers PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Pour l&amp;#8217;exemple que je m&amp;#8217;apprête à vous montrer, je suis partie d&amp;#8217;une machine Rocky Linux 8.7 (Green Obsidian) sur laquelle j&amp;#8217;ai installé une version 19c d&amp;#8217;Oracle en multitenant et une version 13 de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;Sur l&amp;#8217;instance Oracle, j&amp;#8217;ai utilisé une base de données &lt;a href=&#34;https://www.oracletutorial.com/getting-started/oracle-sample-database/&#34;&gt;sample&lt;/a&gt; fournie par Oracle pour avoir de la matière à migrer :&lt;/p&gt;&#xA;&lt;h2&gt;1ère étape : Télécharger la version désirée de Migrator.&lt;/h2&gt;&#xA;&lt;p&gt;Cybertec nous met à disposition trois types de licences pour son nouvel outil :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Une licence standard, qui est une licence gratuite et permet à tout le monde de télécharger l&amp;#8217;outil pour le tester. Cette licence n&amp;#8217;est à utiliser que si vous pouvez vous permettre d&amp;#8217;avoir des temps de maintenance et donc d&amp;#8217;indisponibilité de votre base.&lt;/li&gt;&#xA;&lt;li&gt;Une licence professionnelle, qui garantit des performances de migrations plus hautes, réduisant le temps d&amp;#8217;indisponibilité en augmentant la rapidité d&amp;#8217;exécution de la migration&lt;/li&gt;&#xA;&lt;li&gt;Une licence Enterprise, qui garantit une très nette diminution du temps d&amp;#8217;indisponibilité, passant de quelques heures à quelques minutes pour les bases les plus conséquentes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Ce test est réalisé avec la version standard de l&amp;#8217;application, celle que l&amp;#8217;on peut obtenir gratuitement. Pour l&amp;#8217;obtenir, il suffit de vous rendre sur le &lt;a href=&#34;https://www.cybertec-postgresql.com/en/products/cybertec-migrator/&#34;&gt;site&lt;/a&gt; de Cybertec, et de cliquer sur &amp;#8220;Download&amp;#8221; en dessous de la case de la Standard Edition.&lt;/p&gt;&#xA;&lt;p&gt;La version actuelle du Migrator est la version 3.16.2, la mise à jour est intervenue pendant que je faisais mes tests, j&amp;#8217;ai donc dû mettre à jour le produit pour pouvoir l&amp;#8217;utiliser correctement.&lt;/p&gt;&#xA;&lt;p&gt;Pour pouvoir télécharger l&amp;#8217;outil, il vous faut vous inscrire en fournissant une adresse email sur laquelle le lien de téléchargement vous sera envoyé. Vous n&amp;#8217;avez plus qu&amp;#8217;à transférer l&amp;#8217;archive ainsi téléchargée sur votre serveur d&amp;#8217;installation.&lt;/p&gt;&#xA;&lt;h2&gt;2ème étape : Les dépendances&lt;/h2&gt;&#xA;&lt;p&gt;Pour pouvoir fonctionner, Migrator nécessite entre autre Git et Docker. L&amp;#8217;application fonctionne sur son propre serveur, d&amp;#8217;où l&amp;#8217;utilisation de Docker. Cela permet entre autre de pouvoir installer facilement celle-ci car il ne s&amp;#8217;agit que de déployer un container sur votre installation et le tour est joué.&lt;/p&gt;&#xA;&lt;p&gt;-&amp;gt; Installer Docker&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;sudo dnf check-update&#xD;&#xA;sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo&#xD;&#xA;sudo dnf install docker-ce docker-ce-cli containerd.io&#xD;&#xA;...&#xD;&#xA;Installed:&#xD;&#xA;container-selinux-2:2.189.0-1.module+el8.7.0+1154+147ffa21.noarch containerd.io-1.6.20-3.1.el8.x86_64 docker-buildx-plugin-0.10.4-1.el8.x86_64 docker-ce-3:23.0.4-1.el8.x86_64&#xD;&#xA;docker-ce-cli-1:23.0.4-1.el8.x86_64 docker-ce-rootless-extras-23.0.4-1.el8.x86_64 docker-compose-plugin-2.17.2-1.el8.x86_64 fuse-common-3.3.0-16.el8.x86_64&#xD;&#xA;fuse-overlayfs-1.9-1.module+el8.7.0+1154+147ffa21.x86_64 fuse3-3.3.0-16.el8.x86_64 fuse3-libs-3.3.0-16.el8.x86_64 iptables-1.8.4-23.el8_7.1.x86_64&#xD;&#xA;iptables-libs-1.8.4-23.el8_7.1.x86_64 libcgroup-0.41-19.el8.x86_64 libnetfilter_conntrack-1.0.6-5.el8.x86_64 libnfnetlink-1.0.1-13.el8.x86_64&#xD;&#xA;libnftnl-1.1.5-5.el8.x86_64 libpcap-14:1.9.1-5.el8.x86_64 libslirp-4.4.0-1.module+el8.7.0+1154+147ffa21.x86_64 slirp4netns-1.2.0-2.module+el8.7.0+1154+147ffa21.x86_64&lt;/pre&gt;&#xA;&lt;p&gt;Complete!&lt;/p&gt;&#xA;&lt;p&gt;-&amp;gt; Installer Git :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;sudo dnf install git&#xD;&#xA;...&#xD;&#xA;Installed:&#xD;&#xA;emacs-filesystem-1:26.1-7.el8.noarch         git-2.31.1-3.el8_7.x86_64                                       git-core-2.31.1-3.el8_7.x86_64                              git-core-doc-2.31.1-3.el8_7.noarch&#xD;&#xA;perl-Carp-1.42-396.el8.noarch                perl-Data-Dumper-2.167-399.el8.x86_64                           perl-Digest-1.17-395.el8.noarch                             perl-Digest-MD5-2.55-396.el8.x86_64&#xD;&#xA;perl-Encode-4:2.97-3.el8.x86_64              perl-Errno-1.28-421.el8.x86_64                                  perl-Error-1:0.17025-2.el8.noarch                           perl-Exporter-5.72-396.el8.noarch&#xD;&#xA;perl-File-Path-2.15-2.el8.noarch             perl-File-Temp-0.230.600-1.el8.noarch                           perl-Getopt-Long-1:2.50-4.el8.noarch                        perl-Git-2.31.1-3.el8_7.noarch&#xD;&#xA;perl-HTTP-Tiny-0.074-1.el8.noarch            perl-IO-1.38-421.el8.x86_64                                     perl-IO-Socket-IP-0.39-5.el8.noarch                         perl-IO-Socket-SSL-2.066-4.module+el8.6.0+957+15d660ad.noarch&#xD;&#xA;perl-MIME-Base64-3.15-396.el8.x86_64         perl-Mozilla-CA-20160104-7.module+el8.6.0+965+850557f9.noarch   perl-Net-SSLeay-1.88-2.module+el8.6.0+957+15d660ad.x86_64   perl-PathTools-3.74-1.el8.x86_64&#xD;&#xA;perl-Pod-Escapes-1:1.07-395.el8.noarch       perl-Pod-Perldoc-3.28-396.el8.noarch                            perl-Pod-Simple-1:3.35-395.el8.noarch                       perl-Pod-Usage-4:1.69-395.el8.noarch&#xD;&#xA;perl-Scalar-List-Utils-3:1.49-2.el8.x86_64   perl-Socket-4:2.027-3.el8.x86_64                                perl-Storable-1:3.11-3.el8.x86_64                           perl-Term-ANSIColor-4.06-396.el8.noarch&#xD;&#xA;perl-Term-Cap-1.17-395.el8.noarch            perl-TermReadKey-2.37-7.el8.x86_64                              perl-Text-ParseWords-3.30-395.el8.noarch                    perl-Text-Tabs+Wrap-2013.0523-395.el8.noarch&#xD;&#xA;perl-Time-Local-1:1.280-1.el8.noarch         perl-URI-1.73-3.el8.noarch                                      perl-Unicode-Normalize-1.25-396.el8.x86_64                  perl-constant-1.33-396.el8.noarch&#xD;&#xA;perl-interpreter-4:5.26.3-421.el8.x86_64     perl-libnet-3.11-3.el8.noarch                                   perl-libs-4:5.26.3-421.el8.x86_64                           perl-macros-4:5.26.3-421.el8.x86_64&#xD;&#xA;perl-parent-1:0.237-1.el8.noarch             perl-podlators-4.11-1.el8.noarch                                perl-threads-1:2.21-2.el8.x86_64                            perl-threads-shared-1.58-2.el8.x86_64&lt;/pre&gt;&#xA;&lt;p&gt;Complete!&lt;/p&gt;&#xA;&lt;h2&gt;Etape 3 : Installer Migrator&lt;/h2&gt;&#xA;&lt;p&gt;Une fois l&amp;#8217;archive téléchargée et uploadée sur votre serveur, la première étape c&amp;#8217;est de décompresser l&amp;#8217;archive. Il est conseillé de le faire avec l&amp;#8217;utilisateur root pour avoir les droits suffisant à faire les installations nécessaires.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[root@oracle-02]# tar xf cybertec_migrator-v3.16.0-standard.tar.gz&#xD;&#xA;[root@oracle-02]# cd cybertec_migrator&lt;/pre&gt;&#xA;&lt;p&gt;Une fois notre archive décompressée, on créé la configuration de base pour notre Migrator.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[root@oracle-02 cybertec_migrator]# ./migrator configure&#xD;&#xA;[OK] Generated environment file&#xD;&#xA;[INFO] Run &#39;./migrator install --archive &amp;lt; archive_file &amp;gt; &#39; to complete setup&lt;/pre&gt;&#xA;&lt;p&gt;Avant de passer à la suite, on s&amp;#8217;assure de bien démarrer notre Docker :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[root@oracle-02 cybertec_migrator]# systemctl start docker&#xD;&#xA;[root@oracle-02 cybertec_migrator]# systemctl status docker&#xD;&#xA;● docker.service - Docker Application Container Engine&#xD;&#xA;Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled)&#xD;&#xA;Active: active (running) since Tue 2023-05-02 08:53:00 UTC; 7s ago&#xD;&#xA;Docs: https://docs.docker.com&#xD;&#xA;Main PID: 3197 (dockerd)&#xD;&#xA;Tasks: 8&#xD;&#xA;Memory: 119.0M&#xD;&#xA;CGroup: /system.slice/docker.service&#xD;&#xA;└─3197 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock&lt;/pre&gt;&#xA;&lt;p&gt;On lance ensuite notre installation :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[root@oracle-02 cybertec_migrator]# ./migrator install --archive ../cybertec_migrator-v3.16.0-standard.tar.gz&#xD;&#xA;[INFO] Reading version information from archive file &#39;../cybertec_migrator-v3.16.0-standard.tar.gz&#39;&#xD;&#xA;[INFO] Upgrading to version v3.16.0-standard&#xD;&#xA;[INFO] Extracting archive file &#39;../cybertec_migrator-v3.16.0-standard.tar.gz&#39;&#xD;&#xA;[INFO] Loading container images&#xD;&#xA;c9182c130984: Loading layer [==================================================&amp;gt;] 72.53MB/72.53MB&#xD;&#xA;40599cfe08ec: Loading layer [==================================================&amp;gt;] 349.7kB/349.7kB&#xD;&#xA;20b85315cea4: Loading layer [==================================================&amp;gt;] 102.9MB/102.9MB&#xD;&#xA;61a5eccb8646: Loading layer [==================================================&amp;gt;] 9.454MB/9.454MB&#xD;&#xA;459b6b5a3ba3: Loading layer [==================================================&amp;gt;] 3.584kB/3.584kB&#xD;&#xA;8b2451f44e75: Loading layer [==================================================&amp;gt;] 61.95MB/61.95MB&#xD;&#xA;ff1b0bd4bc3d: Loading layer [==================================================&amp;gt;] 2.048kB/2.048kB&#xD;&#xA;105a91dee35e: Loading layer [==================================================&amp;gt;] 115.5MB/115.5MB&#xD;&#xA;8399b2b8ccbe: Loading layer [==================================================&amp;gt;] 3.173MB/3.173MB&#xD;&#xA;4377e9cc2f2c: Loading layer [==================================================&amp;gt;] 25.5MB/25.5MB&#xD;&#xA;8dbaeed3eff6: Loading layer [==================================================&amp;gt;] 2.56kB/2.56kB&#xD;&#xA;Loaded image: cybertecpostgresql/cybertec_migrator-core:v3.16.0-standard&#xD;&#xA;3af14c9a24c9: Loading layer [==================================================&amp;gt;] 84MB/84MB&#xD;&#xA;af29ec691175: Loading layer [==================================================&amp;gt;] 62.5MB/62.5MB&#xD;&#xA;a0b795906dc1: Loading layer [==================================================&amp;gt;] 3.584kB/3.584kB&#xD;&#xA;95457f8a16fd: Loading layer [==================================================&amp;gt;] 4.608kB/4.608kB&#xD;&#xA;4d0bf5b5e17b: Loading layer [==================================================&amp;gt;] 3.584kB/3.584kB&#xD;&#xA;ff4557f62768: Loading layer [==================================================&amp;gt;] 7.168kB/7.168kB&#xD;&#xA;0c1e2a4e5a14: Loading layer [==================================================&amp;gt;] 13.14MB/13.14MB&#xD;&#xA;Loaded image: cybertecpostgresql/cybertec_migrator-web_gui:v3.16.0-standard&#xD;&#xA;7cd52847ad77: Loading layer [==================================================&amp;gt;] 7.338MB/7.338MB&#xD;&#xA;e2b55894f225: Loading layer [==================================================&amp;gt;] 12.8kB/12.8kB&#xD;&#xA;96139409c02a: Loading layer [==================================================&amp;gt;] 2.048kB/2.048kB&#xD;&#xA;c3ec93ee5b48: Loading layer [==================================================&amp;gt;] 233.7MB/233.7MB&#xD;&#xA;99c761a4ed63: Loading layer [==================================================&amp;gt;] 60.42kB/60.42kB&#xD;&#xA;b3357907ccb7: Loading layer [==================================================&amp;gt;] 2.56kB/2.56kB&#xD;&#xA;a7504fa091bf: Loading layer [==================================================&amp;gt;] 3.584kB/3.584kB&#xD;&#xA;a283b778659e: Loading layer [==================================================&amp;gt;] 15.87kB/15.87kB&#xD;&#xA;Loaded image: postgres:13-alpine&#xD;&#xA;[INFO] Container images loaded&#xD;&#xA;[INFO] Archived container images&#xD;&#xA;[INFO] Upgraded to v3.16.0-standard&#xD;&#xA;[WARN] Could not find TLS/SSL certificate&#xD;&#xA;[INFO] Run &#39;./migrator configure --tls self-signed-cert&#39; to generate a self-signed TLS/SSL certificate&lt;/pre&gt;&#xA;&lt;p&gt;Pour pouvoir fonctionner, les nouvelles versions de Migrator nécessitent un certificat TLS, on en génère donc un :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[root@oracle-02 cybertec_migrator]# ./migrator configure --tls self-signed-cert&#xD;&#xA;[INFO] Generating self-signed TLS/SSL certificate&#xD;&#xA;[+] Running 2/1&#xD;&#xA; Network cybertec_migrator_common         Created                                                                                                                                                                                     0.2s&#xD;&#xA; Volume &amp;quot;cybertec_migrator_core_db-data&amp;quot;  Created                                                                                                                                                                                     0.0s&#xD;&#xA;Generating a RSA private key&#xD;&#xA;.................................................................................+++++&#xD;&#xA;............+++++&#xD;&#xA;writing new private key to &#39;/etc/nginx/certs/nginx.key&#39;&#xD;&#xA;-----&#xD;&#xA;You are about to be asked to enter information that will be incorporated&#xD;&#xA;into your certificate request.&#xD;&#xA;What you are about to enter is what is called a Distinguished Name or a DN.&#xD;&#xA;There are quite a few fields but you can leave some blank&#xD;&#xA;For some fields there will be a default value,&#xD;&#xA;If you enter &#39;.&#39;, the field will be left blank.&#xD;&#xA;-----&#xD;&#xA;Country Name (2 letter code) [AU]:FR&#xD;&#xA;...&#xD;&#xA;Email Address []:sfaveere@capdata-osmozium.com&#xD;&#xA;[OK] Generated self-signed TLS/SSL certificate&#xD;&#xA;[INFO] Run &#39;./migrator up&#39; to switch to new version&#xD;&#xA;[WARN] Switching will abort running migrations&lt;/pre&gt;&#xA;&lt;h2&gt;Etape 4 : Démarrage de l&amp;#8217;application et premiers pas&lt;/h2&gt;&#xA;&lt;p&gt;Une fois notre installation terminée, on peut démarrer l&amp;#8217;outil :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;[root@oracle-02 cybertec_migrator]# ./migrator up&#xD;&#xA;[+] Running 3/3&#xD;&#xA; Container cybertec_migrator-core_db-1 Healthy 6.2s&#xD;&#xA; Container cybertec_migrator-core-1 Started 6.6s&#xD;&#xA; Container cybertec_migrator-web_gui-1 Started 7.3s&#xD;&#xA;[OK] Started on &#39;https://***.**.*.**&#39;&lt;/pre&gt;&#xA;&lt;p&gt;L&amp;#8217;URL fournie par la fin de l&amp;#8217;installation est l&amp;#8217;url à laquelle vous devez accéder pour pouvoir voir s&amp;#8217;afficher votre outil de migration web.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Important :&lt;/strong&gt; Avant de vous connecter sur l&amp;#8217;application, il y a certains droits qu&amp;#8217;il faut s&amp;#8217;assurer d&amp;#8217;avoir.&lt;/p&gt;&#xA;&lt;p&gt;Sur Oracle :&lt;br /&gt;&#xA;J&amp;#8217;ai créé un compte Migrator avec des droits particuliers :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;-- On the Oracle database&#xD;&#xA;CREATE USER migrator IDENTIFIED by migrator;&#xD;&#xA;GRANT CONNECT, SELECT_CATALOG_ROLE, SELECT ANY TABLE, FLASHBACK ANY TABLE TO migrator;&lt;/pre&gt;&#xA;&lt;p&gt;Sur PostgreSQL :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;-- As PostgreSQL super user&#xD;&#xA;CREATE DATABASE demo;&#xD;&#xA;CREATE USER demo WITH PASSWORD &#39;demo&#39;;&#xD;&#xA;GRANT CREATE ON DATABASE demo TO demo;&lt;/pre&gt;&#xA;&lt;p&gt;Il ne nous reste plus qu&amp;#8217;à accéder à notre outil de migration, en se rendant au lien précisé à la fin du start-up :&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_KzosVXNkHr.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone wp-image-10106&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_KzosVXNkHr-300x146.png&#34; alt=&#34;&#34; width=&#34;1079&#34; height=&#34;525&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_KzosVXNkHr-300x146.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_KzosVXNkHr-768x375.png 768w&#34; sizes=&#34;(max-width: 1079px) 100vw, 1079px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Etape 5 : Prévoir sa migration&lt;/h2&gt;&#xA;&lt;p&gt;Une fois que nous avons correctement accès à notre page de garde de Migrator, on peut donc commencer à prévoir une nouvelle migration. En cliquant sur Migration dans le menu à gauche, on accède à une nouvelle fenêtre :&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_jkiw4VdWaK.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone wp-image-10103&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_jkiw4VdWaK-300x146.png&#34; alt=&#34;&#34; width=&#34;1081&#34; height=&#34;526&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_jkiw4VdWaK-300x146.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_jkiw4VdWaK-768x375.png 768w&#34; sizes=&#34;(max-width: 1081px) 100vw, 1081px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Sur cette nouvelle page, on peut cliquer sur Add New Migration afin d&amp;#8217;accéder à la page de création d&amp;#8217;une nouvelle migration&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_YnojWIrMdM.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone wp-image-10107&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_YnojWIrMdM-300x146.png&#34; alt=&#34;&#34; width=&#34;1081&#34; height=&#34;526&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_YnojWIrMdM-300x146.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_YnojWIrMdM-768x375.png 768w&#34; sizes=&#34;(max-width: 1081px) 100vw, 1081px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Ce premier écran est celui sur lequel on définit la connexion d&amp;#8217;origine de la base de données, donc notre connexion Oracle.&lt;/p&gt;&#xA;&lt;p&gt;Les deux premiers champs du formulaire permettent de donner un nom et une description à notre migration.&lt;/p&gt;&#xA;&lt;p&gt;Ensuite, on donne une chaine de connexion pour notre base de données source, le username qu&amp;#8217;on a créé plus tôt et le mot de passe qui lui est lié. On clique sur check, et si la connexion est ok, alors on aperçoit un message &amp;#8220;Connection Success&amp;#8221;. On peut donc cliquer sur &amp;#8220;Next&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_Jl4fKVz8Cv.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone wp-image-10104&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_Jl4fKVz8Cv-300x146.png&#34; alt=&#34;&#34; width=&#34;1081&#34; height=&#34;526&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_Jl4fKVz8Cv-300x146.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_Jl4fKVz8Cv-768x375.png 768w&#34; sizes=&#34;(max-width: 1081px) 100vw, 1081px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L&amp;#8217;écran suivant est l&amp;#8217;écran qui nous permet de gérer le ou les schémas que l&amp;#8217;on souhaite migrer. Dans notre cas, on sélectionne le schéma OT et on clique sur &amp;#8220;Next&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_4qGPRukA04.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone wp-image-10101&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_4qGPRukA04-300x141.png&#34; alt=&#34;&#34; width=&#34;1119&#34; height=&#34;526&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_4qGPRukA04-300x141.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_4qGPRukA04-1024x481.png 1024w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_4qGPRukA04-768x361.png 768w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_4qGPRukA04-1536x722.png 1536w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_4qGPRukA04.png 1920w&#34; sizes=&#34;(max-width: 1119px) 100vw, 1119px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;La fenêtre qui s&amp;#8217;affiche permet de voir tout ce que l&amp;#8217;outil Migrator nous permet de migrer. On peut voir que sur cette version standard, on ne sait pas migrer les partitions. On peut cliquer sur &amp;#8220;Finish&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_69Ikavyp90.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone wp-image-10114&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_69Ikavyp90-300x141.png&#34; alt=&#34;&#34; width=&#34;1124&#34; height=&#34;528&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_69Ikavyp90-300x141.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_69Ikavyp90-1024x481.png 1024w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_69Ikavyp90-768x361.png 768w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_69Ikavyp90-1536x722.png 1536w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_69Ikavyp90.png 1920w&#34; sizes=&#34;(max-width: 1124px) 100vw, 1124px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L&amp;#8217;écran suivant est l&amp;#8217;écran de suivi de la migration en lui-même. Il comporte de nombreuses fonctionnalités qui vous permettent de choisir les objets que vous voulez migrer ou non, en les désactivant on peut aisément ne pas importer certains objets.&lt;/p&gt;&#xA;&lt;p&gt;En cliquant dans le menu déroulant à gauche, on peut dérouler les tables et voir  les champs dans ces tables. En cliquant dessus on peut même aller modifier manuellement les types de ces champs pour leur migration, les contraintes, les index, les triggers&amp;#8230;&lt;/p&gt;&#xA;&lt;p&gt;Une fois nos modifications effectuées, pour qu&amp;#8217;elles soient prises en compte on peut cliquer sur le bouton &amp;#8220;Save&amp;#8221; en bas à gauche, juste en dessous de la ligne.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_rTqk14wyi7.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone wp-image-10115&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_rTqk14wyi7-300x141.png&#34; alt=&#34;&#34; width=&#34;1119&#34; height=&#34;526&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_rTqk14wyi7-300x141.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_rTqk14wyi7-1024x481.png 1024w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_rTqk14wyi7-768x361.png 768w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_rTqk14wyi7-1536x722.png 1536w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_rTqk14wyi7.png 1920w&#34; sizes=&#34;(max-width: 1119px) 100vw, 1119px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Ainsi, on peut par exemple modifier le type des colonnes de clé primaire de Numeric à Integer pour éviter d&amp;#8217;avoir un problème lors de l&amp;#8217;import, dans la mesure où PostgreSQL n&amp;#8217;accepte pas les clé primaires de type Numeric.&lt;/p&gt;&#xA;&lt;p&gt;Une fois que toutes nos modifications sont effectuées, on peut cliquer sur le cercle en bas à gauche pour ouvrir la console qui va nous permettre de lancer la migration.&lt;/p&gt;&#xA;&lt;p&gt;&lt;b&gt;Les quatre étapes de la migration sont les suivantes :&lt;/b&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Schéma : Migrator transfère le schéma depuis l&amp;#8217;ancienne base vers la nouvelle&lt;/li&gt;&#xA;&lt;li&gt;Data : Migrator transfère la data depuis la source vers la destination&lt;/li&gt;&#xA;&lt;li&gt;Integrity : Il transfère les contraintes, les indexes, les clés primaires&lt;/li&gt;&#xA;&lt;li&gt;Logic : Migrator transfère les fonctions, les procédures, les vues et les triggers&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La petite fenêtre de log peut être étendue vers le haut, et elle vous permet d&amp;#8217;avoir un visuel sur ce qui se passe pendant votre migration, et si des erreurs éventuelles sont rencontrées. La majeure partie des erreurs de migrations sont des problèmes de type que l&amp;#8217;on peut modifier directement sur l&amp;#8217;interface pour ensuite relancer le processus.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_pweApXNKTc.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone wp-image-10116&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_pweApXNKTc-300x141.png&#34; alt=&#34;&#34; width=&#34;1119&#34; height=&#34;526&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_pweApXNKTc-300x141.png 300w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_pweApXNKTc-1024x481.png 1024w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_pweApXNKTc-768x361.png 768w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_pweApXNKTc-1536x722.png 1536w, https://blog.capdata.fr/wp-content/uploads/2023/05/chrome_pweApXNKTc.png 1920w&#34; sizes=&#34;(max-width: 1119px) 100vw, 1119px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Quand notre migration est terminée, c&amp;#8217;est affiché dans notre log, et on peut alors aller voir sur l&amp;#8217;environnement PostgreSQL le résultat obtenu.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;psql (13.10)&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;postgres=# \c demo&#xD;&#xA;You are now connected to database &amp;quot;demo&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;demo=# select * from ot.products;&#xD;&#xA;product_id | product_name | description | standard_cost | list_price | category_id&#xD;&#xA;------------+---------------------------------------------+-----------------------------------------------------------------------+---------------+------------+-------------&#xD;&#xA;228 | Intel Xeon E5-2699 V3 (OEM/Tray) | Speed:2.3GHz,Cores:18,TDP:145W | 2867.51 | 3410.46 | 1&#xD;&#xA;248 | Intel Xeon E5-2697 V3 | Speed:2.6GHz,Cores:14,TDP:145W | 2326.27 | 2774.98 | 1&#xD;&#xA;249 | Intel Xeon E5-2698 V3 (OEM/Tray) | Speed:2.3GHz,Cores:16,TDP:135W | 2035.18 | 2660.72 | 1&#xD;&#xA;...&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Notre schéma PostgreSQL qui ne contenait rien à la base contient maintenant l&amp;#8217;intégralité des données que notre schéma Oracle contenait.&lt;/p&gt;&#xA;&lt;h2&gt;Conclusion :&lt;/h2&gt;&#xA;&lt;p&gt;Sur un marché où de plus en plus de produits open-source nous permettent de faciliter des tâches aussi délicates que de la migration d&amp;#8217;un environnement de base de données à un autre, Migrator et son interface graphique nous offrent une solution user-friendly avec une interface qui permet de simplifier les choses.&lt;br /&gt;&#xA;Il faut cependant garder en tête que cet outil n&amp;#8217;est pas gratuit en dehors de sa version standard, et que pour pouvoir profiter des améliorations de performance pour vos migrations, il faut acheter une licence auprès de Cybertec.&lt;br /&gt;&#xA;L&amp;#8217;installation du produit en elle-même ne pose aucune difficulté, et après un peu de prise en main, il s&amp;#8217;avère relativement facile à utiliser.&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/la-migration-oracle-vers-postgresql-avec-ora2pg/&#34; rel=&#34;bookmark&#34; title=&#34;22 août 2019&#34;&gt;La migration Oracle vers PostgreSQL avec ora2pg&lt;/a&gt; (Emmanuel RAMI) [OraclePostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/gerer-votre-disaster-recovery-oracle-avec-dbvisit-standby/&#34; rel=&#34;bookmark&#34; title=&#34;29 avril 2021&#34;&gt;Une solution de &amp;#8220;Disaster Recovery&amp;#8221; sous Oracle Standard Edition avec DBVisit standby&lt;/a&gt; (Emmanuel RAMI) [GénéralOracle]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/containeriser-une-base-de-donnees-postgresql-avec-docker/&#34; rel=&#34;bookmark&#34; title=&#34;23 septembre 2021&#34;&gt;Containeriser PostgreSQL avec Docker !&lt;/a&gt; (Emmanuel RAMI) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-planifier-une-tache-avec-pg_cron/&#34; rel=&#34;bookmark&#34; title=&#34;24 septembre 2019&#34;&gt;PostgreSQL : planifier une tâche avec pg_cron&lt;/a&gt; (Emmanuel RAMI) [Non classéPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/transparent-data-encryption-pour-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;13 mai 2022&#34;&gt;Transparent Data Encryption pour PostgreSQL&lt;/a&gt; (Sarah FAVEERE) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 6.695 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10089&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10089&amp;#038;title=Cybertec%20Migrator%20%3A%20une%20alternative%20%C3%A0%20ora2pg%20%3F&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=Cybertec%20Migrator%20%3A%20une%20alternative%20%C3%A0%20ora2pg%20%3F&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D10089&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/cybertec-migrator-une-alternative-a-ora2pg/&#34;&gt;Cybertec Migrator : une alternative à ora2pg ?&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/cybertec-migrator-une-alternative-a-ora2pg/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Connue pour de nombreux produits développés pour PostgreSQL, Cybertec a récemment mis à jour son outil de migration de base de données du moteur Oracle vers le moteur PostgreSQL. Dans cet article, je vais vous expliquer la mise en place&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/cybertec-migrator-une-alternative-a-ora2pg/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/cybertec-migrator-une-alternative-a-ora2pg/&#34;&gt;Cybertec Migrator : une alternative à ora2pg ?&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>Kubegres : l’opérateur Kubernetes clé en main pour PostgreSQL</title>
    <updated>2023-04-26T16:17:16Z</updated>
    <id>tag:blog.capdata.fr,2023-04-26:/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9778&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9778&amp;#038;title=Kubegres%20%3A%20l%E2%80%99op%C3%A9rateur%20Kubernetes%20cl%C3%A9%20en%20main%20pour%20PostgreSQL&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=Kubegres%20%3A%20l%E2%80%99op%C3%A9rateur%20Kubernetes%20cl%C3%A9%20en%20main%20pour%20PostgreSQL&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9778&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;&lt;a href=&#34;https://blog.capdata.fr/wp-content/uploads/2023/04/2containers.png&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/04/2containers.png&#34; alt=&#34;&#34; width=&#34;623&#34; height=&#34;416&#34; class=&#34;left size-full wp-image-10070&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/04/2containers.png 623w, https://blog.capdata.fr/wp-content/uploads/2023/04/2containers-300x200.png 300w&#34; sizes=&#34;(max-width: 623px) 100vw, 623px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Hello à toutes et tous !&lt;/p&gt;&#xA;&lt;p&gt;Pour faire suite à &lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/&#34;&gt;l&amp;#8217;article d&amp;#8217;Emmanuel&lt;/a&gt; sur l&amp;#8217;installation de PostgreSQL sur un cluster minikube local, aujourd&amp;#8217;hui nous allons découvrir l&amp;#8217;opérateur &lt;a href=&#34;https://www.kubegres.io/&#34;&gt;Kubegres &lt;/a&gt;qui permet de facilement déployer un cluster PostgreSQL avec Primary et Standby à l&amp;#8217;intérieur de pods K8s, sans avoir à créer chaque brique une par une comme on devrait le faire avec un simple StatefulSet. &lt;/p&gt;&#xA;&lt;h2&gt;Pourquoi Kubegres apporte un vrai plus&lt;/h2&gt;&#xA;&lt;p&gt;En un mot : &lt;strong&gt;SIM-PLI-CI-TE !&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;Parce qu&amp;#8217;il introduit un nouveau type d&amp;#8217;objet : &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;kind: Kubegres&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Les specs à l&amp;#8217;intérieur de cet objet encapsulent déjà tout ce qui est nécessaire pour créer les StatefulSets, les ClusterIPs, le Physical Volumes et le PVC associé, la ConfigMap et les Pods. Pas besoin de tout créer à l&amp;#8217;avance et le fichier de déploiement est beaucoup plus compact !&lt;/p&gt;&#xA;&lt;h2&gt;Installation de Kubegres &lt;/h2&gt;&#xA;&lt;p&gt;Nous utiliserons &lt;a href=&#34;https://kubernetes.io/fr/docs/setup/learning-environment/minikube/&#34;&gt;minikube &lt;/a&gt;pour montrer comment déployer Kubegres, je vous renvoie à l&amp;#8217;article d&amp;#8217;Emmanuel cité plus haut pour son installation. Comme nous allons devoir attribuer des fractions de ressource RAM et CPU entre les pods, j&amp;#8217;activerai juste en plus la partie metrics-server :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;$ minikube addons enable metrics-server&lt;/pre&gt;&#xA;&lt;p&gt;La première étape consiste à installer l&amp;#8217;opérateur. Cette première étape va créer un nombre importants d&amp;#8217;objets pour nous, comme en témoigne le contenu de son fichier de déploiement &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ curl --silent https://raw.githubusercontent.com/reactive-tech/kubegres/v1.16/kubegres.yaml \&#xD;&#xA;  | grep  -w &#39;kind:&#39; | awk -F&#39;:&#39; &#39;{print $2}&#39;  \ &#xD;&#xA;  | sort -u&#xD;&#xA;&#xD;&#xA; ClusterRole&#xD;&#xA; ClusterRoleBinding&#xD;&#xA; ConfigMap&#xD;&#xA; ControllerManagerConfig&#xD;&#xA; CustomResourceDefinition&#xD;&#xA; Deployment&#xD;&#xA; Kubegres&#xD;&#xA; Namespace&#xD;&#xA; Role&#xD;&#xA; RoleBinding&#xD;&#xA; Service&#xD;&#xA; ServiceAccount&#xD;&#xA;&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;:&lt;br /&gt;&#xA;On déploie donc via &lt;a href=&#34;https://kubernetes.io/fr/docs/tasks/tools/install-kubectl/&#34;&gt;kubectl&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl apply -f https://raw.githubusercontent.com/reactive-tech/kubegres/v1.16/kubegres.yaml&#xD;&#xA;namespace/kubegres-system created&#xD;&#xA;customresourcedefinition.apiextensions.k8s.io/kubegres.kubegres.reactive-tech.io created&#xD;&#xA;serviceaccount/kubegres-controller-manager created&#xD;&#xA;role.rbac.authorization.k8s.io/kubegres-leader-election-role created&#xD;&#xA;clusterrole.rbac.authorization.k8s.io/kubegres-manager-role created&#xD;&#xA;clusterrole.rbac.authorization.k8s.io/kubegres-metrics-reader created&#xD;&#xA;clusterrole.rbac.authorization.k8s.io/kubegres-proxy-role created&#xD;&#xA;rolebinding.rbac.authorization.k8s.io/kubegres-leader-election-rolebinding created&#xD;&#xA;clusterrolebinding.rbac.authorization.k8s.io/kubegres-manager-rolebinding created&#xD;&#xA;clusterrolebinding.rbac.authorization.k8s.io/kubegres-proxy-rolebinding created&#xD;&#xA;configmap/kubegres-manager-config created&#xD;&#xA;service/kubegres-controller-manager-metrics-service created&#xD;&#xA;deployment.apps/kubegres-controller-manager created&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Un namespace &lt;em&gt;kubegres-system&lt;/em&gt; a été créé, dans lequel notre cluster pourra éventuellement s&amp;#8217;inscrire. Cela dit, la bonne pratique consisterait à créer un namespace à part et laisser le controller-manager kubegres dans son namespace système, mais pour ne pas interférer avec mes autres namespaces, je vais volontairement rajouter le cluster dedans:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl get all --namespace=kubegres-system&#xD;&#xA;NAME                                               READY   STATUS    RESTARTS   AGE&#xD;&#xA;pod/kubegres-controller-manager-794468bbff-bxzxk   2/2     Running   0          3m35s&#xD;&#xA;&#xD;&#xA;NAME                                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE&#xD;&#xA;service/kubegres-controller-manager-metrics-service   ClusterIP   10.100.182.92   &amp;lt;none&amp;gt;        8443/TCP   3m35s&#xD;&#xA;&#xD;&#xA;NAME                                          READY   UP-TO-DATE   AVAILABLE   AGE&#xD;&#xA;deployment.apps/kubegres-controller-manager   1/1     1            1           3m35s&#xD;&#xA;&#xD;&#xA;NAME                                                     DESIRED   CURRENT   READY   AGE&#xD;&#xA;replicaset.apps/kubegres-controller-manager-794468bbff   1         1         1       3m35s&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h2&gt;Création du cluster en 15.2&lt;/h2&gt;&#xA;&lt;p&gt;Avant de créer le cluster PostgreSQL, il va falloir créer un secret qui va contenir les mots de passe du primaire et de sa standby. &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ vi postgres-secret.yaml&#xD;&#xA;(...)&#xD;&#xA;apiVersion: v1&#xD;&#xA;kind: Secret&#xD;&#xA;metadata:&#xD;&#xA;  name: mypostgres-secret&#xD;&#xA;  namespace: kubegres-system&#xD;&#xA;type: Opaque&#xD;&#xA;stringData:&#xD;&#xA;  superUserPassword: capdata&#xD;&#xA;  replicationUserPassword: capdatarep&#xD;&#xA;&#xD;&#xA;$ kubectl apply -f postgres-secret.yaml -n kubegres-system&#xD;&#xA;secret/mypostgres-secret created&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Enfin nous pouvons créer le cluster avec un seul fichier de déploiement:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;&#xD;&#xA;apiVersion: kubegres.reactive-tech.io/v1&#xD;&#xA;kind: Kubegres&#xD;&#xA;metadata:&#xD;&#xA;  name: kpostgres&#xD;&#xA;  namespace: kubegres-system&#xD;&#xA;&#xD;&#xA;spec:&#xD;&#xA;&#xD;&#xA;  replicas: 2&#xD;&#xA;  image: postgres:15.2&#xD;&#xA;  port: 5432&#xD;&#xA;&#xD;&#xA;  database:&#xD;&#xA;    size: 200Mi&#xD;&#xA;    storageClassName: standard&#xD;&#xA;    volumeMount: /var/lib/postgresql/data&#xD;&#xA;&#xD;&#xA;  failover:&#xD;&#xA;    isDisabled: false&#xD;&#xA;    promotePod: &amp;quot;kpostgres-2-0&amp;quot;&#xD;&#xA;&#xD;&#xA;  resources:&#xD;&#xA;    limits:&#xD;&#xA;      memory: &amp;quot;1Gi&amp;quot;&#xD;&#xA;      cpu: &amp;quot;1&amp;quot;&#xD;&#xA;    requests:&#xD;&#xA;      memory: &amp;quot;500Mi&amp;quot;&#xD;&#xA;      cpu: &amp;quot;0.5&amp;quot;&#xD;&#xA;&#xD;&#xA;  probe:&#xD;&#xA;     livenessProbe:&#xD;&#xA;        exec:&#xD;&#xA;           command:&#xD;&#xA;             - sh&#xD;&#xA;             - -c&#xD;&#xA;             - exec pg_isready -U postgres -h $POD_IP&#xD;&#xA;        failureThreshold: 10&#xD;&#xA;        initialDelaySeconds: 60&#xD;&#xA;        periodSeconds: 20&#xD;&#xA;        successThreshold: 1&#xD;&#xA;        timeoutSeconds: 15&#xD;&#xA;&#xD;&#xA;     readinessProbe:&#xD;&#xA;        exec:&#xD;&#xA;           command:&#xD;&#xA;             - sh&#xD;&#xA;             - -c&#xD;&#xA;             - exec pg_isready -U postgres -h $POD_IP&#xD;&#xA;        failureThreshold: 3&#xD;&#xA;        initialDelaySeconds: 5&#xD;&#xA;        periodSeconds: 5&#xD;&#xA;        successThreshold: 1&#xD;&#xA;        timeoutSeconds: 3&#xD;&#xA;&#xD;&#xA;  env:&#xD;&#xA;    - name: POSTGRES_PASSWORD&#xD;&#xA;      valueFrom:&#xD;&#xA;        secretKeyRef:&#xD;&#xA;          name: mypostgres-secret&#xD;&#xA;          key: superUserPassword&#xD;&#xA;&#xD;&#xA;    - name: POSTGRES_REPLICATION_PASSWORD&#xD;&#xA;      valueFrom:&#xD;&#xA;        secretKeyRef:&#xD;&#xA;          name: mypostgres-secret&#xD;&#xA;          key: replicationUserPassword&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;strong&gt;Remarques sur les sections &lt;/strong&gt;:&lt;br /&gt;&#xA;&amp;#8211; La spec database.size permet de dimensionner le PVC à une taille initiale, mais attention ! En fonction de la version de Kubernetes, il peut être compliqué de modifier cette valeur ensuite comme rapporté dans &lt;a href=&#34;https://github.com/reactive-tech/kubegres/issues/49&#34;&gt;cet issue du github Kubegres&lt;/a&gt;.&lt;br /&gt;&#xA;&amp;#8211; On ne créé &amp;#8216;que&amp;#8217; 2 réplicas au sens StatefulSet, c&amp;#8217;est à dire un primaire et une standby.&lt;br /&gt;&#xA;&amp;#8211; La spec failover permet de désactiver ou d&amp;#8217;activer le promote automatique de la standby, et de dire quel est le noeud préférentiel.&lt;br /&gt;&#xA;&amp;#8211; 2 types de sondes : une pour décider de redémarrer le container en cas d&amp;#8217;échec de connexion (livenessProbe), et une autre pour autoriser les connexions (readinessProbe). Le fonctionnement du failover est expliqué plus loin.&lt;br /&gt;&#xA;&amp;#8211; resources permet de limiter l&amp;#8217;utilisation des pods à des plages de CPU et RAM en jouant avec requests et limit.&lt;br /&gt;&#xA;&amp;#8211; Il est aussi possible d&amp;#8217;utiliser l&amp;#8217;anti-affinité pour empêcher les pods primary et standby d&amp;#8217;atterrir sur le même node K8s. On ne le fait évidemment pas dans notre exemple car sur minikube cela n&amp;#8217;aurait aucun sens. &lt;/p&gt;&#xA;&lt;p&gt;La liste complète des propriétés peut être retrouvée sur &lt;a href=&#34;https://www.kubegres.io/doc/properties-explained.html&#34;&gt;la page de documentation &lt;/a&gt;de Kubegres.&lt;/p&gt;&#xA;&lt;p&gt;Une fois le cluster déployé, nous pouvons vérifier tous les nouveaux objets qui ont été créés:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl apply -f postgres-cluster.yaml -n kubegres-system&#xD;&#xA;kubegres.kubegres.reactive-tech.io/kpostgres created&#xD;&#xA;&#xD;&#xA;$ kubectl get all -n kubegres-system&#xD;&#xA;NAME                                               READY   STATUS    RESTARTS       AGE&#xD;&#xA;pod/kpostgres-1-0                                  1/1     Running   2              5d16h&#xD;&#xA;pod/kpostgres-2-0                                  1/1     Running   3              5d16h&#xD;&#xA;pod/kubegres-controller-manager-794468bbff-bxzxk   2/2     Running   13 (23m ago)   5d18h&#xD;&#xA;&#xD;&#xA;NAME                                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE&#xD;&#xA;service/kpostgres                                     ClusterIP   None            &amp;lt;none&amp;gt;        5432/TCP   5d16h&#xD;&#xA;service/kpostgres-replica                             ClusterIP   None            &amp;lt;none&amp;gt;        5432/TCP   5d16h&#xD;&#xA;service/kubegres-controller-manager-metrics-service   ClusterIP   10.100.182.92   &amp;lt;none&amp;gt;        8443/TCP   5d18h&#xD;&#xA;&#xD;&#xA;NAME                                          READY   UP-TO-DATE   AVAILABLE   AGE&#xD;&#xA;deployment.apps/kubegres-controller-manager   1/1     1            1           5d18h&#xD;&#xA;&#xD;&#xA;NAME                                                     DESIRED   CURRENT   READY   AGE&#xD;&#xA;replicaset.apps/kubegres-controller-manager-794468bbff   1         1         1       5d18h&#xD;&#xA;&#xD;&#xA;NAME                           READY   AGE&#xD;&#xA;statefulset.apps/kpostgres-1   1/1     5d16h&#xD;&#xA;statefulset.apps/kpostgres-2   1/1     5d16h&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;En plus du &lt;em&gt;controller manager&lt;/em&gt;, nous avons donc 2 nouveaux pods, 2 services ClusterIP et 2 StatefulSets, un pour chaque instance PostgreSQL.&lt;br /&gt;&#xA;Nous pouvons à partir de là tester la connexion au service (kpostgres), en démarrant un conteneur client &lt;em&gt;ephemeral&lt;/em&gt; (kubectl run &amp;#8230; &amp;#8211;rm). On rappelle que kubegres ne créé par défaut que des &lt;em&gt;Headless Services &lt;/em&gt;(ClusterIP sans adresse attribuée) pour éviter de les rendre visibles depuis l&amp;#8217;extérieur du cluster. On partira toujours du principe que sur un cluster Kubernetes, &lt;strong&gt;tout est deployment / pod&lt;/strong&gt; :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl run postgresql-postgresql-client --rm --tty -i --restart=&#39;Never&#39; \&#xD;&#xA;  --namespace kubegres-system  --image postgres:15.2 \&#xD;&#xA;  --env=&amp;quot;PGPASSWORD=capdata&amp;quot; --command -- psql \&#xD;&#xA;  --host kpostgres -U postgres -c &amp;quot;select version();&amp;quot;&#xD;&#xA;&#xD;&#xA;                    version&#xD;&#xA;&#xD;&#xA;--------------------------------------------------------------------------------&#xD;&#xA;---------------------------------------------&#xD;&#xA; PostgreSQL 15.2 (Debian 15.2-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by g&#xD;&#xA;cc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA;pod &amp;quot;postgresql-postgresql-client&amp;quot; deleted&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h2&gt;Comportement en cas d&amp;#8217;échec du serveur primaire&lt;/h2&gt;&#xA;&lt;p&gt;Le deploiement est configuré avec 2 sondes (liveness et readiness) qui toutes 2 utilisent la commande pg_isready pour vérifier la disponibilité des instances primaire et standby. D&amp;#8217;ailleurs on peut le tester nous-mêmes pour véfifier le retour de la commande :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl exec --tty --stdin -n kubegres-system kpostgres-1-0 -- pg_isready -U postgres &amp;amp;&amp;amp; echo $?&#xD;&#xA;/var/run/postgresql:5432 - accepting connections&#xD;&#xA;0&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Notre Failover est paramétré sur automatique, avec une préférence pour repartir sur le noeud 2, on va simuler une perte du service en faisant un pg_ctl stop sur le premier pod:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl exec --tty --stdin -n kubegres-system kpostgres-1-0 -- su postgres \&#xD;&#xA;  -c &amp;quot;pg_ctl stop -D /var/lib/postgresql/data/pgdata -m fast&amp;quot;                                                                          &#xD;&#xA;waiting for server to shut down....command terminated with exit code 137&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;On voit que la reconnexion immédiate ne fonctionne pas tout de suite: &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl run postgresql-postgresql-client --rm --tty -i --restart=&#39;Never&#39; --namespace kubegres-system  --image postgres:15.2 --env=&amp;quot;PGPASSWORD=capdata&amp;quot; --command -- psql --host kpostgres -U postgres -c &amp;quot;select inet_server_addr();&amp;quot;&#xD;&#xA;(...)&#xD;&#xA;psql: error: could not translate host name &amp;quot;kpostgres&amp;quot; to address: Temporary failure in name resolution&#xD;&#xA;pod &amp;quot;postgresql-postgresql-client&amp;quot; deleted&#xD;&#xA;pod kubegres-system/postgresql-postgresql-client terminated (Error)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;D&amp;#8217;après les logs le failover dure une dizaine de secondes seulement:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl logs pod/kubegres-controller-manager-794468bbff-bxzxk -c manager -n kubegres-system --timestamps | grep &#39;FailOver:&#39;&#xD;&#xA;2023-04-19T20:11:22.687346601Z 1.6819350826873376e+09   INFO    controllers.Kubegres    FailOver: Deleting the failing Primary StatefulSet.     {&amp;quot;Primary name&amp;quot;: &amp;quot;kpostgres-1&amp;quot;}&#xD;&#xA;2023-04-19T20:11:22.690961293Z 1.6819350826909401e+09   INFO    controllers.Kubegres    FailOver: Waiting before promoting a Replica to a Primary...    {&amp;quot;Replica to promote&amp;quot;: &amp;quot;kpostgres-2&amp;quot;}&#xD;&#xA;2023-04-19T20:11:33.712923151Z 1.6819350937128017e+09   INFO    controllers.Kubegres    FailOver: Promoting Replica to Primary. {&amp;quot;Replica to promote&amp;quot;: &amp;quot;kpostgres-2&amp;quot;}&#xD;&#xA;2023-04-19T20:11:33.713030040Z 1.6819350937129502e+09   DEBUG   events  Normal  {&amp;quot;object&amp;quot;: {&amp;quot;kind&amp;quot;:&amp;quot;Kubegres&amp;quot;,&amp;quot;namespace&amp;quot;:&amp;quot;kubegres-system&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;kpostgres&amp;quot;,&amp;quot;uid&amp;quot;:&amp;quot;56c2a503-93f5-4bf8-8d0a-fe88cdaf2bde&amp;quot;,&amp;quot;apiVersion&amp;quot;:&amp;quot;kubegres.reactive-tech.io/v1&amp;quot;,&amp;quot;resourceVersion&amp;quot;:&amp;quot;95195&amp;quot;}, &amp;quot;reason&amp;quot;: &amp;quot;FailOver&amp;quot;, &amp;quot;message&amp;quot;: &amp;quot;FailOver: Promoting Replica to Primary. &#39;Replica to promote&#39;: kpostgres-2&amp;quot;}&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;La nouvelle connexion indique que l&amp;#8217;on a changé de host:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl run postgresql-postgresql-client --rm --tty -i --restart=&#39;Never&#39; --namespace kubegres-system  --image postgres:15.2 --env=&amp;quot;PGPASSWORD=capdata&amp;quot; --command -- psql --host kpostgres -U postgres -c &amp;quot;select inet_server_addr();&amp;quot;&#xD;&#xA; inet_server_addr&#xD;&#xA;------------------&#xD;&#xA; 172.17.0.6&#xD;&#xA;(1 row)&#xD;&#xA;&#xD;&#xA;pod &amp;quot;postgresql-postgresql-client&amp;quot; deleted&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Si on inventorie les objets, on voit qu&amp;#8217;un nouveau Pod et StatefulSet ont été créés (AGE=43s):&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl get pods,svc,statefulset -n kubegres-system&#xD;&#xA;NAME                                               READY   STATUS    RESTARTS       AGE&#xD;&#xA;pod/kpostgres-2-0                                  1/1     Running   0              85s&#xD;&#xA;pod/kpostgres-3-0                                  1/1     Running   0              43s&#xD;&#xA;pod/kubegres-controller-manager-794468bbff-bxzxk   2/2     Running   18 (41m ago)   6d7h&#xD;&#xA;&#xD;&#xA;NAME                                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE&#xD;&#xA;service/kpostgres                                     ClusterIP   None            &amp;lt;none&amp;gt;        5432/TCP   6d5h&#xD;&#xA;service/kpostgres-replica                             ClusterIP   None            &amp;lt;none&amp;gt;        5432/TCP   6d5h&#xD;&#xA;service/kubegres-controller-manager-metrics-service   ClusterIP   10.100.182.92   &amp;lt;none&amp;gt;        8443/TCP   6d7h&#xD;&#xA;&#xD;&#xA;NAME                           READY   AGE&#xD;&#xA;statefulset.apps/kpostgres-2   1/1     6d5h&#xD;&#xA;statefulset.apps/kpostgres-3   1/1     43s&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h2&gt;Paramétrer des sauvegardes&lt;/h2&gt;&#xA;&lt;p&gt;Pour pouvoir générer des sauvegardes de type pg_dumpall, il suffit de créer un PVC dédié et de rajouter une planification dans notre fichier de déploiement, qui à son tour va créer une ressource de type CronJob: &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ vi postgres-backup.yaml&#xD;&#xA;(...)&#xD;&#xA;apiVersion: v1&#xD;&#xA;kind: PersistentVolumeClaim&#xD;&#xA;metadata:&#xD;&#xA;  name: my-backup-pvc&#xD;&#xA;  namespace: kubegres-system&#xD;&#xA;spec:&#xD;&#xA;  storageClassName: &amp;quot;standard&amp;quot;&#xD;&#xA;  accessModes:&#xD;&#xA;    - ReadWriteOnce&#xD;&#xA;  resources:&#xD;&#xA;    requests:&#xD;&#xA;      storage: 200Mi&#xD;&#xA;&#xD;&#xA;$ kubectl apply -f postgres-backup.yaml&#xD;&#xA;persistentvolumeclaim/my-backup-pvc created&#xD;&#xA;&#xD;&#xA;$ kubectl get pvc -n kubegres-system&#xD;&#xA;NAME                         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE&#xD;&#xA;my-backup-pvc                Bound    pvc-b84656cd-904b-4a2b-89b1-e43ddb062be8   200Mi      RWO            standard       16s&#xD;&#xA;postgres-db-kpostgres-1-0    Bound    pvc-03f2e981-a1aa-446e-8f63-e5164a59f742   200Mi      RWO            standard       6d6h&#xD;&#xA;postgres-db-kpostgres-2-0    Bound    pvc-cbdf5810-e5e0-4950-8b06-5243f835be7d   200Mi      RWO            standard       6d6h&#xD;&#xA;postgres-db-kpostgres-3-0    Bound    pvc-dffef05b-f7b6-4618-802f-5fbfff2a0cba   200Mi      RWO            standard       37m&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Le CronJob est alors en place, on a programmé toutes les 5 minutes pour en voir passer un assez rapidement quand même :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl get CronJob -n kubegres-system&#xD;&#xA;NAME               SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE&#xD;&#xA;backup-kpostgres   */5 * * * *   False     0        72s             3m38s&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Pour gérer le backup, kubegres créé un nouveau pod à chaque fois, ce qui permet de contrôler le bon fonctionnement des sauvegardes: &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;$ kubectl get pods -n kubegres-system&#xD;&#xA;NAME                                           READY   STATUS      RESTARTS       AGE&#xD;&#xA;backup-kpostgres-28032310-97jqx                0/1     Completed   0              85s&#xD;&#xA;kpostgres-4-0                                  1/1     Running     0              5m2s&#xD;&#xA;kpostgres-5-0                                  1/1     Running     0              4m4s&#xD;&#xA;kubegres-controller-manager-794468bbff-bxzxk   2/2     Running     18 (99m ago)   6d8h&#xD;&#xA;&#xD;&#xA;$ kubectl logs backup-kpostgres-28032310-97jqx -n kubegres-system&#xD;&#xA;19/04/2023 21:10:01 - Starting DB backup of Kubegres resource kpostgres into file: /var/lib/backup/kpostgres-backup-19_04_2023_21_10_01.gz&#xD;&#xA;19/04/2023 21:10:01 - Running: pg_dumpall -h kpostgres-replica -U postgres -c | gzip &amp;gt; /var/lib/backup/kpostgres-backup-19_04_2023_21_10_01.&#xD;&#xA;gz&#xD;&#xA;19/04/2023 21:10:01 - DB backup completed for Kubegres resource kpostgres into file: /var/lib/backup/kpostgres-backup-19_04_2023_21_10_01.gz&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;h2&gt;Conclusion&lt;/h2&gt;&#xA;&lt;p&gt;Kubegres apporte une grande aisance dans le déploiement de clusters PostgreSQL avec Streaming Replication. Il aurait été beaucoup plus fastidieux ici de tout créer à la main.&lt;br /&gt;&#xA;Nous ne l&amp;#8217;avons pas abordé ici, mais il est aussi possible de customiser la configuration en réalisant son propre ConfigMap, créer d&amp;#8217;autres PVC pour gérer les archives etc&amp;#8230; Dans le prochain épisode, nous le comparerons à &lt;a href=&#34;https://github.com/CrunchyData/postgres-operator&#34;&gt;PGO&lt;/a&gt;, l&amp;#8217;opérateur concurrent de CrunchyDB.&lt;/p&gt;&#xA;&lt;p&gt;A bientôt et doucement sur les chocolats &lt;img src=&#34;https://s.w.org/images/core/emoji/14.0.0/72x72/1f642.png&#34; alt=&#34;🙂&#34; class=&#34;wp-smiley&#34; style=&#34;height: 1em; max-height: 1em;&#34; /&gt; !&lt;br /&gt;&#xA;&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pgo-operateurs-kubernetes-pour-postgresql-la-suite/&#34; rel=&#34;bookmark&#34; title=&#34;6 juin 2023&#34;&gt;PGO : opérateurs kubernetes pour PostgreSQL, la suite !&lt;/a&gt; (David Baffaleuf) [ContainerDevopsPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/&#34; rel=&#34;bookmark&#34; title=&#34;29 mars 2023&#34;&gt;PostgreSQL sur la solution Kubernetes locale Minikube&lt;/a&gt; (Emmanuel RAMI) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/comparatif-des-gestionnaires-de-vip-dans-un-cluster-patroni-episode-2-vip-manager/&#34; rel=&#34;bookmark&#34; title=&#34;11 mars 2022&#34;&gt;Comparatif des gestionnaires de VIP dans un cluster Patroni : épisode 2 (VIP-MANAGER)&lt;/a&gt; (David Baffaleuf) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/comparatif-des-gestionnaires-de-vip-dans-un-cluster-patroni-episode-1-keepalived/&#34; rel=&#34;bookmark&#34; title=&#34;6 mars 2022&#34;&gt;Comparatif des gestionnaires de VIP dans un cluster Patroni : épisode 1 (KEEPALIVED)&lt;/a&gt; (David Baffaleuf) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-la-streaming-replication-en-12/&#34; rel=&#34;bookmark&#34; title=&#34;19 novembre 2019&#34;&gt;PostgreSQL : la streaming replication en 12.&lt;/a&gt; (Emmanuel RAMI) [PostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 3.048 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9778&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9778&amp;#038;title=Kubegres%20%3A%20l%E2%80%99op%C3%A9rateur%20Kubernetes%20cl%C3%A9%20en%20main%20pour%20PostgreSQL&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=Kubegres%20%3A%20l%E2%80%99op%C3%A9rateur%20Kubernetes%20cl%C3%A9%20en%20main%20pour%20PostgreSQL&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9778&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/&#34;&gt;Kubegres : l&amp;#8217;opérateur Kubernetes clé en main pour PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Hello à toutes et tous ! Pour faire suite à l&amp;#8217;article d&amp;#8217;Emmanuel sur l&amp;#8217;installation de PostgreSQL sur un cluster minikube local, aujourd&amp;#8217;hui nous allons découvrir l&amp;#8217;opérateur Kubegres qui permet de facilement déployer un cluster PostgreSQL avec Primary et Standby à&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/&#34;&gt;Kubegres : l&amp;#8217;opérateur Kubernetes clé en main pour PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL sur la solution Kubernetes locale Minikube</title>
    <updated>2023-03-29T14:42:35Z</updated>
    <id>tag:blog.capdata.fr,2023-03-29:/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9753&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9753&amp;#038;title=PostgreSQL%20sur%20la%20solution%20Kubernetes%20locale%20Minikube&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%20sur%20la%20solution%20Kubernetes%20locale%20Minikube&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9753&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34; wp-image-9756&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/03/istockphoto-486570435-612x612-1-300x200.jpg&#34; alt=&#34;&#34; width=&#34;490&#34; height=&#34;326&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/03/istockphoto-486570435-612x612-1-300x200.jpg 300w, https://blog.capdata.fr/wp-content/uploads/2023/03/istockphoto-486570435-612x612-1.jpg 612w&#34; sizes=&#34;(max-width: 490px) 100vw, 490px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Hello&lt;/p&gt;&#xA;&lt;p&gt;Il y a quelques temps, je vous avais présenté un premier article sur l&amp;#8217;installation d&amp;#8217;une instance de base de données PostgreSQL sous Docker. C&amp;#8217;est &lt;a href=&#34;https://blog.capdata.fr/index.php/containeriser-une-base-de-donnees-postgresql-avec-docker/&#34;&gt;cet article&lt;/a&gt; qui nous a permis de mettre un premier pas dans le monde de la containerisation de services.&lt;/p&gt;&#xA;&lt;p&gt;L&amp;#8217;article d&amp;#8217;aujourd&amp;#8217;hui reprend les mêmes concepts, à savoir, comment installer et configurer PostgreSQL sous &lt;a href=&#34;https://minikube.sigs.k8s.io/docs/&#34;&gt;minikube&lt;/a&gt; et &lt;a href=&#34;https://kubernetes.io/fr/&#34;&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2&gt;Présentation de l&amp;#8217;environnement Kubernetes&lt;/h2&gt;&#xA;&lt;p&gt;Avant de présenter Minikube, il nous faut parler de Kubernetes.&lt;/p&gt;&#xA;&lt;p&gt;Kubernetes est un outil d&amp;#8217;orchestration de conteneurs. En d&amp;#8217;autres termes, celui ci permet de gérer des déploiements d&amp;#8217;applications directement via une plate forme open-source.&lt;br /&gt;&#xA;Pour le fonctionnement, il nous faut un environnement virtualisé avec l&amp;#8217;hyperviseur qui communique avec les couches applicatives précompilées embarquant leurs librairies. Ce sont donc ces couches applicatives que l&amp;#8217;on appelle containers et qui peuvent être utilisées sur des serveurs &amp;#8220;on premise&amp;#8221; ou dans un service Cloud.&lt;/p&gt;&#xA;&lt;p&gt;C&amp;#8217;est autour de ce concept que Minikube s&amp;#8217;est créé. Cet outil utilise les fonctionnalités propres à Kubernetes mais assure un déploiement sur un noeud unique.&lt;/p&gt;&#xA;&lt;p&gt;Il vous est donc possible de profiter d&amp;#8217;un éco-système Kubernetes complet sur un simple PC de bureau (avec une configuration RAM/Cpu exigeante) .&lt;/p&gt;&#xA;&lt;p&gt;L&amp;#8217;objectif de cet article est donc de déployer une instance PostgreSQL sur Minikube.&lt;/p&gt;&#xA;&lt;h2&gt;Prérequis propres à AWS&lt;/h2&gt;&#xA;&lt;p&gt;Si, comme moi, vous utilisez des VMs EC2 AWS, il y a quelques informations à connaître.&lt;/p&gt;&#xA;&lt;p&gt;Tout d&amp;#8217;abord, il faut savoir que AWS met à disposition un service nommé EKS, &lt;a href=&#34;https://aws.amazon.com/fr/eks/&#34;&gt;Elastic Kubernetes Service&lt;/a&gt;, pour la gestion de clusters directement intégré dans AWS.&lt;br /&gt;&#xA;Il n&amp;#8217;est donc pas nécessaire de configurer manuellement Kubernetes via des commandes &amp;#8220;kubectl&amp;#8221;. De plus les mises à jour des outils sont automatisées.&lt;/p&gt;&#xA;&lt;p&gt;AWS met également à disposition &lt;a href=&#34;https://aws.amazon.com/fr/fargate/&#34;&gt;AWS Fargate&lt;/a&gt;. Un service qui permet de configurer des containers, sans se soucier des types de serveurs à mettre à disposition. L&amp;#8217;utilisateur de cette solution ne voit donc que le coté application, ses besoins en terme de scalabilité, et AWS fait le reste.&lt;/p&gt;&#xA;&lt;p&gt;Mais pour notre article, comme nous souhaitons utiliser Minikube, il nous faut une VM supportant les exigences de la virtualisation. Or sous AWS, ce sont les instances EC2 de type &amp;#8220;bare metal&amp;#8221; qui répondent à ce besoin. Attention donc à regarder ce point, et surtout prendre en considération la partie facturation qui est loin d&amp;#8217;être négligeable&lt;/p&gt;&#xA;&lt;p&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; class=&#34;alignnone wp-image-9755 size-full&#34; src=&#34;https://blog.capdata.fr/wp-content/uploads/2023/03/ec2_metal.jpg&#34; alt=&#34;&#34; width=&#34;1356&#34; height=&#34;606&#34; srcset=&#34;https://blog.capdata.fr/wp-content/uploads/2023/03/ec2_metal.jpg 1356w, https://blog.capdata.fr/wp-content/uploads/2023/03/ec2_metal-300x135.jpg 300w, https://blog.capdata.fr/wp-content/uploads/2023/03/ec2_metal-1024x458.jpg 1024w, https://blog.capdata.fr/wp-content/uploads/2023/03/ec2_metal-768x343.jpg 768w&#34; sizes=&#34;(max-width: 1356px) 100vw, 1356px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Pour notre exemple, nous partirons sur une instance EC2 &amp;#8220;c5.metal&amp;#8221;. Ce type d&amp;#8217;instance permet la virtualisation.&lt;/p&gt;&#xA;&lt;h2&gt;Les différentes étapes d&amp;#8217;installation&lt;/h2&gt;&#xA;&lt;p&gt;Il conviendra de s&amp;#8217;assurer que les CPU de notre instance acceptent la virtualisation. Passer les commandes ci après&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# egrep -q &#39;vmx|svm&#39; /proc/cpuinfo  &amp;quot;&amp;amp;&amp;amp;&amp;quot; echo yes || echo no&#xD;&#xA;yes&lt;/pre&gt;&#xA;&lt;p&gt;ou&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# grep -E &amp;quot;vmx|svm&amp;quot; /proc/cpuinfo&#xD;&#xA;flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni md_clear flush_l1d arch_capabilities&#xD;&#xA;flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni md_clear flush_l1d arch_capabilities&#xD;&#xA;.........&lt;/pre&gt;&#xA;&lt;p&gt;Le système d&amp;#8217;exploitation choisi pour ce serveur est un Rocky Linux 8.7 , un fork Red Hat avec lequel nous pourrons gérer nos packages d&amp;#8217;installation via yum.&lt;br /&gt;&#xA;Plusieurs packages sont à intégrer afin de faire fonctionner notre cluster mono nœud.&lt;/p&gt;&#xA;&lt;h3&gt;Installer la couche KVM&lt;/h3&gt;&#xA;&lt;p&gt;Afin de pouvoir installer Minikube, il nous faut un gestionnaire de container.&lt;br /&gt;&#xA;Pour l&amp;#8217;article propre à Docker, nous avions utilisé le Docker Engine, qui a la particularité de pouvoir se passer de la partie Virtualisation et d&amp;#8217;hyperviseur.&lt;/p&gt;&#xA;&lt;p&gt;Pour notre exemple, l&amp;#8217;idée est d&amp;#8217;utiliser KVM (Kernel-linux Virtual Machine), qui nécessite une virtualisation active.&lt;br /&gt;&#xA;Installer les packages suivants sur le serveur&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# yum update&#xD;&#xA;# yum install qemu-kvm libvirt libguestfs-tools virt-install&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;La librairie de virtualisation doit être activée et le service démarré automatiquement&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# systemctl enable libvirtd.service&#xD;&#xA;# systemctl start libvirtd.service&lt;/pre&gt;&#xA;&lt;h3&gt;Installer helm et kubectl&lt;/h3&gt;&#xA;&lt;p&gt;Ces outils sont nécessaires à l&amp;#8217;administration de notre cluster, et l&amp;#8217;installation d&amp;#8217;applications. Helm nous sert à installer PostgreSQL depuis un repository, et kubectl est un interpréteur de commandes pour  notre cluster.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# curl -LO &amp;quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&amp;quot;&#xD;&#xA;% Total % Received % Xferd Average Speed Time Time Time Current&#xD;&#xA;Dload Upload Total Spent Left Speed&#xD;&#xA;100 138 100 138 0 0 1179 0 --:--:-- --:--:-- --:--:-- 1179&#xD;&#xA;100 45.8M 100 45.8M 0 0 70.1M 0 --:--:-- --:--:-- --:--:-- 117M&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3&#xD;&#xA;&#xD;&#xA;# chmod 700 get_helm.sh&#xD;&#xA;# ./get_helm.sh&#xD;&#xA;Downloading https://get.helm.sh/helm-v3.11.2-linux-amd64.tar.gz&#xD;&#xA;Verifying checksum... Done.&#xD;&#xA;Preparing to install helm into /usr/local/bin&#xD;&#xA;helm installed into /usr/local/bin/helm&lt;/pre&gt;&#xA;&lt;p&gt;Installer ces binaires dans &amp;#8220;/usr/local/bin&amp;#8221;. Attention, par la suite, votre variable PATH doit contenir le chemin vers ce répertoire.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# install kubectl /usr/local/bin/kubectl&#xD;&#xA;# install helm /usr/local/bin/helm&#xD;&#xA;# chmod 755 /usr/local/bin/helm&#xD;&#xA;# chmod 755 /usr/local/bin/kubectl&lt;/pre&gt;&#xA;&lt;p&gt;Valider l&amp;#8217;installation de helm et kubectl.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; # helm version&#xD;&#xA;version.BuildInfo{&#xD;&#xA;Version:&amp;quot;v3.11.2&amp;quot;, &#xD;&#xA;GitCommit:&amp;quot;912ebc1cd10d38d340f048efaf0abda047c3468e&amp;quot;, &#xD;&#xA;GitTreeState:&amp;quot;clean&amp;quot;, &#xD;&#xA;GoVersion:&amp;quot;go1.18.10&amp;quot;&#xD;&#xA;}&lt;/pre&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# kubectl version -o json&#xD;&#xA;{&#xD;&#xA;&amp;quot;clientVersion&amp;quot;: {&#xD;&#xA;&amp;quot;major&amp;quot;: &amp;quot;1&amp;quot;,&#xD;&#xA;&amp;quot;minor&amp;quot;: &amp;quot;26&amp;quot;,&#xD;&#xA;&amp;quot;gitVersion&amp;quot;: &amp;quot;v1.26.2&amp;quot;,&#xD;&#xA;&amp;quot;gitCommit&amp;quot;: &amp;quot;fc04e732bb3e7198d2fa44efa5457c7c6f8c0f5b&amp;quot;,&#xD;&#xA;&amp;quot;gitTreeState&amp;quot;: &amp;quot;clean&amp;quot;,&#xD;&#xA;&amp;quot;buildDate&amp;quot;: &amp;quot;2023-02-22T13:39:03Z&amp;quot;,&#xD;&#xA;&amp;quot;goVersion&amp;quot;: &amp;quot;go1.19.6&amp;quot;,&#xD;&#xA;&amp;quot;compiler&amp;quot;: &amp;quot;gc&amp;quot;,&#xD;&#xA;&amp;quot;platform&amp;quot;: &amp;quot;linux/amd64&amp;quot;&#xD;&#xA;},&#xD;&#xA;&amp;quot;kustomizeVersion&amp;quot;: &amp;quot;v4.5.7&amp;quot;&#xD;&#xA;}&lt;/pre&gt;&#xA;&lt;h3 tabindex=&#34;0&#34;&gt;Installation de minikube&lt;/h3&gt;&#xA;&lt;p&gt;Télécharger et installer le binaire Minikube, puis le placer dans le répertoire &amp;#8220;/usr/local/bin&amp;#8221;.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64&#xD;&#xA;# install minikube-linux-amd64 /usr/local/bin/minikube&lt;/pre&gt;&#xA;&lt;p&gt;Attention, minikube doit fonctionner avec un utilisateur linux dédié, autre que &amp;#8220;root&amp;#8221;. Il convient donc de créer un utilisateur appartenant aux 2 groupes &amp;#8220;libvirt&amp;#8221; et &amp;#8220;qemu&amp;#8221;.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# useradd -u 1001 -g qemu -G qemu,libvirt manu&#xD;&#xA;# passwd manu&lt;/pre&gt;&#xA;&lt;p&gt;Se connecter avec ce nouvel utilisateur et vérifier ses groupes.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;# su - manu&#xD;&#xA;[manu@ ~]$ id&#xD;&#xA;uid=1001(manu) gid=107(qemu) groups=107(qemu),986(libvirt) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023&lt;/pre&gt;&#xA;&lt;h2&gt;Gestion du cluster Minikube&lt;/h2&gt;&#xA;&lt;p&gt;Une fois les packages installés il nous faut démarrer Minikube avec notre compte linux dédié.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;manu@~$ minikube start --driver=kvm2&#xD;&#xA;* minikube v1.29.0 on Rocky 8.7&#xD;&#xA;* Using the kvm2 driver based on user configuration&#xD;&#xA;* Downloading driver docker-machine-driver-kvm2:&#xD;&#xA; docker-machine-driver-kvm2-...: 65 B / 65 B [---------] 100.00% ? p/s 0s&#xD;&#xA; docker-machine-driver-kvm2-...: 12.30 MiB / 12.30 MiB 100.00% 13.05 MiB&#xD;&#xA;* Downloading VM boot image ...&#xD;&#xA; minikube-v1.29.0-amd64.iso....: 65 B / 65 B [---------] 100.00% ? p/s 0s&#xD;&#xA; minikube-v1.29.0-amd64.iso: 276.35 MiB / 276.35 MiB 100.00% 167.79 MiB&#xD;&#xA;* Starting control plane node minikube in cluster minikube&#xD;&#xA;* Downloading Kubernetes v1.26.1 preload ...&#xD;&#xA; preloaded-images-k8s-v18-v1...: 397.05 MiB / 397.05 MiB 100.00% 111.49&#xD;&#xA;* Creating kvm2 VM (CPUs=2, Memory=6000MB, Disk=20000MB) ...&#xD;&#xA;* Preparing Kubernetes v1.26.1 on Docker 20.10.23 ...&#xD;&#xA;- Generating certificates and keys ...&#xD;&#xA;- Booting up control plane ...&#xD;&#xA;- Configuring RBAC rules ...&#xD;&#xA;* Configuring bridge CNI (Container Networking Interface) ...&#xD;&#xA;- Using image gcr.io/k8s-minikube/storage-provisioner:v5&#xD;&#xA;* Verifying Kubernetes components...&#xD;&#xA;* Enabled addons: storage-provisioner, default-storageclass&#xD;&#xA;* Done! kubectl is now configured to use &amp;quot;minikube&amp;quot; cluster and &amp;quot;default&amp;quot; namespace by default&lt;/pre&gt;&#xA;&lt;p&gt;Au premier démarrage, Minikube cherche  les différentes images dont il a besoin.&lt;br /&gt;&#xA;Le démarrage suivant donnera ce résultat :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~$ minikube start&#xD;&#xA;* minikube v1.29.0 on Rocky 8.7&#xD;&#xA;* Using the kvm2 driver based on existing profile&#xD;&#xA;* Starting control plane node minikube in cluster minikube&#xD;&#xA;* Restarting existing kvm2 VM for &amp;quot;minikube&amp;quot; ...&#xD;&#xA;* Preparing Kubernetes v1.26.1 on Docker 20.10.23 ...&#xD;&#xA;* Configuring bridge CNI (Container Networking Interface) ...&#xD;&#xA;* Verifying Kubernetes components...&#xD;&#xA;- Using image gcr.io/k8s-minikube/storage-provisioner:v5&#xD;&#xA;- Using image docker.io/kubernetesui/dashboard:v2.7.0&#xD;&#xA;- Using image docker.io/kubernetesui/metrics-scraper:v1.0.8&#xD;&#xA;* Some dashboard features require the metrics-server addon. To enable all features please run:&#xD;&#xA;&#xD;&#xA;minikube addons enable metrics-server&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;* Enabled addons: storage-provisioner, dashboard, default-storageclass&#xD;&#xA;* Done! kubectl is now configured to use &amp;quot;minikube&amp;quot; cluster and &amp;quot;default&amp;quot; namespace by default&lt;/pre&gt;&#xA;&lt;p&gt;Minikube est maintenant actif sur notre serveur.&lt;/p&gt;&#xA;&lt;p&gt;Vérifier l&amp;#8217;état de la couche virtualisation.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~ $ sudo virsh net-list --all&#xD;&#xA;Name        State  Autostart Persistent&#xD;&#xA;------------------------------------------------&#xD;&#xA;default     active yes       yes&#xD;&#xA;mk-minikube active yes       yes&lt;/pre&gt;&#xA;&lt;p&gt;Valider notre cluster avec &amp;#8220;kubctl&amp;#8221;&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~$ kubectl get nodes&#xD;&#xA;NAME      STATUS ROLES         AGE  VERSION&#xD;&#xA;minikube  Ready  control-plane 35m  v1.26.1&lt;/pre&gt;&#xA;&lt;p&gt;Pour arrêter le cluster&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~$ minikube stop&#xD;&#xA;* Stopping node &amp;quot;minikube&amp;quot; ...&#xD;&#xA;* 1 node stopped.&lt;/pre&gt;&#xA;&lt;h2&gt;Déploiement générique de PostgreSQL sur Minikube&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;#8217;outil helm permet de déployer simplement une instance PostgreSQL sur notre cluster mono-nœud Minikube.&lt;br /&gt;&#xA;Pour cela, utilisons le repository &amp;#8220;bitnami&amp;#8221; via le site : https://charts.bitnami.com/bitnami.&lt;/p&gt;&#xA;&lt;p&gt;Le fonctionnement s&amp;#8217;apparente &amp;#8220;un peu&amp;#8221; à yum pour un système RedHat, il s&amp;#8217;agit d&amp;#8217;une source vers laquelle chercher pour enregistrer des applications à containeriser.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;manu@ ~$ helm repo add bitnami https://charts.bitnami.com/bitnami&#xD;&#xA;&amp;quot;bitnami&amp;quot; has been added to your repositories&lt;/pre&gt;&#xA;&lt;p&gt;Une fois le repository initier, vérifier les versions PostgreSQL disponibles.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~ $ helm search repo postgres&#xD;&#xA;NAME                         CHART VERSION   APP VERSION            DESCRIPTION&#xD;&#xA;bitnami/postgresql           12.2.5          15.2.0                 PostgreSQL (Postgres) is an open source object-...&#xD;&#xA;bitnami/postgresql-ha        11.1.6          15.2.0                 This PostgreSQL cluster solution includes the P...&#xD;&#xA;bitnami/supabase             0.1.4           0.23.2                 Supabase is an open source Firebase alternative...&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Le repository bitnami nous propose la dernière version 15.2 de PostgreSQL. Nous allons l&amp;#8217;installer pour notre environnement minikube.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~ $ helm install postgres bitnami/postgresql&#xD;&#xA;NAME: postgres&#xD;&#xA;LAST DEPLOYED: Mon Mar 20 15:41:00 2023&#xD;&#xA;NAMESPACE: default&#xD;&#xA;STATUS: deployed&#xD;&#xA;REVISION: 1&#xD;&#xA;TEST SUITE: None&#xD;&#xA;NOTES:&#xD;&#xA;CHART NAME: postgresql&#xD;&#xA;CHART VERSION: 12.2.5&#xD;&#xA;APP VERSION: 15.2.0&#xD;&#xA;&#xD;&#xA;** Please be patient while the chart is being deployed **&#xD;&#xA;&#xD;&#xA;PostgreSQL can be accessed via port 5432 on the following DNS names from within your cluster:&#xD;&#xA;&#xD;&#xA;postgres-postgresql.default.svc.cluster.local - Read/Write connection&#xD;&#xA;&#xD;&#xA;To get the password for &amp;quot;postgres&amp;quot; run:&#xD;&#xA;&#xD;&#xA;export POSTGRES_PASSWORD=$(kubectl get secret --namespace default postgres-postgresql -o jsonpath=&amp;quot;{.data.postgres-password}&amp;quot; | base64 -d)&#xD;&#xA;&#xD;&#xA;To connect to your database run the following command:&#xD;&#xA;&#xD;&#xA;kubectl run postgres-postgresql-client --rm --tty -i --restart=&#39;Never&#39; --namespace default --image docker.io/bitnami/postgresql:15.2.0-debian-11-r13 --env=&amp;quot;PGPASSWORD=$POSTGRES_PASSWORD&amp;quot; \&#xD;&#xA;--command -- psql --host postgres-postgresql -U postgres -d postgres -p 5432&#xD;&#xA;&#xD;&#xA; NOTE: If you access the container using bash, make sure that you execute &amp;quot;/opt/bitnami/scripts/postgresql/entrypoint.sh /bin/bash&amp;quot; in order to avoid the error &amp;quot;psql: local user with ID 1001} does not exist&amp;quot;&#xD;&#xA;&#xD;&#xA;To connect to your database from outside the cluster execute the following commands:&#xD;&#xA;&#xD;&#xA;kubectl port-forward --namespace default svc/postgres-postgresql 5432:5432 &amp;quot;&amp;amp;&amp;quot; PGPASSWORD=&amp;quot;$POSTGRES_PASSWORD&amp;quot; psql --host 127.0.0.1 -U postgres -d postgres -p 5432&#xD;&#xA;&#xD;&#xA;WARNING: The configured password will be ignored on new installation in case when previous Posgresql release was deleted through the helm command. In that case, old PVC will have an old password, and setting it through helm won&#39;t take effect. Deleting persistent volumes (PVs) will solve the issue.&lt;/pre&gt;&#xA;&lt;p&gt;Vérifier le déploiement dans le repository&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~ $ helm list&#xD;&#xA;NAME     NAMESPACE REVISION UPDATED                                 STATUS   CHART             APP VERSION&#xD;&#xA;postgres default   1        2023-03-20 15:41:00.677760646 +0000 UTC deployed postgresql-12.2.5 15.2.0&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Notre application containerisée PostgreSQL est bien déployée dans le repository.&lt;/p&gt;&#xA;&lt;p&gt;Vérifier son installation dans le cluster minikube et voir les différents services présents :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~ $ kubectl get deployment,pods,svc&#xD;&#xA;NAME                                                READY STATUS  RESTARTS AGE&#xD;&#xA;pod/postgres-postgresql-0                           1/1   Running 0        18m&#xD;&#xA;&#xD;&#xA;NAME                           TYPE       CLUSTER-IP    EXTERNAL-IP  PORT(S)  AGE&#xD;&#xA;service/kubernetes             ClusterIP  10.96.0.1     none         443/TCP  36m&#xD;&#xA;service/postgres-postgresql    ClusterIP  10.109.83.132 none         5432/TCP 18m&#xD;&#xA;service/postgres-postgresql-hl ClusterIP  None          none         5432/TCP 18m&lt;/pre&gt;&#xA;&lt;p&gt;Nous remarquons que notre application PostgreSQL est enregistrée sous l&amp;#8217;adresse IP  10.109.83.132. Le port de communication est 5432.&lt;br /&gt;&#xA;C&amp;#8217;est cette adresse qui sera référencée comme VIP pour notre cluster.&lt;/p&gt;&#xA;&lt;h3&gt;Connexion à l&amp;#8217;instance PostgreSQL&lt;/h3&gt;&#xA;&lt;p&gt;Lors de l&amp;#8217;installation, les instructions de connexion nous ont été données (notamment la gestion du password de connexion).&lt;/p&gt;&#xA;&lt;p&gt;Pour retrouver le password postgres, c&amp;#8217;est l&amp;#8217;outil &amp;#8220;kubectl&amp;#8221; qui est appelé.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~ $ kubectl get secret --namespace default postgres-postgresql -o jsonpath=&amp;quot;{.data.postgres-password}&amp;quot; | base64 -d&#xD;&#xA;HvbCO9Co5R&lt;/pre&gt;&#xA;&lt;p&gt;Enregistrer cette valeur dans une variable que l&amp;#8217;on peut nommer PGPASS par exemple.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~$ export PGPASS=$(kubectl get secret --namespace default postgres-postgresql -o jsonpath=&amp;quot;{.data.postgres-password}&amp;quot; | base64 --decode)&lt;/pre&gt;&#xA;&lt;p&gt;Lancer la commande, indiquée lors de l&amp;#8217;installation de PostgreSQL avec &amp;#8220;helm&amp;#8221;, pour se connecter à l&amp;#8217;instance.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@~$ kubectl run postgres-postgresql-client --rm --tty -i --restart=&#39;Never&#39; --namespace default --image docker.io/bitnami/postgresql:15.2.0-debian-11-r13 --env=&amp;quot;PGPASSWORD=$PGPASS&amp;quot; --command -- psql --host postgres-postgresql -U postgres -d postgres -p 5432&#xD;&#xA;If you don&#39;t see a command prompt, try pressing enter.&#xD;&#xA;&#xD;&#xA;postgres=# \l+&#xD;&#xA;                                                     List of databases&#xD;&#xA;Name       | Owner    | Encoding | Collate     | Ctype       | Access privileges     | Size    | Tablespace | Description&#xD;&#xA;-----------+----------+----------+-------------+-------------+-----------------------+---------+------------+--------------------------------------------&#xD;&#xA;postgres   | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7453 kB | pg_default | default administrative connection database&#xD;&#xA;template0  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7297 kB | pg_default | unmodifiable empty database&#xD;&#xA;           |          |          |             |             | postgres=CTc/postgres |         |            |&#xD;&#xA;template1  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7525 kB | pg_default | default template for new databases&#xD;&#xA;           |          |          |             |             | postgres=CTc/postgres |         |            |&#xD;&#xA;(3 rows)&#xD;&#xA;&#xD;&#xA;postgres=# select version();&#xD;&#xA;version&#xD;&#xA;---------------------------------------------------------------------------------------------------&#xD;&#xA;PostgreSQL 15.2 on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit&#xD;&#xA;(1 row)&lt;/pre&gt;&#xA;&lt;p&gt;Pour se connecter à cette instance PostgreSQL, nous avons lancé une application &amp;#8220;PostgreSQL cliente&amp;#8221; déployée à partir d&amp;#8217;une image Docker &amp;#8216;docker.io/bitnami/postgresql:15.2.0-debian-11-r13&amp;#8217;  en PostgreSQL version 15.2 compilée sous un Debian 11.13. Cette application une fois déployée, nous permet d&amp;#8217;exécuter l&amp;#8217;outil &amp;#8220;psql&amp;#8221; pour se connecter.&lt;/p&gt;&#xA;&lt;p&gt;A noter qu&amp;#8217;à la première exécution, cette image est enregistrée dans le node minikube&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@ ~$ kubectl get pods -o wide&#xD;&#xA;NAME                        READY  STATUS    RESTARTS    AGE IP          NODE     NOMINATED NODE READINESS GATES&#xD;&#xA;postgres-postgresql-0       1/1    Running   2 (25m ago) 24h 10.244.0.17 minikube none      none &#xD;&#xA;postgres-postgresql-client  0/1    Completed 0           16m 10.244.0.19 minikube none      none &lt;/pre&gt;&#xA;&lt;p&gt;Repérer le pod &amp;#8220;postgres-postgresql-client&amp;#8221;, le status est à &amp;#8220;completed&amp;#8221; car nous n&amp;#8217;avons plus de connexion active. D&amp;#8217;ailleurs, le &amp;#8220;READY&amp;#8221; est à 0/1 car aucune connexion.&lt;br /&gt;&#xA;Il est tout à fait possible de retirer cette application publiée dans les pods de minikube. Pour cela, lancer la commande :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@ ~$ kubectl delete pod postgres-postgresql-client&#xD;&#xA;pod &amp;quot;postgres-postgresql-client&amp;quot; deleted&lt;/pre&gt;&#xA;&lt;p&gt;Vérifier:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@ ~$ kubectl get pods -o wide&#xD;&#xA;NAME                   READY STATUS   RESTARTS    AGE IP           NODE      NOMINATED NODE READINESS GATES&#xD;&#xA;postgres-postgresql-0  1/1   Running  2 (25m ago) 24h 10.244.0.17  minikube  none           none&lt;/pre&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Nous venons donc d&amp;#8217;installer une instance PostgreSQL par défaut grâce à l&amp;#8217;outil helm dans notre cluster Minikube.&lt;/p&gt;&#xA;&lt;h2&gt;Configuration d&amp;#8217;instance et volume persisté sur Minikube&lt;/h2&gt;&#xA;&lt;p&gt;Afin de pouvoir conserver vos données sur disque, il est possible de monter une instance PostgreSQL avec, ce que l&amp;#8217;on appelle, un &amp;#8220;volume persisté&amp;#8221;.&lt;br /&gt;&#xA;Il faut, pour cela, dédier un FileSystem pour les données PostgreSQL sur la VM locale exécutant Minikube.&lt;/p&gt;&#xA;&lt;p&gt;De plus,  PostgreSQL peut être créé avec des valeurs de configuration différentes que ce qui est proposé avec l&amp;#8217;outil helm.&lt;/p&gt;&#xA;&lt;p&gt;L&amp;#8217;intérêt est de monter une instance pré-configurée, pour une application métier, dès le démarrage.&lt;/p&gt;&#xA;&lt;h2&gt;Les fichiers YAML&lt;/h2&gt;&#xA;&lt;p&gt;Pour le déploiement d&amp;#8217;une instance PostgreSQL spécifique, nous devons utiliser des fichiers de configuration &amp;#8220;yaml&amp;#8221; que nous chargerons dans le cluster via &amp;#8220;kubectl&amp;#8221;.&lt;/p&gt;&#xA;&lt;h4&gt;fichier YAML de configuration d&amp;#8217;instance&lt;/h4&gt;&#xA;&lt;p&gt;Un fichier &amp;#8220;configmap&amp;#8221; doit être créé si l&amp;#8217;on souhaite spécifier des informations sur les credentials (user/password), et/ou base de données métier.&lt;/p&gt;&#xA;&lt;p&gt;Utiliser pour cela le fichier yaml suivant pour créer un utilisateur &amp;#8220;&lt;strong&gt;capdata&lt;/strong&gt;&amp;#8220;, avec une base &amp;#8220;&lt;strong&gt;capddb&lt;/strong&gt;&amp;#8221; pour l&amp;#8217;application &amp;#8220;postgres&amp;#8221;.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;apiVersion: v1&#xD;&#xA;kind: ConfigMap&#xD;&#xA;metadata:&#xD;&#xA;  name: pg-capdata&#xD;&#xA;  labels:&#xD;&#xA;  app: postgres&#xD;&#xA;data:&#xD;&#xA;  POSTGRES_DB: capdb&#xD;&#xA;  POSTGRES_USER: capdata&#xD;&#xA;  POSTGRES_PASSWORD: passcapdata2023&lt;/pre&gt;&#xA;&lt;p&gt;Appliquer ce fichier à votre configuration Kubernenetes Minikube, puis valider celle ci&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;manu@~$ kubectl apply -f pg-configmap.yaml&#xD;&#xA;configmap/pg-capdata created&#xD;&#xA;&#xD;&#xA;manu@ ~$ kubectl get configmap&#xD;&#xA;NAME              DATA AGE&#xD;&#xA;kube-root-ca.crt  1    3d23h&#xD;&#xA;pg-capdata        3    4s&lt;/pre&gt;&#xA;&lt;h4&gt;fichier YAML pour les volumes&lt;/h4&gt;&#xA;&lt;p&gt;Choisir un FileSystem dédié sur le serveur, et créer le répertoire pour accueillir l&amp;#8217;instance PostgreSQL.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;manu@ ~$ df -h /data&#xD;&#xA;Filesystem     Size Used Avail Use% Mounted on&#xD;&#xA;/dev/nvme1n1p1 19G  28K  18G   1%   /data&#xD;&#xA;&#xD;&#xA;manu@ ~$ mkdir -p /data/postgresql&lt;/pre&gt;&#xA;&lt;p&gt;Nous aurons besoin de 2 fichiers yaml pour la configuration des volumes, 1 pour le volume persisté qui nous permet de conserver nos données d&amp;#8217;instance durant le cycle de vie de celle ci. De plus, il nous faut, ce que l&amp;#8217;on appelle, un &amp;#8220;Persistent Volume Claim&amp;#8221;. C&amp;#8217;est une vue logique du volume géré par le cluster Kubernetes.&lt;/p&gt;&#xA;&lt;p&gt;Les 2 fichiers contiennent les entrées suivantes :&lt;/p&gt;&#xA;&lt;p&gt;pg-data-pvc.yaml&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;apiVersion: v1&#xD;&#xA;kind: PersistentVolume &#xD;&#xA;metadata:&#xD;&#xA;  name: pg-data &#xD;&#xA;  labels:&#xD;&#xA;    type: local &#xD;&#xA;    app: postgres&#xD;&#xA;spec:&#xD;&#xA;  storageClassName: manual&#xD;&#xA;  capacity:&#xD;&#xA;    storage: 8Gi &#xD;&#xA;  accessModes:&#xD;&#xA;    - ReadWriteMany&#xD;&#xA;  hostPath:&#xD;&#xA;    path: &amp;quot;/data/postgresql&amp;quot; &lt;/pre&gt;&#xA;&lt;p&gt;pg-data-pvc.yaml&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;apiVersion: v1&#xD;&#xA;kind: PersistentVolumeClaim &#xD;&#xA;metadata:&#xD;&#xA;  name: pg-data-claim&#xD;&#xA;  labels:&#xD;&#xA;    app: postgres &#xD;&#xA;spec:&#xD;&#xA;  storageClassName: manual&#xD;&#xA;  accessModes:&#xD;&#xA;    - ReadWriteMany&#xD;&#xA;  resources:&#xD;&#xA;    requests:&#xD;&#xA;     storage: 8Gi&lt;/pre&gt;&#xA;&lt;p&gt;Charger ces 2 fichiers yaml dans Kubernetes.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;manu@ ~$ kubectl apply -f pg-data.yaml&#xD;&#xA;&#xD;&#xA;manu@ ~$ kubectl apply -f pg-data-pvc.yaml&lt;/pre&gt;&#xA;&lt;p&gt;Vérifier les informations dans le cluster&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;manu@ ~$ kubectl get pv -o wide&#xD;&#xA;NAME     CAPACITY     ACCESS MODES     RECLAIM POLICY STATUS  CLAIM STORAGECLASS     REASON  AGE    VOLUMEMODE&#xD;&#xA;pg-data  8Gi          RWX              Retain         Bound   default/pg-data-claim  manual  2m50s  Filesystem&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;manu@ ~$ kubectl get pvc -o wide&#xD;&#xA;NAME                  STATUS  VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS  AGE   VOLUMEMODE&#xD;&#xA;pg-data-claim         Bound   pg-data  8Gi        RWX            manual        94s   Filesystem&lt;/pre&gt;&#xA;&lt;h3&gt;&lt;/h3&gt;&#xA;&lt;h4&gt;Fichier YAML de déploiement&lt;/h4&gt;&#xA;&lt;p&gt;Après avoir déclarer la configuration, les volumes, nous pouvons déployer l&amp;#8217;instance dans le cluster Kubernetes. Par exemple, nous déclarons 2 répliquas d&amp;#8217;une instance PostgreSQL 15.2, écoutant sur le port 5432.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;apiVersion: apps/v1&#xD;&#xA;kind: Deployment &#xD;&#xA;metadata:&#xD;&#xA;  name: postgres&#xD;&#xA;spec:&#xD;&#xA;  replicas: 2 &#xD;&#xA;  selector:&#xD;&#xA;    matchLabels:&#xD;&#xA;      app: postgres&#xD;&#xA;  template:&#xD;&#xA;    metadata:&#xD;&#xA;      labels:&#xD;&#xA;        app: postgres&#xD;&#xA;   spec:&#xD;&#xA;      containers:&#xD;&#xA;        - name: postgres&#xD;&#xA;          image: postgres:15.2 &#xD;&#xA;          imagePullPolicy: &amp;quot;IfNotPresent&amp;quot;&#xD;&#xA;          ports:&#xD;&#xA;            - containerPort: 5432&#xD;&#xA;          envFrom:&#xD;&#xA;            - configMapRef:&#xD;&#xA;               name: pg-capdata &#xD;&#xA;          volumeMounts:&#xD;&#xA;            - mountPath: /var/lib/postgresql/data&#xD;&#xA;               name: postgresdata&#xD;&#xA;       volumes:&#xD;&#xA;        - name: postgresdata&#xD;&#xA;            persistentVolumeClaim:&#xD;&#xA;              claimName: pg-data-claim&lt;/pre&gt;&#xA;&lt;p&gt;Appliquer ce fichier yaml et vérifier que le status &amp;#8220;Running&amp;#8221; apparaisse sur les 2 répliquas PostgreSQL. On appelle &amp;#8220;pod&amp;#8221; sur Kubernetes, un container applicatif avec ses librairies embarquées.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;manu@ ~$ kubectl apply -f pg-deploiement.yaml&#xD;&#xA;deployment.apps/postgres-deploy created&#xD;&#xA;&#xD;&#xA;manu@ ~$ kubectl get pods,deployments -o wide&#xD;&#xA;NAME                             READY   STATUS   RESTARTS    AGE    IP            NODE      NOMINATED NODE   READINESS GATES&#xD;&#xA;pod/postgres-66855ddfc5-drsqj    1/1     Running  0           83s    10.244.0.3    minikube  none             none           &#xD;&#xA;pod/postgres-66855ddfc5-n9fc8    1/1     Running  1 (71s ago) 83s    10.244.0.4    minikube  none             none&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;NAME                       READY   UP-TO-DATE   AVAILABLE     AGE  CONTAINERS    IMAGES         SELECTOR&#xD;&#xA;deployment.apps/postgres   2/2     2            2             83s  postgres      postgres:15.2  app=postgres&lt;/pre&gt;&#xA;&lt;p&gt;Sur le node nommé &amp;#8220;Minikube&amp;#8221;, nous voyons donc tourner nos 2 répliquas PostgreSQL avec leurs IP en 10.244.0.***&lt;/p&gt;&#xA;&lt;h4&gt;Fichier yaml de service PostgreSQL&lt;/h4&gt;&#xA;&lt;p&gt;Afin de pouvoir se connecter à notre instance PostgreSQL, il faut lui définir un service. C&amp;#8217;est une sorte de porte d&amp;#8217;entrée pour accéder à notre instance.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: yaml; title: ; notranslate&#34;&gt;apiVersion: v1&#xD;&#xA;kind: Service&#xD;&#xA;metadata:&#xD;&#xA;  name: postgres-capdata&#xD;&#xA;  labels:&#xD;&#xA;   app: postgres &#xD;&#xA;spec:&#xD;&#xA;   type: NodePort &#xD;&#xA;  ports:&#xD;&#xA;   - port: 5432&#xD;&#xA;  selector:&#xD;&#xA;    app: postgres&lt;/pre&gt;&#xA;&lt;p&gt;Appliquer ce fichier yaml sur le cluster.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;manu@ ~$ kubectl apply -f pg-service.yaml service/postgres-capdata created[/yaml]&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;manu@ ~$ kubectl get svc -o wide&#xD;&#xA;NAME              TYPE          CLUSTER-IP    EXTERNAL-IP            PORT(S)         AGE   SELECTOR&#xD;&#xA;kubernetes        ClusterIP     10.96.0.1     none                   443/TCP          16d  none&#xD;&#xA;postgres          NodePort      10.110.166.18 none                   5432:32581/TCP  6m48s app=postgres&lt;/pre&gt;&#xA;&lt;h3&gt;Connexion à PostgreSQL&lt;/h3&gt;&#xA;&lt;p&gt;2 méthodes pour nous connecter à l&amp;#8217;instance PostgreSQL s&amp;#8217;offrent à nous.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Connexion via Kubernetes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Utiliser l&amp;#8217;outil &amp;#8220;kubectl&amp;#8221; pour se connecter à l&amp;#8217;instance PostgreSQL. Utiliser le compte préalablement défini, &amp;#8220;&lt;strong&gt;capdata&lt;/strong&gt;&amp;#8220;, sur la base &amp;#8220;&lt;strong&gt;capdb&lt;/strong&gt;&amp;#8220;.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@ ~$ kubectl exec -it postgres-66855ddfc5-drsqj -- psql -h localhost -U capdata --password -p 5432 capdb&#xD;&#xA;Password:&#xD;&#xA;psql (15.2 (Debian 15.2-1.pgdg110+1))&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&#xD;&#xA;capdb=# \conninfo&#xD;&#xA;You are connected to database &amp;quot;capdb&amp;quot; as user &amp;quot;capdata&amp;quot; on host &amp;quot;localhost&amp;quot; (address &amp;quot;127.0.0.1&amp;quot;) at port &amp;quot;5432&amp;quot;.&#xD;&#xA;capdb=#&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Connexion via un client PostgreSQL local à la VM.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Sur notre VM Rocky Linux, nous disposons d&amp;#8217;une vieille version de &amp;#8220;psql&amp;#8221; que nous pouvons utiliser pour la connexion (version 10 de PostgreSQL).&lt;/p&gt;&#xA;&lt;p&gt;Repérer auparavant, la valeur du port de sortie que nous avions trouvé lorsque nous avons passé la commande &amp;#8220;kubectl get svc -o wide&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;Pour notre service dédié à postgreSQL, nous avons comme port &amp;#8220;5432:32581&amp;#8221;. Le 5432 est le port d&amp;#8217;écoute local à Kubernetes. Pour accèder depuis notre VM, c&amp;#8217;est le port 32581 dont nous aurons besoin.&lt;/p&gt;&#xA;&lt;p&gt;De plus, l&amp;#8217;IP de notre cluster Kubernetes, doit être connue. Pour cela , exécuter cette commande :&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@ip-172-44-3-198 ~]$ kubectl get pods --all-namespaces -o wide&#xD;&#xA;NAMESPACE    NAME                              READY STATUS   RESTARTS    AGE   IP              NODE      NOMINATED NODE READINESS GATES&#xD;&#xA;default      postgres-66855ddfc5-drsqj         1/1   Running  0           17m   10.244.0.3      minikube  none           none&#xD;&#xA;default      postgres-66855ddfc5-n9fc8         1/1   Running  1(17m ago)  17m   10.244.0.4      minikube  none           none&#xD;&#xA;kube-system  coredns-787d4945fb-87kzd          1/1   Running  0           23m   10.244.0.2      minikube  none           none&#xD;&#xA;kube-system  etcd-minikube                     1/1   Running  0           23m   192.168.39.227  minikube  none           none&#xD;&#xA;kube-system  kube-apiserver-minikube           1/1   Running  0           23m   192.168.39.227  minikube  none           none &#xD;&#xA;kube-system  kube-controller-manager-minikube  1/1   Running  0           23m   192.168.39.227  minikube  none           none&#xD;&#xA;kube-system  kube-proxy-lptq2                  1/1   Running  0           23m   192.168.39.227  minikube  none           none&#xD;&#xA;kube-system  kube-scheduler-minikube           1/1   Running  0           23m   192.168.39.227  minikube  none           none&#xD;&#xA;kube-system  storage-provisioner               1/1   Running  1 (22m ago) 23m   192.168.39.227  minikube  none           none&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;L&amp;#8217;IP du cluster Kubernetes est 192.168.39.227.&lt;/p&gt;&#xA;&lt;p&gt;La connexion via PSQL se fait donc sur cette IP. Valider la connexion sur la base &amp;#8220;capdb&amp;#8221;.&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;manu@ ~$ psql -h 192.168.39.227 -U capdata -p 32581 capdb&#xD;&#xA;Password for user capdata:&#xD;&#xA;psql (10.23, server 15.2 (Debian 15.2-1.pgdg110+1))&#xD;&#xA;WARNING: psql major version 10, server major version 15.&#xD;&#xA;Some psql features might not work.&#xD;&#xA;Type &amp;quot;help&amp;quot; for help.&#xD;&#xA;&#xD;&#xA;capdb=# \conninfo&#xD;&#xA;You are connected to database &amp;quot;capdb&amp;quot; as user &amp;quot;capdata&amp;quot; on host &amp;quot;192.168.39.227&amp;quot; at port &amp;quot;32581&amp;quot;.&#xD;&#xA;capdb=# \l+&#xD;&#xA;List of databases&#xD;&#xA;Name       | Owner   | Encoding | Collate    | Ctype      | Access privileges   | Size    | Tablespace | Description&#xD;&#xA;-----------+---------+----------+------------+------------+---------------------+---------+------------+--------------------------------------------&#xD;&#xA;capdb      | capdata | UTF8     | en_US.utf8 | en_US.utf8 |                     | 7453 kB | pg_default |&#xD;&#xA;postgres   | capdata | UTF8     | en_US.utf8 | en_US.utf8 |                     | 7453 kB | pg_default | default administrative connection database&#xD;&#xA;template0  | capdata | UTF8     | en_US.utf8 | en_US.utf8 |         =c/capdata +| 7297 kB | pg_default | unmodifiable empty database&#xD;&#xA;           |         |          |            |            | capdata=CTc/capdata |         |            |&#xD;&#xA;template1  | capdata | UTF8     | en_US.utf8 | en_US.utf8 |         =c/capdata +| 7525 kB | pg_default | default template for new databases&#xD;&#xA;           |         |          |            |            | capdata=CTc/capdata |         |            |&#xD;&#xA;(4 rows)&lt;/pre&gt;&#xA;&lt;p&gt;Le compte &amp;#8220;capdata&amp;#8221; que nous avons inscrit dans le fichier configmap est owner pour toutes les bases de cette instance.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Les logs&lt;/h2&gt;&#xA;&lt;p&gt;Il est possible d&amp;#8217;aller regarder les logs de nos &amp;#8220;pods&amp;#8221; déployés sur Kubernetes.&lt;br /&gt;&#xA;Pour cela choisir la commande &amp;#8220;kubectl logs&amp;#8221;.&lt;/p&gt;&#xA;&lt;p&gt;Par exemple, lancer cette commande sur 1 des répliquas PostgreSQL du cluster, et vous avec accès en lecture au fichier &amp;#8220;postgresql.log&amp;#8221; de l&amp;#8217;instance&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt; manu@ ~$ kubectl logs pod/postgres-66855ddfc5-drsqj&#xD;&#xA;The files belonging to this database system will be owned by user &amp;quot;postgres&amp;quot;.&#xD;&#xA;This user must also own the server process.&#xD;&#xA;&#xD;&#xA;The database cluster will be initialized with locale &amp;quot;en_US.utf8&amp;quot;.&#xD;&#xA;The default database encoding has accordingly been set to &amp;quot;UTF8&amp;quot;.&#xD;&#xA;The default text search configuration will be set to &amp;quot;english&amp;quot;.&#xD;&#xA;&#xD;&#xA;Data page checksums are disabled.&#xD;&#xA;&#xD;&#xA;fixing permissions on existing directory /var/lib/postgresql/data ... ok&#xD;&#xA;creating subdirectories ... ok&#xD;&#xA;selecting dynamic shared memory implementation ... posix&#xD;&#xA;selecting default max_connections ... 100&#xD;&#xA;selecting default shared_buffers ... 128MB&#xD;&#xA;selecting default time zone ... Etc/UTC&#xD;&#xA;creating configuration files ... ok&#xD;&#xA;running bootstrap script ... ok&#xD;&#xA;performing post-bootstrap initialization ... ok&#xD;&#xA;syncing data to disk ... ok&#xD;&#xA;&#xD;&#xA;initdb: warning: enabling &amp;quot;trust&amp;quot; authentication for local connections&#xD;&#xA;initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.&#xD;&#xA;&#xD;&#xA;Success. You can now start the database server using:&#xD;&#xA;&#xD;&#xA;pg_ctl -D /var/lib/postgresql/data -l logfile start&#xD;&#xA;&#xD;&#xA;pg_ctl: another server might be running; trying to start server anyway&#xD;&#xA;waiting for server to start....2023-03-27 09:30:32.071 UTC [48] LOG: starting PostgreSQL 15.2 (Debian 15.2-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit&#xD;&#xA;2023-03-27 09:30:32.075 UTC [48] LOG: listening on Unix socket &amp;quot;/var/run/postgresql/.s.PGSQL.5432&amp;quot;&#xD;&#xA;2023-03-27 09:30:32.087 UTC [51] LOG: database system was interrupted; last known up at 2023-03-27 09:30:32 UTC&#xD;&#xA;2023-03-27 09:30:32.110 UTC [51] LOG: database system was not properly shut down; automatic recovery in progress&#xD;&#xA;2023-03-27 09:30:32.113 UTC [51] LOG: invalid record length at 0/14FE0E0: wanted 24, got 0&#xD;&#xA;2023-03-27 09:30:32.113 UTC [51] LOG: redo is not required&#xD;&#xA;2023-03-27 09:30:32.118 UTC [49] LOG: checkpoint starting: end-of-recovery immediate wait&#xD;&#xA;2023-03-27 09:30:32.140 UTC [49] LOG: checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.006 s, sync=0.003 s, total=0.024 s; sync files=2, longest=0.002 s, average=0.002 s; distance=0 kB, estimate=0 kB&#xD;&#xA;2023-03-27 09:30:32.144 UTC [48] LOG: database system is ready to accept connections&#xD;&#xA;done&#xD;&#xA;server started&#xD;&#xA;CREATE DATABASE&#xD;&#xA;&#xD;&#xA;/usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*&#xD;&#xA;&#xD;&#xA;2023-03-27 09:30:32.262 UTC [48] LOG: received fast shutdown request&#xD;&#xA;waiting for server to shut down....2023-03-27 09:30:32.266 UTC [48] LOG: aborting any active transactions&#xD;&#xA;2023-03-27 09:30:32.268 UTC [48] LOG: background worker &amp;quot;logical replication launcher&amp;quot; (PID 54) exited with exit code 1&#xD;&#xA;2023-03-27 09:30:32.268 UTC [49] LOG: shutting down&#xD;&#xA;2023-03-27 09:30:32.271 UTC [49] LOG: checkpoint starting: shutdown immediate&#xD;&#xA;2023-03-27 09:30:32.341 UTC [49] LOG: checkpoint complete: wrote 916 buffers (5.6%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.013 s, sync=0.045 s, total=0.073 s; sync files=249, longest=0.036 s, average=0.001 s; distance=4217 kB, estimate=4217 kB&#xD;&#xA;2023-03-27 09:30:32.345 UTC [48] LOG: database system is shut down&#xD;&#xA;done&#xD;&#xA;server stopped&#xD;&#xA;&#xD;&#xA;PostgreSQL init process complete; ready for start up.&#xD;&#xA;&#xD;&#xA;2023-03-27 09:30:32.384 UTC [1] LOG: starting PostgreSQL 15.2 (Debian 15.2-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit&#xD;&#xA;2023-03-27 09:30:32.385 UTC [1] LOG: listening on IPv4 address &amp;quot;0.0.0.0&amp;quot;, port 5432&#xD;&#xA;2023-03-27 09:30:32.385 UTC [1] LOG: listening on IPv6 address &amp;quot;::&amp;quot;, port 5432&#xD;&#xA;2023-03-27 09:30:32.392 UTC [1] LOG: listening on Unix socket &amp;quot;/var/run/postgresql/.s.PGSQL.5432&amp;quot;&#xD;&#xA;2023-03-27 09:30:32.401 UTC [64] LOG: database system was shut down at 2023-03-27 09:30:32 UTC&#xD;&#xA;2023-03-27 09:30:32.406 UTC [1] LOG: database system is ready to accept connections&lt;/pre&gt;&#xA;&lt;p&gt;Nous obtenons les informations de la création de l&amp;#8217;instance jusqu&amp;#8217;au dernier démarrage.&lt;/p&gt;&#xA;&lt;p&gt;N&amp;#8217;hésitez pas à laisser un message !&lt;/p&gt;&#xA;&lt;p&gt;Emmanuel RAMI.&lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/kubegres-loperateur-kubernetes-cle-en-main-pour-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;26 avril 2023&#34;&gt;Kubegres : l&amp;#8217;opérateur Kubernetes clé en main pour PostgreSQL&lt;/a&gt; (David Baffaleuf) [ContainerDevopsPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pgo-operateurs-kubernetes-pour-postgresql-la-suite/&#34; rel=&#34;bookmark&#34; title=&#34;6 juin 2023&#34;&gt;PGO : opérateurs kubernetes pour PostgreSQL, la suite !&lt;/a&gt; (David Baffaleuf) [ContainerDevopsPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/comparatif-des-gestionnaires-de-vip-dans-un-cluster-patroni-episode-2-vip-manager/&#34; rel=&#34;bookmark&#34; title=&#34;11 mars 2022&#34;&gt;Comparatif des gestionnaires de VIP dans un cluster Patroni : épisode 2 (VIP-MANAGER)&lt;/a&gt; (David Baffaleuf) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/comparatif-des-gestionnaires-de-vip-dans-un-cluster-patroni-episode-1-keepalived/&#34; rel=&#34;bookmark&#34; title=&#34;6 mars 2022&#34;&gt;Comparatif des gestionnaires de VIP dans un cluster Patroni : épisode 1 (KEEPALIVED)&lt;/a&gt; (David Baffaleuf) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/containeriser-une-base-de-donnees-postgresql-avec-docker/&#34; rel=&#34;bookmark&#34; title=&#34;23 septembre 2021&#34;&gt;Containeriser PostgreSQL avec Docker !&lt;/a&gt; (Emmanuel RAMI) [ContainerPostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 3.174 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9753&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9753&amp;#038;title=PostgreSQL%20sur%20la%20solution%20Kubernetes%20locale%20Minikube&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=PostgreSQL%20sur%20la%20solution%20Kubernetes%20locale%20Minikube&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9753&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/&#34;&gt;PostgreSQL sur la solution Kubernetes locale Minikube&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Hello Il y a quelques temps, je vous avais présenté un premier article sur l&amp;#8217;installation d&amp;#8217;une instance de base de données PostgreSQL sous Docker. C&amp;#8217;est cet article qui nous a permis de mettre un premier pas dans le monde de&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/postgresql-sur-la-solution-kubernetes-locale-minikube/&#34;&gt;PostgreSQL sur la solution Kubernetes locale Minikube&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>Nouveautés pg_stat_statements avec PostgreSQL 15</title>
    <updated>2023-03-16T05:36:32Z</updated>
    <id>tag:blog.capdata.fr,2023-03-16:/index.php/nouveautes-pg_stat_statements-avec-postgresql-15/</id>
    <content type="html">&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9742&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9742&amp;#038;title=Nouveaut%C3%A9s%20pg_stat_statements%20avec%20PostgreSQL%2015&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=Nouveaut%C3%A9s%20pg_stat_statements%20avec%20PostgreSQL%2015&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9742&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;Salut à toutes et tous, aujourd&amp;#8217;hui un petit post pour évoquer les quelques petites modifications apportées à pg_stat_statements, l&amp;#8217;extension phare de PostgreSQL, et qui ont pu passer inaperçues depuis le 13 octobre, date de sortie de la dernière release majeure du SGBD aux grandes oreilles. &lt;/p&gt;&#xA;&lt;p&gt;Si vous n&amp;#8217;êtes pas familiers de pg_stat_statements je vous renvoie sur mon talk aux &lt;a href=&#34;https://blog.capdata.fr/index.php/pgday-nantes-2021-session-sur-pg_stat_statements/&#34;&gt;PGDays en 2021&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Si on regarde d&amp;#8217;un peu plus près la &lt;a href=&#34;https://www.postgresql.org/docs/current/pgstatstatements.html&#34;&gt;documentation de référence&lt;/a&gt;, on va retrouver deux ajouts principaux: &lt;/p&gt;&#xA;&lt;h1&gt;Séparation des stats IO data &amp;#038; temporary&lt;/h1&gt;&#xA;&lt;p&gt;Tout d&amp;#8217;abord en version 14, les colonnes &lt;em&gt;blk_read_time&lt;/em&gt; et &lt;em&gt;blk_write_time&lt;/em&gt; comptabilisaient les entrées / sorties vers tous les blocs, à la fois data et temporary. En version 15, deux nouvelles colonnes &lt;em&gt;temp_blk_read_time &lt;/em&gt;et &lt;em&gt;temp_blk_write_time&lt;/em&gt; sont ajoutées à la vue, pour séparer les deux types d&amp;#8217;accès. Les anciennes colonnes ne font donc plus référence qu&amp;#8217;aux accès aux blocs de data, et les 2 nouvelles qu&amp;#8217;aux accès aux blocs temporary. &lt;/p&gt;&#xA;&lt;h1&gt;Infos sur les compilations JIT:&lt;/h1&gt;&#xA;&lt;p&gt;La deuxième différence qui est nettement plus visible, est l&amp;#8217;ajout de toute la métrologie associée à la compilation Jit, introduite en 2018 pour la version 11 par &lt;a href=&#34;https://www.postgresql.org/message-id/20161206034955.bh33paeralxbtluv@alap3.anarazel.de&#34;&gt;Andres Freund&lt;/a&gt;, et qui permet d&amp;#8217;accélérer l&amp;#8217;exécution de code PL/PGSQL davantage en le compilant en langage natif à l&amp;#8217;exécution, si le coût dépasse un seuil fixé par le paramètre &lt;a href=&#34;https://www.postgresql.org/docs/current/runtime-config-query.html#GUC-JIT-ABOVE-COST&#34;&gt;jit_above_cost&lt;/a&gt;.  Parmi ces nouvelles colonnes : &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34;&gt;&#xD;&#xA;jit_functions           : Total number of functions JIT-compiled by the statement&#xD;&#xA;jit_generation_time     : Total time spent by the statement on generating JIT code, in milliseconds&#xD;&#xA;jit_inlining_count      : Number of times functions have been inlined&#xD;&#xA;jit_inlining_time       : Total time spent by the statement on inlining functions, in milliseconds&#xD;&#xA;jit_optimization_count  : Number of times the statement has been optimized&#xD;&#xA;jit_optimization_time   : Total time spent by the statement on optimizing, in milliseconds&#xD;&#xA;jit_emission_count      : Number of times code has been emitted&#xD;&#xA;jit_emission_time       : Total time spent by the statement on emitting code, in milliseconds&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Petit test pour voir avec une bonne grosse requête qui va nous faire un parallel seq scan et un hash aggregate en sortie, le tout sur 40 millions de lignes. Pour avoir un peu de volumétrie j&amp;#8217;utilise la base de test de &lt;a href=&#34;https://musicbrainz.org/doc/MusicBrainz_Database/Download&#34;&gt;musicbrainz&lt;/a&gt; que je vous recommande: &lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;(postgres@[local]:5432) [postgres] &amp;gt; select name, setting from pg_settings where name in (&#39;jit&#39;,&#39;jit_above_cost&#39;) ;&#xD;&#xA;      name      | setting &#xD;&#xA;----------------+---------&#xD;&#xA; jit            | on&#xD;&#xA; jit_above_cost | 100000&#xD;&#xA;(2 rows)&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5432) [postgres] &amp;gt; \c musicbrainz&#xD;&#xA;You are now connected to database &amp;quot;musicbrainz&amp;quot; as user &amp;quot;postgres&amp;quot;.&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5432) [musicbrainz] &amp;gt; explain select name, count(id), avg(length) from track group by name having count(id) &amp;gt; 5 ;&#xD;&#xA;                                            QUERY PLAN                                             &#xD;&#xA;---------------------------------------------------------------------------------------------------&#xD;&#xA; Finalize GroupAggregate  (cost=2399394.22..2481941.16 rows=104483 width=60)&#xD;&#xA;   Group Key: name&#xD;&#xA;   Filter: (count(id) &amp;gt; 5)&#xD;&#xA;   -&amp;gt;  Gather Merge  (cost=2399394.22..2472537.66 rows=626900 width=60)&#xD;&#xA;         Workers Planned: 2&#xD;&#xA;         -&amp;gt;  Sort  (cost=2398394.20..2399177.83 rows=313450 width=60)&#xD;&#xA;               Sort Key: name&#xD;&#xA;               -&amp;gt;  Partial HashAggregate  (cost=2124704.40..2357991.54 rows=313450 width=60)&#xD;&#xA;                     Group Key: name&#xD;&#xA;                     Planned Partitions: 16&#xD;&#xA;                     -&amp;gt;  Parallel Seq Scan on track  (cost=0.00..741158.22 rows=16834022 width=28)&#xD;&#xA; JIT:&#xD;&#xA;   Functions: 8&#xD;&#xA;   Options: Inlining true, Optimization true, Expressions true, Deforming true&#xD;&#xA;(14 rows)&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;OK on voit bien qu&amp;#8217;avec notre cost final de +2399394 on est au dessus des 100K minimums nécessaire pour forcer le JIT. Exécutons la requête pour voir ce que l&amp;#8217;on retrouve dans pg_stat_statements:&lt;/p&gt;&#xA;&lt;pre class=&#34;brush: sql; title: ; notranslate&#34;&gt;&#xD;&#xA;(postgres@[local]:5432) [musicbrainz] &amp;gt; select name, count(id), avg(length) from track group by name having count(id) &amp;gt; 5 ;&#xD;&#xA;(...)&#xD;&#xA;(746785 rows)&#xD;&#xA;Time: 210439.640 ms (03:30.440)&#xD;&#xA;&#xD;&#xA;(postgres@[local]:5432) [postgres] &amp;gt; \x&#xD;&#xA;Expanded display is on.&#xD;&#xA;(postgres@[local]:5432) [postgres] &amp;gt; select * from pg_stat_statements where query like &#39;select name, count(id), avg(length) from track%&#39; ;&#xD;&#xA;-[ RECORD 1 ]----------+-----------------------------------------------------------------------------------&#xD;&#xA;userid                 | 10&#xD;&#xA;dbid                   | 16388&#xD;&#xA;toplevel               | t&#xD;&#xA;queryid                | 6022129428306982548&#xD;&#xA;query                  | select name, count(id), avg(length) from track group by name having count(id) &amp;gt; $1&#xD;&#xA;plans                  | 0&#xD;&#xA;total_plan_time        | 0&#xD;&#xA;min_plan_time          | 0&#xD;&#xA;max_plan_time          | 0&#xD;&#xA;mean_plan_time         | 0&#xD;&#xA;stddev_plan_time       | 0&#xD;&#xA;calls                  | 1&#xD;&#xA;total_exec_time        | 210435.894037&#xD;&#xA;min_exec_time          | 210435.894037&#xD;&#xA;max_exec_time          | 210435.894037&#xD;&#xA;mean_exec_time         | 210435.894037&#xD;&#xA;stddev_exec_time       | 0&#xD;&#xA;rows                   | 746785&#xD;&#xA;shared_blks_hit        | 16&#xD;&#xA;shared_blks_read       | 572818&#xD;&#xA;shared_blks_dirtied    | 0&#xD;&#xA;shared_blks_written    | 0&#xD;&#xA;local_blks_hit         | 0&#xD;&#xA;local_blks_read        | 0&#xD;&#xA;local_blks_dirtied     | 0&#xD;&#xA;local_blks_written     | 0&#xD;&#xA;temp_blks_read         | 1071638&#xD;&#xA;temp_blks_written      | 1325851&#xD;&#xA;blk_read_time          | 0&#xD;&#xA;blk_write_time         | 0&#xD;&#xA;temp_blk_read_time     | 0&#xD;&#xA;temp_blk_write_time    | 0&#xD;&#xA;wal_records            | 0&#xD;&#xA;wal_fpi                | 0&#xD;&#xA;wal_bytes              | 0&#xD;&#xA;jit_functions          | 15&#xD;&#xA;jit_generation_time    | 1.491564&#xD;&#xA;jit_inlining_count     | 1&#xD;&#xA;jit_inlining_time      | 237.918294&#xD;&#xA;jit_optimization_count | 1&#xD;&#xA;jit_optimization_time  | 360.290152&#xD;&#xA;jit_emission_count     | 1&#xD;&#xA;jit_emission_time      | 230.831919&#xD;&#xA;&lt;/pre&gt;&#xA;&lt;p&gt;Le cost étant à 2M+ on aura donc à la fois inlining et optimization car les 2 seuils &lt;em&gt;jit_inline_above_cost&lt;/em&gt; et &lt;em&gt;jit_optimize_above_cost &lt;/em&gt;sont à 500K, ce qui est confirmé par la sortie de PGSS ci-dessus.&lt;/p&gt;&#xA;&lt;p&gt;Pour ce qui est de la version 16, qui devrait être ouverte en Beta d&amp;#8217;ici un ou deux mois, pour l&amp;#8217;instant &lt;a href=&#34;https://www.postgresql.org/docs/devel/pgstatstatements.html&#34;&gt;pas d&amp;#8217;ajout de nouvelle colonne &lt;/a&gt;à l&amp;#8217;horizon. &lt;/p&gt;&#xA;&lt;p&gt;Pensez à vous abonner à la page &lt;a href=&#34;https://www.linkedin.com/company/136256/admin/&#34;&gt;linkedin &lt;/a&gt; et à la &lt;a href=&#34;https://www.youtube.com/@Capdata&#34;&gt;chaîne youtube&lt;/a&gt; de Capdata si ce n&amp;#8217;est pas déjà fait !&lt;br /&gt;&#xA;A+ &lt;strong&gt;Continuez votre lecture sur le blog :&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul class=&#34;similar-posts&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/requetes-consommatrices-sous-postgresql-episode-1/&#34; rel=&#34;bookmark&#34; title=&#34;24 mai 2016&#34;&gt;Requêtes consommatrices sous PostgreSQL (épisode 1)&lt;/a&gt; (David Baffaleuf) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/dmv-et-probleme-de-tri/&#34; rel=&#34;bookmark&#34; title=&#34;29 juin 2016&#34;&gt;DMV et problème de tri&lt;/a&gt; (David Baffaleuf) [SQL Server]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pruning-de-partitions-sous-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;7 décembre 2020&#34;&gt;&amp;#8220;Pruning&amp;#8221; de partitions sous PostgreSQL ou comment bien élaguer !&lt;/a&gt; (Capdata team) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/pgday-nantes-2021-session-sur-pg_stat_statements/&#34; rel=&#34;bookmark&#34; title=&#34;9 juillet 2021&#34;&gt;PGDay Nantes 2021 session sur pg_stat_statements&lt;/a&gt; (David Baffaleuf) [PostgreSQL]&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.capdata.fr/index.php/aws-rds-les-extensions-postgresql/&#34; rel=&#34;bookmark&#34; title=&#34;21 janvier 2020&#34;&gt;AWS RDS : les extensions PostgreSQL&lt;/a&gt; (Emmanuel RAMI) [AWSPostgreSQL]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;!-- Similar Posts took 2.433 ms --&gt;&lt;/p&gt;&#xA;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-twitter nolightbox&#34; data-provider=&#34;twitter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Twitter&#34; href=&#34;https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9742&amp;#038;text=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;twitter&#34; title=&#34;Share on Twitter&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/twitter.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-linkedin nolightbox&#34; data-provider=&#34;linkedin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; title=&#34;Share on Linkedin&#34; href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;#038;url=https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9742&amp;#038;title=Nouveaut%C3%A9s%20pg_stat_statements%20avec%20PostgreSQL%2015&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px;margin-right:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;linkedin&#34; title=&#34;Share on Linkedin&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/linkedin.png&#34; /&gt;&lt;/a&gt;&lt;a class=&#34;synved-social-button synved-social-button-share synved-social-size-24 synved-social-resolution-single synved-social-provider-mail nolightbox&#34; data-provider=&#34;mail&#34; rel=&#34;nofollow&#34; title=&#34;Share by email&#34; href=&#34;mailto:?subject=Nouveaut%C3%A9s%20pg_stat_statements%20avec%20PostgreSQL%2015&amp;#038;body=Article%20sur%20le%20blog%20de%20la%20Capdata%20Tech%20Team%20%3A%20:%20https%3A%2F%2Fblog.capdata.fr%2F%3Fp%3D9742&#34; style=&#34;font-size: 0px;width:24px;height:24px;margin:0;margin-bottom:5px&#34;&gt;&lt;img decoding=&#34;async&#34; loading=&#34;lazy&#34; alt=&#34;mail&#34; title=&#34;Share by email&#34; class=&#34;synved-share-image synved-social-image synved-social-image-share&#34; width=&#34;24&#34; height=&#34;24&#34; style=&#34;display: inline;width:24px;height:24px;margin: 0;padding: 0;border: none;box-shadow: none&#34; src=&#34;https://blog.capdata.fr/wp-content/plugins/social-media-feather/synved-social/image/social/regular/48x48/mail.png&#34; /&gt;&lt;/a&gt;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/nouveautes-pg_stat_statements-avec-postgresql-15/&#34;&gt;Nouveautés pg_stat_statements avec PostgreSQL 15&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.capdata.fr/index.php/nouveautes-pg_stat_statements-avec-postgresql-15/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Salut à toutes et tous, aujourd&amp;#8217;hui un petit post pour évoquer les quelques petites modifications apportées à pg_stat_statements, l&amp;#8217;extension phare de PostgreSQL, et qui ont pu passer inaperçues depuis le 13 octobre, date de sortie de la dernière release majeure&amp;#8230; &lt;a href=&#34;https://blog.capdata.fr/index.php/nouveautes-pg_stat_statements-avec-postgresql-15/&#34; class=&#34;more-link&#34;&gt;Continuer la lecture &lt;span class=&#34;meta-nav&#34;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr/index.php/nouveautes-pg_stat_statements-avec-postgresql-15/&#34;&gt;Nouveautés pg_stat_statements avec PostgreSQL 15&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.capdata.fr&#34;&gt;Capdata TECH BLOG&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Emmanuel RAMI</name>
    </author>
  </entry>
  <entry>
    <title>En route vers la liberté avec db_migrator</title>
    <updated>2023-07-28T00:00:00Z</updated>
    <id>tag:fljd.in,2023-07-28:/2023/07/28/en-route-vers-la-liberte-avec-db_migrator/</id>
    <link href="https://fljd.in/2023/07/28/en-route-vers-la-liberte-avec-db_migrator/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;J&amp;rsquo;ai passé plusieurs semaines ces derniers mois à contribuer à l&amp;rsquo;extension&#xA;&lt;a href=&#34;https://github.com/cybertec-postgresql/db_migrator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;db_migrator&lt;/a&gt;. Rédigée uniquement en PL/pgSQL, elle permet de migrer les schémas&#xA;et les données d&amp;rsquo;un système de bases de données vers PostgreSQL à l&amp;rsquo;aide des&#xA;données externes que j&amp;rsquo;avais déjà présentées il y a &lt;a href=&#34;https://fljd.in/2021/07/16/parlons-un-peu-des-donnees-externes/&#34;&gt;quelques années&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Dans cet article, je présente le fonctionnement de l&amp;rsquo;outil, sa philosophie et la&#xA;raison d&amp;rsquo;être que je lui ai trouvée, alors même qu&amp;rsquo;il rejoint l&amp;rsquo;écosystème des&#xA;projets libres déjà bien installés dans le paysage de la migration. Que vaut-il&#xA;aux côtés d&amp;rsquo;&lt;a href=&#34;https://ora2pg.darold.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ora2Pg&lt;/a&gt; ou de &lt;a href=&#34;https://pgloader.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pgloader&lt;/a&gt; ?&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Les colonnes générées</title>
    <updated>2023-03-22T00:00:00Z</updated>
    <id>tag:fljd.in,2023-03-22:/2023/03/22/les-colonnes-generees/</id>
    <link href="https://fljd.in/2023/03/22/les-colonnes-generees/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;La norme ISO SQL/Foundation (&lt;a href=&#34;https://www.iso.org/standard/63556.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ISO/IEC 9075-2:2016&lt;/a&gt;) fait partie du standard&#xA;SQL et définit les règles pour la définition des relations et la manipulation&#xA;des données. En adoptant cette norme, les moteurs de bases de données&#xA;garantissent une interopérabilité avec leurs concurrents et permettent aux&#xA;entreprises de bénéficier d&amp;rsquo;une plus grande flexibilité lorsqu&amp;rsquo;elles souhaitent&#xA;passer de l&amp;rsquo;un à l&amp;rsquo;autre sans (trop) réécrire leur modèle de données ou leurs&#xA;requêtes SQL.&lt;/p&gt;&#xA;&lt;p&gt;Dans sa publication SQL:2003, la norme a introduit le concept de &lt;strong&gt;colonnes&#xA;générées&lt;/strong&gt; comme nouvelle spécification technique. Parfois appelées &lt;em&gt;colonnes&#xA;calculées&lt;/em&gt; ou &lt;em&gt;colonnes virtuelles&lt;/em&gt;, leurs valeurs dérivent de celles des autres&#xA;colonnes de la table. &lt;a href=&#34;https://modern-sql.com/caniuse/generated-always-as&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Un des articles&lt;/a&gt; de Markus Winand passe au crible les&#xA;différents systèmes du marché pour voir s&amp;rsquo;ils respectent ce standard.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Le fenêtrage à la rescousse</title>
    <updated>2023-02-10T00:00:00Z</updated>
    <id>tag:fljd.in,2023-02-10:/2023/02/10/le-fenetrage-a-la-rescousse/</id>
    <link href="https://fljd.in/2023/02/10/le-fenetrage-a-la-rescousse/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PostgreSQL propose un certain nombre de fonctions qui permettent de calculer des&#xA;valeurs agrégées ou relatives sur un ensemble de lignes qui se situent dans une&#xA;« fenêtre » autour de la ligne courante. En utilisant de telles fonctions,&#xA;n&amp;rsquo;importe qui peut créer des requêtes plus avancées et plus efficaces pour&#xA;l&amp;rsquo;analyse de leur base de données.&lt;/p&gt;&#xA;&lt;p&gt;Depuis plusieurs semaines, je contribue à un projet de conversion de modèles de&#xA;données vers PostgreSQL, appelé &lt;a href=&#34;https://github.com/cybertec-postgresql/db_migrator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;db_migrator&lt;/a&gt;. À cette occasion, j&amp;rsquo;ai&#xA;(re)découvert la puissance de ces &lt;a href=&#34;https://www.postgresql.org/docs/current/functions-window.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fonctions de fenêtrage&lt;/a&gt; avec le langage&#xA;SQL. Dans cet article, je reviens sur un &lt;a href=&#34;https://github.com/cybertec-postgresql/db_migrator/pull/11&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cas concret&lt;/a&gt; de transformation des&#xA;bornes supérieures d&amp;rsquo;une table partitionnée en tableau de valeur.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Construire PostgreSQL avec Meson</title>
    <updated>2022-09-29T00:00:00Z</updated>
    <id>tag:fljd.in,2022-09-29:/2022/09/29/construire-postgresql-avec-meson/</id>
    <link href="https://fljd.in/2022/09/29/construire-postgresql-avec-meson/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Alors que la version 15 de PostgreSQL se prépare à sortir dans les &lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-15-rc-1-released-2516/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;prochains&#xA;jours&lt;/a&gt;, le groupe de développement du projet communautaire ont intégré &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=e6927270cd18d535b77cbe79c55c6584351524be&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;leurs&#xA;récents travaux&lt;/a&gt; pour accélérer les tâches d&amp;rsquo;automatisation et de compilation&#xA;à l&amp;rsquo;aide du système de construction &lt;a href=&#34;https://mesonbuild.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Meson&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Ce chantier n&amp;rsquo;est pas anodin et redessine les contours de l&amp;rsquo;écosystème du moteur&#xA;de bases de données open-source le plus avancé au monde. Depuis sa forme libre&#xA;publiée en 1998, PostgreSQL repose sur des solutions robustes et éprouvées, mais&#xA;de plus en plus complexes à maintenir pour les nouvelles générations de&#xA;contributeur·rices. En proposant de se tourner vers un logiciel comme Meson, ces&#xA;amoureux et amoureuses du libre se tournent résolument vers l&amp;rsquo;avenir.&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Dessine-moi un arbre (abstrait)</title>
    <updated>2022-06-29T00:00:00Z</updated>
    <id>tag:fljd.in,2022-06-29:/2022/06/29/dessine-moi-un-arbre-abstrait/</id>
    <link href="https://fljd.in/2022/06/29/dessine-moi-un-arbre-abstrait/" rel="alternate"></link>
    <summary type="html">&lt;blockquote&gt;&#xA;&lt;p&gt;L&amp;rsquo;étape d&amp;rsquo;analyse crée un arbre d&amp;rsquo;analyse qui n&amp;rsquo;utilise que les règles fixes&#xA;de la structure syntaxique de SQL. Il ne fait aucune recherche dans les&#xA;catalogues système. Il n&amp;rsquo;y a donc aucune possibilité de comprendre la sémantique&#xA;détaillée des opérations demandées.&lt;/p&gt;&#xA;&lt;p&gt;(Documentation : &lt;a href=&#34;https://docs.postgresql.fr/14/parser-stage.html#id-1.10.3.6.4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Processus de transformation&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Que se passe-t-il entre l&amp;rsquo;instant où une requête SQL est soumise par l&amp;rsquo;utilisateur&#xA;et l&amp;rsquo;envoi du résultat sous forme de lignes par le serveur PostgreSQL ? Cette&#xA;question passionnante (pour une poignée de personnes, ne nous le cachons pas) a&#xA;été étudiée par Stefan Simkovics durant &lt;a href=&#34;https://archive.org/details/Enhancement_of_the_ANSI_SQL_Implementation_of_PostgreSQL/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sa thèse&lt;/a&gt; pour l&amp;rsquo;université de&#xA;technologie de Vienne en 1998.&lt;/p&gt;&#xA;&lt;p&gt;Ces travaux ont notamment permis d&amp;rsquo;enrichir la &lt;a href=&#34;https://docs.postgresql.fr/14/overview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation officielle&lt;/a&gt; avec&#xA;le chapitre « Présentation des mécanismes internes de PostgreSQL », qui reprend&#xA;assez largement les observations de Simkovics de manière simplifiée pour en&#xA;faciliter l&amp;rsquo;accès au plus grand nombre.&lt;/p&gt;&#xA;&lt;p&gt;Dans cet article, je souhaite présenter de récentes découvertes sur l&amp;rsquo;une de ces&#xA;phases internes, l&amp;rsquo;étape d&amp;rsquo;analyse, qui permet de manipuler une requête SQL sous&#xA;une forme d&amp;rsquo;arbre et qui respecte un pattern de développement avancé nommé &lt;a href=&#34;https://fr.wikipedia.org/wiki/Arbre_de_la_syntaxe_abstraite&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AST&lt;/a&gt;&#xA;(&lt;em&gt;abstract syntax tree&lt;/em&gt;).&lt;/p&gt;</summary>
    <author>
      <name>Florent Jardin</name>
    </author>
  </entry>
  <entry>
    <title>Classification des caractères avec ICU</title>
    <updated>2023-06-11T14:32:00Z</updated>
    <id>tag:blog-postgresql.verite.pro,2023-06-11:/2023/06/11/caracteres-icu.html</id>
    <link href="https://blog-postgresql.verite.pro/2023/06/11/caracteres-icu.html" rel="alternate"></link>
    <summary type="html">Avec PostgreSQL 16 où ICU devient le fournisseur de collations par défaut, il y a quelques différences sémantiques à anticiper dans la classification des caractères. Cet article en détaille quelques-unes.</summary>
    <author>
      <name>blog-postgresql.verite.pro</name>
    </author>
  </entry>
  <entry>
    <title>Isolation Repeatable Read avec PostgreSQL versus MySQL</title>
    <updated>2020-02-10T17:50:00Z</updated>
    <id>tag:blog-postgresql.verite.pro,2020-02-10:/2020/02/10/isolation-postgresql-vs-mysql.html</id>
    <link href="https://blog-postgresql.verite.pro/2020/02/10/isolation-postgresql-vs-mysql.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Les moteurs SQL permettent aux transactions concurrentes d’être&#xA;isolées les unes des autres pour éviter les interférences.&#xA;Cette propriété d’isolation correspond à la lettre I de l’acronyme&#xA;bien connu &lt;a href=&#34;https://fr.wikipedia.org/wiki/Propri%C3%A9t%C3%A9s_ACID&#34;&gt;“ACID”&lt;/a&gt;,&#xA;les autres propriétés étant Atomicité, Cohérence&#xA;(&lt;em&gt;Consistency&lt;/em&gt; en anglais) et Durabilité.&lt;/p&gt;</summary>
    <author>
      <name>blog-postgresql.verite.pro</name>
    </author>
  </entry>
  <entry>
    <title>Recherche et remplacement multiple avec plperl</title>
    <updated>2020-01-22T09:05:14Z</updated>
    <id>tag:blog-postgresql.verite.pro,2020-01-22:/2020/01/22/multi-replace.html</id>
    <link href="https://blog-postgresql.verite.pro/2020/01/22/multi-replace.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Remplacer une chaîne par une autre dans une chaîne plus large est simple&#xA;en SQL, avec la fonction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;replace&lt;/code&gt;:&lt;/p&gt;</summary>
    <author>
      <name>blog-postgresql.verite.pro</name>
    </author>
  </entry>
  <entry>
    <title>Les collations non déterministes</title>
    <updated>2019-10-16T16:32:15Z</updated>
    <id>tag:blog-postgresql.verite.pro,2019-10-16:/2019/10/16/collations-non-deterministes.html</id>
    <link href="https://blog-postgresql.verite.pro/2019/10/16/collations-non-deterministes.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Depuis la version 12, les collations de PostgreSQL peuvent être créées&#xA;avec un paramètre nommé &lt;strong&gt;deterministic&lt;/strong&gt;, qui peut être vrai&#xA;ou faux, si bien que les collations  sont maintenant&#xA;soit &lt;strong&gt;déterministes&lt;/strong&gt; (ce qu’elles sont par défaut), soit&#xA;&lt;strong&gt;non déterministes&lt;/strong&gt;.&lt;/p&gt;</summary>
    <author>
      <name>blog-postgresql.verite.pro</name>
    </author>
  </entry>
  <entry>
    <title>Faire une clef synthétique pour se référer aux rôles?</title>
    <updated>2019-09-30T17:50:12Z</updated>
    <id>tag:blog-postgresql.verite.pro,2019-09-30:/2019/09/30/clef-synthetique-roles.html</id>
    <link href="https://blog-postgresql.verite.pro/2019/09/30/clef-synthetique-roles.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Dans des tables utilisateurs, on peut avoir besoin de stocker&#xA;une référence aux rôles PostgreSQL, par exemple pour&#xA;représenter des droits d’accès à des fonctionnalités applicatives,&#xA;ou des méta-données associées aux comptes.&#xA;Se pose alors la question de ce qu’on peut utiliser&#xA;comme référence pour désigner un rôle.&lt;/p&gt;</summary>
    <author>
      <name>blog-postgresql.verite.pro</name>
    </author>
  </entry>
  <entry>
    <title>Le format de sortie CSV de psql</title>
    <updated>2019-06-13T13:50:02Z</updated>
    <id>tag:blog-postgresql.verite.pro,2019-06-13:/2019/06/13/psql-csv-output.html</id>
    <link href="https://blog-postgresql.verite.pro/2019/06/13/psql-csv-output.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;On peut depuis bien longtemps exporter des résultats de requête&#xA;en CSV, soit avec &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;COPY (SELECT ...) TO STDOUT CSV&lt;/code&gt; qui est une&#xA;commande SQL, soit via la méta-commande &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;\copy&lt;/code&gt; de psql qui appelle&#xA;en sous-main &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;COPY&lt;/code&gt; en gérant le flux de données côté client.&lt;/p&gt;</summary>
    <author>
      <name>blog-postgresql.verite.pro</name>
    </author>
  </entry>
  <entry>
    <title>Suivons le Père Noël avec PostGIS</title>
    <updated>2022-12-14T15:04:42Z</updated>
    <id>tag:blog.arthurbazin.com,2022-12-14:/bdd/postgresql/suivons-le-pere-noel-avec-postgis</id>
    <link href="https://blog.arthurbazin.com/bdd/postgresql/suivons-le-pere-noel-avec-postgis" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Découvrez ce qui se cache derrière une application de suivi du Père Noël. Une liste de destination, quelques requêtes SQL et le tour est joué ? Ce n&#39;est pas aussi simple que ça, vous allez le voir...&lt;br /&gt;&#xA;En partenariat avec Ciril GROUP.&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com/bdd/postgresql/suivons-le-pere-noel-avec-postgis&#34;&gt;Suivons le Père Noël avec PostGIS&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com&#34;&gt;BazinGa&amp;#039;s&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Arthur Bazin</name>
    </author>
  </entry>
  <entry>
    <title>Importer des données binaires dans PostgreSQL</title>
    <updated>2022-02-06T20:54:04Z</updated>
    <id>tag:blog.arthurbazin.com,2022-02-06:/bdd/postgresql/importer-des-donnees-binaires-dans-postgresql</id>
    <link href="https://blog.arthurbazin.com/bdd/postgresql/importer-des-donnees-binaires-dans-postgresql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Voici tous mes conseils sur un sujet qui m&#39;a longtemps tenu en échec : l&#39;import de données binaires en base PostgreSQL&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com/bdd/postgresql/importer-des-donnees-binaires-dans-postgresql&#34;&gt;Importer des données binaires dans PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com&#34;&gt;BazinGa&amp;#039;s&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Arthur Bazin</name>
    </author>
  </entry>
  <entry>
    <title>Reprojeter toutes les tables d’un schéma</title>
    <updated>2022-02-02T19:10:00Z</updated>
    <id>tag:blog.arthurbazin.com,2022-02-02:/bdd/reprojeter-toutes-les-tables-dun-schema</id>
    <link href="https://blog.arthurbazin.com/bdd/reprojeter-toutes-les-tables-dun-schema" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Reprojeter le contenu d&#39;un schéma est parfois fastidieux, sauf avec une petite procédure.&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com/bdd/reprojeter-toutes-les-tables-dun-schema&#34;&gt;Reprojeter toutes les tables d&amp;rsquo;un schéma&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com&#34;&gt;BazinGa&amp;#039;s&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Arthur Bazin</name>
    </author>
  </entry>
  <entry>
    <title>Halte là qui va là ? Maitriser les utilisateurs et leurs droits dans PostgreSQL</title>
    <updated>2022-01-19T19:01:00Z</updated>
    <id>tag:blog.arthurbazin.com,2022-01-19:/bdd/maitriser-les-droits-dans-postgresql</id>
    <link href="https://blog.arthurbazin.com/bdd/maitriser-les-droits-dans-postgresql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PostgreSQL permet une gestion particulièrement avancée de l’accès aux données et ce au travers de deux volets : les utilisateurs et les autorisations.&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com/bdd/maitriser-les-droits-dans-postgresql&#34;&gt;Halte là qui va là ? Maitriser les utilisateurs et leurs droits dans PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com&#34;&gt;BazinGa&amp;#039;s&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Arthur Bazin</name>
    </author>
  </entry>
  <entry>
    <title>Agréger des lignes : ST_Union, ST_Collect, ST_MakeLine ou ST_LineMerge ?</title>
    <updated>2021-06-21T18:00:00Z</updated>
    <id>tag:blog.arthurbazin.com,2021-06-21:/sig/agreger-des-lignes</id>
    <link href="https://blog.arthurbazin.com/sig/agreger-des-lignes" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lorsqu&#39;il s&#39;agit de fusionner des lignes, PostGIS n&#39;est pas en reste et propose plusieurs fonctions. Cependant, le résultat de ces unions peut fortement varier.&lt;br /&gt;&#xA;Voici donc un petit récapitulatif.&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com/sig/agreger-des-lignes&#34;&gt;Agréger des lignes : ST_Union, ST_Collect, ST_MakeLine ou ST_LineMerge ?&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com&#34;&gt;BazinGa&amp;#039;s&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Arthur Bazin</name>
    </author>
  </entry>
  <entry>
    <title>osm2pgsql – Exploiter les données d’OpenStreetMap dans PostGIS</title>
    <updated>2021-05-01T18:00:00Z</updated>
    <id>tag:blog.arthurbazin.com,2021-05-01:/bdd/postgresql/postgresql-utilitaire-osm2pgsql</id>
    <link href="https://blog.arthurbazin.com/bdd/postgresql/postgresql-utilitaire-osm2pgsql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Toutes les informations pour démarrer rapidement et efficacement avec cet utilitaire permettant d&#39;importer les données d&#39;OpenStreetMap (format .pbf ou .osm) dans une BDD PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt;L’article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com/bdd/postgresql/postgresql-utilitaire-osm2pgsql&#34;&gt;osm2pgsql &amp;#8211; Exploiter les données d&amp;rsquo;OpenStreetMap dans PostGIS&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.arthurbazin.com&#34;&gt;BazinGa&amp;#039;s&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Arthur Bazin</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL compression du TOAST et toast_tuple_target</title>
    <updated>2022-02-14T07:00:00Z</updated>
    <id>tag:blog.anayrat.info,2022-02-14:/2022/02/14/postgresql-compression-du-toast-et-toast_tuple_target/</id>
    <link href="https://blog.anayrat.info/2022/02/14/postgresql-compression-du-toast-et-toast_tuple_target/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Quelques rappels sur le TOAST et présentation d&amp;rsquo;un changement apparu avec PostgreSQL 11.&lt;/p&gt;&#xA;&lt;h2&gt;Table des matières&lt;/h2&gt;&#xA;&lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#quest-ce-que-le-toast-&#34;&gt;Qu&amp;rsquo;est-ce que le TOAST ?&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#exemple-avec-le-jsonb&#34;&gt;Exemple avec le JSONB&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#paramétrage-avancé&#34;&gt;Paramétrage avancé&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#bonus&#34;&gt;Bonus&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;h1 id=&#34;quest-ce-que-le-toast-&#34;&gt;Qu&amp;rsquo;est-ce que le TOAST ?&lt;/h1&gt;&#xA;&lt;p&gt;Vous êtes-vous déjà posé la question sur comment Postgres fait pour stocker des lignes dépassant la taille d&amp;rsquo;un bloc? Pour rappel, la taille par défaut d&amp;rsquo;un bloc est de 8Ko.&lt;/p&gt;&#xA;&lt;p&gt;Postgres utilise un mécanisme appelé TOAST pour &#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/storage-toast.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Oversized-Attribute Storage Technique&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Lorsqu&amp;rsquo;un enregistrement devient trop gros pour être stocké dans un bloc, le moteur va le stocker &amp;ldquo;à part&amp;rdquo;, dans une table de toast.&#xA;L&amp;rsquo;enregistrement sera découpé en &lt;em&gt;chunks&lt;/em&gt;, ainsi la table principale (appelée &lt;em&gt;heap&lt;/em&gt;) contiendra un pointeur (&lt;em&gt;chunk_id&lt;/em&gt;) pointant vers le bon &lt;em&gt;chunk&lt;/em&gt; dans la table de toast.&lt;/p&gt;&#xA;&lt;p&gt;Ce &lt;em&gt;chunk&lt;/em&gt; sera stocké sur plusieurs lignes, pour un &lt;em&gt;chunk_id&lt;/em&gt; on peut avoir plusieurs lignes dans cette table de toast.&#xA;Ainsi, cette table de toast est composée de 3 colonnes:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;chunk_id&lt;/em&gt; : Numéro du chunk référencé dans la heap&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;chunk_seq&lt;/em&gt; : Numéro de chaque segment d&amp;rsquo;un chunk&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;chunk_data&lt;/em&gt; : Partie données de chaque segment&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La réalité est un peu plus complexe, en vrai le moteur va tenter d&amp;rsquo;éviter de stocker la donnée dans la table toast.&#xA;Si la ligne dépasse &lt;code&gt;TOAST_TUPLE_THRESHOLD&lt;/code&gt; (2Ko), il va tenter de compresser les colonnes pour essayer de faire rentrer la ligne dans le bloc.&#xA;Plus précisément, il faut que la taille soit inférieure à &lt;code&gt;TOAST_TUPLE_TARGET&lt;/code&gt; (2Ko par défaut, on va en reparler).&lt;/p&gt;&#xA;&lt;p&gt;Si on a de la chance, la ligne compressée rentre dans la heap. Sinon, il va tenter de compresser les colonnes,&#xA;de la plus grande à la plus petite et les stocker dans la partie toast jusqu&amp;rsquo;à ce que les colonnes restantes rentrent dans une ligne de la heap. &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&lt;p&gt;A noter également que si le gain en compression est trop faible, il considère qu&amp;rsquo;il est inutile de dépenser&#xA;de la ressource de calcul à tenter de compresser. Il stocke donc la donnée sans compression. &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&lt;p&gt;Avez-vous déjà prêté attention à la colonne &amp;ldquo;Storage&amp;rdquo; lorsque vous affichez les caractéristiques d&amp;rsquo;une table à l&amp;rsquo;aide de la méta commande &lt;code&gt;\d+ table&lt;/code&gt; ?&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;stackoverflow=# \d+ posts&#xA;                   Table &amp;quot;public.posts&amp;quot;&#xA;    Column     |  Type   | Collation | Nullable | Default | Storage  |&#xA;---------------+---------+-----------+----------+---------+----------+&#xA; id            | integer |           | not null |         | plain    |&#xA; posttypeid    | integer |           | not null |         | plain    |&#xA; score         | integer |           |          |         | plain    |&#xA; viewcount     | integer |           |          |         | plain    |&#xA; body          | text    |           |          |         | extended |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Dans cet exemple, la colonne prend comme valeur &lt;em&gt;plain&lt;/em&gt; ou &lt;em&gt;extended&lt;/em&gt;. En réalité, il existe 4 valeurs possibles selon le type de donnée :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;plain&lt;/em&gt; : la colonne est stockée dans la heap uniquement et sans compression.&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;extended&lt;/em&gt; : la colonne peut être compressée et stockée dans le toast si nécessaire.&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;external&lt;/em&gt; : la colonne peut être stockée dans le toast mais uniquement sans compression. Parfois on peut utiliser ce mode pour avoir un gain en performance (évite la compression/décompression)&#xA;au prix d&amp;rsquo;une consommation plus importante de l&amp;rsquo;espace disque.&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;main&lt;/em&gt; : La colonne est stockée dans la heap uniquement mais contrairement au mode &lt;em&gt;plain&lt;/em&gt;, on autorise la compression.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Au premier abord, on peut penser que l&amp;rsquo;intérêt est surtout sur la possibilité de stocker&#xA;des lignes dépassant la taille d&amp;rsquo;un bloc et de compresser la donnée pour gagner de l&amp;rsquo;espace disque.&lt;/p&gt;&#xA;&lt;p&gt;Il y a un autre intérêt : lors d&amp;rsquo;une mise à jour d&amp;rsquo;une ligne, si les colonnes &amp;ldquo;toastées&amp;rdquo; ne sont pas modifiées, le moteur n&amp;rsquo;a pas besoin de modifier la table toast.&#xA;On va ainsi éviter de devoir décompresser et recompresser le toast et écrire tout ça dans des journaux de transaction.&lt;/p&gt;&#xA;&lt;p&gt;Nous allons voir qu&amp;rsquo;un autre avantage est que le moteur peut éviter de lire le toast si ce n&amp;rsquo;est pas nécessaire.&lt;/p&gt;&#xA;&lt;h1 id=&#34;exemple-avec-le-jsonb&#34;&gt;Exemple avec le JSONB&lt;/h1&gt;&#xA;&lt;p&gt;Pour étudier ça, on va utiliser le type JSONB. De manière générale, je déconseille l&amp;rsquo;usage de ce type :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;On perd les avantages d&amp;rsquo;avoir un schéma :&#xA;&lt;ul&gt;&#xA;&lt;li&gt;vérification des types&lt;/li&gt;&#xA;&lt;li&gt;contraintes d&amp;rsquo;intégrité&lt;/li&gt;&#xA;&lt;li&gt;pas de clés étrangères&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;L&amp;rsquo;écriture des requêtes devient plus complexe&lt;/li&gt;&#xA;&lt;li&gt;Absence des statistiques sur les clés d&amp;rsquo;un champ json&lt;/li&gt;&#xA;&lt;li&gt;Perte d&amp;rsquo;efficacité du stockage vu qu&amp;rsquo;on stocke les clés pour chaque ligne&lt;/li&gt;&#xA;&lt;li&gt;Pas de mise à jour partielle du JSONB. Si on modifie une clé on est obligé de &lt;em&gt;detoaster&lt;/em&gt; et &lt;em&gt;toaster&lt;/em&gt; tout le JSONB&lt;/li&gt;&#xA;&lt;li&gt;Pas de &lt;em&gt;detoast&lt;/em&gt; partiel : si on souhaite lire une seule clé du JSONB, on est contraint de &lt;em&gt;detoaster&lt;/em&gt; tout le JSONB &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Cependant, il y a quelques exceptions où le JSON peut être utile :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Lorsqu&amp;rsquo;on n&amp;rsquo;a pas besoin de chercher dans de multiples champs et qu&amp;rsquo;on récupère le json via une autre colonne. (Statistiques sur les clés du json inutiles).&lt;/li&gt;&#xA;&lt;li&gt;Et, lorsqu&amp;rsquo;il serait très difficile de faire rentrer le json dans un schéma relationnel. Certains cas impliqueraient d&amp;rsquo;avoir énormément de colonnes et la plupart à &lt;code&gt;NULL&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Par exemple, pour stocker des caractéristiques de produit où une version normalisée entrainerait l&amp;rsquo;usage de beaucoup de colonnes dont la plupart seraient à &lt;code&gt;NULL&lt;/code&gt;.&#xA;Imaginons que vous stockez des produits, une télévision aurait des caractéristiques spécifiques (type d&amp;rsquo;écran, taille etc). Une machine à laver aurait aussi d&amp;rsquo;autre caractéristiques spécifiques (vitesse essorage, poids accepté&amp;hellip;).&lt;/p&gt;&#xA;&lt;p&gt;On pourrait ainsi envisager d&amp;rsquo;avoir des colonnes &amp;ldquo;normales&amp;rdquo; comprenant le modèle, son prix, sa référence etc, et une colonne contenant toutes les caractéristiques.&#xA;On accèderait à la ligne via la référence et ainsi on récupèrerait toutes les caractéristiques du produit stockées dans le json.&lt;/p&gt;&#xA;&lt;p&gt;Je vais réutiliser la table des posts de Stackoverflow en déplaçant quelques colonnes dans une colonne de type jsonb (colonne &lt;em&gt;jsonfield&lt;/em&gt; dans cet exemple):&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;\d posts&#xA;                            Unlogged table &amp;quot;public.posts&amp;quot;&#xA;        Column         |            Type             | Collation | Nullable | Default&#xA;-----------------------+-----------------------------+-----------+----------+---------&#xA; id                    | integer                     |           | not null |&#xA; posttypeid            | integer                     |           | not null |&#xA; acceptedanswerid      | integer                     |           |          |&#xA; parentid              | integer                     |           |          |&#xA; creationdate          | timestamp without time zone |           | not null |&#xA; score                 | integer                     |           |          |&#xA; viewcount             | integer                     |           |          |&#xA; body                  | text                        |           |          |&#xA; owneruserid           | integer                     |           |          |&#xA; lasteditoruserid      | integer                     |           |          |&#xA; lasteditordisplayname | text                        |           |          |&#xA; lasteditdate          | timestamp without time zone |           |          |&#xA; lastactivitydate      | timestamp without time zone |           |          |&#xA; title                 | text                        |           |          |&#xA; tags                  | text                        |           |          |&#xA; answercount           | integer                     |           |          |&#xA; commentcount          | integer                     |           |          |&#xA; favoritecount         | integer                     |           |          |&#xA; closeddate            | timestamp without time zone |           |          |&#xA; communityowneddate    | timestamp without time zone |           |          |&#xA; jsonfield             | jsonb                       |           |          |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Voici une requête toute simple d&amp;rsquo;agrégation :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT&#xA;  avg(viewcount),&#xA;  avg(answercount),&#xA;  avg(commentcount),&#xA;  avg(favoritecount)&#xA;FROM posts;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;                                                          QUERY PLAN&#xA;-------------------------------------------------------------------------------------------------------------------------------&#xA; Aggregate  (cost=10265135.77..10265135.78 rows=1 width=128) (actual time=170221.557..170221.558 rows=1 loops=1)&#xA;   Buffers: shared hit=1 read=9186137&#xA;   I/O Timings: read=138022.290&#xA;   -&amp;gt;  Seq Scan on posts  (cost=0.00..9725636.88 rows=53949888 width=16) (actual time=0.014..153665.913 rows=53949886 loops=1)&#xA;         Buffers: shared hit=1 read=9186137&#xA;         I/O Timings: read=138022.290&#xA; Planning Time: 0.240 ms&#xA; Execution Time: 170221.627 ms&#xA;(8 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;La requête lit 70 Go de données et met environ 2min 50s à s&amp;rsquo;exécuter.&lt;/p&gt;&#xA;&lt;p&gt;Maintenant la même requête, mais cette fois en utilisant les clés présentes dans le json.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT&#xA;  avg((jsonfield -&amp;gt;&amp;gt; &#39;ViewCount&#39;)::int),&#xA;  avg((jsonfield -&amp;gt;&amp;gt; &#39;AnswerCount&#39;)::int),&#xA;  avg((jsonfield -&amp;gt;&amp;gt; &#39;CommentCount&#39;)::int),&#xA;  avg((jsonfield -&amp;gt;&amp;gt; &#39;FavoriteCount&#39;)::int)&#xA;FROM posts;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;                           QUERY PLAN&#xA;------------------------------------------------------------------------------&#xA; Aggregate  (cost=11883632.41..11883632.42 rows=1 width=128)&#xA;            (actual time=520917.028..520917.030 rows=1 loops=1)&#xA;   Buffers: shared hit=241116554 read=13625756&#xA;   -&amp;gt;  Seq Scan on posts  (cost=0.00..9725636.88 rows=53949888 width=570)&#xA;                          (actual time=0.972..70569.365 rows=53949886 loops=1)&#xA;         Buffers: shared read=9186138&#xA; Planning Time: 0.118 ms&#xA; Execution Time: 520945.395 ms&#xA;(10 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;La requête met environ 8min 40s à s&amp;rsquo;exécuter. En revanche le nombre de blocs lus semble un peu délirant :&lt;/p&gt;&#xA;&lt;p&gt;Le Seq Scan indique comme tout à l&amp;rsquo;heure 70Go. En revanche, le nœud parent indique plus de 1.9 To lus!&lt;/p&gt;&#xA;&lt;p&gt;Voici la taille de la table avec le paramétrage par défaut. Il faut savoir que pour certains enregistrements,&#xA;le moteur va, soit compresser la ligne dans la heap, soit la compresser et la placer dans le toast.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;SELECT&#xA;  pg_size_pretty(pg_relation_size(oid)) table_size,&#xA;  pg_size_pretty(pg_relation_size(reltoastrelid)) toast_size&#xA;FROM pg_class&#xA;WHERE relname = &#39;posts&#39;;&#xA;&#xA; table_size | toast_size&#xA;------------+-----------&#xA; 70 GB      | 33 GB&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Comment expliquer les 1.9 To lus ?&lt;/p&gt;&#xA;&lt;p&gt;Par curiosité, j&amp;rsquo;ai fait la même requête, mais avec une seule agrégation et j&amp;rsquo;obtiens environ 538 Go.&lt;/p&gt;&#xA;&lt;p&gt;On peut se poser plusieurs questions :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Comment savoir si le moteur va lire le toast ?&lt;/li&gt;&#xA;&lt;li&gt;Pourquoi un tel écart de temps d&amp;rsquo;exécution entre la version &amp;ldquo;colonne standard&amp;rdquo; et champ jsonb?&lt;/li&gt;&#xA;&lt;li&gt;A quoi correspondent les compteurs dans le nœud &lt;code&gt;Aggregate&lt;/code&gt; ?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Pour répondre à la première question, il suffit de lire la vue &lt;code&gt;pg_statio_user_tables&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Avant exécution de la requête :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;select relid,schemaname,relname,heap_blks_read,heap_blks_hit,toast_blks_read,toast_blks_hit from pg_statio_all_tables where relname in (&#39;posts&#39;,&#39;pg_toast_26180851&#39;);&#xA;  relid   | schemaname |      relname      | heap_blks_read | heap_blks_hit | toast_blks_read | toast_blks_hit&#xA;----------+------------+-------------------+----------------+---------------+-----------------+----------------&#xA; 26180851 | public     | posts             |      422018238 |      87673549 |       129785076 |      628153337&#xA; 26180854 | pg_toast   | pg_toast_26180851 |      129785076 |     628153337 |                 |&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Après :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;  relid   | schemaname |      relname      | heap_blks_read | heap_blks_hit | toast_blks_read | toast_blks_hit&#xA;----------+------------+-------------------+----------------+---------------+-----------------+----------------&#xA; 26180851 | public     | posts             |      431204376 |      87673549 |       134156898 |      686299551&#xA; 26180854 | pg_toast   | pg_toast_26180851 |      134156898 |     686299551 |                 |&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Ce qui nous fait :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT&#xA;pg_size_pretty(&#xA;    ((431204376 + 87673549) - (422018238 + 87673549) ) * 8*1024::bigint&#xA;) heap_buffers,&#xA;pg_size_pretty(&#xA;    ((134156898 + 686299551) - (129785076 + 628153337) ) * 8*1024::bigint&#xA;) toast_buffers;&#xA;&#xA; heap_buffers | toast_buffers&#xA;--------------+---------------&#xA; 70 GB        | 477 GB&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Le moteur va bien lire le toast. En revanche les compteurs laissent penser que le moteur va lire plusieurs fois le toast.&lt;/p&gt;&#xA;&lt;p&gt;Si je fais le même calcul, mais cette fois en effectuant l&amp;rsquo;agrégation que sur un seul champ, j&amp;rsquo;obtiens 119 Go (~ 477 Go / 4)&#xA;J&amp;rsquo;imagine que le moteur lit le toast pour chaque fonction.&lt;/p&gt;&#xA;&lt;p&gt;Ensuite, l&amp;rsquo;écart du temps d&amp;rsquo;exécution s&amp;rsquo;explique par plusieurs facteurs :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Le moteur va devoir lire et &lt;em&gt;detoaster&lt;/em&gt; (décompresser) le toast&lt;/li&gt;&#xA;&lt;li&gt;Faire des opérations supplémentaires sur le jsonb pour accéder à la valeur&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Avec la première requête, le moteur n&amp;rsquo;avait pas à lire le toast. D&amp;rsquo;une part, il a moins de données à lire,&#xA;d&amp;rsquo;autre part, il n&amp;rsquo;a pas à manipuler le json pour identifier la clé et extraire la valeur à calculer.&lt;/p&gt;&#xA;&lt;p&gt;Enfin, les compteurs du nœud aggregate doivent correspondre aux données décompressées pour chaque fonction qui va lire dans le json.&#xA;En effet, si on prend le total moins le &lt;em&gt;seqscan&lt;/em&gt; de la table, donc que la partie &lt;em&gt;toast&lt;/em&gt;, on a :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;468 Go pour un seul champ&lt;/li&gt;&#xA;&lt;li&gt;936 Go, le double pour deux champs&lt;/li&gt;&#xA;&lt;li&gt;1873 Go pour les 4 champs (donc environ 4 x 468 Go)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;C&amp;rsquo;est ce qui explique pourquoi on obtient une valeur aussi élevée.&lt;/p&gt;&#xA;&lt;h1 id=&#34;paramétrage-avancé&#34;&gt;Paramétrage avancé&lt;/h1&gt;&#xA;&lt;p&gt;Maintenant, on va encourager Postgres à placer le maximum de données dans le toast grâce à l&amp;rsquo;option &lt;em&gt;toast_tuple_target&lt;/em&gt; apparue avec la version 11 de Postgres.&lt;/p&gt;&#xA;&lt;p&gt;Cette option permet de manipuler le seuil à partir duquel les données sont stockée dans le &lt;em&gt;toast&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Par ailleurs, étant sous Postgres 14, j&amp;rsquo;en ai profité pour utiliser l&amp;rsquo;algorithme de compression lz4 (paramètre &lt;em&gt;default_toast_compression&lt;/em&gt;).&#xA;Cet algorithme offre un ratio de compression similaire à pglz, cependant, il est beaucoup plus rapide (Voir &#xA;&lt;a href=&#34;https://www.postgresql.fastware.com/blog/what-is-the-new-lz4-toast-compression-in-postgresql-14&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;What is the new LZ4 TOAST compression in PostgreSQL 14, and how fast is it?&lt;/a&gt;).&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE posts_toast&#xA;  WITH (toast_tuple_target = 128) AS&#xA;    SELECT *&#xA;    FROM posts;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Voici la taille de la table obtenue.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;SELECT&#xA;  pg_size_pretty(pg_relation_size(oid)) table_size,&#xA;  pg_size_pretty(pg_relation_size(reltoastrelid)) toast_size&#xA;FROM pg_class&#xA;WHERE relname = &#39;posts_toast&#39;;&#xA;&#xA; table_size | toast_size&#xA;------------+------------&#xA; 59 GB      | 52 GB&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Au total, la table avec le toast fait grosso-modo la même taille. Dans l&amp;rsquo;exemple avec la première table,&#xA;il faut savoir que le moteur compresse aussi les données dans la heap.&lt;/p&gt;&#xA;&lt;p&gt;Rejouons notre requête d&amp;rsquo;agrégation :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT&#xA;  avg(viewcount),&#xA;  avg(answercount),&#xA;  avg(commentcount),&#xA;  avg(favoritecount)&#xA;FROM posts_toast;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Cette fois la requête lit 59 Go de données et met 2min 17 secondes.&#xA;On a gagné environ 20% de temps d&amp;rsquo;exécution sur cet exemple.&lt;/p&gt;&#xA;&lt;p&gt;On pourrait gagner beaucoup plus si la partie stockée en toast était plus importante. Le volume de donnée à lire dans la heap serait beaucoup plus réduit.&lt;/p&gt;&#xA;&lt;p&gt;Par curiosité, j&amp;rsquo;ai aussi exécuté la requête qui fait l&amp;rsquo;agrégation depuis les données du champ json. J&amp;rsquo;obtiens un temps d&amp;rsquo;exécution de 7min 17s.&lt;/p&gt;&#xA;&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&lt;p&gt;Résumé en quelques chiffres :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Agrégation type standard, stockage standard : 2min 50s&lt;/li&gt;&#xA;&lt;li&gt;Agrégation type jsonb, stockage standard : 8min 40s&lt;/li&gt;&#xA;&lt;li&gt;Agrégation type standard, stockage avec &lt;em&gt;toast_tuple_target&lt;/em&gt; = 128 : 2min 17s&lt;/li&gt;&#xA;&lt;li&gt;Agrégation type jsonb, stockage avec &lt;em&gt;toast_tuple_target&lt;/em&gt; = 128 : 7min 17s&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;On constate que l&amp;rsquo;usage du JSON est bien plus couteux que d&amp;rsquo;utiliser les types standards. Le moteur doit faire plus d&amp;rsquo;opérations pour accéder à la valeur d&amp;rsquo;une clé json.&lt;/p&gt;&#xA;&lt;p&gt;Par ailleurs, il est obligé de décompresser les données dans le toast pour y accéder. Néanmoins, on peut aussi jouer avec le paramètre &lt;code&gt;toast_tuple_target&lt;/code&gt; pour pousser plus&#xA;d&amp;rsquo;informations dans le toast. Ainsi, dans certains cas, cela peut permettre de réduire la quantité de données lues en évitant de lire le toast.&lt;/p&gt;&#xA;&lt;h1 id=&#34;bonus&#34;&gt;Bonus&lt;/h1&gt;&#xA;&lt;p&gt;Comment souvent dans Postgres, tout évolue au fil des versions. Le TOAST n&amp;rsquo;échappe pas à cette règle.&#xA;Ainsi, quelques nouveautés pourraient apparaitre dans les prochaines versions :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Un premier patch a été proposé pour avoir plus de statistiques sur le toast : &#xA;&lt;a href=&#34;https://commitfest.postgresql.org/37/3457/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pg_stat_toast&lt;/a&gt;.&#xA;L&amp;rsquo;idée, est d&amp;rsquo;avoir des statistiques sur la compression : gain compression, stockage inline ou séparé dans le toast&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;Un second patch appelé &#xA;&lt;a href=&#34;https://commitfest.postgresql.org/37/3490/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pluggable toaster&lt;/a&gt;. Celui-ci est beaucoup plus important. Il propose d&amp;rsquo;étendre le &lt;em&gt;&amp;ldquo;toaster&amp;rdquo;&lt;/em&gt;.&#xA;L&amp;rsquo;idée serait de pouvoir proposer différents &lt;em&gt;&amp;ldquo;toaster&amp;rdquo;&lt;/em&gt; selon le type de donnée (notamment le JSONB).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;&#xA;&lt;p&gt;Voir &#xA;&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/access/heap/heaptoast.c;h=55bbe1d584760a849960871296dfbdd7447b2b67;hb=refs/heads/REL_14_STABLE#l160&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;heap_toast_insert_or_update&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;&#xA;&lt;p&gt;Il existe deux algorithmes de compression supportés : &lt;em&gt;pglz&lt;/em&gt; (historique et intégré dans Postgres) et &lt;em&gt;lz4&lt;/em&gt; (depuis Postgres 14).&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Pour &lt;em&gt;pglz&lt;/em&gt;, voir &#xA;&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/include/common/pg_lzcompress.h;h=3e53fbe97bd0a10e3fbf7ed4396924084f657868;hb=refs/heads/REL_14_STABLE#l25&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PGLZ_Strategy&lt;/a&gt;&#xA;et &#xA;&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/common/pg_lzcompress.c;h=a30a2c2eb83a71725754d8dd680621a02e7557e9;hb=refs/heads/REL_14_STABLE#l223&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;strategy_default_data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Pour &lt;em&gt;lz4&lt;/em&gt;, il s&amp;rsquo;agit d&amp;rsquo;une librarie externe. Voir &#xA;&lt;a href=&#34;https://github.com/lz4/lz4/blob/dev/lib/lz4.h#L145&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LZ4_compress_default&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;&#xA;&lt;p&gt;Voir les slides de la conférence d&amp;rsquo;Oleg Bartunov et Nikita Glukhov : &#xA;&lt;a href=&#34;http://www.sai.msu.su/~megera/postgres/talks/jsonb-nizhny-2021.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;json or not json that is the question&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/section&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>Cas d&#39;usages du partitionnement natif dans PostgreSQL</title>
    <updated>2021-09-01T07:00:00Z</updated>
    <id>tag:blog.anayrat.info,2021-09-01:/2021/09/01/cas-dusages-du-partitionnement-natif-dans-postgresql/</id>
    <link href="https://blog.anayrat.info/2021/09/01/cas-dusages-du-partitionnement-natif-dans-postgresql/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Après une période d&amp;rsquo;inactivité, je reprends l&amp;rsquo;écriture d&amp;rsquo;articles techniques sur Postgres. C&amp;rsquo;est aussi pour moi l&amp;rsquo;occasion de vous annoncer mon changement d&amp;rsquo;activité. Depuis courant 2021 je suis passé freelance pour permettre aux entreprises de bénéficier de mon expérience sur Postgres.&lt;/p&gt;&#xA;&lt;h2&gt;Table des matières&lt;/h2&gt;&#xA;&lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#histoire-du-partitionnement-dans-postgresql&#34;&gt;Histoire du partitionnement dans PostgreSQL&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#erreurs-courantes&#34;&gt;Erreurs courantes&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#il-faut-partitionner-dès-que-la-volumétrie-est-importante&#34;&gt;&amp;ldquo;Il faut partitionner dès que la volumétrie est importante&amp;rdquo;&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#il-faut-partitionner-pour-répartir-les-données-sur-plusieurs-disques&#34;&gt;&amp;ldquo;Il faut partitionner pour répartir les données sur plusieurs disques&amp;rdquo;&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#cas-dusages-du-partitionnement&#34;&gt;Cas d&amp;rsquo;usages du partitionnement&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionner-pour-gérer-la-rétention&#34;&gt;Partitionner pour gérer la rétention&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionner-pour-contrôler-la-fragmentation-des-index&#34;&gt;Partitionner pour contrôler la fragmentation des index&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionner-pour-faciliter-lexécution-de-requête-lorsque-la-cardinalité-est-faible&#34;&gt;Partitionner pour faciliter l&amp;rsquo;exécution de requête lorsque la cardinalité est faible&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionner-pour-obtenir-de-meilleures-statistiques&#34;&gt;Partitionner pour obtenir de meilleures statistiques&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#partitionwise-join--partitionwise-aggregate&#34;&gt;partitionwise join &amp;amp; partitionwise aggregate&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#stockage-avec-tiering&#34;&gt;Stockage avec tiering&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;h1 id=&#34;histoire-du-partitionnement-dans-postgresql&#34;&gt;Histoire du partitionnement dans PostgreSQL&lt;/h1&gt;&#xA;&lt;p&gt;PostgreSQL permet depuis très longtemps de partitionner des tables en exploitant l&amp;rsquo;héritage de table. Toutefois, cette méthode était assez lourde à mettre en oeuvre : elle impliquait de mettre en place soi-même des triggers pour rediriger les écritures (moins performant que le partitionnement natif), le temps de planification pouvait augmenter fortement au-delà d&amp;rsquo;une centaine de partitions&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;Le partitionnement natif est arrivé avec la version 10. C&amp;rsquo;est depuis cette version que le moteur est capable (entre autres) de diriger lui-même les écritures vers les bonnes tables, lire seulement les tables concernées, d&amp;rsquo;utiliser des algorithmes exploitant le partitionnement etc.&#xA;Il offre ainsi de meilleures performances et une facilité d&amp;rsquo;exploitation. On peut entre autres :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Partitionner :&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Par liste&lt;/li&gt;&#xA;&lt;li&gt;Par hashage&lt;/li&gt;&#xA;&lt;li&gt;Par intervalles&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Faire des partitionnements à plusieurs niveaux&lt;/li&gt;&#xA;&lt;li&gt;Partitionner sur plusieurs colonnes&lt;/li&gt;&#xA;&lt;li&gt;Utiliser des clés primaires et clés étrangères&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Toutes ces fonctionnalités sont intéressantes, mais on en vient à se poser une question toute bête : quand mettre en oeuvre le partitionnement?&lt;/p&gt;&#xA;&lt;p&gt;Je vais vous présenter plusieurs cas d&amp;rsquo;usages que j&amp;rsquo;ai pu rencontrer. Mais avant, voici quelques erreurs courantes sur le partitionnement.&lt;/p&gt;&#xA;&lt;h1 id=&#34;erreurs-courantes&#34;&gt;Erreurs courantes&lt;/h1&gt;&#xA;&lt;h2 id=&#34;il-faut-partitionner-dès-que-la-volumétrie-est-importante&#34;&gt;&amp;ldquo;Il faut partitionner dès que la volumétrie est importante&amp;rdquo;&lt;/h2&gt;&#xA;&lt;p&gt;Déjà, qu&amp;rsquo;est-ce qu&amp;rsquo;une volumétrie &amp;ldquo;importante&amp;rdquo;?&lt;/p&gt;&#xA;&lt;p&gt;Certains diront que c&amp;rsquo;est au-delà de plusieurs centaines de Go, d&amp;rsquo;autres au-delà du téraoctet, d&amp;rsquo;autres encore au-delà du pétaoctet&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;Il n&amp;rsquo;existe pas vraiment de réponse à cette question et globalement ça va dépendre du type d&amp;rsquo;activité : ratio INSERT/UPDATE/DELETE, type de SELECT (OLTP, OLAP&amp;hellip;).&#xA;Ca dépendra également du matériel. Il y a 10 ans, quand les serveurs n&amp;rsquo;avaient que quelques Go de RAM avec des disques mécaniques, il était probable qu&amp;rsquo;une base de quelques centaines de Go soit perçue comme une grosse base.&#xA;Maintenant il n&amp;rsquo;est pas rare de voir des serveurs avec plus d&amp;rsquo;un téraoctet de RAM, des disques NVMe.&lt;/p&gt;&#xA;&lt;p&gt;Ainsi, une base de quelques centaines de Go n&amp;rsquo;est plus considérée comme une grosse base. Mais plutôt comme une base de taille modeste.&lt;/p&gt;&#xA;&lt;p&gt;Petite anecdote, pour se rassurer, un client m&amp;rsquo;a questionné si Postgres était déjà utilisé pour des volumétries &amp;ldquo;importantes&amp;rdquo;. On parlait alors d&amp;rsquo;une base d&amp;rsquo;une quarantaine de Go sur un serveur qui disposait de 64Go de RAM. Toutes les lectures se faisaient depuis le cache&amp;hellip; :). J&amp;rsquo;ai pu le rassurer sur la taille de sa base qui était relativement modeste.&lt;/p&gt;&#xA;&lt;p&gt;Il peut tout à fait être superflu de partitionner une base de quelques To comme il peut être nécessaire de partitionner une base de quelques centaines de Go. Par exemple, si l&amp;rsquo;activité consiste juste à ajouter des lignes à des tables et que les requêtes se résument à de simple &lt;code&gt;WHERE colonne = 4&lt;/code&gt; qui retournent quelques lignes. Un simple Btree fera l&amp;rsquo;affaire. Et si la requête retourne un nombre assez important de lignes, il est possible d&amp;rsquo;utiliser les index BRIN ou les bloom filter.&lt;/p&gt;&#xA;&lt;p&gt;Les index BRIN présentent des bénéfices proches du partitionnement ou sharding en évitant la complexité de mise en oeuvre&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;il-faut-partitionner-pour-répartir-les-données-sur-plusieurs-disques&#34;&gt;&amp;ldquo;Il faut partitionner pour répartir les données sur plusieurs disques&amp;rdquo;&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;rsquo;idée serait de créer des partitions et des tablespaces sur différents disques afin de répartir les opérations d&amp;rsquo;entrées/sorties.&lt;/p&gt;&#xA;&lt;p&gt;Pour PostgreSQL, un tablespace n&amp;rsquo;est ni plus, ni moins qu&amp;rsquo;un chemin vers un répertoire. Il est tout à fait possible&#xA;de gérer le stockage au niveau du système d&amp;rsquo;exploitation et d&amp;rsquo;agréger plusieurs disques (en RAID10) par exemple.&#xA;Ensuite, il suffit de stocker la table sur le volume créé. Ainsi, on peut répartir les I/O sur un ensemble de disques.&lt;/p&gt;&#xA;&lt;p&gt;Dans ce cas, il n&amp;rsquo;est donc pas nécessaire de mettre en oeuvre le partitionnement. Toutefois, nous verrons un cas où il pourrait avoir du sens.&lt;/p&gt;&#xA;&lt;p&gt;Maintenant nous allons nous intéresser à des cas d&amp;rsquo;usage &amp;ldquo;légitimes&amp;rdquo; du partitionnement.&lt;/p&gt;&#xA;&lt;h1 id=&#34;cas-dusages-du-partitionnement&#34;&gt;Cas d&amp;rsquo;usages du partitionnement&lt;/h1&gt;&#xA;&lt;h2 id=&#34;partitionner-pour-gérer-la-rétention&#34;&gt;Partitionner pour gérer la rétention&lt;/h2&gt;&#xA;&lt;p&gt;A cause du modèle MVCC, la suppression massive de données entraine de la fragmentation dans les tables.&lt;/p&gt;&#xA;&lt;p&gt;Un cas d&amp;rsquo;usage possible est de partitionner par date. Supprimer les anciennes données revient à supprimer une partition complète. L&amp;rsquo;opération sera rapide et les tables ne seront pas fragmentées&lt;/p&gt;&#xA;&lt;h2 id=&#34;partitionner-pour-contrôler-la-fragmentation-des-index&#34;&gt;Partitionner pour contrôler la fragmentation des index&lt;/h2&gt;&#xA;&lt;p&gt;L&amp;rsquo;ajout et modification de données dans une table fragmente les index au fil du temps. Pour faire simple, on ne peut pas récupérer l&amp;rsquo;espace libre dans un bloc tant qu&amp;rsquo;il n&amp;rsquo;est pas vide. Avec le temps les splits d&amp;rsquo;index créent du &amp;ldquo;vide&amp;rdquo; dans ce dernier et le seul moyen de récupérer cet espace est de reconstruire l&amp;rsquo;index.&lt;/p&gt;&#xA;&lt;p&gt;On appelle cela le &amp;ldquo;bloat&amp;rdquo;. Il y a eu de nombreuses améliorations sur les dernières versions de Postgres:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Version 12, on peut lire dans les &#xA;&lt;a href=&#34;https://www.postgresql.org/docs/12/release-12.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Releases Notes&lt;/a&gt;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Improve performance and space utilization of btree indexes with many duplicates (Peter Geoghegan, Heikki Linnakangas)&lt;/p&gt;&#xA;&lt;p&gt;Previously, duplicate index entries were stored unordered within their duplicate groups. This caused overhead during index inserts, wasted space due to excessive page splits, and it reduced VACUUM&amp;rsquo;s ability to recycle entire pages. Duplicate index entries are now sorted in heap-storage order.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Version 13, on peut lire dans les &#xA;&lt;a href=&#34;https://www.postgresql.org/docs/13/release-13.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Releases Notes&lt;/a&gt;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;More efficiently store duplicates in B-tree indexes (Anastasia Lubennikova, Peter Geoghegan)&lt;/p&gt;&#xA;&lt;p&gt;This allows efficient B-tree indexing of low-cardinality columns by storing duplicate keys only once. Users upgrading with pg_upgrade will need to use REINDEX to make an existing index use this feature.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Version 14, on peut lire dans les &#xA;&lt;a href=&#34;https://www.postgresql.org/docs/14/release-14.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Releases Notes&lt;/a&gt;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Allow btree index additions to remove expired index entries to prevent page splits (Peter Geoghegan)&lt;/p&gt;&#xA;&lt;p&gt;This is particularly helpful for reducing index bloat on tables whose indexed columns are frequently updated.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Pour contrôler le bloat, on pourrait reconstruire l&amp;rsquo;index à intervalles réguliers (merci &lt;code&gt;REINDEX CONCURRENTLY&lt;/code&gt; arrivé en version 12). Cette solution serait contraignante, car il faudrait régulièrement reconstruire l&amp;rsquo;intégralité de l&amp;rsquo;index.&lt;/p&gt;&#xA;&lt;p&gt;Si la majorité des modifications sont faites sur les données récentes, par exemple: table de logs, commandes clients, rendez-vous&amp;hellip; On pourrait imaginer un partitionnement par mois. Ainsi, à chaque début de mois on part sur une table &amp;ldquo;neuve&amp;rdquo; et on peut ré-indexer la précédente table pour supprimer le bloat.&lt;/p&gt;&#xA;&lt;p&gt;On peut aussi en profiter pour faire un &lt;code&gt;CLUSTER&lt;/code&gt; sur la table pour avoir une bonne corrélation des données avec le stockage.&lt;/p&gt;&#xA;&lt;h2 id=&#34;partitionner-pour-faciliter-lexécution-de-requête-lorsque-la-cardinalité-est-faible&#34;&gt;Partitionner pour faciliter l&amp;rsquo;exécution de requête lorsque la cardinalité est faible&lt;/h2&gt;&#xA;&lt;p&gt;Petit à petit on va voir des cas d&amp;rsquo;usages un peu plus compliqués :)&lt;/p&gt;&#xA;&lt;p&gt;Prenons un exemple : une table de commande comprenant un statut de livraison, au bout de quelques années 99% des commandes sont livrées (on l&amp;rsquo;espère!) et très peu en cours de paiement ou livraison.&lt;/p&gt;&#xA;&lt;p&gt;Imaginons qu&amp;rsquo;on souhaite récupérer 100 commandes en cours de livraison. On va créer un index sur le statut et l&amp;rsquo;utiliser pour récupérer les enregistrements.&#xA;En étant un peu astucieux, on peut créer un index partiel sur ce statut particulier. Problème, cet index va se fragmenter assez vite au fur et à mesure que les commandes seront livrées.&lt;/p&gt;&#xA;&lt;p&gt;Dans ce cas on pourrait faire un partitionnement sur le statut. Ainsi, récupérer 100 commandes en cours de livraison revient à lire 100 enregistrements de la partition.&lt;/p&gt;&#xA;&lt;h2 id=&#34;partitionner-pour-obtenir-de-meilleures-statistiques&#34;&gt;Partitionner pour obtenir de meilleures statistiques&lt;/h2&gt;&#xA;&lt;p&gt;Pour déterminer le meilleur plan d&amp;rsquo;exécution, Postgres prend des décisions à partir des statistiques d&amp;rsquo;une table. Ces statistiques sont obtenues à partir d&amp;rsquo;un échantillon de la table (le &lt;code&gt;default_statistic_target&lt;/code&gt; qui vaut 100 par défaut).&lt;/p&gt;&#xA;&lt;p&gt;Par défaut le moteur va collecter 300 x &lt;code&gt;default_statistic_target&lt;/code&gt; lignes, soit 30 000 lignes. Avec une table de plusieurs centaines de millions de lignes, cet échantillon est parfois trop petit.&lt;/p&gt;&#xA;&lt;p&gt;On peut augmenter de manière drastique la taille de l&amp;rsquo;échantillon, mais cette approche présente quelques inconvénients:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ca alourdis le temps de planification&lt;/li&gt;&#xA;&lt;li&gt;Ca alourdis le &lt;code&gt;ANALYZE&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Parfois ce n&amp;rsquo;est pas suffisant si les données sont mal réparties. Par exemple si on prend quelques centaines de milliers de lignes sur une table qui comprend plusieurs centaines de millions, on peut rater les lignes dont le statut est en livraison.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Avec le partitionnement on pourrait avoir un même échantillon, mais par partition, ce qui permet de gagner en précision.&lt;/p&gt;&#xA;&lt;p&gt;Ce serait également utile quand on a des données corrélées entre colonnes. Je vais reprendre l&amp;rsquo;exemple des commandes. On a une année entière de commandes: toutes les commandes qui ont plus d&amp;rsquo;un mois sont livrées, celles du dernier mois sont livrées à 90% (10% sont en cours de livraison).&lt;/p&gt;&#xA;&lt;p&gt;Intuitivement, si je cherche une commande en cours de livraison il y a plus de 6 mois je ne devrais pas avoir de résultat. Inversement, si je cherche des commandes en cours de livraison sur le dernier mois, je devrais obtenir 10% de la table. Or, le moteur ne le sait pas, pour lui les commandes en cours de livraison sont réparties sur toute la table.&lt;/p&gt;&#xA;&lt;p&gt;Avec un partitionnement par date, il peut estimer qu&amp;rsquo;il n&amp;rsquo;y a pas de commande en cours de livraisons de plus d&amp;rsquo;un mois. Ce type d&amp;rsquo;approche permet surtout de réduire une erreur d&amp;rsquo;estimation dans un plan d&amp;rsquo;exécution.&lt;/p&gt;&#xA;&lt;p&gt;Voici un exemple avec cette table de commandes, &lt;code&gt;orders_p&lt;/code&gt; est la version partitionnée par mois de la table &lt;code&gt;orders&lt;/code&gt;. Les données étant identiques dans les deux tables.&lt;/p&gt;&#xA;&lt;p&gt;On peut remarquer que l&amp;rsquo;estimation est bien meilleure dans le cas où la table est partitionnée, le moteur ayant des statistiques par partition.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;div style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&#xA;&lt;table style=&#34;border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;&#34;&gt;&lt;tr&gt;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 1&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 2&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 3&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 4&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 5&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 6&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 7&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 8&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 9&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;11&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;12&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;13&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;14&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;15&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;16&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;17&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;18&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;19&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;20&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;21&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;22&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;23&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;24&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;25&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;26&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;27&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;28&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;29&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;30&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;31&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&#xA;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;;width:100%&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;EXPLAIN&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ANALYZE&lt;/span&gt;&#xA;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&#xA;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; orders_p&#xA;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;&#xA;    &lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&#xA;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; c1 &lt;span style=&#34;color:#66d9ef&#34;&gt;BETWEEN&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-01-01&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-01-31&amp;#39;&lt;/span&gt;;&#xA;&lt;/span&gt;&#xA;                                                  QUERY PLAN                                                  &#xA;&lt;span style=&#34;color:#75715e&#34;&gt;--------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Index&lt;/span&gt; Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;using&lt;/span&gt; orders_13_state_idx &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_13  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;Index&lt;/span&gt; Cond: (&lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;::text)&#xA;   Filter: ((c1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-01-01&amp;#39;&lt;/span&gt;::date) &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; (c1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-01-31&amp;#39;&lt;/span&gt;::date))&#xA; Planning Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt; ms&#xA; Execution Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;059&lt;/span&gt; ms&#xA;(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;)&#xA;&#xA;&lt;span style=&#34;color:#66d9ef&#34;&gt;EXPLAIN&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ANALYZE&lt;/span&gt;&#xA;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&#xA;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; orders&#xA;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;&#xA;    &lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&#xA;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; c1 &lt;span style=&#34;color:#66d9ef&#34;&gt;BETWEEN&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-01-01&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-01-31&amp;#39;&lt;/span&gt;;&#xA;&lt;/span&gt;                                                  QUERY PLAN                                                   &#xA;&lt;span style=&#34;color:#75715e&#34;&gt;---------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Index&lt;/span&gt; Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;using&lt;/span&gt; orders_state_idx &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;44&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;13168&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3978&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;Index&lt;/span&gt; Cond: (&lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;::text)&#xA;   Filter: ((c1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-01-01&amp;#39;&lt;/span&gt;::date) &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; (c1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-01-31&amp;#39;&lt;/span&gt;::date))&#xA;   &lt;span style=&#34;color:#66d9ef&#34;&gt;Rows&lt;/span&gt; Removed &lt;span style=&#34;color:#66d9ef&#34;&gt;by&lt;/span&gt; Filter: &lt;span style=&#34;color:#ae81ff&#34;&gt;100161&lt;/span&gt;&#xA; Planning Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;188&lt;/span&gt; ms&#xA; Execution Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;141&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;571&lt;/span&gt; ms&#xA;(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Maintenant prenons la même requête sur le dernier mois:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;div style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&#xA;&lt;table style=&#34;border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;&#34;&gt;&lt;tr&gt;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 1&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 2&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 3&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 4&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 5&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 6&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 7&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 8&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 9&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;11&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;12&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;13&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;14&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;15&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;16&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;17&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;18&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;19&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;20&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;21&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;22&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;23&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;24&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;25&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;26&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;27&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;28&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;29&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;30&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;31&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;32&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&#xA;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;;width:100%&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;EXPLAIN&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ANALYZE&lt;/span&gt;&#xA;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&#xA;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; orders_p&#xA;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;&#xA;    &lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&#xA;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; c1 &lt;span style=&#34;color:#66d9ef&#34;&gt;BETWEEN&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-07-01&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-07-31&amp;#39;&lt;/span&gt;;&#xA;&lt;/span&gt;&#xA;                                                       QUERY PLAN                                                        &#xA;&lt;span style=&#34;color:#75715e&#34;&gt;-------------------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Index&lt;/span&gt; Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;using&lt;/span&gt; orders_19_state_idx &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_19  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;43&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;2417&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;19215&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20931&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;Index&lt;/span&gt; Cond: (&lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;::text)&#xA;   Filter: ((c1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-07-01&amp;#39;&lt;/span&gt;::date) &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; (c1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-07-31&amp;#39;&lt;/span&gt;::date))&#xA; Planning Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;297&lt;/span&gt; ms&#xA; Execution Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;618&lt;/span&gt; ms&#xA;(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;)&#xA;&#xA;&lt;span style=&#34;color:#66d9ef&#34;&gt;EXPLAIN&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ANALYZE&lt;/span&gt;&#xA;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&#xA;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; orders&#xA;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;&#xA;    &lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&#xA;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; c1 &lt;span style=&#34;color:#66d9ef&#34;&gt;BETWEEN&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-07-01&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-07-31&amp;#39;&lt;/span&gt;;&#xA;&lt;/span&gt;&#xA;                                                     QUERY PLAN                                                     &#xA;&lt;span style=&#34;color:#75715e&#34;&gt;--------------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Index&lt;/span&gt; Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;using&lt;/span&gt; orders_state_idx &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;44&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;13168&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15008&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20931&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;Index&lt;/span&gt; Cond: (&lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;::text)&#xA;   Filter: ((c1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-07-01&amp;#39;&lt;/span&gt;::date) &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; (c1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2021-07-31&amp;#39;&lt;/span&gt;::date))&#xA;   &lt;span style=&#34;color:#66d9ef&#34;&gt;Rows&lt;/span&gt; Removed &lt;span style=&#34;color:#66d9ef&#34;&gt;by&lt;/span&gt; Filter: &lt;span style=&#34;color:#ae81ff&#34;&gt;79230&lt;/span&gt;&#xA; Planning Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;173&lt;/span&gt; ms&#xA; Execution Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;146&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;326&lt;/span&gt; ms&#xA;(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Ici aussi on peut remarquer que l&amp;rsquo;estimation est meilleure.&lt;/p&gt;&#xA;&lt;h2 id=&#34;partitionwise-join--partitionwise-aggregate&#34;&gt;partitionwise join &amp;amp; partitionwise aggregate&lt;/h2&gt;&#xA;&lt;p&gt;Un autre intérêt du partitionnement est de bénéficier de meilleurs algorithmes pour les jointures et agrégation.&lt;/p&gt;&#xA;&lt;p&gt;Le &lt;code&gt;partitionwise aggregate&lt;/code&gt; permet de faire une agregation ou un regroupement partition par partition. Un exemple vaut mieux qu&amp;rsquo;un long discours:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;div style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&#xA;&lt;table style=&#34;border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;&#34;&gt;&lt;tr&gt;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 1&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 2&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 3&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 4&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 5&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 6&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 7&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 8&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 9&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;10&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;11&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;12&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;13&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;14&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;15&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;16&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;17&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;18&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;19&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;20&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;21&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;22&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;23&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;24&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;25&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;26&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;27&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;28&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;29&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;30&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;31&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;32&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;33&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;34&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;35&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;36&#xA;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;37&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&#xA;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;;width:100%&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;explain&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;analyze&lt;/span&gt;,timing &lt;span style=&#34;color:#66d9ef&#34;&gt;off&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;count&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;), c1 &lt;span style=&#34;color:#66d9ef&#34;&gt;from&lt;/span&gt; orders_p &lt;span style=&#34;color:#66d9ef&#34;&gt;group&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;by&lt;/span&gt; c1;&#xA;                                                  QUERY PLAN                                                  &#xA;&lt;span style=&#34;color:#75715e&#34;&gt;--------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt; HashAggregate  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;508361&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;508365&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;365&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;365&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;Group&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Key&lt;/span&gt;: orders_01.c1&#xA;   &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  Append  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;408317&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;35&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20008890&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20000000&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  Seq Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_01  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;70&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1270&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  Seq Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_02  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;70&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1270&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;[...]&#xA;         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  Seq Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_19  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;45308&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;04&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2941004&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2941004&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  Seq Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_20  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;131708&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;21&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8549421&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8549421&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA; Planning Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;576&lt;/span&gt; ms&#xA; Execution Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;5273&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;217&lt;/span&gt; ms&#xA;(&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;)&#xA;&#xA;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;set&lt;/span&gt; enable_partitionwise_aggregate &lt;span style=&#34;color:#66d9ef&#34;&gt;to&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt;;&#xA;&lt;/span&gt;&#xA;&lt;span style=&#34;color:#66d9ef&#34;&gt;explain&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;analyze&lt;/span&gt;,timing &lt;span style=&#34;color:#66d9ef&#34;&gt;off&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;count&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;), c1 &lt;span style=&#34;color:#66d9ef&#34;&gt;from&lt;/span&gt; orders_p &lt;span style=&#34;color:#66d9ef&#34;&gt;group&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;by&lt;/span&gt; c1;&#xA;                                                  QUERY PLAN                                                  &#xA;&lt;span style=&#34;color:#75715e&#34;&gt;--------------------------------------------------------------------------------------------------------------&#xA;&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt; Append  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;05&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;408343&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;83&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1765&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;365&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;&lt;/span&gt;   &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  HashAggregate  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;05&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;05&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;         &lt;span style=&#34;color:#66d9ef&#34;&gt;Group&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Key&lt;/span&gt;: orders_01.c1&#xA;         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  Seq Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_01  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;70&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1270&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;   &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  HashAggregate  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;05&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;05&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;         &lt;span style=&#34;color:#66d9ef&#34;&gt;Group&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Key&lt;/span&gt;: orders_02.c1&#xA;         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  Seq Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_02  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;70&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1270&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;[...]&#xA;   &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  HashAggregate  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;60013&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;06&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;60013&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;37&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;         &lt;span style=&#34;color:#66d9ef&#34;&gt;Group&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Key&lt;/span&gt;: orders_19.c1&#xA;         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  Seq Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_19  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;45308&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;04&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2941004&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2941004&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;   &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  HashAggregate  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;174455&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;174455&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;55&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;         &lt;span style=&#34;color:#66d9ef&#34;&gt;Group&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Key&lt;/span&gt;: orders_20.c1&#xA;         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;  Seq Scan &lt;span style=&#34;color:#66d9ef&#34;&gt;on&lt;/span&gt; orders_20  (cost&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;00&lt;/span&gt;..&lt;span style=&#34;color:#ae81ff&#34;&gt;131708&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;21&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8549421&lt;/span&gt; width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) (actual &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8549421&lt;/span&gt; loops&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA; Planning Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;461&lt;/span&gt; ms&#xA; Execution Time: &lt;span style=&#34;color:#ae81ff&#34;&gt;4669&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;315&lt;/span&gt; ms&#xA;(&lt;span style=&#34;color:#ae81ff&#34;&gt;63&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rows&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Dans le premier cas l&amp;rsquo;agrégation se fait une fois pour toutes les tables, alors que dans le second exemple, on fait l&amp;rsquo;agrégation par partition.&#xA;On peut également remarquer que le coût total est inférieur dans le plan avec agrégation par partition.&lt;/p&gt;&#xA;&lt;p&gt;Le &lt;code&gt;partitionwise join&lt;/code&gt; fonctionne sur le même principe, on fait une jointure partition par partition. C&amp;rsquo;est utile pour joindre deux tables partitionnées.&lt;/p&gt;&#xA;&lt;h2 id=&#34;stockage-avec-tiering&#34;&gt;Stockage avec tiering&lt;/h2&gt;&#xA;&lt;p&gt;Enfin, un autre cas d&amp;rsquo;usage serait de vouloir stocker une partie de la table sur un stockage différent:&lt;/p&gt;&#xA;&lt;p&gt;On peut stocker une table partitionnée dans des tablespaces différents. Par exemple les données récentes sur un tablespace rapide sur SSD NVMe.&#xA;Puis les données plus rarement accédées sur un autre tablespace, avec des disques mécaniques moins couteux.&lt;/p&gt;&#xA;&lt;p&gt;Cette approche peut aussi avoir du sens à l&amp;rsquo;heure du cloud où le stockage est très onéreux.&lt;/p&gt;&#xA;&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&lt;p&gt;Voilà, je pense avoir fait le tour des principaux cas d&amp;rsquo;usages qui me venaient en tête.&lt;/p&gt;&#xA;&lt;p&gt;Evidemment, la mise en oeuvre du partitionnement implique une plus grande complexité (gestion des partitions&amp;hellip;)&#xA;et des limitations qu&amp;rsquo;il faudra étudier en amont.&lt;/p&gt;&#xA;&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;&#xA;&lt;p&gt;&amp;ldquo;BRIN indexes provide similar benefits to horizontal partitioning or sharding but without needing to explicitly declare partitions.&amp;rdquo; - &#xA;&lt;a href=&#34;https://en.wikipedia.org/wiki/Block_Range_Index&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/Block_Range_Index&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/section&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>pg_sampletolog : Une extension permettant de loguer un échantillon de requêtes</title>
    <updated>2019-01-28T06:00:00Z</updated>
    <id>tag:blog.anayrat.info,2019-01-28:/2019/01/28/pg_sampletolog-une-extension-permettant-de-loguer-un-échantillon-de-requêtes/</id>
    <link href="https://blog.anayrat.info/2019/01/28/pg_sampletolog-une-extension-permettant-de-loguer-un-%C3%A9chantillon-de-requ%C3%AAtes/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cet article va vous présenter une extension que j&amp;rsquo;ai développé dans le but de&#xA;loguer un échantillon de requêtes.&lt;/p&gt;&#xA;&lt;p&gt;Lorsqu&amp;rsquo;un DBA est confronté à un problème de performance, il aura pour&#xA;réflexe d&amp;rsquo;inspecter les logs, mais également la vue &lt;code&gt;pg_stat_statements&lt;/code&gt;.&#xA;Une requête coûteuse apparaîtra dans &lt;code&gt;pg_stat_statements&lt;/code&gt; et dans les logs si la&#xA;requête dépasse &lt;code&gt;log_min_duration_statement&lt;/code&gt;. On peut ainsi rejouer la requête,&#xA;obtenir son plan d&amp;rsquo;exécution et investiguer.&lt;/p&gt;&#xA;&lt;p&gt;Pour aller encore plus loin, il est possible d&amp;rsquo;activer l&amp;rsquo;extension &lt;code&gt;auto_explain&lt;/code&gt;.&#xA;Ainsi on aura directement le plan de la requête. Au passage, l&amp;rsquo;option &lt;code&gt;auto_explain.log_analyze&lt;/code&gt;&#xA;n&amp;rsquo;implique pas une double exécution de la requête. Ce paramètre peut être activé&#xA;sans crainte. Néanmoins cela peut s&amp;rsquo;avérer coûteux car le moteur doit mettre en&#xA;place l&amp;rsquo;instrumentation pour obtenir le &lt;em&gt;timing&lt;/em&gt; des différents nœuds. Si on a&#xA;beaucoup de trafic, il est également possible de faire un échantillonnage avec&#xA;&lt;code&gt;auto_explain.sample_rate&lt;/code&gt;. Cette option peut produire une quantité importante&#xA;de logs ce qui peut être problématique sur une instance à fort trafic.&lt;/p&gt;&#xA;&lt;p&gt;J&amp;rsquo;ai été confronté à un problème tout simple : comment investiguer sur une requête&#xA;dont le temps d&amp;rsquo;exécution est très court? C&amp;rsquo;est très simple &amp;ldquo;Regardez &lt;code&gt;pg_stat_statements&lt;/code&gt;!&amp;rdquo;.&lt;/p&gt;&#xA;&lt;p&gt;Voici ce qu&amp;rsquo;on pourrait obtenir sur un test pgbench :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;query               | SELECT abalance FROM pgbench_accounts WHERE aid = $1&#xA;calls               | 12000&#xA;total_time          | 214.564185000001&#xA;min_time            | 0.013751&#xA;max_time            | 0.044711&#xA;mean_time           | 0.0178803487499999&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;La requête est normalisée. Sans paramètre impossible d&amp;rsquo;obtenir son plan. choisir&#xA;un paramètre au hasard n&amp;rsquo;est pas la bonne solution : ce n&amp;rsquo;est pas forcément représentatif&#xA;du véritable trafic de production.&lt;/p&gt;&#xA;&lt;p&gt;Il y a quelques mois, j&amp;rsquo;ai proposé un patch pour loguer un échantillon de requêtes.&#xA;Celui-ci a été intégré dans la version 12 en cours de développement :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;commit 88bdbd3f746049834ae3cc972e6e650586ec3c9d&#xA;Author:     Alvaro Herrera &amp;lt;alvherre@alvh.no-ip.org&amp;gt;&#xA;AuthorDate: Thu Nov 29 18:42:53 2018 -0300&#xA;Commit:     Alvaro Herrera &amp;lt;alvherre@alvh.no-ip.org&amp;gt;&#xA;CommitDate: Thu Nov 29 18:42:53 2018 -0300&#xA;&#xA;    Add log_statement_sample_rate parameter&#xA;&#xA;    This allows to set a lower log_min_duration_statement value without&#xA;    incurring excessive log traffic (which reduces performance).  This can&#xA;    be useful to analyze workloads with lots of short queries.&#xA;&#xA;    Author: Adrien Nayrat&#xA;    Reviewed-by: David Rowley, Vik Fearing&#xA;    Discussion: https://postgr.es/m/c30ee535-ee1e-db9f-fa97-146b9f62caed@anayrat.info&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Dans le fil des échanges, Nikolay Samokhvalov a émis l&amp;rsquo;idée d&amp;rsquo;avoir ce même type&#xA;fonctionnalité mais au niveau d&amp;rsquo;une transaction : &#xA;&lt;a href=&#34;https://www.postgresql.org/message-id/CANNMO%2BLg65EFqHb%2BZYbMLKyE2y498HJzsdFrMnW1dQ6AFJ3Mpw%40mail.gmail.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.postgresql.org/message-id/CANNMO%2BLg65EFqHb%2BZYbMLKyE2y498HJzsdFrMnW1dQ6AFJ3Mpw%40mail.gmail.com&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;J&amp;rsquo;ai également proposé un patch en ce sens : &#xA;&lt;a href=&#34;https://commitfest.postgresql.org/21/1923/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Log a sample of transactions&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Tout ça est intéressant, mais il faudra attendre la version 12. Et encore, rien&#xA;ne garanti que le second patch soit commité (ou que le premier ne soit pas reverté).&lt;/p&gt;&#xA;&lt;p&gt;Tout ça m&amp;rsquo;a donné l&amp;rsquo;idée et l&amp;rsquo;envie de créer une extension, c&amp;rsquo;est ainsi qu&amp;rsquo;est née&#xA;&#xA;&lt;a href=&#34;https://github.com/anayrat/pg_sampletolog&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pg_sampletolog&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Cette extension permet de :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Loguer un échantillon de requêtes&lt;/li&gt;&#xA;&lt;li&gt;Loguer un échantillon de transactions&lt;/li&gt;&#xA;&lt;li&gt;Choisir de loguer avant ou après l&amp;rsquo;exécution (pour un usage futur avec pgreplay)&lt;/li&gt;&#xA;&lt;li&gt;Choisir de loguer tous les ordres de type DDL ou qui impliquent une modification des donnée&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Elle fonctionne sur toutes les versions supportées, de la 9.4 à la 11.&lt;/p&gt;&#xA;&lt;p&gt;L&amp;rsquo;activation se fait soit dans une session en chargeant l&amp;rsquo;extension : &lt;code&gt;LOAD &#39;pg_sampletolog&#39;;&lt;/code&gt;.&#xA;Ou dans le fichier postgresql.conf pour qu&amp;rsquo;elle soit chargée lors de toute nouvelle&#xA;connexion avec  &lt;code&gt;session_preload_libraries = &#39;pg_sampletolog&#39;&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;Si l&amp;rsquo;extension est bien chargée, ces nouveaux paramètres apparaissent :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;select name from pg_settings where name like &#39;pg_sampletolog%&#39;;&#xA;                 name                 &#xA;----------------------------------------&#xA; pg_sampletolog.disable_log_duration&#xA; pg_sampletolog.log_before_execution&#xA; pg_sampletolog.log_level&#xA; pg_sampletolog.log_statement&#xA; pg_sampletolog.statement_sample_rate&#xA; pg_sampletolog.transaction_sample_rate&#xA;(6 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Voici quelques exemples :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Loguer seulement 10% des requêtes : &lt;code&gt;pg_sampletolog.statement_sample_rate = 0.1&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;pg_sampelog va loguer 10% des requêtes. Pour chaque requête, le moteur va faire&#xA;un tirage aléatoire à l&amp;rsquo;aide de la fonction &lt;code&gt;random()&lt;/code&gt;. Le coût de cette fonction&#xA;est très faible, donc il ne devrait pas y avoir d&amp;rsquo;impact sur les performances.&#xA;Après quelques requêtes vous devriez obtenir ce genre de message dans les logs :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;2019-01-27 12:50:39.361 CET [27047] LOG:  Sampled query duration: 0.014 ms - SELECT 1;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;pg_sampelog va loguer la requête ainsi que son temps d&amp;rsquo;exécution.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Loguer seulement 10% des transactions : &lt;code&gt;pg_sampletolog.transaction_sample_rate = 0.1&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Le fonctionnement est le même que précédemment, à la différence que le moteur va&#xA;choisir de loguer ou non toutes les requêtes d&amp;rsquo;une même transaction. Cela peut s&amp;rsquo;avérer&#xA;très utile pour comprendre ce que fait un applicatif. Par exemple lorsqu&amp;rsquo;on ne peut&#xA;pas accéder au code de l&amp;rsquo;applicatif ou lorsque les requêtes sont générées par un ORM.&#xA;Exemple avec une transaction toute simple &lt;code&gt;BEGIN; SELECT 1; SELECT 1; COMMIT;&lt;/code&gt;&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;2019-01-27 12:51:40.562 CET [27069] LOG:  Sampled transaction duration: 0.008 ms - SELECT 1;&#xA;2019-01-27 12:51:40.562 CET [27069] LOG:  Sampled transaction duration: 0.005 ms - SELECT 1;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Les deux SELECT ont bien été logués. En adaptant le &lt;code&gt;log_line_prefix&lt;/code&gt;, on peut&#xA;voir qu&amp;rsquo;il s&amp;rsquo;agit de la même transaction (regardez le &lt;em&gt;lxid&lt;/em&gt;):&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;2019-01-27 16:32:16 CET [18556]: lxid=3/177,db=postgres,user=anayrat LOG:  Sampled transaction - SELECT 1;&#xA;2019-01-27 16:32:16 CET [18556]: lxid=3/177,db=postgres,user=anayrat LOG:  Sampled transaction - SELECT 1;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Loguer tous les ordres DDL : &lt;code&gt;pg_sampletolog.log_statement = &#39;ddl&#39;&lt;/code&gt;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;pg_sampletolog va loguer tous les ordres de type DDL (&lt;code&gt;CREATE TABLE&lt;/code&gt;,&lt;code&gt;CREATE INDEX&lt;/code&gt;,&amp;hellip;).&#xA;Ca peut être utile si on veut juste loguer un échantillon en lecture mais tous&#xA;les ordres DDL.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;2019-01-27 12:53:47.564 CET [27103] LOG:  Sampled ddl CREATE TABLE t1(c1 int);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Loguer tous les ordres modifiants des données : &lt;code&gt;pg_sampletolog.log_statement = &#39;mod&#39;&lt;/code&gt;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Exactement comme l&amp;rsquo;exemple précédent, mais cette fois on logue aussi tous les &lt;code&gt;UPDATES, DELETE&lt;/code&gt;.&#xA;Cela comprend aussi les ordres DDL.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;2019-01-27 12:59:54.043 CET [27160] LOG:  Sampled query duration: 0.246 ms - INSERT INTO t1 VALUES(1);&#xA;2019-01-27 13:00:16.468 CET [27160] LOG:  Sampled ddl CREATE INDEX ON t1(c1);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Loguer la requête avant son exécution : &lt;code&gt;pg_sampletolog.log_before_execution = on&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Cette option pourrait être utile pour rejouer logs avec &#xA;&lt;a href=&#34;https://github.com/laurenz/pgreplay&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pgreplay&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;bonus&#34;&gt;Bonus&lt;/h1&gt;&#xA;&lt;p&gt;L&amp;rsquo;extension fonctionne aussi sur les serveurs secondaires.&lt;/p&gt;&#xA;&lt;h1 id=&#34;deuxième-bonus&#34;&gt;Deuxième bonus&lt;/h1&gt;&#xA;&lt;p&gt;Si &lt;code&gt;pg_stat_statements&lt;/code&gt; est activée, le queryid est également logué. Ca peut être&#xA;très utile si vous identifiez une requête dans &lt;code&gt;pg_stat_statements&lt;/code&gt; et que vous&#xA;souhaitez la retrouver dans les logs à l&amp;rsquo;aide de son queryid.&lt;/p&gt;&#xA;&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&lt;p&gt;Je me suis régalé avec ce projet personnel. J&amp;rsquo;ai beaucoup appris sur &lt;del&gt;les segfaults&lt;/del&gt;&#xA;le code de postgres et ça montre également les possibilités d&amp;rsquo;extension du moteur.&lt;/p&gt;&#xA;&lt;p&gt;A l&amp;rsquo;avenir j&amp;rsquo;aimerai rajouter la possibilité de loguer un échantillon de requête&#xA;correspondant à tel queryid. Il faut également que je regarde pour supporter les&#xA;requêtes préparées.&lt;/p&gt;&#xA;&lt;p&gt;Enfin, j&amp;rsquo;aimerai tester cette extension avec pgreplay : En loguant tous les ordres&#xA;&lt;em&gt;MOD&lt;/em&gt; (afin d&amp;rsquo;assurer la cohérence lors du rejeu) ainsi qu&amp;rsquo;une fraction des&#xA;requêtes en lecture. Puis, restaurer un backup PITR et d&amp;rsquo;un côté rejouer le trafic en écriture.&#xA;De l&amp;rsquo;autre côté, rejouer une portion du trafic en lecture avec un &lt;em&gt;speed_factor&lt;/em&gt;.&#xA;Par exemple x10 en rejouant 10% du trafic. Même si ça ne sera jamais parfait (il&#xA;manquera la cohérence des lectures), je serai curieux de voir les résultats qu&amp;rsquo;on&#xA;peut obtenir. Surtout dans le cas où loguer toutes les requêtes s’avérerait trop&#xA;coûteux.&lt;/p&gt;&#xA;&lt;p&gt;Je suis preneur de tout retour à faire sur &#xA;&lt;a href=&#34;https://github.com/anayrat/pg_sampletolog&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;la page github du projet&lt;/a&gt;.&lt;/p&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL et updates heap-only-tuples - partie 3</title>
    <updated>2018-11-26T07:00:00Z</updated>
    <id>tag:blog.anayrat.info,2018-11-26:/2018/11/26/postgresql-et-updates-heap-only-tuples-partie-3/</id>
    <link href="https://blog.anayrat.info/2018/11/26/postgresql-et-updates-heap-only-tuples-partie-3/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Voici une série d&amp;rsquo;articles qui va porter sur une nouveauté de la version 11.&lt;/p&gt;&#xA;&lt;p&gt;Durant le développement de cette version, une fonctionnalité a attiré mon attention.&#xA;On peut la retrouver dans les releases notes : &#xA;&lt;a href=&#34;https://www.postgresql.org/docs/11/static/release-11.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.postgresql.org/docs/11/static/release-11.html&lt;/a&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Allow heap-only-tuple (HOT) updates for expression indexes when the values of the expressions are unchanged (Konstantin Knizhnik)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;J&amp;rsquo;avoue que ce n&amp;rsquo;est pas très explicite et cette fonctionnalité nécessite quelques&#xA;connaissances sur le fonctionnement du moteur que je vais essayer d&amp;rsquo;expliquer à travers&#xA;plusieurs articles :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;a href=&#34;https://blog.anayrat.info/2018/11/12/postgresql-et-updates-heap-only-tuples-partie-1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fonctionnement du MVCC et update &lt;em&gt;heap-only-tuples&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;a href=&#34;https://blog.anayrat.info/2018/11/19/postgresql-et-updates-heap-only-tuples-partie-2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quand le moteur ne fait pas d&amp;rsquo;update &lt;em&gt;heap-only-tuple&lt;/em&gt; et présentation de la nouveauté de la version 11&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;a href=&#34;https://blog.anayrat.info/2018/11/26/postgresql-et-updates-heap-only-tuples-partie-3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Impact sur les performances&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;Cette fonctionnalité a été désactivée en 11.1 car elle pouvait conduire à des&#xA;crash d&amp;rsquo;instance&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. J&amp;rsquo;ai tout de même choisi de publier ces articles car ils permettent&#xA;de comprendre le mécanisme des updates HOT et le gain que pourrait apporter cette&#xA;fonctionnalité.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Je remercie au passage Guillaume Lelarge pour la relecture de cet article ;).&lt;/p&gt;&#xA;&lt;h1 id=&#34;impact-sur-les-performances&#34;&gt;Impact sur les performances&lt;/h1&gt;&#xA;&lt;p&gt;Voici un test assez simple pour mettre en évidence l&amp;rsquo;intérêt de cette fonctionnalité.&#xA;On pourrait s&amp;rsquo;attendre à des gains en performances car le moteur évite de mettre&#xA;à jour les index, ainsi qu&amp;rsquo;en matière de taille d&amp;rsquo;index, comme vu précédemment,&#xA;on évite la fragmentation.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE t5 (c1 jsonb, c2 int,c3 int);&#xA;CREATE INDEX ON t5 ((c1-&amp;gt;&amp;gt;&#39;prenom&#39;)) ;&#xA;CREATE INDEX ON t5 (c2);&#xA;INSERT INTO t5 VALUES (&#39;{ &amp;quot;prenom&amp;quot;:&amp;quot;adrien&amp;quot; , &amp;quot;valeur&amp;quot; : &amp;quot;1&amp;quot;}&#39;::jsonb,1,1);&#xA;INSERT INTO t5 VALUES (&#39;{ &amp;quot;prenom&amp;quot;:&amp;quot;guillaume&amp;quot; , &amp;quot;valeur&amp;quot; : &amp;quot;2&amp;quot;}&#39;::jsonb,2,2);&#xA;\dt+ t5&#xA;                   List of relations&#xA; Schema | Name | Type  |  Owner   | Size  | Description&#xA;--------+------+-------+----------+-------+-------------&#xA; public | t5   | table | postgres | 16 kB |&#xA;(1 row)&#xA;&#xA;\di+ t5*&#xA;                           List of relations&#xA; Schema |    Name     | Type  |  Owner   | Table | Size  | Description&#xA;--------+-------------+-------+----------+-------+-------+-------------&#xA; public | t5_c2_idx   | index | postgres | t5    | 16 kB |&#xA; public | t5_expr_idx | index | postgres | t5    | 16 kB |&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Puis ce test pgbench :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;\set id  random(1, 100000)&#xA;\set id2  random(1, 100000)&#xA;&#xA;UPDATE t5 SET c1 = &#39;{&amp;quot;valeur&amp;quot;: &amp;quot;:id&amp;quot;, &amp;quot;prenom&amp;quot;: &amp;quot;guillaume&amp;quot;}&#39; WHERE c2=2;&#xA;UPDATE t5 SET c1 = &#39;{&amp;quot;valeur&amp;quot;: &amp;quot;:id2&amp;quot;, &amp;quot;prenom&amp;quot;: &amp;quot;adrien&amp;quot;}&#39; WHERE c2=1;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Qu&amp;rsquo;on exécute pendant 60 secondes, avec &lt;code&gt;recheck_on_update=on&lt;/code&gt; (par défaut) :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pgbench -f test.sql -n -c6 -T 120&#xA;transaction type: test.sql&#xA;scaling factor: 1&#xA;query mode: simple&#xA;number of clients: 6&#xA;number of threads: 1&#xA;duration: 120 s&#xA;number of transactions actually processed: 2743163&#xA;latency average = 0.262 ms&#xA;tps = 22859.646914 (including connections establishing)&#xA;tps = 22859.938191 (excluding connections establishing)&#xA;&#xA; \dt+ t5*&#xA;                    List of relations&#xA; Schema | Name | Type  |  Owner   |  Size  | Description&#xA;--------+------+-------+----------+--------+-------------&#xA; public | t5   | table | postgres | 376 kB |&#xA;(1 row)&#xA;\di+ t5*&#xA;                           List of relations&#xA; Schema |    Name     | Type  |  Owner   | Table | Size  | Description&#xA;--------+-------------+-------+----------+-------+-------+-------------&#xA; public | t5_c2_idx   | index | postgres | t5    | 16 kB |&#xA; public | t5_expr_idx | index | postgres | t5    | 32 kB |&#xA;(2 rows)&#xA;&#xA;SELECT * FROM pg_stat_user_tables WHERE relname = &#39;t5&#39;;&#xA;-[ RECORD 1 ]-------+------------------------------&#xA;relid               | 8890622&#xA;schemaname          | public&#xA;relname             | t5&#xA;seq_scan            | 4&#xA;seq_tup_read        | 0&#xA;idx_scan            | 7999055&#xA;idx_tup_fetch       | 7999055&#xA;n_tup_ins           | 4&#xA;n_tup_upd           | 7999055&#xA;n_tup_del           | 0&#xA;n_tup_hot_upd       | 7998236&#xA;n_live_tup          | 2&#xA;n_dead_tup          | 0&#xA;n_mod_since_analyze | 0&#xA;last_vacuum         |&#xA;last_autovacuum     | 2018-09-19 06:29:37.690575+00&#xA;last_analyze        |&#xA;last_autoanalyze    | 2018-09-19 06:29:37.719911+00&#xA;vacuum_count        | 0&#xA;autovacuum_count    | 5&#xA;analyze_count       | 0&#xA;autoanalyze_count   | 5&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Et maintenant avec &lt;code&gt;recheck_on_update=off&lt;/code&gt;. Donc même jeu de donnée que&#xA;précédemment mais cette fois l&amp;rsquo;index est créé avec cet ordre :&#xA;&lt;code&gt;CREATE INDEX ON t5 ((c1-&amp;gt;&amp;gt;&#39;prenom&#39;)) WITH (recheck_on_update=off);&lt;/code&gt;&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pgbench -f test.sql -n -c6 -T 120&#xA;transaction type: test.sql&#xA;scaling factor: 1&#xA;query mode: simple&#xA;number of clients: 6&#xA;number of threads: 1&#xA;duration: 120 s&#xA;number of transactions actually processed: 1065688&#xA;latency average = 0.676 ms&#xA;tps = 8880.679565 (including connections establishing)&#xA;tps = 8880.796478 (excluding connections establishing)&#xA;&#xA;\dt+ t5&#xA;                    List of relations&#xA; Schema | Name | Type  |  Owner   |  Size   | Description&#xA;--------+------+-------+----------+---------+-------------&#xA; public | t5   | table | postgres | 9496 kB |&#xA;(1 row)&#xA;&#xA;\di+ t5*&#xA;                           List of relations&#xA; Schema |    Name     | Type  |  Owner   | Table |  Size  | Description&#xA;--------+-------------+-------+----------+-------+--------+-------------&#xA; public | t5_c2_idx   | index | postgres | t5    | 768 kB |&#xA; public | t5_expr_idx | index | postgres | t5    | 58 MB  |&#xA;(2 rows)&#xA;&#xA;select * from pg_stat_user_tables where relname = &#39;t5&#39;;&#xA;-[ RECORD 1 ]-------+------------------------------&#xA;relid               | 8890635&#xA;schemaname          | public&#xA;relname             | t5&#xA;seq_scan            | 2&#xA;seq_tup_read        | 0&#xA;idx_scan            | 2131376&#xA;idx_tup_fetch       | 2131376&#xA;n_tup_ins           | 2&#xA;n_tup_upd           | 2131376&#xA;n_tup_del           | 0&#xA;n_tup_hot_upd       | 19&#xA;n_live_tup          | 2&#xA;n_dead_tup          | 0&#xA;n_mod_since_analyze | 0&#xA;last_vacuum         |&#xA;last_autovacuum     | 2018-09-19 06:34:42.045905+00&#xA;last_analyze        |&#xA;last_autoanalyze    | 2018-09-19 06:34:42.251183+00&#xA;vacuum_count        | 0&#xA;autovacuum_count    | 3&#xA;analyze_count       | 0&#xA;autoanalyze_count   | 3&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th style=&#34;text-align:right&#34;&gt;recheck_on_update&lt;/th&gt;&#xA;&lt;th&gt;on&lt;/th&gt;&#xA;&lt;th&gt;off&lt;/th&gt;&#xA;&lt;th&gt;Gain&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:right&#34;&gt;TPS&lt;/td&gt;&#xA;&lt;td&gt;22859&lt;/td&gt;&#xA;&lt;td&gt;8880&lt;/td&gt;&#xA;&lt;td&gt;157%&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:right&#34;&gt;t5 size&lt;/td&gt;&#xA;&lt;td&gt;376 kB&lt;/td&gt;&#xA;&lt;td&gt;9496 kB&lt;/td&gt;&#xA;&lt;td&gt;-96%&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:right&#34;&gt;t5_c2_idx size&lt;/td&gt;&#xA;&lt;td&gt;16 kB&lt;/td&gt;&#xA;&lt;td&gt;768 kB&lt;/td&gt;&#xA;&lt;td&gt;-98%&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:right&#34;&gt;t5_expr_idx size&lt;/td&gt;&#xA;&lt;td&gt;32 kB&lt;/td&gt;&#xA;&lt;td&gt;58 MB&lt;/td&gt;&#xA;&lt;td&gt;-99.9%&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;L&amp;rsquo;écart de performance est assez impressionnant de même que la taille des tables&#xA;et index.&lt;/p&gt;&#xA;&lt;p&gt;J&amp;rsquo;ai refait le premier test en désactivant l&amp;rsquo;autovacuum et voici le résultat :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pgbench -f test.sql -n -c6 -T 120&#xA;transaction type: test.sql&#xA;scaling factor: 1&#xA;query mode: simple&#xA;number of clients: 6&#xA;number of threads: 1&#xA;duration: 120 s&#xA;number of transactions actually processed: 2752479&#xA;latency average = 0.262 ms&#xA;tps = 22937.271749 (including connections establishing)&#xA;tps = 22937.545872 (excluding connections establishing)&#xA;&#xA;&#xA;select * from pg_stat_user_tables where relname = &#39;t5&#39;;&#xA;-[ RECORD 1 ]-------+--------&#xA;relid               | 8890643&#xA;schemaname          | public&#xA;relname             | t5&#xA;seq_scan            | 2&#xA;seq_tup_read        | 0&#xA;idx_scan            | 5504958&#xA;idx_tup_fetch       | 5504958&#xA;n_tup_ins           | 2&#xA;n_tup_upd           | 5504958&#xA;n_tup_del           | 0&#xA;n_tup_hot_upd       | 5504258&#xA;n_live_tup          | 2&#xA;n_dead_tup          | 2416&#xA;n_mod_since_analyze | 5504960&#xA;last_vacuum         |&#xA;last_autovacuum     |&#xA;last_analyze        |&#xA;last_autoanalyze    |&#xA;vacuum_count        | 0&#xA;autovacuum_count    | 0&#xA;analyze_count       | 0&#xA;autoanalyze_count   | 0&#xA;&#xA;\di+ t5*&#xA;List of relations&#xA;-[ RECORD 1 ]------------&#xA;Schema      | public&#xA;Name        | t5_c2_idx&#xA;Type        | index&#xA;Owner       | postgres&#xA;Table       | t5&#xA;Size        | 16 kB&#xA;Description |&#xA;-[ RECORD 2 ]------------&#xA;Schema      | public&#xA;Name        | t5_expr_idx&#xA;Type        | index&#xA;Owner       | postgres&#xA;Table       | t5&#xA;Size        | 40 kB&#xA;Description |&#xA;&#xA;\dt+ t5&#xA;List of relations&#xA;-[ RECORD 1 ]---------&#xA;Schema      | public&#xA;Name        | t5&#xA;Type        | table&#xA;Owner       | postgres&#xA;Size        | 1080 kB&#xA;Description |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Puis le second test :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pgbench -f test.sql -n -c6 -T 120&#xA;transaction type: test.sql&#xA;scaling factor: 1&#xA;query mode: simple&#xA;number of clients: 6&#xA;number of threads: 1&#xA;duration: 120 s&#xA;number of transactions actually processed: 881434&#xA;latency average = 0.817 ms&#xA;tps = 7345.208875 (including connections establishing)&#xA;tps = 7345.304797 (excluding connections establishing)&#xA;&#xA;select * from pg_stat_user_tables where relname = &#39;t5&#39;;&#xA;-[ RECORD 1 ]-------+--------&#xA;relid               | 8890651&#xA;schemaname          | public&#xA;relname             | t5&#xA;seq_scan            | 2&#xA;seq_tup_read        | 0&#xA;idx_scan            | 1762868&#xA;idx_tup_fetch       | 1762868&#xA;n_tup_ins           | 2&#xA;n_tup_upd           | 1762868&#xA;n_tup_del           | 0&#xA;n_tup_hot_upd       | 23&#xA;n_live_tup          | 2&#xA;n_dead_tup          | 1762845&#xA;n_mod_since_analyze | 1762870&#xA;last_vacuum         |&#xA;last_autovacuum     |&#xA;last_analyze        |&#xA;last_autoanalyze    |&#xA;vacuum_count        | 0&#xA;autovacuum_count    | 0&#xA;analyze_count       | 0&#xA;autoanalyze_count   | 0&#xA;&#xA;\di+ t5*&#xA;List of relations&#xA;-[ RECORD 1 ]------------&#xA;Schema      | public&#xA;Name        | t5_c2_idx&#xA;Type        | index&#xA;Owner       | postgres&#xA;Table       | t5&#xA;Size        | 600 kB&#xA;Description |&#xA;-[ RECORD 2 ]------------&#xA;Schema      | public&#xA;Name        | t5_expr_idx&#xA;Type        | index&#xA;Owner       | postgres&#xA;Table       | t5&#xA;Size        | 56 MB&#xA;Description |&#xA;&#xA;\dt+ t5*&#xA;List of relations&#xA;-[ RECORD 1 ]---------&#xA;Schema      | public&#xA;Name        | t5&#xA;Type        | table&#xA;Owner       | postgres&#xA;Size        | 55 MB&#xA;Description |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th style=&#34;text-align:right&#34;&gt;recheck_on_update&lt;/th&gt;&#xA;&lt;th&gt;on&lt;/th&gt;&#xA;&lt;th&gt;off&lt;/th&gt;&#xA;&lt;th&gt;Gain&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:right&#34;&gt;TPS&lt;/td&gt;&#xA;&lt;td&gt;22937&lt;/td&gt;&#xA;&lt;td&gt;7345&lt;/td&gt;&#xA;&lt;td&gt;212%&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:right&#34;&gt;t5 size&lt;/td&gt;&#xA;&lt;td&gt;1080 kB&lt;/td&gt;&#xA;&lt;td&gt;55 MB&lt;/td&gt;&#xA;&lt;td&gt;-98%&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:right&#34;&gt;t5_c2_idx size&lt;/td&gt;&#xA;&lt;td&gt;16 kB&lt;/td&gt;&#xA;&lt;td&gt;600 kB&lt;/td&gt;&#xA;&lt;td&gt;-97%&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:right&#34;&gt;t5_expr_idx size&lt;/td&gt;&#xA;&lt;td&gt;40 kB&lt;/td&gt;&#xA;&lt;td&gt;56 MB&lt;/td&gt;&#xA;&lt;td&gt;-99.9%&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;A nouveau, l&amp;rsquo;écart de performance est important, il en est de même pour la taille&#xA;des tables et index. On note également l&amp;rsquo;importance de laisser l&amp;rsquo;autovacuum activé.&lt;/p&gt;&#xA;&lt;p&gt;Pourquoi avons-nous un tel écart de taille sur les index et la table ?&lt;/p&gt;&#xA;&lt;p&gt;Pour les index, c&amp;rsquo;est dû au mécanisme expliqué plus haut. Le moteur a pu chaîner&#xA;les enregistrements en évitant de mettre à jour l&amp;rsquo;index. L&amp;rsquo;index a quand même&#xA;légèrement augmenté de taille, il arrive que le moteur ne peut pas faire de HOT,&#xA;par exemple quand il n&amp;rsquo;y a plus de place dans le bloc.&lt;/p&gt;&#xA;&lt;p&gt;Pour ce qui est de la taille de la table, lors du test avec autovacuum activé,&#xA;l&amp;rsquo;autovacuum avait plus de difficultés à passer sur la table avec le HOT désactivé.&#xA;L&amp;rsquo;index grossissant, cela engendrait plus de &amp;ldquo;travail&amp;rdquo;.&#xA;Lors du test sans autovacuum, l&amp;rsquo;écart s&amp;rsquo;explique par le fait que même un simple&#xA;SELECT peut nettoyer des blocs&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Rappelons que cette fonctionnalité a été retirée avec la version 11.1. J&amp;rsquo;avais écrit&#xA;ces articles peu après la sortie de la version 11.0 et j&amp;rsquo;ai tout de même choisit&#xA;de les publier afin de présenter le fonctionnement des UPDATES HOT. Espérons que&#xA;cette fonctionnalité sera corrigée dans les versions à venir.&lt;/p&gt;&#xA;&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;&#xA;&lt;p&gt;&#xA;&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=05f84605dbeb9cf8279a157234b24bbb706c5256&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disable recheck_on_update optimization to avoid crashes&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;&#xA;&lt;p&gt;&#xA;&lt;a href=&#34;https://github.com/postgres/postgres/blob/master/src/backend/access/heap/README.HOT#L251&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;README.HOT&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/section&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL et updates heap-only-tuples - partie 2</title>
    <updated>2018-11-19T07:00:00Z</updated>
    <id>tag:blog.anayrat.info,2018-11-19:/2018/11/19/postgresql-et-updates-heap-only-tuples-partie-2/</id>
    <link href="https://blog.anayrat.info/2018/11/19/postgresql-et-updates-heap-only-tuples-partie-2/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Voici une série d&amp;rsquo;articles qui va porter sur une nouveauté de la version 11.&lt;/p&gt;&#xA;&lt;p&gt;Durant le développement de cette version, une fonctionnalité a attiré mon attention.&#xA;On peut la retrouver dans les releases notes : &#xA;&lt;a href=&#34;https://www.postgresql.org/docs/11/static/release-11.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.postgresql.org/docs/11/static/release-11.html&lt;/a&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Allow heap-only-tuple (HOT) updates for expression indexes when the values of the expressions are unchanged (Konstantin Knizhnik)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;J&amp;rsquo;avoue que ce n&amp;rsquo;est pas très explicite et cette fonctionnalité nécessite quelques&#xA;connaissances sur le fonctionnement du moteur que je vais essayer d&amp;rsquo;expliquer à travers&#xA;plusieurs articles :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;a href=&#34;https://blog.anayrat.info/2018/11/12/postgresql-et-updates-heap-only-tuples-partie-1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fonctionnement du MVCC et update &lt;em&gt;heap-only-tuples&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;a href=&#34;https://blog.anayrat.info/2018/11/19/postgresql-et-updates-heap-only-tuples-partie-2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quand le moteur ne fait pas d&amp;rsquo;update &lt;em&gt;heap-only-tuple&lt;/em&gt; et présentation de la nouveauté de la version 11&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;a href=&#34;https://blog.anayrat.info/2018/11/26/postgresql-et-updates-heap-only-tuples-partie-3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Impact sur les performances&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;Cette fonctionnalité a été désactivée en 11.1 car elle pouvait conduire à des&#xA;crash d&amp;rsquo;instance&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. J&amp;rsquo;ai tout de même choisi de publier ces articles car ils permettent&#xA;de comprendre le mécanisme des updates HOT et le gain que pourrait apporter cette&#xA;fonctionnalité.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Je remercie au passage Guillaume Lelarge pour la relecture de cet article ;).&lt;/p&gt;&#xA;&lt;p&gt;L&amp;rsquo;article précédent présentait le fonctionnement des UDATES heap-only-tuple. Dans&#xA;cet article nous allons voir le cas où Postgres ne fait pas d&amp;rsquo;UPDATE heap-ony-tuple.&#xA;Ce qui nous permettra d&amp;rsquo;aborder la fonctionnalité qui aurait du arriver dans la version 11.&lt;/p&gt;&#xA;&lt;h1 id=&#34;cas-avec-un-index-sur-une-colonne-mise-à-jour&#34;&gt;Cas avec un index sur une colonne mise à jour&lt;/h1&gt;&#xA;&lt;p&gt;Reprenons l&amp;rsquo;exemple précédent et rajoutons une colonne indexée :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;ALTER TABLE t3 ADD COLUMN c3 int;&#xA;CREATE INDEX ON t3(c3);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Les UPDATE précédents portaient sur une colonne non-indexée. Que se passe-t-il&#xA;si l&amp;rsquo;UPDATE porte sur c3 ?&lt;/p&gt;&#xA;&lt;p&gt;État de la table et des index avant UPDATE :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT lp,lp_flags,t_data,t_ctid FROM  heap_page_items(get_raw_page(&#39;t3&#39;,0));&#xA; lp | lp_flags |       t_data       | t_ctid&#xA;----+----------+--------------------+--------&#xA;  1 |        2 |                    |&#xA;  2 |        1 | \x0200000002000000 | (0,2)&#xA;  3 |        0 |                    |&#xA;  4 |        0 |                    |&#xA;  5 |        1 | \x0100000006000000 | (0,5)&#xA;(5 rows)&#xA;&#xA;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c1_idx&#39;,1));              &#xA; itemoffset | ctid  | itemlen | nulls | vars |          data&#xA;------------+-------+---------+-------+------+-------------------------&#xA;          1 | (0,1) |      16 | f     | f    | 01 00 00 00 00 00 00 00&#xA;          2 | (0,2) |      16 | f     | f    | 02 00 00 00 00 00 00 00&#xA;(2 rows)&#xA;&#xA;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c3_idx&#39;,1));&#xA; itemoffset | ctid  | itemlen | nulls | vars | data&#xA;------------+-------+---------+-------+------+------&#xA;          1 | (0,1) |      16 | t     | f    |&#xA;          2 | (0,2) |      16 | t     | f    |&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Pas de changement sur la table car la colonne c3 ne contient que des nulls, on&#xA;peut le constater en observant l&amp;rsquo;index &lt;code&gt;t3_c3_idx&lt;/code&gt; où &lt;code&gt;nulls&lt;/code&gt; est à &lt;em&gt;true&lt;/em&gt; sur&#xA;chaque ligne.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;UPDATE t3 SET c3 = 7 WHERE c1=1;&#xA;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c3_idx&#39;,1));&#xA; itemoffset | ctid  | itemlen | nulls | vars |          data&#xA;------------+-------+---------+-------+------+-------------------------&#xA;          1 | (0,3) |      16 | f     | f    | 07 00 00 00 00 00 00 00&#xA;          2 | (0,1) |      16 | t     | f    |&#xA;          3 | (0,2) |      16 | t     | f    |&#xA;(3 rows)&#xA;&#xA;SELECT lp,lp_flags,t_data,t_ctid FROM  heap_page_items(get_raw_page(&#39;t3&#39;,0));&#xA; lp | lp_flags |           t_data           | t_ctid&#xA;----+----------+----------------------------+--------&#xA;  1 |        2 |                            |&#xA;  2 |        1 | \x0200000002000000         | (0,2)&#xA;  3 |        1 | \x010000000600000007000000 | (0,3)&#xA;  4 |        0 |                            |&#xA;  5 |        1 | \x0100000006000000         | (0,3)&#xA;(5 rows)&#xA;&#xA;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c1_idx&#39;,1));              &#xA; itemoffset | ctid  | itemlen | nulls | vars |          data&#xA;------------+-------+---------+-------+------+-------------------------&#xA;          1 | (0,3) |      16 | f     | f    | 01 00 00 00 00 00 00 00&#xA;          2 | (0,1) |      16 | f     | f    | 01 00 00 00 00 00 00 00&#xA;          3 | (0,2) |      16 | f     | f    | 02 00 00 00 00 00 00 00&#xA;(3 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;On remarque bien la nouvelle entrée dans l&amp;rsquo;index portant sur c3. La table contient&#xA;bien un nouvel enregistrement. En revanche, l&amp;rsquo;index &lt;code&gt;t3_c1_idx&lt;/code&gt; a également été&#xA;mis à jour. Entraînant l&amp;rsquo;ajout d&amp;rsquo;une troisième entrée, même si la valeur de la&#xA;colonne c1 n&amp;rsquo;a pas changée.&lt;/p&gt;&#xA;&lt;p&gt;Après un VACUUM :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;VACUUM t3;&#xA;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c1_idx&#39;,1));&#xA; itemoffset | ctid  | itemlen | nulls | vars |          data&#xA;------------+-------+---------+-------+------+-------------------------&#xA;          1 | (0,3) |      16 | f     | f    | 01 00 00 00 00 00 00 00&#xA;          2 | (0,2) |      16 | f     | f    | 02 00 00 00 00 00 00 00&#xA;(2 rows)&#xA;&#xA;SELECT lp,lp_flags,t_data,t_ctid FROM  heap_page_items(get_raw_page(&#39;t3&#39;,0));&#xA; lp | lp_flags |           t_data           | t_ctid&#xA;----+----------+----------------------------+--------&#xA;  1 |        0 |                            |&#xA;  2 |        1 | \x0200000002000000         | (0,2)&#xA;  3 |        1 | \x010000000600000007000000 | (0,3)&#xA;  4 |        0 |                            |&#xA;  5 |        0 |                            |&#xA;(5 rows)&#xA;&#xA;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c3_idx&#39;,1));&#xA; itemoffset | ctid  | itemlen | nulls | vars |          data&#xA;------------+-------+---------+-------+------+-------------------------&#xA;          1 | (0,3) |      16 | f     | f    | 07 00 00 00 00 00 00 00&#xA;          2 | (0,2) |      16 | t     | f    |&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Le moteur a nettoyé les index et la table. La première ligne de la table n&amp;rsquo;a plus&#xA;le flag &lt;code&gt;REDIRECT&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;nouveauté-de-la-version--11-heap-only-tuple-hot-avec-index-fonctionnels&#34;&gt;Nouveauté de la version : 11 heap-only-tuple (HOT) avec index fonctionnels&lt;/h1&gt;&#xA;&lt;p&gt;Lorsqu&amp;rsquo;un index fonctionnel porte sur la colonne modifiée, il peut arriver que&#xA;le résultat de l&amp;rsquo;expression reste inchangé malgré la mise à jour de la colonne.&#xA;La clé dans l&amp;rsquo;index serait donc inchangée.&lt;/p&gt;&#xA;&lt;p&gt;Prenons un exemple : un index fonctionnel sur une &lt;em&gt;clé spécifique&lt;/em&gt; d&amp;rsquo;un objet JSON.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;CREATE TABLE t4 (c1 jsonb, c2 int,c3 int);&#xA;CREATE INDEX ON t4 ((c1-&amp;gt;&amp;gt;&#39;prenom&#39;)) ;&#xA;CREATE INDEX ON t4 (c2);&#xA;INSERT INTO t4 VALUES (&#39;{ &amp;quot;prenom&amp;quot;:&amp;quot;adrien&amp;quot; , &amp;quot;ville&amp;quot; : &amp;quot;valence&amp;quot;}&#39;::jsonb,1,1);&#xA;INSERT INTO t4 VALUES (&#39;{ &amp;quot;prenom&amp;quot;:&amp;quot;guillaume&amp;quot; , &amp;quot;ville&amp;quot; : &amp;quot;lille&amp;quot;}&#39;::jsonb,2,2);&#xA;&#xA;-- changement qui ne porte pas sur prenom, on change que la ville&#xA;UPDATE t4 SET c1 = &#39;{&amp;quot;ville&amp;quot;: &amp;quot;valence (#soleil)&amp;quot;, &amp;quot;prenom&amp;quot;: &amp;quot;guillaume&amp;quot;}&#39; WHERE c2=2;&#xA;SELECT pg_stat_get_xact_tuples_hot_updated(&#39;t4&#39;::regclass);&#xA; pg_stat_get_xact_tuples_hot_updated&#xA;-------------------------------------&#xA;                                   0&#xA;(1 row)&#xA;&#xA;UPDATE t4 SET c1 = &#39;{&amp;quot;ville&amp;quot;: &amp;quot;nantes&amp;quot;, &amp;quot;prenom&amp;quot;: &amp;quot;guillaume&amp;quot;}&#39; WHERE c2=2;&#xA;SELECT pg_stat_get_xact_tuples_hot_updated(&#39;t4&#39;::regclass);&#xA; pg_stat_get_xact_tuples_hot_updated&#xA;-------------------------------------&#xA;                                   0&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;La fonction &lt;code&gt;pg_stat_get_xact_tuples_hot_updated&lt;/code&gt; indique le nombre de lignes mises&#xA;à jour par le mécanisme HOT.&lt;/p&gt;&#xA;&lt;p&gt;Les deux UPDATE n&amp;rsquo;ont fait que modifier la clé &amp;ldquo;ville&amp;rdquo; et pas la clé &amp;ldquo;prenom&amp;rdquo;.&#xA;Ce qui n’entraîne pas de modification de l&amp;rsquo;index car il n&amp;rsquo;indexe que la clé &amp;ldquo;prenom&amp;rdquo;.&lt;/p&gt;&#xA;&lt;p&gt;Le moteur n&amp;rsquo;a pas pu faire d&amp;rsquo;HOT. En effet, pour lui, l&amp;rsquo;UPDATE a porté sur la colonne et&#xA;l&amp;rsquo;index doit être mis à jour.&lt;/p&gt;&#xA;&lt;p&gt;Avec la version 11, le moteur est capable de constater que le résultat de&#xA;l&amp;rsquo;expression ne change pas. Effectuons le même test sur la version 11 :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;CREATE TABLE t4 (c1 jsonb, c2 int,c3 int);&#xA;-- CREATE INDEX ON t4 ((c1-&amp;gt;&amp;gt;&#39;prenom&#39;))  WITH (recheck_on_update=&#39;false&#39;);&#xA;CREATE INDEX ON t4 ((c1-&amp;gt;&amp;gt;&#39;prenom&#39;)) ;&#xA;CREATE INDEX ON t4 (c2);&#xA;INSERT INTO t4 VALUES (&#39;{ &amp;quot;prenom&amp;quot;:&amp;quot;adrien&amp;quot; , &amp;quot;ville&amp;quot; : &amp;quot;valence&amp;quot;}&#39;::jsonb,1,1);&#xA;INSERT INTO t4 VALUES (&#39;{ &amp;quot;prenom&amp;quot;:&amp;quot;guillaume&amp;quot; , &amp;quot;ville&amp;quot; : &amp;quot;lille&amp;quot;}&#39;::jsonb,2,2);&#xA;&#xA;-- changement qui ne porte pas sur prenom&#xA;UPDATE t4 SET c1 = &#39;{&amp;quot;ville&amp;quot;: &amp;quot;valence (#soleil)&amp;quot;, &amp;quot;prenom&amp;quot;: &amp;quot;guillaume&amp;quot;}&#39; WHERE c2=2;&#xA;SELECT pg_stat_get_xact_tuples_hot_updated(&#39;t4&#39;::regclass);&#xA; pg_stat_get_xact_tuples_hot_updated&#xA;-------------------------------------&#xA;                                   1&#xA;(1 row)&#xA;&#xA;UPDATE t4 SET c1 = &#39;{&amp;quot;ville&amp;quot;: &amp;quot;nantes&amp;quot;, &amp;quot;prenom&amp;quot;: &amp;quot;guillaume&amp;quot;}&#39; WHERE c2=2;&#xA;SELECT pg_stat_get_xact_tuples_hot_updated(&#39;t4&#39;::regclass);&#xA; pg_stat_get_xact_tuples_hot_updated&#xA;-------------------------------------&#xA;                                   2&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Cette fois, le moteur a bien utilisé le mécanisme HOT. On peut le vérifier en&#xA;regardant le contenu physique de l&amp;rsquo;index avec pageinspect :&lt;/p&gt;&#xA;&lt;p&gt;Version 10 :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM  bt_page_items(get_raw_page(&#39;t4_expr_idx&#39;,1));&#xA;itemoffset | ctid  | itemlen | nulls | vars |                      data                       &#xA;------------+-------+---------+-------+------+-------------------------------------------------&#xA;         1 | (0,1) |      16 | f     | t    | 0f 61 64 72 69 65 6e 00&#xA;         2 | (0,4) |      24 | f     | t    | 15 67 75 69 6c 6c 61 75 6d 65 00 00 00 00 00 00&#xA;         3 | (0,3) |      24 | f     | t    | 15 67 75 69 6c 6c 61 75 6d 65 00 00 00 00 00 00&#xA;         4 | (0,2) |      24 | f     | t    | 15 67 75 69 6c 6c 61 75 6d 65 00 00 00 00 00 00&#xA;(4 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Version 11 :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM  bt_page_items(get_raw_page(&#39;t4_expr_idx&#39;,1));&#xA;itemoffset | ctid  | itemlen | nulls | vars |                      data&#xA;------------+-------+---------+-------+------+-------------------------------------------------&#xA;         1 | (0,1) |      16 | f     | t    | 0f 61 64 72 69 65 6e 00&#xA;         2 | (0,2) |      24 | f     | t    | 15 67 75 69 6c 6c 61 75 6d 65 00 00 00 00 00 00&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Ce comportement peut se contrôler grâce à une nouvelle option lors de la création&#xA;de l&amp;rsquo;index : &lt;code&gt;recheck_on_update&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Par défaut à &lt;code&gt;on&lt;/code&gt;, le moteur effectue la vérification du résultat de l&amp;rsquo;expression&#xA;pour faire un UPDATE HOT. On peut le paramétrer à &lt;code&gt;off&lt;/code&gt; s&amp;rsquo;il y a de fortes chances&#xA;pour que le résultat de l&amp;rsquo;expression change lors d&amp;rsquo;un UPDATE. Cela permet d&amp;rsquo;éviter&#xA;d&amp;rsquo;exécuter l&amp;rsquo;expression inutilement.&lt;/p&gt;&#xA;&lt;p&gt;A noter également que le moteur évite l&amp;rsquo;évaluation de l&amp;rsquo;expression si son coût est&#xA;supérieur à 1000.&lt;/p&gt;&#xA;&lt;p&gt;Dans le troisième et dernier article, nous verrons un cas un peu plus concret&#xA;pour voir l&amp;rsquo;impact en terme de performance et de volumétrie.&lt;/p&gt;&#xA;&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;&#xA;&lt;p&gt;&#xA;&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=05f84605dbeb9cf8279a157234b24bbb706c5256&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disable recheck_on_update optimization to avoid crashes&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/section&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL et updates heap-only-tuples - partie 1</title>
    <updated>2018-11-12T07:00:00Z</updated>
    <id>tag:blog.anayrat.info,2018-11-12:/2018/11/12/postgresql-et-updates-heap-only-tuples-partie-1/</id>
    <link href="https://blog.anayrat.info/2018/11/12/postgresql-et-updates-heap-only-tuples-partie-1/" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Voici une série d&amp;rsquo;articles qui va porter sur une nouveauté de la version 11.&lt;/p&gt;&#xA;&lt;p&gt;Durant le développement de cette version, une fonctionnalité a attiré mon attention.&#xA;On peut la retrouver dans les releases notes : &#xA;&lt;a href=&#34;https://www.postgresql.org/docs/11/static/release-11.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.postgresql.org/docs/11/static/release-11.html&lt;/a&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Allow heap-only-tuple (HOT) updates for expression indexes when the values of the expressions are unchanged (Konstantin Knizhnik)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;J&amp;rsquo;avoue que ce n&amp;rsquo;est pas très explicite et cette fonctionnalité nécessite quelques&#xA;connaissances sur le fonctionnement du moteur que je vais essayer d&amp;rsquo;expliquer à travers&#xA;plusieurs articles :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;a href=&#34;https://blog.anayrat.info/2018/11/12/postgresql-et-updates-heap-only-tuples-partie-1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fonctionnement du MVCC et update &lt;em&gt;heap-only-tuples&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;a href=&#34;https://blog.anayrat.info/2018/11/19/postgresql-et-updates-heap-only-tuples-partie-2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quand le moteur ne fait pas d&amp;rsquo;update &lt;em&gt;heap-only-tuple&lt;/em&gt; et présentation de la nouveauté de la version 11&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;a href=&#34;https://blog.anayrat.info/2018/11/26/postgresql-et-updates-heap-only-tuples-partie-3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Impact sur les performances&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;Cette fonctionnalité a été désactivée en 11.1 car elle pouvait conduire à des&#xA;crash d&amp;rsquo;instance&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. J&amp;rsquo;ai tout de même choisi de publier ces articles car ils permettent&#xA;de comprendre le mécanisme des updates HOT et le gain que pourrait apporter cette&#xA;fonctionnalité.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Je remercie au passage Guillaume Lelarge pour la relecture de cet article ;).&lt;/p&gt;&#xA;&lt;h1 id=&#34;fonctionnement-mvcc&#34;&gt;Fonctionnement MVCC&lt;/h1&gt;&#xA;&lt;p&gt;Dans l&amp;rsquo;implémentation &#xA;&lt;a href=&#34;https://fr.wikipedia.org/wiki/Multiversion_Concurrency_Control&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MVCC&lt;/a&gt;&#xA;de Postgres, le moteur ne met pas à jour une ligne directement : il duplique&#xA;l&amp;rsquo;enregistrement et renseigne des informations de visibilité.&lt;/p&gt;&#xA;&lt;p&gt;Pourquoi ce fonctionnement?&lt;/p&gt;&#xA;&lt;p&gt;Il y a une composante capitale à prendre en compte quand on travaille avec un&#xA;SGBG : la concurrence d&amp;rsquo;accès.&lt;/p&gt;&#xA;&lt;p&gt;La ligne que vous êtes en train de modifier est peut être utilisée par une transaction&#xA;antérieure. Une sauvegarde en cours par exemple :)&lt;/p&gt;&#xA;&lt;p&gt;Pour cela, les SGBD ont adopté différentes techniques :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Modifier l&amp;rsquo;enregistrement et stocker les versions antérieures sur un autre&#xA;emplacement. C&amp;rsquo;est ce que fait oracle par exemple avec les undo logs.&lt;/li&gt;&#xA;&lt;li&gt;Dupliquer l&amp;rsquo;enregistrement et stocker des informations de visibilité pour&#xA;savoir quelle ligne est visible par telle ou telle transaction. Cela nécessite&#xA;d&amp;rsquo;avoir un mécanisme de nettoyage des lignes qui ne sont plus visibles par&#xA;personne. C&amp;rsquo;est l&amp;rsquo;implémentation dans Postgres et le vacuum a pour rôle d&amp;rsquo;effectuer ce nettoyage.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Prenons une table toute simple et regardons son contenu évoluer à l&amp;rsquo;aide de l&amp;rsquo;extension pageinspect :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE t2(c1 int);&#xA;INSERT INTO t2 VALUES (1);&#xA;SELECT lp,t_data FROM  heap_page_items(get_raw_page(&#39;t2&#39;,0));&#xA; lp |   t_data   &#xA;----+------------&#xA;  1 | \x01000000&#xA;(1 row)&#xA;&#xA;UPDATE t2 SET c1 = 2 WHERE c1 = 1;&#xA;SELECT lp,t_data FROM  heap_page_items(get_raw_page(&#39;t2&#39;,0));&#xA; lp |   t_data   &#xA;----+------------&#xA;  1 | \x01000000&#xA;  2 | \x02000000&#xA;(2 rows)&#xA;&#xA;VACUUM t2;&#xA;SELECT lp,t_data FROM  heap_page_items(get_raw_page(&#39;t2&#39;,0));&#xA; lp |   t_data   &#xA;----+------------&#xA;  1 |&#xA;  2 | \x02000000&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;On peut voir que le moteur a dupliqué la ligne et le vacuum a nettoyé&#xA;l&amp;rsquo;emplacement pour un usage futur.&lt;/p&gt;&#xA;&lt;h1 id=&#34;mécanisme-dupdate-heap-only-tuple&#34;&gt;Mécanisme d&amp;rsquo;update heap-only-tuple&lt;/h1&gt;&#xA;&lt;p&gt;Prenons un autre cas, un peu plus compliqué, une table avec deux colonnes et un&#xA;index sur une des deux colonnes :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE t3(c1 int,c2 int);&#xA;CREATE INDEX ON t3(c1);&#xA;INSERT INTO t3(c1,c2) VALUES (1,1);&#xA;INSERT INTO t3(c1,c2) VALUES (2,2);&#xA;SELECT ctid,* FROM t3;&#xA; ctid  | c1 | c2&#xA;-------+----+----&#xA; (0,1) |  1 |  1&#xA; (0,2) |  2 |  2&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;De la même façon qu&amp;rsquo;il est possible de lire les blocs d&amp;rsquo;une table, il est possible&#xA;de lire les blocs d&amp;rsquo;un index avec pageinspect :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c1_idx&#39;,1));&#xA; itemoffset | ctid  | itemlen | nulls | vars |          data           &#xA;------------+-------+---------+-------+------+-------------------------&#xA;          1 | (0,1) |      16 | f     | f    | 01 00 00 00 00 00 00 00&#xA;          2 | (0,2) |      16 | f     | f    | 02 00 00 00 00 00 00 00&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Jusque-là, c&amp;rsquo;est assez simple, ma table contient deux enregistrements et l&amp;rsquo;index&#xA;contient également deux enregistrements pointant vers les blocs correspondants de&#xA;la table (colonne ctid).&lt;/p&gt;&#xA;&lt;p&gt;Si je mets à jour la colonne c1, avec la nouvelle valeur 3 par exemple, l&amp;rsquo;index&#xA;devra être mis à jour.&lt;/p&gt;&#xA;&lt;p&gt;Maintenant, si je mets à jour la colonne c2, est-ce que l&amp;rsquo;index portant sur c1&#xA;sera mis à jour ?&lt;/p&gt;&#xA;&lt;p&gt;Au premier abord, on pourrait se dire non car c1 n&amp;rsquo;est pas modifiée.&lt;/p&gt;&#xA;&lt;p&gt;Mais à cause du modèle MVCC présenté plus haut, en théorie, la réponse sera oui :&#xA;nous venons de voir que le moteur va dupliquer la ligne, son emplacement physique&#xA;sera donc différent (le ctid suivant sera (0,3)).&lt;/p&gt;&#xA;&lt;p&gt;Vérifions le :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;UPDATE t3 SET c2 = 3 WHERE c1=1;&#xA;SELECT lp,t_data,t_ctid FROM  heap_page_items(get_raw_page(&#39;t3&#39;,0));&#xA; lp |       t_data       | t_ctid&#xA;----+--------------------+--------&#xA;  1 | \x0100000001000000 | (0,3)&#xA;  2 | \x0200000002000000 | (0,2)&#xA;  3 | \x0100000003000000 | (0,3)&#xA;(3 rows)&#xA;&#xA;&#xA;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c1_idx&#39;,1));&#xA; itemoffset | ctid  | itemlen | nulls | vars |          data           &#xA;------------+-------+---------+-------+------+-------------------------&#xA;          1 | (0,1) |      16 | f     | f    | 01 00 00 00 00 00 00 00&#xA;          2 | (0,2) |      16 | f     | f    | 02 00 00 00 00 00 00 00&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;La lecture du bloc de la table confirme bien que la ligne a été dupliquée.&#xA;En observant attentivement le champ &lt;code&gt;t_data&lt;/code&gt;, on arrive à distinguer le 1 de la&#xA;colonne c1 et le 3 de la colonne c2.&lt;/p&gt;&#xA;&lt;p&gt;En lisant le bloc de l&amp;rsquo;index, on constate que son contenu n&amp;rsquo;a pas bougé ! Si je&#xA;cherche la ligne &lt;code&gt;WHERE c1 = 1&lt;/code&gt;, l&amp;rsquo;index m&amp;rsquo;oriente vers l&amp;rsquo;enregistrement (0,1) qui&#xA;correspond à l&amp;rsquo;ancienne ligne !&lt;/p&gt;&#xA;&lt;p&gt;Que s&amp;rsquo;est-il passé ?&lt;/p&gt;&#xA;&lt;p&gt;En réalité, nous venons de mettre en évidence un mécanisme un peu particulier&#xA;appelé &lt;em&gt;heap-only-tuple&lt;/em&gt; alias HOT. Lorsqu&amp;rsquo;une colonne est mise à jour, qu&amp;rsquo;aucun&#xA;index ne pointe vers cette colonne et qu&amp;rsquo;on peut insérer l&amp;rsquo;enregistrement dans&#xA;le même bloc, le moteur va se contenter de faire un pointeur entre l&amp;rsquo;ancien&#xA;enregistrement le nouveau.&lt;/p&gt;&#xA;&lt;p&gt;Cela permet au moteur d&amp;rsquo;éviter d&amp;rsquo;avoir à mettre à jour l&amp;rsquo;index. Avec tout ce que&#xA;cela entraîne :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Des opérations en lecture/écriture évitées&lt;/li&gt;&#xA;&lt;li&gt;Réduction de la fragmentation de l&amp;rsquo;index et donc de sa taille (il est&#xA;difficile de réutiliser les anciens emplacements d&amp;rsquo;un index)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Si vous observez le bloc de la table, la colonne &lt;code&gt;t_ctid&lt;/code&gt; de la&#xA;première ligne pointe vers (0,3). Si la ligne était à nouveau mise à jour, la&#xA;première ligne de la table pointerait vers la ligne (0,3) et la ligne (0,3)&#xA;pointerait vers (0,4), formant ce qu&amp;rsquo;on appelle une chaîne. Un vacuum nettoierait&#xA;les espaces libres mais conserverait toujours la première ligne qui pointerait vers&#xA;le dernier enregistrement.&lt;/p&gt;&#xA;&lt;p&gt;On modifie une ligne et l&amp;rsquo;index ne change toujours pas :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;UPDATE t3 SET c2 = 4 WHERE c1=1;&#xA;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c1_idx&#39;,1));&#xA; itemoffset | ctid  | itemlen | nulls | vars |          data           &#xA;------------+-------+---------+-------+------+-------------------------&#xA;          1 | (0,1) |      16 | f     | f    | 01 00 00 00 00 00 00 00&#xA;          2 | (0,2) |      16 | f     | f    | 02 00 00 00 00 00 00 00&#xA;(2 rows)&#xA;&#xA;SELECT lp,t_data,t_ctid FROM  heap_page_items(get_raw_page(&#39;t3&#39;,0));&#xA; lp |       t_data       | t_ctid&#xA;----+--------------------+--------&#xA;  1 | \x0100000001000000 | (0,3)&#xA;  2 | \x0200000002000000 | (0,2)&#xA;  3 | \x0100000003000000 | (0,4)&#xA;  4 | \x0100000004000000 | (0,4)&#xA;(4 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Vacuum nettoie les emplacements disponibles :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;VACUUM t3;&#xA;SELECT lp,t_data,t_ctid FROM  heap_page_items(get_raw_page(&#39;t3&#39;,0));&#xA; lp |       t_data       | t_ctid&#xA;----+--------------------+--------&#xA;  1 |                    |&#xA;  2 | \x0200000002000000 | (0,2)&#xA;  3 |                    |&#xA;  4 | \x0100000004000000 | (0,4)&#xA;(4 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Un update va réutiliser le second emplacement et l&amp;rsquo;index reste inchangé.&#xA;Observez la valeur de la colonne &lt;code&gt;t_ctid&lt;/code&gt; pour reconstituer la chaîne :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;UPDATE t3 SET c2 = 5 WHERE c1=1;&#xA;SELECT lp,t_data,t_ctid FROM  heap_page_items(get_raw_page(&#39;t3&#39;,0));&#xA; lp |       t_data       | t_ctid&#xA;----+--------------------+--------&#xA;  1 |                    |&#xA;  2 | \x0200000002000000 | (0,2)&#xA;  3 | \x0100000005000000 | (0,3)&#xA;  4 | \x0100000004000000 | (0,3)&#xA;(4 rows)&#xA;&#xA;&#xA;SELECT * FROM  bt_page_items(get_raw_page(&#39;t3_c1_idx&#39;,1));&#xA; itemoffset | ctid  | itemlen | nulls | vars |          data           &#xA;------------+-------+---------+-------+------+-------------------------&#xA;          1 | (0,1) |      16 | f     | f    | 01 00 00 00 00 00 00 00&#xA;          2 | (0,2) |      16 | f     | f    | 02 00 00 00 00 00 00 00&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Euh, la première ligne est vide et le moteur a réutilisé le troisième emplacement ?&lt;/p&gt;&#xA;&lt;p&gt;En fait, une information n’apparaît pas dans pageinspect. Allons lire directement le bloc avec&#xA;&#xA;&lt;a href=&#34;https://wiki.postgresql.org/wiki/Pg_filedump&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pg_filedump&lt;/a&gt; :&lt;/p&gt;&#xA;&lt;p&gt;Note : Il faut demander un &lt;code&gt;CHECKPOINT&lt;/code&gt; au préalable. Dans le cas contraire, le bloc pourrait ne&#xA;pas encore être écrit sur le disque.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pg_filedump  11/main/base/16606/8890510&#xA;&#xA;*******************************************************************&#xA;* PostgreSQL File/Block Formatted Dump Utility - Version 10.1&#xA;*&#xA;* File: 11/main/base/16606/8890510&#xA;* Options used: None&#xA;*&#xA;* Dump created on: Sun Sep  2 13:09:53 2018&#xA;*******************************************************************&#xA;&#xA;Block    0 ********************************************************&#xA;&amp;lt;Header&amp;gt; -----&#xA; Block Offset: 0x00000000         Offsets: Lower      40 (0x0028)&#xA; Block: Size 8192  Version    4            Upper    8096 (0x1fa0)&#xA; LSN:  logid     52 recoff 0xc39ea148      Special  8192 (0x2000)&#xA; Items:    4                      Free Space: 8056&#xA; Checksum: 0x0000  Prune XID: 0x0000168b  Flags: 0x0001 (HAS_FREE_LINES)&#xA; Length (including item array): 40&#xA;&#xA;&amp;lt;Data&amp;gt; ------&#xA; Item   1 -- Length:    0  Offset:    4 (0x0004)  Flags: REDIRECT&#xA; Item   2 -- Length:   32  Offset: 8160 (0x1fe0)  Flags: NORMAL&#xA; Item   3 -- Length:   32  Offset: 8096 (0x1fa0)  Flags: NORMAL&#xA; Item   4 -- Length:   32  Offset: 8128 (0x1fc0)  Flags: NORMAL&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;La première ligne contient &lt;code&gt;Flags: REDIRECT&lt;/code&gt;. Ceci indique que cette ligne&#xA;correspond à une redirection HOT. C&amp;rsquo;est documenté dans &lt;code&gt;src/include/storage/itemid.h&lt;/code&gt; :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;/*&#xA; * lp_flags has these possible states.  An UNUSED line pointer is available     &#xA; * for immediate re-use, the other states are not.                              &#xA; */                                                                             &#xA;#define LP_UNUSED       0       /* unused (should always have lp_len=0) */      &#xA;#define LP_NORMAL       1       /* used (should always have lp_len&amp;gt;0) */        &#xA;#define LP_REDIRECT     2       /* HOT redirect (should have lp_len=0) */       &#xA;#define LP_DEAD         3       /* dead, may or may not have storage */   &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Il est AUSSI possible de le voir avec pageinspect en affichant la colonne &lt;code&gt;lp_flags&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT lp,lp_flags,t_data,t_ctid FROM  heap_page_items(get_raw_page(&#39;t3&#39;,0));&#xA; lp | lp_flags |       t_data       | t_ctid&#xA;----+----------+--------------------+--------&#xA;  1 |        2 |                    |&#xA;  2 |        1 | \x0200000002000000 | (0,2)&#xA;  3 |        1 | \x0100000005000000 | (0,3)&#xA;  4 |        1 | \x0100000004000000 | (0,3)&#xA;(4 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Si on refait un UPDATE, puis VACUUM, suivi d&amp;rsquo;un CHECKPOINT pour écrire le bloc sur disque :&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT lp,lp_flags,t_data,t_ctid FROM  heap_page_items(get_raw_page(&#39;t3&#39;,0));&#xA; lp | lp_flags |       t_data       | t_ctid&#xA;----+----------+--------------------+--------&#xA;  1 |        2 |                    |&#xA;  2 |        1 | \x0200000002000000 | (0,2)&#xA;  3 |        0 |                    |&#xA;  4 |        0 |                    |&#xA;  5 |        1 | \x0100000006000000 | (0,5)&#xA;(5 rows)&#xA;&#xA;CHECKPOINT;&#xA;&#xA;pg_filedump  11/main/base/16606/8890510&#xA;&#xA;*******************************************************************&#xA;* PostgreSQL File/Block Formatted Dump Utility - Version 10.1&#xA;*&#xA;* File: 11/main/base/16606/8890510&#xA;* Options used: None&#xA;*&#xA;* Dump created on: Sun Sep  2 13:16:12 2018&#xA;*******************************************************************&#xA;&#xA;Block    0 ********************************************************&#xA;&amp;lt;Header&amp;gt; -----&#xA; Block Offset: 0x00000000         Offsets: Lower      44 (0x002c)&#xA; Block: Size 8192  Version    4            Upper    8128 (0x1fc0)&#xA; LSN:  logid     52 recoff 0xc39ea308      Special  8192 (0x2000)&#xA; Items:    5                      Free Space: 8084&#xA; Checksum: 0x0000  Prune XID: 0x00000000  Flags: 0x0005 (HAS_FREE_LINES|ALL_VISIBLE)&#xA; Length (including item array): 44&#xA;&#xA;&amp;lt;Data&amp;gt; ------&#xA; Item   1 -- Length:    0  Offset:    5 (0x0005)  Flags: REDIRECT&#xA; Item   2 -- Length:   32  Offset: 8160 (0x1fe0)  Flags: NORMAL&#xA; Item   3 -- Length:    0  Offset:    0 (0x0000)  Flags: UNUSED&#xA; Item   4 -- Length:    0  Offset:    0 (0x0000)  Flags: UNUSED&#xA; Item   5 -- Length:   32  Offset: 8128 (0x1fc0)  Flags: NORMAL&#xA;&#xA;&#xA;*** End of File Encountered. Last Block Read: 0 ***&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Le moteur a conservé la première ligne (flag &lt;code&gt;REDIRECT&lt;/code&gt;) et écrit une nouvelle&#xA;ligne à l&amp;rsquo;emplacement 5.&lt;/p&gt;&#xA;&lt;p&gt;Il y a cependant quelques cas où le moteur ne peut pas utiliser ce mécanisme :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Lorsqu&amp;rsquo;il n&amp;rsquo;y a plus de place dans le bloc et qu&amp;rsquo;il doit écrire un autre bloc.&#xA;On peut en déduire que la fragmentation de la table est ici bénéfique pour bénéficier&#xA;du HOT.&lt;/li&gt;&#xA;&lt;li&gt;Un index porte sur la colonne mise à jour. Dans ce cas le moteur doit mettre&#xA;à jour l&amp;rsquo;index. Le moteur peut détecter s&amp;rsquo;il y a eu un changement&#xA;en effectuant une comparaison binaire entre la nouvelle valeur et la précédente &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Dans le prochain article nous verrons justement un exemple où le moteur&#xA;ne peut pas employer le mécanisme HOT. Puis, la nouveauté de la version 11&#xA;où le moteur peut utiliser se mécanisme.&lt;/p&gt;&#xA;&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;&#xA;&lt;p&gt;&#xA;&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=05f84605dbeb9cf8279a157234b24bbb706c5256&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disable recheck_on_update optimization to avoid crashes&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;&#xA;&lt;p&gt;&#xA;&lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/access/heap/README.HOT;h=4cf3c3a0d4c2db96a57e73e46fdd7463db439f79;hb=HEAD#l128&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;README.HOT&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/section&gt;</summary>
    <author>
      <name>blog.anayrat.info</name>
    </author>
  </entry>
  <entry>
    <title>[Infographie] PostgreSQL</title>
    <updated>2021-02-11T11:23:13Z</updated>
    <id>tag:blog.atolcd.com,2021-02-11:/infographie-postgresql/</id>
    <content type="html">&#xA;&lt;p&gt;PostgreSQL est un SGBD que nous affectionnons particulièrement chez Atol CD ! Retrouvez dans cette infographie quelques caractéristiques techniques, des chiffres-clé, son histoire mais aussi pourquoi nous l&amp;rsquo;aimons et notre Top5 des fonctionnalités côté développement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-container-2 wp-block-gallery-1 wp-block-gallery columns-1 is-cropped&#34;&gt;&lt;ul class=&#34;blocks-gallery-grid&#34;&gt;&lt;li class=&#34;blocks-gallery-item&#34;&gt;&lt;figure&gt;&lt;img width=&#34;866&#34; height=&#34;2560&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-scaled.jpg&#34; alt=&#34;&#34; data-id=&#34;4477&#34; data-full-url=&#34;https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-scaled.jpg&#34; data-link=&#34;https://blog.atolcd.com/infographie-postgresql/infographie_postgresql/&#34; class=&#34;wp-image-4477&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-scaled.jpg 866w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-101x300.jpg 101w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-346x1024.jpg 346w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-768x2271.jpg 768w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-520x1536.jpg 520w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-693x2048.jpg 693w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-600x1774.jpg 600w, https://blog.atolcd.com/wp-content/uploads/2021/02/infographie_PostgreSQL-945x2794.jpg 945w&#34; sizes=&#34;(max-width: 866px) 100vw, 866px&#34; /&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/infographie-postgresql/&#34;&gt;[Infographie] PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/infographie-postgresql/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=infographie-postgresql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PostgreSQL est un SGBD que nous affectionnons particulièrement chez Atol CD ! Retrouvez dans cette infographie quelques caractéristiques techniques, des chiffres-clé, son histoire mais aussi pourquoi nous l&amp;#8217;aimons et notre Top5 des fonctionnalités côté développement.&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/infographie-postgresql/&#34;&gt;[Infographie] PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Sortie de PostgreSQL 13</title>
    <updated>2020-09-24T05:54:57Z</updated>
    <id>tag:blog.atolcd.com,2020-09-24:/sortie-de-postgresql-13/</id>
    <content type="html">&#xA;&lt;p&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;&lt;img loading=&#34;lazy&#34; class=&#34;alignnone size-full wp-image-4130&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2020/09/pg13.jpg&#34; alt=&#34;&#34; width=&#34;960&#34; height=&#34;540&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2020/09/pg13.jpg 960w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-300x169.jpg 300w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-768x432.jpg 768w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-600x338.jpg 600w, https://blog.atolcd.com/wp-content/uploads/2020/09/pg13-945x532.jpg 945w&#34; sizes=&#34;(max-width: 960px) 100vw, 960px&#34; /&gt;Malgré des actualités plutôt moroses au Botswana concernant nos chers éléphants, il y en a un qui se porte bien et est encore plus fort à savoir PostgreSQL qui sort en version 13 stable ce jeudi 24 septembre 2020. &lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;Après seulement 3 versions Bêta et une RC le voilà dans les starting blocks pour débarquer sur vos serveurs ! Et comme à chaque nouvelle version son&lt;/span&gt; &lt;span style=&#34;font-weight: 400;&#34;&gt;lot de nouveautés&lt;/span&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-weight: 400;&#34;&gt;Un petit rappel qui peut parfois éviter bien des catastrophes, si vous avez prévu de migrer vers PostgreSQL 13, vous devriez jeter un oeil sur &lt;a href=&#34;https://www.postgresql.org/docs/13/release-13.html#id-1.11.6.5.4&#34;&gt;les potentielles incompatibilités avec les précédentes versions&lt;/a&gt;  (et aussi sur les versions intermédiaires si vous faite un gap de plusieurs versions d&amp;rsquo;un coup), il est toujours préférable d&amp;rsquo;identifier ces légers changements en amont plutôt qu&amp;rsquo;une fois en production. Mais rassurez-vous, dans cette version pas de quoi freiner significativement une migration.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;h1&gt;Partitionnement&lt;/h1&gt;&#xA;&lt;p&gt;Des améliorations sont ajoutées sur le partitionnement de tables, tant au niveau performance avec l&amp;rsquo;ajout de cas où une jointure directe entre partition peut être utilisée dans une requête, mais aussi de fonctionnalités telles que  la gestion des triggers avec le support de la clause BEFORE ou bien encore la réplication logique sans avoir besoin de publier chaque partition.&lt;/p&gt;&#xA;&lt;h1&gt;Index&lt;/h1&gt;&#xA;&lt;p&gt;Là aussi des améliorations de performances mais aussi des gains d&amp;rsquo;espace disque sur les index B-tree surtout pour ceux contenant des doublons, mais si vous passez par un pg_upgrade il voudra passer par un reindex pour bénéficier de ces changements.&lt;/p&gt;&#xA;&lt;h1&gt;Planificateur&lt;/h1&gt;&#xA;&lt;p&gt;Le planificateur de requête PostgreSQL a lui aussi eu le droit à quelques améliorations notamment au niveau des statistiques ce qui peut améliorer les plans d&amp;rsquo;exécution et donc les performances.&lt;/p&gt;&#xA;&lt;h1&gt;Performance générale&lt;/h1&gt;&#xA;&lt;p&gt;Les performances ne sont pas en reste dans cette nouvelle version, avec l&amp;rsquo;ajout du &lt;span style=&#34;font-weight: 400;&#34;&gt;tri incrémentiel ce qui accélère le tri des données dans certains cas,  sur les agrégations de hachage qui peuvent désormais utiliser le stockage sur disque dans le cadre de grands ensembles d&amp;rsquo;agrégation, sur la conversion de type entier vers texte.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;h1&gt;Vues système&lt;/h1&gt;&#xA;&lt;p&gt;De nouvelles vues système font leur apparition :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/progress-reporting.html#BASEBACKUP-PROGRESS-REPORTING&#34;&gt;pg_stat_progress_basebackup &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/progress-reporting.html#ANALYZE-PROGRESS-REPORTING&#34;&gt;pg_stat_progress_analyze &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/view-pg-shmem-allocations.html&#34;&gt;pg_shmem_allocations &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/docs/13/monitoring-stats.html#MONITORING-PG-STAT-SLRU-VIEW&#34;&gt;pg_stat_slru&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;la vue &lt;a href=&#34;https://www.postgresql.org/docs/13/monitoring-stats.html#PG-STAT-ACTIVITY-VIEW&#34;&gt;pg_stat_activity&lt;/a&gt; se voit elle ajoutée une colonne leader_pid ce qui permet de retrouver rapidement tous les processus impliqués dans une requête parallèle.&lt;/p&gt;&#xA;&lt;h1&gt;Fonctionnalités&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ajout de la fonctionnalité &lt;a href=&#34;https://www.postgresql.org/docs/13/sql-select.html#SQL-LIMIT&#34;&gt;FETCH FIRST WITH TIES&lt;/a&gt; (vous trouverez &lt;a href=&#34;http://pgphil.ovh/topn_13_beta_01.php&#34;&gt;ici&lt;/a&gt; un exemple)&lt;/li&gt;&#xA;&lt;li&gt;Ajout de la fonction gen_random_uuid() utilisable sans activer d’extensions&lt;/li&gt;&#xA;&lt;li&gt;Ajout de la possibilité de renommer une colonne d&amp;rsquo;une vue :&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;ALTER VIEW [ IF EXISTS ] name RENAME [ COLUMN ] column_name TO new_column_name&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de la fonction .datetime() dans les jsonpath pour convertir automatique une chaîne en date ou horodatage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1&gt;Client psql&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de nouvelles commandes pour afficher la description de classe d&amp;rsquo;opérateur et famille d&amp;rsquo;opérateur&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a class=&#34;link&#34; title=&#34;Meta-Commands&#34; href=&#34;https://www.postgresql.org/docs/13/app-psql.html#APP-PSQL-META-COMMANDS&#34;&gt;&lt;code class=&#34;literal&#34;&gt;\dAc&lt;/code&gt;&lt;/a&gt;, &lt;code class=&#34;literal&#34;&gt;\dAf&lt;/code&gt;, &lt;code class=&#34;literal&#34;&gt;\dAo&lt;/code&gt;, et &lt;code class=&#34;literal&#34;&gt;\dAp&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Ajout du statut de la transaction dans le prompt &lt;br /&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;* dans une transaction&lt;/li&gt;&#xA;&lt;li&gt;! dans un échec de transaction&lt;/li&gt;&#xA;&lt;li&gt;? pour un état indéterminé de la transaction&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1&gt;Administration&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ajout de la capacité de la commande VACUUM à traiter des index en parallèle&lt;/li&gt;&#xA;&lt;li&gt;la commande reindexdb peut aussi paralléliser les tâches&lt;/li&gt;&#xA;&lt;li&gt;introduction de la notion de « trusted extension » qui permet à un super utilisateur de définir les extensions qu’un utilisateur a le droit d&amp;rsquo;installer dans sa base de données en ayant le droit CREATE.&lt;/li&gt;&#xA;&lt;li&gt;Ajout pour pg_dump de l&amp;rsquo;option &amp;#8211;include-foreign-data pour inclure dans la sauvegarde les données de serveurs distants&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La liste des nouveautés dans cette version est grande, toutes les nouveautés n&amp;rsquo;ont pas été abordées mais vous pouvez bien sur les retrouver dans la &lt;a href=&#34;https://www.postgresql.org/docs/13/release-13.html&#34;&gt;note de version&lt;/a&gt;. Le focus a surtout été fait sur le côté utilisateur plutôt qu&amp;rsquo;administrateur de PostgreSQL.&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-13/&#34;&gt;Sortie de PostgreSQL 13&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/sortie-de-postgresql-13/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sortie-de-postgresql-13" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Malgré des actualités plutôt moroses au Botswana concernant nos chers éléphants, il y en a un qui se porte bien et est encore plus fort à savoir PostgreSQL qui sort en version 13 stable ce jeudi 24 septembre 2020.  Après... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-13/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-13/&#34;&gt;Sortie de PostgreSQL 13&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Sortie de PostgreSQL 11</title>
    <updated>2018-10-19T13:12:39Z</updated>
    <id>tag:blog.atolcd.com,2018-10-19:/sortie-de-postgresql-11/</id>
    <content type="html">&lt;p&gt;Après seulement une release candidate (mais auparavant 4 version bêta), PostgreSQL 11 vient de sortir!!!! Et comme à chaque nouvelle version son lot de nouveautés que nous allons essayer de passer rapidement en revue.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; class=&#34;aligncenter size-full wp-image-3169&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11.jpg&#34; alt=&#34;&#34; width=&#34;826&#34; height=&#34;540&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11.jpg 826w, https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11-300x196.jpg 300w, https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11-768x502.jpg 768w, https://blog.atolcd.com/wp-content/uploads/2018/10/PostGresql11-600x392.jpg 600w&#34; sizes=&#34;(max-width: 826px) 100vw, 826px&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Amélioration de la parallélisation&lt;/h2&gt;&#xA;&lt;p&gt;Quoi de mieux que de commencer le tour des nouveautés par un sujet que l&amp;rsquo;on a abordé lors du &lt;a href=&#34;https://blog.atolcd.com/conference-la-parallelisation-au-service-de-loptimisation/&#34;&gt;PG Day France 2018&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;PostgreSQL 11 va encore plus loin dans la parallélisation avec :&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Création d&amp;rsquo;index B-tree en parallèle&lt;/li&gt;&#xA;&lt;li&gt;Parallélisation des UNION ALL&lt;/li&gt;&#xA;&lt;li&gt;Amélioration du Parallel hash join (paralléliser le remplissage d’une seule table de hachage, partagée) et parallelized sequential scans&lt;/li&gt;&#xA;&lt;li&gt;Parallélisation sur la création de vue matérialisée et table à partir des résultats d&amp;rsquo;une requête&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE .. AS, SELECT INTO et CREATE MATERIALIZED VIEW.&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout d&amp;rsquo;un paramètre de configuration du serveur « parallel_leader_participation » qui permet de contrôler si le processus leader participe à l&amp;rsquo;exécution des sous plans d&amp;rsquo;exécution&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Amélioration du partitionnement&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;La possibilité de partitionner une table par hashage de clé (en plus des autres)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE hash1 (col1 NUMERIC, col2 VARCHAR(10)) PARTITION BY HASH(col1);&#xD;&#xA;CREATE TABLE hash1a PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 0) ;&#xD;&#xA;CREATE TABLE hash1b PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 1) ;&#xD;&#xA;CREATE TABLE hash1c PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 2) ;&#xD;&#xA;CREATE TABLE hash1d PARTITION OF hash1 FOR VALUES WITH (MODULUS 4, REMAINDER 3) ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout possible d&amp;rsquo;une partition par défaut pour les données ne correspondant à aucune partition&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE table1d PARTITION OF table1 DEFAULT;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;La possibilité de créer des clés primaires, clés étrangères, index et triggers qui seront automatiquement applicables sur l&amp;rsquo;ensemble des partitions&lt;/li&gt;&#xA;&lt;li&gt;Support du changement automatique de partition en cas de mise à jour de la clé de partitionnement&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances lors des SELECT sur la lecture des partitions&lt;/li&gt;&#xA;&lt;li&gt;Support des upsert sur les tables partitionnées&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;INSERT  INTO  tablep1 (col1, col2) &#xD;&#xA;VALUES  (100,  &#39;update&#39;) &#xD;&#xA;ON  CONFLICT ON CONSTRAINT tablep1_pkey &#xD;&#xA;DO UPDATE SET col2=&#39;update&#39; ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Gestion des transactions dans les procédures stockées&lt;/h2&gt;&#xA;&lt;p&gt;PostgreSQL 11 introduit la possibilité de créer des procédures (en PL/pgSQL, PL/Perl, PL/Python, et PL/Tcl). Depuis de nombreuses années, il est possible dans PostgreSQL de créer des fonctions et bien ici ça y ressemble fortement, sauf que l&amp;rsquo;on ne retourne pas de résultats et que l&amp;rsquo;on peut gérer les transactions !&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE PROCEDURE transaction_test1()&#xD;&#xA;LANGUAGE plpgsql&#xD;&#xA;AS $$&#xD;&#xA;BEGIN&#xD;&#xA;  FOR i IN 0..9 LOOP&#xD;&#xA;    INSERT INTO table1 (col1) VALUES (i) ;&#xD;&#xA;    IF i % 2 = 0 THEN&#xD;&#xA;      COMMIT;&#xD;&#xA;    ELSE&#xD;&#xA;      ROLLBACK;&#xD;&#xA;    END IF;&#xD;&#xA;  END LOOP;&#xD;&#xA;END;&#xD;&#xA;$$;&lt;/pre&gt;&lt;p&gt;L&amp;rsquo;exécution de ces procédures se fait en utilisant la commande CALL&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CALL transaction_test1();&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Compilation JIT&lt;/h2&gt;&#xA;&lt;p&gt;PostgreSQL 11 introduit le support de la compilation Just-in-Time (JIT) pour optimiser l’exécution de code et d’autres opérations. Utilisant des composants du projet LLVM, l’introduction de JIT dans PostgreSQL accélère les requêtes utilisant des expressions, listes, agrégats, projections, ainsi que certaines opérations internes.&lt;/p&gt;&#xA;&lt;p&gt;Pour pouvoir utiliser la compilation JIT, vous devrez installer la dépendance LLVM puis activer la compilation JIT soit dans le fichier de configuration (jit = on), soit durant votre session en exécutant SET jit = on.&lt;/p&gt;&#xA;&lt;p&gt;La compilation JIT bénéficie surtout aux requêtes de longue durée et limitées par le processeur. Ce seront souvent des requêtes analytiques (OLAP). Pour les requêtes courtes, le surcoût apporté par la compilation JIT sera souvent supérieur au temps qu&amp;rsquo;elle permet de gagner.&lt;/p&gt;&#xA;&lt;h2&gt;Améliorations générales SQL&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Support de toutes les clauses (SQL:2011) dans les fonctions de fenêtrage ce qui permet maintenant l’utilisation de RANGE dans des clauses PRECEDING/FOLLOWING, GROUPS ou d’exclusion&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;WINDOW window_name AS ( &#xD;&#xA;  [ PARTITION BY expression [, ...] ]&#xD;&#xA;  [ ORDER BY expression [ ASC | DESC | USING operator ] [ NULLS { FIRST | LAST } ] [, ...] ]&#xD;&#xA;  [ frame_clause ]&#xD;&#xA;)&#xD;&#xA;&#xD;&#xA;frame_clause :&#xD;&#xA;{ RANGE | ROWS | GROUPS } frame_start [ frame_exclusion ]&#xD;&#xA;{ RANGE | ROWS | GROUPS } BETWEEN frame_start AND frame_end [ frame_exclusion ]&#xD;&#xA;&#xD;&#xA;frame_start / frame_end :&#xD;&#xA;&#xD;&#xA;UNBOUNDED PRECEDING&#xD;&#xA;offset PRECEDING&#xD;&#xA;CURRENT ROW&#xD;&#xA;offset FOLLOWING&#xD;&#xA;UNBOUNDED FOLLOWING&#xD;&#xA;&#xD;&#xA;frame_exclusion :&#xD;&#xA;&#xD;&#xA;EXCLUDE CURRENT ROW&#xD;&#xA;EXCLUDE GROUP&#xD;&#xA;EXCLUDE TIES&#xD;&#xA;EXCLUDE NO OTHERS&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de fonctions de hash sha-2 : sha224(), sha256(), sha384() et sha512()&lt;/li&gt;&#xA;&lt;li&gt;Ajout de fonctions de recherche plein texte : json(b)_to_tsvector() et websearch_to_tsquery()&lt;/li&gt;&#xA;&lt;li&gt;Ajout de l&amp;rsquo;opérateur ^@ identique à LIKE &amp;lsquo;mot%&amp;rsquo; mais plus efficace sur un index b-tree&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;text ^@ text&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Amélioration des index avec l&amp;rsquo;ajout du mot clef INCLUDE, qui permet d&amp;rsquo;indiquer une liste de colonnes qui seront incluses dans l&amp;rsquo;index comme des colonnes non clés. L&amp;rsquo;ajout de colonnes dans la création d&amp;rsquo;index permet alors l&amp;rsquo;utilisation de parcours d&amp;rsquo;index couvrants.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] nom ] ON [ ONLY ] nom_table [ USING méthode ]&#xD;&#xA;    ( { nom_colonne | ( expression ) } [ COLLATE collation ] [ classeop ] [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, ...] )&#xD;&#xA;    [ INCLUDE ( nom_colonne [, ...] ) ]&#xD;&#xA;    [ WITH ( parametre_stockage = valeur [, ... ] ) ]&#xD;&#xA;    [ TABLESPACE nom_espacelogique ]&#xD;&#xA;    [ WHERE prédicat ]&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Amélioration de l’ordre ALTER TABLE .. ADD COLUMN .. DEFAULT .. avec une valeur par défaut non NULL n’a plus besoin de réécrire entièrement la table lors de son exécution, ce qui entraîne une grosse amélioration des performances.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Authentification&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de l&amp;rsquo;authentification LDAP, mais celle ci n&amp;rsquo;est utilisée que pour valider les paires nom d&amp;rsquo;utilisateur/mot de passe. De ce fait, pour pouvoir utiliser LDAP comme méthode d&amp;rsquo;authentification, l&amp;rsquo;utilisateur doit préalablement exister dans la base.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;psql&lt;/h2&gt;&#xA;&lt;p&gt;Le client psql évolue lui aussi :&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout des commandes « quit » et « exit » dans le client psql&amp;#8230; (fini les personnes prisent de panique pour sortir de leur terminal ??? )&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/xTk9ZBWrma4PIC9y4E/giphy.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de la commande \gdesc pour afficher les noms et types de colonnes du résultat de la requête&lt;/li&gt;&#xA;&lt;li&gt;Ajout de variables pour les erreurs et activités des requêtes ERROR, SQLSTATE, ROW_COUNT, LAST_ERROR_MESSAGE, and LAST_ERROR_SQLSTATE.&lt;/li&gt;&#xA;&lt;li&gt;Ajout de la possibilité de tester l&amp;rsquo;existence d&amp;rsquo;une variable par exemple dans un if&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;\if :{?variable_name}&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Amélioration de la complétion dans l&amp;rsquo;écriture de requêtes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;En dehors de ces nouveautés en terme d&amp;rsquo;utilisation, cette nouvelle version apporte aussi des améliorations de performance et d&amp;rsquo;utilisation de mémoire.&lt;/p&gt;&#xA;&lt;p&gt;Et voilà, nous avons fini notre petit tour rapide des nouveautés de postgreSQL 11, mais ne vous inquiétez pas une version 12 est déjà en préparation pour le troisième trimestre 2019.&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-11/&#34;&gt;Sortie de PostgreSQL 11&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/sortie-de-postgresql-11/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sortie-de-postgresql-11" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Après seulement une release candidate (mais auparavant 4 version bêta), PostgreSQL 11 vient de sortir!!!! Et comme à chaque nouvelle version son lot de nouveautés que nous allons essayer de passer rapidement en revue. Amélioration de la parallélisation Quoi de... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-11/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-11/&#34;&gt;Sortie de PostgreSQL 11&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Pimp My PostgreSQL</title>
    <updated>2018-01-26T11:07:23Z</updated>
    <id>tag:blog.atolcd.com,2018-01-26:/pimp-my-postgresql/</id>
    <content type="html">&lt;p&gt;&lt;img loading=&#34;lazy&#34; class=&#34;alignright wp-image-2934&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2018/01/pimp-my-postgresql.png&#34; alt=&#34;&#34; width=&#34;491&#34; height=&#34;290&#34; /&gt;Une question qui se pose souvent après l&amp;rsquo;installation d&amp;rsquo;une instance postgreSQL, c&amp;rsquo;est comment configurer ce fichier postgresql.conf. Dans le doute souvent, beaucoup de personnes conservent la configuration par défaut, ce qui ne va pas poser vraiment de problème pour une utilisation légère. Mais si on a une instance postgreSQL avec postGIS et des millions d&amp;rsquo;enregistrements, cela va rapidement se trouver problématique si on laisse les valeurs par défaut&amp;#8230;&lt;/p&gt;&#xA;&lt;p&gt;Pour les initiés qui installent régulièrement de nouvelles instances postgreSQL, se plonger dans les plus de 600 lignes du fichier de configuration par défaut ne les effraie pas. Mais on n&amp;rsquo;installe pas forcément tous les jours un nouveau serveur avec des caractéristiques différentes. Il faut donc soit se replonger pour une centième fois dans la documentation de postgres pour se rappeler à notre bonne mémoire les différents paramètres et les valeurs à adapter en fonction de la ram, disque, cpu&amp;#8230;&lt;/p&gt;&#xA;&lt;p&gt;En plus de devoir se rappeler les &lt;strong&gt;paramètres à modifier,&lt;/strong&gt; il faut aussi connaître les &lt;strong&gt;règles de calcul &lt;/strong&gt;pour les valeurs comme par exemple le « effective_cache_size » qui est préconisé à 75% de la ram total du serveur si celui-ci est dédié à postgres.&lt;/p&gt;&#xA;&lt;p&gt;Le but de cet article n&amp;rsquo;est pas de voir ni de détailler tous les paramètres de configuration possibles et inimaginables, mais de voir cela comme un mémo pour les initiés ou de s’interroger sur les &lt;strong&gt;paramètres qui seraient potentiellement à modifier en fonction du serveur&lt;/strong&gt; (et des applications qui l&amp;rsquo;utilisent) si l&amp;rsquo;on ne connait pas l&amp;rsquo;utilisation des paramètres de ce fichier postgresql.conf.&lt;/p&gt;&#xA;&lt;p&gt;Pour cela un petit outil a été conçu par Cybertec, qui permet de renseigner quelques caractéristiques et de voir évoluer en conséquence le fichier postgresql.conf notamment en fonction de la ram du serveur, du nombre de cpu, de la taille de la base&amp;#8230; etc.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; class=&#34;alignnone size-full wp-image-2925&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator.png&#34; alt=&#34;&#34; width=&#34;1005&#34; height=&#34;993&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator.png 1005w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-300x296.png 300w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-768x759.png 768w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-945x934.png 945w, https://blog.atolcd.com/wp-content/uploads/2018/01/pgconfigurator-600x593.png 600w&#34; sizes=&#34;(max-width: 1005px) 100vw, 1005px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cela ne remplace pas une connaissance aguerrie de postgreSQL et de sa configuration mais ça permet de se faire une idée des paramètres à adapter en fonction de son serveur et de ses besoins.&lt;/p&gt;&#xA;&lt;p&gt;Cet outil est disponible en ligne à cette adresse : &lt;a href=&#34;http://pgconfigurator.cybertec.at/&#34;&gt;http://pgconfigurator.cybertec.at/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/pimp-my-postgresql/&#34;&gt;Pimp My PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/pimp-my-postgresql/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pimp-my-postgresql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Une question qui se pose souvent après l&amp;#8217;installation d&amp;#8217;une instance postgreSQL, c&amp;#8217;est comment configurer ce fichier postgresql.conf. Dans le doute souvent, beaucoup de personnes conservent la configuration par défaut, ce qui ne va pas poser vraiment de problème pour une... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/pimp-my-postgresql/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/pimp-my-postgresql/&#34;&gt;Pimp My PostgreSQL&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Sortie de PostgreSQL 10</title>
    <updated>2017-10-05T13:28:32Z</updated>
    <id>tag:blog.atolcd.com,2017-10-05:/sortie-de-postgresql-10/</id>
    <content type="html">&lt;p&gt;Aujourd&amp;rsquo;hui, c&amp;rsquo;est la sortie de &lt;strong&gt;PostgreSQL 10&lt;/strong&gt;!!!! Première révolution, la numérotation des versions : on passe de 9.4&amp;#8230;9.6 pour les versions majeures à 10, 11, 12&amp;#8230; Ce point est important car un changement de version majeure implique une migration des données. Une opération beaucoup plus lourde que la seule mise à jour des exécutables !&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; class=&#34;aligncenter size-full wp-image-2788&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/10/postgresql-10.jpg&#34; alt=&#34;&#34; width=&#34;558&#34; height=&#34;337&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/10/postgresql-10.jpg 558w, https://blog.atolcd.com/wp-content/uploads/2017/10/postgresql-10-300x181.jpg 300w&#34; sizes=&#34;(max-width: 558px) 100vw, 558px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Voici quelques détails sur cette&lt;strong&gt; nouvelle version 10&lt;/strong&gt; et ce qu&amp;rsquo;elle apporte :&lt;/p&gt;&#xA;&lt;h2&gt;Performance et partitionnement&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Le partitionnement de table est maintenant un attribut de la table :&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE table_name ( ... )&#xD;&#xA;[ PARTITION BY { RANGE | LIST } ( { column_name | ( expression ) }&#xD;&#xA;&#xD;&#xA;CREATE TABLE table_name&#xD;&#xA;PARTITION OF parent_table [ (&#xD;&#xA;) ] FOR VALUES partition_bound_spec&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;PostgreSQL 10 va plus loin dans la parallélisation avec le parallélisme des Index-Only Scan, Index Scan, Bitmap Heap Scan, Merge Join / Gather Merge, Subplan-Related Improvements&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances pour les agrégats et jointures avec &lt;code&gt;postgres_fdw&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances de l&amp;rsquo;analyseur de requête&lt;/li&gt;&#xA;&lt;li&gt;Apparition des statistiques multi-colonnes&lt;/li&gt;&#xA;&lt;li&gt;Amélioration du plan d’exécution des requêtes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Réplication et scalabilité&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Réplication logique : légère et basée sur les WAL, répliquant les objets individuellement via les commandes PUBLICATION (primaire) et SUBSCRIPTION (secondaire)&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE PUBLICATION financials FOR TABLE ONLY loans, ONLY fines;&lt;/pre&gt;&lt;br /&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE SUBSCRIPTION financials&#xD;&#xA;CONNECTION &#39;dbname=libdata user=postgres host=172.17.0.2&#39;&#xD;&#xA;PUBLICATION financials;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;QUORUM replication : avec ANY et FIRST pour synchronous_standby_names;&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;synchronous_standby_names = ANY 2(node1,node2,node3);&#xD;&#xA;synchronous_standby_names = FIRST 2(node1,node2);&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Suppression automatique à la fin de la session des slots de réplication temporaires&lt;/li&gt;&#xA;&lt;li&gt;Amélioration de libpq permettant des connexions a de multiples systèmes&lt;/li&gt;&#xA;&lt;li&gt;Amélioration des performances de la réplication physique&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Administration&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Support de la compression pour pg_receivewal&lt;/li&gt;&#xA;&lt;li&gt;Ajout d&amp;rsquo;informations sur les Background processes et Wait Events dans pg_stat_activity&lt;/li&gt;&#xA;&lt;li&gt;Ajout de fonctions qui remontent à l&amp;rsquo;utilisateur des informations sur le status de transaction. L&amp;rsquo;usage principal de ces fonctions est de déterminer les transactions commitées entre deux snapshots.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;txid_status(bigint)&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Fonctionnalités SQL et développeurs&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Gestion de colonne Identity qui vise à remplacer l&amp;rsquo;utilisation du type serial et qui est conforme au standard SQL&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TABLE test_new (&#xD;&#xA;    id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,&#xD;&#xA;    payload text&#xD;&#xA;);&lt;/pre&gt;&lt;p&gt;plus d&amp;rsquo;informations sur ce sujet &lt;a href=&#34;https://blog.2ndquadrant.com/postgresql-10-identity-columns/&#34;&gt;ici par exemple&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Possibilité de renommer la valeur d&amp;rsquo;une énumération&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TYPE langage AS ENUM (&#39;SQL&#39;, &#39;JAVA&#39;, &#39;HTML&#39;) ;&#xD;&#xA;ALTER TYPE langage RENAME VALUE &#39;HTML&#39; TO &#39;HTML5&#39; ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout des triggers AFTER STATEMENT qui peuvent avoir accès à l’ensemble des lignes modifiées, avant et après changement, à travers une pseudo-variable de type table&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE TRIGGER nom_trigger AFTER DELETE ON nom_table&#xD;&#xA;REFERENCING OLD TABLE AS OLD&#xD;&#xA;FOR EACH STATEMENT&#xD;&#xA;EXECUTE PROCEDURE nom_procedure();&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de la fonction xmltable qui produit une table basée sur la valeur XML donnée.&lt;/li&gt;&#xA;&lt;li&gt;Supprimer des éléments d&amp;rsquo;un JSONB&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;SELECT &#39;{&#34;a&#34;:1 , &#34;b&#34;:2, &#34;c&#34;:3}&#39;::jsonb - &#39;{a,c}&#39;::text[] ;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Il est possible de créer des indexes full text sur une colonne JSON ou JSONB&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE INDEX bookdata_fts ON bookdata&#xD;&#xA;USING gin (( to_tsvector(&#39;english&#39;,bookdata) ));&#xD;&#xA;&#xD;&#xA;SELECT bookdata -&amp;gt; &#39;title&#39;&#xD;&#xA;FROM bookdata&#xD;&#xA;WHERE to_tsvector(&#39;english&#39;,bookdata) @@ to_tsquery(&#39;duke&#39;);&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Sécurité&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Authentification SCRAM plus sécurisée que md5&lt;/li&gt;&#xA;&lt;li&gt;Création de nouveau rôle pour le monitoring évitant ainsi d&amp;rsquo;être super utilisateur&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;pg_read_all_settings : Lit toutes les variables de configuration, y compris celles normalement visibles des seuls super-utilisateurs.&#xD;&#xA;pg_read_all_stats : Lit toutes les vues pg_stat_* et utilise plusieurs extensions relatives aux statistiques, y compris celles normalement visibles des seuls super-utilisateurs.&#xD;&#xA;pg_stat_scan_tables : Exécute des fonctions de monitoring pouvant prendre des verrous verrous ACCESS SHARE sur les tables, potentiellement pour une longue durée.&#xD;&#xA;pg_monitor : Lit et exécute plusieurs vues et fonctions de monitoring. Ce rôle est membre de pg_read_all_settings, pg_read_all_stats et pg_stat_scan_tables.&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;Ajout de politiques restrictive dans les politiques de sécurité pour l&amp;rsquo;accès aux lignes et plus seulement de politiques permissives&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;/p&gt;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE POLICY admin_local_only ON passwd AS RESTRICTIVE TO admin&#xD;&#xA;    USING (pg_catalog.inet_client_addr() IS NULL);&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Autres fonctionnalités&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;file_fdw peut maintenant utiliser les programmes&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE FOREIGN TABLE&#xD;&#xA;   test(a int, b text)&#xD;&#xA;   SERVER csv&#xD;&#xA;   OPTIONS (program &#39;gunzip -c /tmp/data.czv.gz&#39;);&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;support des collations ICU&lt;/li&gt;&#xA;&lt;li&gt;Ajout d&amp;rsquo;un module amcheck permettant de vérifier cohérence / corruption d&amp;rsquo;un index B-Tree&lt;/li&gt;&#xA;&lt;li style=&#34;list-style-type: none;&#34;&gt;&#xA;&lt;pre class=&#34;crayon-plain-tag&#34;&gt;CREATE EXTENSION amcheck ;&#xD;&#xA;   SELECT bt_index_check(&#39;idx1_check1&#39;) ;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Modifications entrainant une incompatibilité ascendante&lt;/h2&gt;&#xA;&lt;ul style=&#34;list-style-type: disc;&#34;&gt;&#xA;&lt;li&gt;“xlog” et “clog” qui deviennent respectivement “wal” et “xact”.&lt;/li&gt;&#xA;&lt;li&gt;fin du support du protocole client/serveur 1.0 (clients datant d’avant la version 6.3)&lt;/li&gt;&#xA;&lt;li&gt;changement de valeurs par défaut pour pg_basebackup&lt;/li&gt;&#xA;&lt;li&gt;fin du support des TIMESTAMP avec floating point.&lt;/li&gt;&#xA;&lt;li&gt;Le module contrib/tsearch2 a été supprimé qui permettait une comptabilité avec les fonction de recherche full text avant la version 8.3&lt;/li&gt;&#xA;&lt;li&gt;fin du support de la commande pg_dump pour les bases de données plus anciennes que la version 8.0&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Et voilà, nous avons fini notre petit tour rapide des nouveautés de postgreSQL 10 mais une version 11 est déjà prévue pour dans 12 mois !&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-10/&#34;&gt;Sortie de PostgreSQL 10&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/sortie-de-postgresql-10/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sortie-de-postgresql-10" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Aujourd&amp;#8217;hui, c&amp;#8217;est la sortie de PostgreSQL 10!!!! Première révolution, la numérotation des versions : on passe de 9.4&amp;#8230;9.6 pour les versions majeures à 10, 11, 12&amp;#8230; Ce point est important car un changement de version majeure implique une migration des... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-10/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/sortie-de-postgresql-10/&#34;&gt;Sortie de PostgreSQL 10&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Nouveau module d’export de données pour REMOcRA</title>
    <updated>2017-05-12T13:52:26Z</updated>
    <id>tag:blog.atolcd.com,2017-05-12:/nouveau-module-dexport-de-donnees-remocra/</id>
    <content type="html">&lt;h1&gt;Objectif du module&lt;/h1&gt;&#xA;&lt;p&gt;Le SDIS du Var ne disposait pas jusqu&amp;rsquo;à ce jour, à travers la plate-forme collaborative &lt;a href=&#34;http://sdis.atolcd.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;REMOcRA&lt;/a&gt;, d&amp;rsquo;une méthode simple pour exporter le contenu de la base de données auprès de ses partenaires. Les demandes étant de plus en plus récurrentes, le SDIS du Var a décidé &lt;strong&gt;de faire évoluer l&amp;rsquo;application pour l&amp;rsquo;enrichir d&amp;rsquo;un module dédié aux exports&lt;/strong&gt; et a confié à Atol Conseils et Développements sa réalisation en veillant à respecter les besoins suivants :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;En tant qu&amp;rsquo;administrateur de l&amp;rsquo;extranet, être en mesure de réaliser facilement des exports de données en se basant sur des modèles administrables. Ce module devait être en mesure de produire des fichiers tabulaires ou des fichiers géographiques.&lt;/li&gt;&#xA;&lt;li&gt;En tant que partenaire, être en mesure d&amp;rsquo;exporter soit même les données mises à disposition par le SDIS sur un territoire autorisé.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1&gt;Comment ça marche ?&lt;/h1&gt;&#xA;&lt;h2&gt;Un fonctionnement basé sur des modèles d&amp;rsquo;exports&lt;/h2&gt;&#xA;&lt;p&gt;Le mécanisme d&amp;rsquo;export repose sur des modèles. Ces derniers peuvent être référencés directement par les administrateurs de la plate-forme REMOcRA grâce à des fichiers de définition de modèle (format XML) déposés fia FTP dans un sous-dossier de REMOcRA.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; class=&#34;aligncenter size-large wp-image-2626&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-1024x220.png&#34; alt=&#34;&#34; width=&#34;676&#34; height=&#34;145&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-1024x220.png 1024w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-300x64.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-768x165.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-945x203.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1-600x129.png 600w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-1.png 1067w&#34; sizes=&#34;(max-width: 676px) 100vw, 676px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Le fichier XML précise principalement la requête SQL à utiliser pour filtrer et formater les données à la bonne structure. L&amp;rsquo;attribut spatial du nœud racine permet de préciser si l&amp;rsquo;export est de type tabulaire (CSV) ou géographique (Esri Shapefile). Dans le cas d&amp;rsquo;un export géographique, la colonne « wkt » contenant la géométrie encodée en WKT est exploitée.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; class=&#34;aligncenter size-full wp-image-2627&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2.png&#34; alt=&#34;&#34; width=&#34;822&#34; height=&#34;341&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2.png 822w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2-300x124.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2-768x319.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-2-600x249.png 600w&#34; sizes=&#34;(max-width: 822px) 100vw, 822px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Le référencement des modèles est réalisé directement depuis l&amp;rsquo;interface en exécutant depuis REMOcRA le traitement « Référencer les modèles d&amp;rsquo;export de données » disponible dans la catégorie d&amp;rsquo;applications « Divers »&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; class=&#34;aligncenter size-full wp-image-2628&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3.png&#34; alt=&#34;&#34; width=&#34;968&#34; height=&#34;288&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3.png 968w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-300x89.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-768x228.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-945x281.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-3-600x179.png 600w&#34; sizes=&#34;(max-width: 968px) 100vw, 968px&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Un traitement spécifique intégrant le filtrage spatial des données&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; class=&#34;aligncenter size-large wp-image-2629&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-1024x525.png&#34; alt=&#34;&#34; width=&#34;676&#34; height=&#34;347&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-1024x525.png 1024w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-300x154.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-768x394.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-945x484.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4-600x307.png 600w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-4.png 1167w&#34; sizes=&#34;(max-width: 676px) 100vw, 676px&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;La réalisation d&amp;rsquo;un export de données depuis le système REMOcRA se base sur le mécanisme suivant :&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;L&amp;rsquo;utilisateur de profil « administrateur » dispose d&amp;rsquo;un nouveau traitement intitulé « Exporter les données à partir d&amp;rsquo;un modèle ». Ce dernier permet de réaliser des exports de données en s&amp;rsquo;appuyant sur la liste de modèles.&lt;/li&gt;&#xA;&lt;li&gt;Après avoir choisi son modèle, la demande d&amp;rsquo;export formulée par l&amp;rsquo;utilisateur est stockée en file d&amp;rsquo;attente. Une tâche planifiée vérifie régulièrement la présence de demandes en attente&lt;/li&gt;&#xA;&lt;li&gt;Lors de l’exécution de la tâche planifiée, le moteur ETL exécute les demandes d&amp;rsquo;export en attente en s&amp;rsquo;appuyant sur les informations contenues dans le modèle pour générer un fichier CSV (dans le cas de données non géographiques) ou des fichiers de formes (fichiers ESRI Shapefile).&lt;/li&gt;&#xA;&lt;li&gt;A l&amp;rsquo;issu du traitement, les fichiers produits sont compressés au format ZIP et un lien de téléchargement est fourni dans un mél envoyé au demandeur du traitement.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; class=&#34;aligncenter size-full wp-image-2630&#34; src=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5.png&#34; alt=&#34;&#34; width=&#34;962&#34; height=&#34;367&#34; srcset=&#34;https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5.png 962w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-300x114.png 300w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-768x293.png 768w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-945x361.png 945w, https://blog.atolcd.com/wp-content/uploads/2017/05/billet-remocra-5-600x229.png 600w&#34; sizes=&#34;(max-width: 962px) 100vw, 962px&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Une mutualisation des connaissances !&lt;/h2&gt;&#xA;&lt;p&gt;Le SDIS du Var (83), à l&amp;rsquo;initiative de la plate-forme collaborative métier REMOcRA, a décidé de faire bénéficier ses confrères de sa démarche en redistribuant gratuitement l&amp;rsquo;outil et ce module sous licence Creative Commons.&lt;br /&gt;&#xA;Dans cette démarche open source, la solution et le nouveau module sont disponibles sur Github pour installation et test à tous les SDIS sur &lt;a href=&#34;https://github.com/atolcd/sdis-remocra&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/atolcd/sdis-remocra&lt;/a&gt;. Pour plus d&amp;rsquo;information sur la solution REMOcRA, consulter &lt;a href=&#34;http://sdis.atolcd.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;http://sdis.atolcd.com&lt;/a&gt;&lt;br /&gt;&#xA;&lt;em&gt;REMOcRA est cofinancé par l’Union européenne. L’Europe s’engage avec le Fonds européen de développement régional.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/&#34;&gt;Nouveau module d&amp;rsquo;export de données pour REMOcRA&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=nouveau-module-dexport-de-donnees-remocra" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Objectif du module Le SDIS du Var ne disposait pas jusqu&amp;#8217;à ce jour, à travers la plate-forme collaborative REMOcRA, d&amp;#8217;une méthode simple pour exporter le contenu de la base de données auprès de ses partenaires. Les demandes étant de plus... &lt;a class=&#34;more-link&#34; href=&#34;https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/&#34;&gt;Continue Reading &amp;#8594;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cet article &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com/nouveau-module-dexport-de-donnees-remocra/&#34;&gt;Nouveau module d&amp;rsquo;export de données pour REMOcRA&lt;/a&gt; est apparu en premier sur &lt;a rel=&#34;nofollow&#34; href=&#34;https://blog.atolcd.com&#34;&gt;Atol Open Blog&lt;/a&gt;.&lt;/p&gt;&#xA;</summary>
    <author>
      <name>Caroline Chanlon</name>
    </author>
  </entry>
  <entry>
    <title>Nouveau dans pg13: Colonne leader_pid dans pg_stat_activity</title>
    <updated>2020-03-08T05:33:26Z</updated>
    <id>tag:rjuju.github.io,2020-03-08:/postgresqlfr/2020/03/08/nouveau-dans-pg13-leader_pid.html</id>
    <content type="html">&lt;h3 id=&#34;nouvelle-colonne-leader_pid-dans-la-vue-pg_stat_activity&#34;&gt;Nouvelle colonne leader_pid dans la vue pg_stat_activity&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Étonnamment, depuis que les requêtes parallèles ont été ajoutées dans&#xA;PostgreSQL 9.6, il était impossible de savoir à quel processus client était lié&#xA;un worker parallèle.  Ainsi, comme &lt;a href=&#34;https://twitter.com/g_lelarge/status/1209486212190343168&#34;&gt;Guillaume l’a fait&#xA;remarquer&lt;/a&gt;, it makes&#xA;il est assez difficile de construire des outils simples permettant&#xA;d’échantillonner les événements d’attente liés à tous les processus impliqués&#xA;dans une requête.  Une solution simple à ce problème est d’exporter&#xA;l’information de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;lock group leader&lt;/code&gt; disponible dans le processus client au&#xA;niveau SQL :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit b025f32e0b5d7668daec9bfa957edf3599f4baa8&#xA;Author: Michael Paquier &amp;lt;michael@paquier.xyz&amp;gt;&#xA;Date:   Thu Feb 6 09:18:06 2020 +0900&#xA;&#xA;Add leader_pid to pg_stat_activity&#xA;&#xA;This new field tracks the PID of the group leader used with parallel&#xA;query.  For parallel workers and the leader, the value is set to the&#xA;PID of the group leader.  So, for the group leader, the value is the&#xA;same as its own PID.  Note that this reflects what PGPROC stores in&#xA;shared memory, so as leader_pid is NULL if a backend has never been&#xA;involved in parallel query.  If the backend is using parallel query or&#xA;has used it at least once, the value is set until the backend exits.&#xA;&#xA;Author: Julien Rouhaud&#xA;Reviewed-by: Sergei Kornilov, Guillaume Lelarge, Michael Paquier, Tomas&#xA;Vondra&#xA;Discussion: https://postgr.es/m/CAOBaU_Yy5bt0vTPZ2_LUM6cUcGeqmYNoJ8-Rgto+c2+w3defYA@mail.gmail.com&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Avec cette modification, il est maintenant très simple de trouver tous les&#xA;processus impliqués dans une requête parallèle.  Par exemple :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;=#&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;  &lt;span class=&#34;n&#34;&gt;array_agg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;members&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_stat_activity&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;IS&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;GROUP&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;       &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leader_pid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;members&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-------------------+------------+---------------&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;      &lt;span class=&#34;mi&#34;&gt;31630&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32269&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32268&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;}&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Attention toutefois, comme indiqué dans le message de commit, si la colonne&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;leader_pid&lt;/code&gt; à la même valeur que la colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pid&lt;/code&gt;, cela ne veut pas forcément&#xA;dire que le processus client est actuellement en train d’effectuer une requête&#xA;parallèle, car une fois que le champ est positionné il n’est jamais&#xA;réinitialisé.  De plus, pour éviter tout surcoût, aucun verrou supplémentaire&#xA;n’est maintenu lors de l’affichage de ces données.  Cela veut dire que chaque&#xA;ligne est traitée indépendamment.  Ainsi, bien que cela soit fort peu probable,&#xA;vous pouvez obtenir des données incohérentes dans certaines circonstances,&#xA;comme par exemple un worker paralèlle pointant vers un pid qui est déjà&#xA;déconnecté.&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2020/03/08/nouveau-dans-pg13-leader_pid.html&#34;&gt;Nouveau dans pg13: Colonne leader_pid dans pg_stat_activity&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on March 08, 2020.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2020/03/08/nouveau-dans-pg13-leader_pid.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>pg qualstats 2: Suggestion d&#39;index globale</title>
    <updated>2020-01-06T12:23:29Z</updated>
    <id>tag:rjuju.github.io,2020-01-06:/postgresqlfr/2020/01/06/pg_qualstats-2-suggestion-index-globale.html</id>
    <content type="html">&lt;p&gt;Parvenir à une suggestion d’index de qualité peut être une tâche complexe.&#xA;Cela nécessite à la fois une connaissance des requêtes applicatives et des&#xA;spécificités de la base de données.  Avec le temps de nombreux projets ont&#xA;essayé de résoudre ce problème, l’un d’entre eux étant &lt;a href=&#34;https://powa.readthedocs.io/&#34;&gt;PoWA version&#xA;3&lt;/a&gt;, avec l’aide de &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/pg_qualstats.html&#34;&gt;pg_qualstats&#xA;extension&lt;/a&gt;.&#xA;Cet outil donne de plutôt bonnes suggestions d’index, mais il est nécessaire&#xA;d’installer et configurer PoWA, alors que certains utilisateurs aimeraient&#xA;n’avoir que la suggestion d’index globale.  Pour répondre à ce besoin de&#xA;simplicité, l’algorithme utilisé dans PoWA est maintenant disponible dans&#xA;pg_qualstats version 2, sans avoir besoin d’utiliser des composants&#xA;additionnels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: La fonction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_qualstats_index\_advisor()&lt;/code&gt; a été changée pour retourner&#xA;du &lt;strong&gt;json&lt;/strong&gt; plutôt que du &lt;strong&gt;jsonb&lt;/strong&gt;, afin de conserver la compatibilité avec PostgreSQL&#xA;9.3.  Les requêtes d’exemples sont donc également modifiées pour utiliser&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;json_array_elements()&lt;/code&gt; plutôt que &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;jsonb_array_elements()&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;quest-ce-que-pg_qualstats&#34;&gt;Qu’est-ce que pg_qualstats&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Une manière simple d’expliquer ce qu’est pg_qualstats serait de dire qu’il&#xA;s’agit d’une extension similaire à&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/pgstatstatements.html&#34;&gt;pg_stat_statements&lt;/a&gt;&#xA;mais travaillant au niveaux des prédicats.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cette extension sauvegarde des statistiques utiles pour les clauses &lt;strong&gt;WHERE&lt;/strong&gt;&#xA;et &lt;strong&gt;JOIN&lt;/strong&gt; : à quelle table et quelle colonne un prédicat fait référénce, le&#xA;nombre de fois qu’un prédicat a été utilisé, le nombre d’exécutions de&#xA;l’opérateur sous-jacent, si le prédicat provient d’un parcours d’index ou non,&#xA;la sélectivité, la valeur des constantes et bien plus encore.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il est possible de déduire beaucoup de choses depuis ces informations.  Par&#xA;exemple, si vous examinez les prédicats qui contiennent des références à des&#xA;tables différentes, vous pouvez trouver quelles tables sont jointes ensembles,&#xA;et à quel point les conditions de jointures sont sélectives.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;suggestion-globale-&#34;&gt;Suggestion Globale ?&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Comment je l’ai mentionné, la suggestion d’index globale ajoutée dans&#xA;pg_qualstats 2 utilise la même approche que celle de PoWA, ainsi cet article&#xA;peut servir à décrire le fonctionnement des deux outils.  La seule différence&#xA;est que vous obtiendrez probablement une suggestion de meilleure qualité avec&#xA;PoWA, puisque plus de prédicats seront disponibles, et que vous pourrez&#xA;également choisir sur quel intervalle de temps vous souhaitez effectuer une&#xA;suggestion d’index manquants.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La chose importante à retenir ici est qu’il s’agit d’une suggestion effectuée&#xA;de manière &lt;strong&gt;globale&lt;/strong&gt;, c’est-à-dire en prenant en compte tous les prédicats&#xA;intéressant en même temps.  Cette approche est différente de toutes les autres&#xA;dont j’ai connaissance, qui ne prennent en compte qu’une seule requête à la&#xA;fois.  Selon moi, une approche globale est meilleure, car il est possible de&#xA;réduire le nombre total d’index, en maximisant l’efficacité des index&#xA;multi-colonnes.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;comment-marche-la-suggestion-globale&#34;&gt;Comment marche la suggestion globale&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;La première étape consiste à récupérer tous les prédicats qui pourraient&#xA;bénéficier de nouveaux index.  C’est particulièrement facile à obtenir avec&#xA;pg_qualstats.  En filtrant les prédicats venant d’un parcours séquentiel,&#xA;exécutés de nombreuses fois et qui filtrent de nombreuses lignes (à la fois en&#xA;nombre et en pourcentage), vous obtenez une liste parfaite de prédicats qui&#xA;auraient très probablement besoin d’un index (ou alors dans certains cas une&#xA;liste des requêtes mal écrites).  Voyons regardons par exemple le cas d’une&#xA;applications qui utiliserait ces 4 prédicats:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/global_advisor_1_quals.png&#34;&gt;&lt;img src=&#34;/images/global_advisor_1_quals.png&#34; alt=&#34;Liste de tous les prédicats&#xA;trouvés&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ensuite, il faut construire l’ensemble entier des chemins de toutes les&#xA;prédicats joints par un AND logique, qui contiennent d’autres prédicats, qui&#xA;peuvent être eux-meme également joints par des AND logiques.  En utilisants les&#xA;même 4 prédicats vus précédemments, nous obtenons ces chemins :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/global_advisor_2_graphs.png&#34;&gt;&lt;img src=&#34;/images/global_advisor_2_graphs.png&#34; alt=&#34;Construction de tous les chemins de prédicats&#xA;possibles&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois tous les chemins construits, il suffit d’obtenir le meilleur chemin&#xA;pour trouver le meilleur index à suggérer.  Le classement de ces chemins est&#xA;pour le moment fait en donnant un poids à chaque nœud de chaque chemin qui&#xA;correspond au nombre de prédicats simple qu’il contient, et en additionnant le&#xA;poids pour chaque chemin.  C’est une approche très simple, et qui permet de&#xA;favoriser un nombre minimal d’index qui optimisent le plus de requêtes&#xA;possible.  Avec nos exemple, nous obtenons :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/global_advisor_3_weighted.png&#34;&gt;&lt;img src=&#34;/images/global_advisor_3_weighted.png&#34; alt=&#34;Ajout d&#39;un poids à tous les chemins et choix du score le plus&#xA;haut&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bien évidemment, d’autres approches de classement pourraient être utilisée pour&#xA;prendre en compte d’autres paramètres, et potentiellement obtenir une meilleur&#xA;suggestion.  Par exemple, en prenant en compte également le nombre d’exécution&#xA;ou la sélectivité des prédicats.  Si le ratio de lecture/écriture pour chaque&#xA;table est connu (ce qui est disponible avec l’extension&#xA;&lt;a href=&#34;https://github.com/powa-team/powa-archivist&#34;&gt;powa-archivist&lt;/a&gt;), il serait&#xA;également possible d’adapter le classement pour limiter la suggestion d’index&#xA;pour les tables qui ne sont accédées presque exclusivement en écriture.  Avec&#xA;cet algorithme, ces ajustements seraient relativement simples à faire.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une fois que le meilleur chemin est trouvé, on peut générer l’ordre de création&#xA;de l’index !  Comme l’ordre des colonnes peut être important, l’ordre est&#xA;généré en récupérant les colonnes de chaque nœud par poids croissant.  Avec&#xA;notre exemple, l’index suivant est généré :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Une fois que l’index est trouvé, on supprime simplement les prédicats contenus&#xA;de la liste globale de prédicats et on reprendre de zéro jusqu’à ce qu’il n’y&#xA;ait plus de prédicats.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;un-peu-plus-de-détails-et-mise-en-garde&#34;&gt;Un peu plus de détails et mise en garde&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Bien évidemment, il s’agit ici d’une version simplifiée de l’algorithme de&#xA;suggestion, car d’autres informations sont nécessaires.  Par exemple, la liste&#xA;des prédicats est en réalité ajustée avec les &lt;a href=&#34;https://www.postgresql.org/docs/current/indexes-opclass.html&#34;&gt;classes d’opérateurs et méthode&#xA;d’acces&lt;/a&gt; en&#xA;fonction du type de la colonne et de sont opérateur, afin de s’assurer&#xA;d’obtenir des index valides.  Si plusieurs méthodes d’accès aux index sont&#xA;trouvées pour un même meilleur chemin, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;btree&lt;/code&gt; sera choisi en priorité.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cela nous amène à un autre détail : cette approche est principalement pensée&#xA;pour les index &lt;strong&gt;btree&lt;/strong&gt;, pour lesqules l’ordre des colonnes est critiques.&#xA;D’autres méthodes d’accès ne requièrent pas un ordre spécifique pour les&#xA;colonnes, et pour ces méthodes d’accès il est possible qu’une suggestion plus&#xA;optimale soit possible si l’ordre des colonnes n’était pas pris en compte.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Un autre point important est que les classes d’opérateurs et méthodes d’accès&#xA;ne sont pas gérés en dur mais récupérés à l’exécution en utilisant les&#xA;catalogues locaux.  Par conséquent, vous pouvez obtenir des résultats&#xA;différents (et potentiellement meilleurs) si vous faites en sorte d’avoir&#xA;toutes les classes d’opérateur additionelles disponibles quand vous utilisez la&#xA;suggestion d’index globale.  Cela pourrait être les extensions &lt;strong&gt;btree_gist&lt;/strong&gt;&#xA;et &lt;strong&gt;btree_gist&lt;/strong&gt;, mais également d’autres méthodes d’accès aux index.  Il est&#xA;également possible que certain types / opérateurs n’aient pas de méthode&#xA;d’accès associée dans les catalogues.  Dans ce cas, ces prédicats sont&#xA;retournées séparément dans une liste de prédicats non optimisables&#xA;automatiquement, et pour lequel une analyse manuelle est nécessaire.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Enfin, comme pg_qualstats ne traite pas les prédicats composés d’expressions,&#xA;l’outil ne peut pas suggérer d’index sur des expressions, par exemple en cas&#xA;d’utilisateur de recherche plein texte.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;exemple-dutilisation&#34;&gt;Exemple d’utilisation&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Une simple fonction est fournie, avec des paramètres facultatifs, qui retourne&#xA;une valeur de type json :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;OR&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;REPLACE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FUNCTION&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_qualstats_index_advisor&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;min_filter&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;min_selectivity&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;forbidden_am&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;{}&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;RETURNS&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Les noms de paramètres sont parlants :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;min_filter&lt;/code&gt;: combien de lignes le prédicat doit-il filtrer en moyenne pour&#xA;être pris en compte par la suggestion globale, par défaut &lt;strong&gt;1000&lt;/strong&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;min_selectivity&lt;/code&gt;: quelle doit être la sélectivité moyenne d’un prédicat&#xA;pour qu’il soit pris en compte par la suggestion globale, par défaut&#xA;&lt;strong&gt;30%&lt;/strong&gt; ;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;forbidden_am&lt;/code&gt;: liste des méthodes d’accès aux index à ignorer.  Aucune par&#xA;défaut, bien que pour les version 9.6 et inférieures &lt;strong&gt;les index hash sont&#xA;ignoré en interne&lt;/strong&gt;, puisque ceux-ci ne sont sur que depuis la version 10.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple simple, tirés des tests de non régression de pg_qualstats :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pgqs&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;a&#39;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generate_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id2&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id3&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;INSERT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;INTO&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;line &#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generate_series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_qualstats_reset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;meh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;ILIKE&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;moh&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;COUNT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pgqs&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Et voici ce que la fonction retourne :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json_array_elements&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;pg_qualstats_index_advisor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min_filter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&#39;indexes&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;ORDER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;COLLATE&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;C&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;                               &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;---------------------------------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;CREATE INDEX ON public.adv USING btree (id1)&#34;&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;CREATE INDEX ON public.adv USING btree (val, id1, id2, id3)&#34;&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;CREATE INDEX ON public.pgqs USING btree (id)&#34;&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&#xA;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json_array_elements&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;pg_qualstats_index_advisor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min_filter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&#39;unoptimised&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;ORDER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;COLLATE&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;C&#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;        &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-----------------&lt;/span&gt;&#xA; &lt;span class=&#34;nv&#34;&gt;&#34;adv.val ~~* ?&#34;&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;La &lt;a href=&#34;https://github.com/powa-team/pg_qualstats/&#34;&gt;version 2 de pg_qualstats&lt;/a&gt;&#xA;n’est pas encore disponible en version stable, mais n’hésitez pas à la tester&#xA;et &lt;a href=&#34;https://github.com/powa-team/pg_qualstats/issues&#34;&gt;rapporter tout problème que vous pourriez&#xA;rencontrer&lt;/a&gt; !&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2020/01/06/pg_qualstats-2-suggestion-index-globale.html&#34;&gt;pg qualstats 2: Suggestion d&#39;index globale&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on January 06, 2020.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2020/01/06/pg_qualstats-2-suggestion-index-globale.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>PoWA 4: Nouveau daemon powa-collector</title>
    <updated>2019-12-10T18:54:17Z</updated>
    <id>tag:rjuju.github.io,2019-12-10:/postgresqlfr/2019/12/10/powa-4-nouveau-powa-collector.html</id>
    <content type="html">&lt;p&gt;Cet article fait partie d’une série d’article sur &lt;a href=&#34;http://powa.readthedocs.io/&#34;&gt;la beta de PoWA&#xA;4&lt;/a&gt;, et décrit le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon&#xA;powa-collector&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;nouveau-daemon-powa-collector&#34;&gt;Nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon powa-collector&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Ce daemon remplace le précédent &lt;em&gt;background worker&lt;/em&gt; lorsque le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html&#34;&gt;mode&#xA;remote&lt;/a&gt; est utilisé.&#xA;Il s’agit d’un simple daemon écrit en python, qui s’occupera de toutes les&#xA;étapes nécessaires pour effectuer des &lt;em&gt;snapshots distants&lt;/em&gt;.  Il est &lt;a href=&#34;https://pypi.org/project/powa-collector/&#34;&gt;disponible&#xA;sur pypi&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Comme je l’ai expliqué dans mon &lt;a href=&#34;/postgresql/2019/05/17/powa-4-with-remote-mode-beta-is-available.html&#34;&gt;précédent article introduistant PoWA 4&lt;/a&gt;, ce&#xA;daemon est nécessaire  pour la configuration d’un mode remote, en gardant cette&#xA;architecture à l’esprit :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_remote.svg&#34;&gt;&lt;img src=&#34;/images/powa_4_remote.svg&#34; alt=&#34;Architecture de PoWA 4 en mode distant&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sa configuration est très simple.  Il vous suffit tout simplement de renommer&#xA;le fichier &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa-collector.conf.sample&lt;/code&gt; fourni, et d’adapter &lt;a href=&#34;https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING&#34;&gt;l’URI de&#xA;connexion&lt;/a&gt;&#xA;pour décrire comment se connecter sur votre &lt;em&gt;serveur repository&lt;/em&gt; dédié, et&#xA;c’est fini.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une configuration typique devrait ressembler à :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-conf&#34; data-lang=&#34;conf&#34;&gt;{&#xA;    &lt;span class=&#34;s2&#34;&gt;&#34;repository&#34;&lt;/span&gt;: {&#xA;        &lt;span class=&#34;s2&#34;&gt;&#34;dsn&#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&#34;postgresql://powa_user@server_dns:5432/powa&#34;&lt;/span&gt;,&#xA;    },&#xA;    &lt;span class=&#34;s2&#34;&gt;&#34;debug&#34;&lt;/span&gt;: &lt;span class=&#34;n&#34;&gt;true&lt;/span&gt;&#xA;}&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;La liste des &lt;em&gt;serveur distants&lt;/em&gt;, leur configuration ainsi que tout le reste qui&#xA;est nécessaire pour le bon fonctionnement sera automatiquement récupéré depuis&#xA;le &lt;em&gt;serveur repository&lt;/em&gt; que vous ave déjà configuré.  Une fois démarré, il&#xA;démarrera un thread dédié par &lt;em&gt;serveur distant&lt;/em&gt; déclaré, et maintiendra une&#xA;&lt;strong&gt;connexion persistente&lt;/strong&gt; sur ce &lt;em&gt;serveur distant&lt;/em&gt;.  Chaque thread effectuera&#xA;un &lt;em&gt;snapshot distant&lt;/em&gt;, exportant les données sur le &lt;em&gt;serveur repository&lt;/em&gt; en&#xA;utilisant les nouvelles &lt;em&gt;fonctions sources&lt;/em&gt;.  Chaque thread ouvrira et fermera&#xA;une connexion sur le &lt;em&gt;serveur repository&lt;/em&gt; lors de l’exécution du &lt;em&gt;snapshot&#xA;distant&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bien évidemment, ce daemon a besoin de pouvoir se connecter sur tous les&#xA;&lt;em&gt;serveurs distants&lt;/em&gt; déclarés ainsi que le &lt;em&gt;serveur repository&lt;/em&gt;.  La table&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_servers&lt;/code&gt;, qui stocke la liste des &lt;em&gt;serveurs distants&lt;/em&gt;, a un champ pour&#xA;stocker les nom d’utilisateur et mot de passe pour se connecter aux &lt;em&gt;serveur&#xA;distants&lt;/em&gt;.  Stocker un mot de passe en clair dans cette table est une hérésie,&#xA;si l’on considère l’aspect sécurité.  Ainsi, comme indiqué dans la&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/security.html#connection-on-remote-servers&#34;&gt;section sécurité de&#xA;PoWA&lt;/a&gt;,&#xA;vous pouve stocker un mot de passe NULL et &lt;a href=&#34;https://www.postgresql.org/docs/current/auth-methods.html&#34;&gt;utiliser à la place n’importe&#xA;laquelle des autres méthodes d’authentification supportées par la&#xA;libpq&lt;/a&gt; (fichier&#xA;.pgpass, certificat…).  C’est très fortement recommandé pour toute&#xA;installation sérieuse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La connexion persistente sur le &lt;em&gt;serveur repository&lt;/em&gt; est utilisée pour&#xA;superviser la daemon :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;pour vérifier  que le daemon est bien démarré&lt;/li&gt;&#xA;  &lt;li&gt;pour communiquer au travers de l’UI en utilisant un &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/protocol.html&#34;&gt;protocole simple&lt;/a&gt;&#xA;afin d’effectuer des actions diverses (recharger la configuration, vérifier&#xA;le status d’un thread dédié à un &lt;em&gt;serveur distant&lt;/em&gt;…)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Il est à noter que vous pouvez également demander au daemon de recharger sa&#xA;configuration en envoyant un SIGHUP au processus du daemon.  Un rechargement&#xA;est nécessaire pour toute modification effectuée sur la liste des serveurs&#xA;distants (ajout ou suppression d’un &lt;em&gt;serveur distant&lt;/em&gt;, ou mise à jour d’un&#xA;existant).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez également noter que, par choix,&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;powa-collector&lt;/a&gt;&#xA;n’effectuera pas de &lt;em&gt;snapshot local&lt;/em&gt;.  Si vous voulez utiliser PoWA pour le&#xA;&lt;em&gt;serveur repository&lt;/em&gt;, il vous faudra activer le &lt;em&gt;background worker&lt;/em&gt; original.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;nouvelle-page-de-configuration&#34;&gt;Nouvelle page de configuration&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;La page de configuration est maintenant modifiée pour donner toutes les&#xA;informations nécessaires sur le status du background worker, le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;powa-collector&#xA;daemon&lt;/a&gt;&#xA;(incluant tous ses threads dédiés) ainsi que la liste des &lt;em&gt;serveurs distants&lt;/em&gt;&#xA;déclarés.  Voici un exemple de cette nouvelle page racine de configuration :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_configuration_page.png&#34;&gt;&lt;img src=&#34;/images/powa_4_configuration_page.png&#34; alt=&#34;Nouvelle page de&#xA;configuration&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon&#xA;powa-collector&lt;/a&gt;&#xA;est utilisé, le status de chaque serveur distant sera récupéré en utilisant le&#xA;protocole de communication.  Si le collecteur rencontre des erreurs (lors de la&#xA;connexion à un &lt;em&gt;serveur distant&lt;/em&gt;, durant un &lt;em&gt;snapshot&lt;/em&gt; par exemple), celles-ci&#xA;seront également affichées ici.  À noter également que ces erreurs seront&#xA;également affichées en haut de chaque page de toutes les pages de l’UI, afin&#xA;d’être sûr de ne pas les rater.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;De plus, la section configuration a maintenant une hiérarchie, et vous pourrez&#xA;voir la liste des extensions ainsi que la configuration actuelle de PostgreSQL&#xA;pour le serveur &lt;strong&gt;local&lt;/strong&gt; ou &lt;strong&gt;distant&lt;/strong&gt; en cliquant sur le serveur de votre&#xA;choix!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il y a également un nouveau bouton &lt;strong&gt;Reload collector&lt;/strong&gt; sur le bandeau&#xA;d’en-tête qui, comme on pourrait s’y attendre, demandera au collecteur de&#xA;recharger sa configuration.  Cela peut être utile si vous avez déclarés de&#xA;nouveaux serveurs mais n’ave pas d’accès au serveur sur lequel le collecteur&#xA;s’exécute.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette article est le dernier de la séurie concernant la nouvelle version de&#xA;PoWA.  Il est toujours en beta, n’hésitez donc pas à le tester, &lt;a href=&#34;https://powa.readthedocs.io/en/latest/support.html#support&#34;&gt;rapporter&#xA;tout bug rencontré&lt;/a&gt;&#xA;ou donner tout autre retour!&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/12/10/powa-4-nouveau-powa-collector.html&#34;&gt;PoWA 4: Nouveau daemon powa-collector&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on December 10, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/12/10/powa-4-nouveau-powa-collector.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>PoWA 4: nouveautés dans powa-archivist !</title>
    <updated>2019-06-05T14:26:17Z</updated>
    <id>tag:rjuju.github.io,2019-06-05:/postgresqlfr/2019/06/05/powa-4-nouveaute-dans-powa-archivist.html</id>
    <content type="html">&lt;p&gt;Cet article fait partie d’une série d’article sur &lt;a href=&#34;http://powa.readthedocs.io/&#34;&gt;la beta de PoWA&#xA;4&lt;/a&gt;, et décrit les changements présents dans&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/index.html&#34;&gt;powa-archivist&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour plus d’information sur cette version 4, vous pouvez consulter &lt;a href=&#34;/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html&#34;&gt;l’article&#xA;de présentation général&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;aperçu-rapide&#34;&gt;Aperçu rapide&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Tout d’abord, il faut savoir qu’il n’y a pas d’upgrade possible depuis la v3&#xA;vers la v4, il est donc nécessaire d’effectuer un &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;DROP EXTENSION powa&lt;/code&gt; si vous&#xA;utilisiez déjà PoWA sur vos serveurs.  Cela est du au fait que la v4 apporte&#xA;&lt;strong&gt;de très nombreux&lt;/strong&gt; changements dans la partie SQL de l’extension, ce qui en&#xA;fait le changement le plus significatif dans la suite PoWA pour cette nouvelle&#xA;version.  Au moment où j’écris cet article, la quantité de changements apportés&#xA;dans cette extension est :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-diff&#34; data-lang=&#34;diff&#34;&gt; CHANGELOG.md       |   14 +&#xA; powa--4.0.0dev.sql | 2075 +++++++++++++++++++++-------&#xA; powa.c             |   44 +-&#xA; 3 files changed, 1629 insertions(+), 504 deletions(-)&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;L’absence d’upgrade ne devrait pas être un problème en pratique.  PoWA est un&#xA;outil pour analyser les performances, il est fait pour avoir des données avec&#xA;une grande précision mais un historique très limité.  Si vous cherchez une&#xA;solution de supervision généraliste pour conserver des mois de données, PoWA&#xA;n’est définitivement pas l’outil qu’il vous faut.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;configurer-la-liste-des-serveurs-distants&#34;&gt;Configurer la liste des &lt;em&gt;serveurs distants&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;En ce qui concerne les changements à proprement parler, le premier petit&#xA;changement est que le &lt;a href=&#34;https://www.postgresql.org/docs/current/bgworker.html&#34;&gt;background&#xA;worker&lt;/a&gt; n’est plus&#xA;nécessaire pour le fonctionnement de powa-archivist, car il n’est pas utilisé&#xA;pour le mode distant.  Cela signifie qu’un redémarrage de PostgreSQL n’est plus&#xA;nécessaire pour installer PoWA.  Bien évidemment, un redémarrage est toujours&#xA;nécessaire si vous souhaitez utiliser le mode local, en utilisant le background&#xA;worker, or si vous voulez installer des extensions additionelles qui&#xA;nécessitent elles-même un redémarrage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ensuite, comme PoWA requiert un peu de configuration (fréquence des snapshot,&#xA;rétention des données et ainsi de suite), certaines nouvelles tables sont&#xA;ajouter pour permettre de configurer tout ça.  La nouvelle table &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_servers&lt;/code&gt;&#xA;stocke la configuration de toutes les instances distantes dont les données&#xA;doivent être stockées sur cette instance.  Cette &lt;em&gt;instance PoWA locale&lt;/em&gt; est&#xA;appelée un &lt;strong&gt;serveur repository&lt;/strong&gt; (qui devrait typiquement être dédiée à&#xA;stocker des données PoWA), en opposition aux &lt;strong&gt;instances distantes&lt;/strong&gt; qui sont&#xA;les instances que vous voulez monitorer.  Le contenu de cette table est tout ce&#xA;qu’il y a de plus simple :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powa_servers&lt;/span&gt;&#xA;                              &lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_servers&#34;&lt;/span&gt;&#xA;  &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;   &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;                 &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-----------+----------+-----------+----------+------------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;            &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nextval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&#39;powa_servers_id_seq&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;regclass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;hostname&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;alias&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;port&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;username&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;password&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;dbname&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;frequency&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;300&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;powa_coalesce&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;retention&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interval&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;1 day&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;interval&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Si vous avez déjà utilisé PoWA, vous devriez reconnaître la plupart des options&#xA;de configuration qui sont maintenant stockées ici.  Les nouvelles options sont&#xA;utilisées pour décrire comment se connecter aux &lt;em&gt;instances distances&lt;/em&gt;, et&#xA;peuvent fournir un alias à afficher sur l’UI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Vous avez également probablement remarqué une colonne &lt;strong&gt;password&lt;/strong&gt;.  Stocker un&#xA;mot de passe en clair dans cette table est une hérésie pour n’importe qui&#xA;désirant un minimum de sécurité.  Ainsi, comme mentionné dans la &lt;a href=&#34;https://powa.readthedocs.io/en/latest/security.html#connection-on-remote-servers&#34;&gt;section&#xA;sécurité de la documentation de PoWA&#xA;&lt;/a&gt;,&#xA;vous pouvez stocker NULL pour le champ password et à la place utiliser&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/auth-methods.html&#34;&gt;n’importe laquelle des autres méthodes d’authentification supportée par la&#xA;libpq&lt;/a&gt;&#xA;(fichier .pgpass, certificat…).  Une authentification plus sécurisée est&#xA;chaudement recommandée pour toute installation sérieuse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Une autre table, la table &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_snapshot_metas&lt;/code&gt;, est également ajoutée pour&#xA;stocker quelques métadonnées concernant les informations de snapshot pour&#xA;chaque &lt;em&gt;serveur distant&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;                                   &lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_snapshot_metas&#34;&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;                &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;--------------+--------------------------+-----------+----------+---------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;                  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;coalesce_seq&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;bigint&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;snapts&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;-infinity&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;aggts&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;-infinity&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;purgets&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&#39;-infinity&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;errors&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Il s’agit tout simplement d’un compteur pour compter le nombre de snapshots&#xA;effectués, un timestamp pour chaque type d’événement survenu (snapshot,&#xA;aggrégation et purge) et un tableau de chaîne de caractères pour stocker toute&#xA;erreur survenant durant le snapshot, afin que l’UI pour l’afficher.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;api-sql-pour-configurer-les-serveurs-distants&#34;&gt;API SQL pour configurer les &lt;em&gt;serveurs distants&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Bien que ces tables soient très simples, une &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html#configure-powa-and-stats-extensions-on-each-remote-server&#34;&gt;API SQL basique est disponible&#xA;pour déclarer de nouveaux serveurs et les&#xA;configurer&lt;/a&gt;.&#xA;6 fonctions de bases sont disponibles :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_register_server()&lt;/code&gt;, pour déclarer un nouveau &lt;em&gt;servuer distant&lt;/em&gt;, ainsi&#xA;que la liste des extensions qui y sont disponibles&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_configure_server()&lt;/code&gt; pour mettre à jour un des paramètres pour le&#xA;&lt;em&gt;serveur distant&lt;/em&gt; spécifié (en utilisant un paramètre JSON, où la clé est&#xA;le nom du paramètre à changer et la valeur la nouvelle valeur à utiliser)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_deactivate_server()&lt;/code&gt; pour désactiver les snapshots pour le &lt;em&gt;serveur&#xA;distant&lt;/em&gt; spécifiqué (ce qui concrètement positionnera le paramètre&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;frequency&lt;/code&gt; à &lt;strong&gt;-1&lt;/strong&gt;)&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_delete_and_purge_server()&lt;/code&gt; pour supprimer le &lt;em&gt;serveur distant&lt;/em&gt;&#xA;spécifié de la liste des serveurs et supprimer toutes les données associées&#xA;aux snapshots&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_activate_extension()&lt;/code&gt;, pour déclarer qu’une nouvelle extension est&#xA;disponible sur le &lt;em&gt;serveur distant&lt;/em&gt; spécifié&lt;/li&gt;&#xA;  &lt;li&gt;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_deactivate_extension()&lt;/code&gt;, pour spécifier qu’une extension n’est plus&#xA;disponible sur le &lt;em&gt;serveur distant&lt;/em&gt; spécifié&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Toute action plus compliquée que ça devra être effectuée en utilisant des&#xA;requêtes SQL.  Heureusement, il ne devrait pas y avoir beaucoup d’autres&#xA;besoins, et les tables sont vraiment très simple donc cela ne devrait pas poser&#xA;de soucis.  &lt;a href=&#34;https://github.com/powa-team/powa-archivist/issues&#34;&gt;N’hésitez cependant pas à demander de nouvelles&#xA;fonctions&lt;/a&gt; si vous aviez&#xA;d’autres besoins.  Veuillez également noter que l’UI ne vous permet pas&#xA;d’appeler ces fonctions, puisque celle-ci est pour le moment &lt;strong&gt;entièrement en&#xA;lecture seule&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;effectuer-des-snapshots-distants&#34;&gt;Effectuer des &lt;em&gt;snapshots distants&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Puisque les métriques sont maintenant stockées sur une instance PostgreSQL&#xA;différente, nous avons énormément changé la façon dont les &lt;em&gt;snapshots&lt;/em&gt;&#xA;(récupérer les données fournies par une &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/index.html&#34;&gt;extensions&#xA;statistique&lt;/a&gt;&#xA;et les stockées dans le catalogue PoWA &lt;a href=&#34;/postgresqlfr/2019/04/06/minimiser-le-surcout-de-stockage-par-ligne.html&#34;&gt;de manière à optimiser le stockage&lt;/a&gt;) sont&#xA;effectués.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La liste de toutes les extensions statistiques, ou &lt;em&gt;sources de données&lt;/em&gt;, qui&#xA;sont disponibles sur un &lt;strong&gt;serveur&lt;/strong&gt; (soit &lt;em&gt;distant&lt;/em&gt; soit &lt;em&gt;local&lt;/em&gt;) et pour&#xA;lesquelles un &lt;em&gt;snapshot&lt;/em&gt; devrait être effectué est stockée dans une table&#xA;appelée &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_functions&lt;/code&gt;:&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;               &lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_functions&#34;&lt;/span&gt;&#xA;     &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;----------------+---------+-----------+----------+---------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;module&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;operation&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;function_name&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;query_source&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;added_manually&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;boolean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;true&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;enabled&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;boolean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;true&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;priority&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;numeric&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Un nouveau champ &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;query_source&lt;/code&gt; a été rajouté.  Celui-ci fournit le nom de la&#xA;&lt;em&gt;fonction source&lt;/em&gt;, nécessaire pour la compatibilité d’une &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/index.html&#34;&gt;extension&#xA;statistique&lt;/a&gt;&#xA;avec les snapshots distants.  Cette fonction est utilisée pour exporter les&#xA;compteurs fournis par cette extension sur un serveur différent, dans une &lt;em&gt;table&#xA;transitoire&lt;/em&gt; dédiée.  La fonction de &lt;em&gt;snapshot&lt;/em&gt; effectuera alors le &lt;em&gt;snapshot&lt;/em&gt;&#xA;en utilisant automatiquement ces données exportées plutôt que celles fournies&#xA;par l’extension statististique locale quand le mode distant est utilisé.  Il&#xA;est à noter que l’export de ces compteurs ainsi que le snapshot distant est&#xA;effectué automatiquement par le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon&#xA;powa-collector&lt;/a&gt;&#xA;que je présenterai dans un autre article.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple montant comment PoWA effectue un &lt;em&gt;snapshot distant&lt;/em&gt; d’une&#xA;liste de base données.  Comme vous allez le voir, c’est très simple ce qui&#xA;signifie qu’il est également très simple d’ajouter cette même compatibilité&#xA;pour une nouvelle extension statistique.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La &lt;em&gt;table transitoire&lt;/em&gt;:&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;   &lt;span class=&#34;n&#34;&gt;Unlogged&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;public.powa_databases_src_tmp&#34;&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;---------+---------+-----------+----------+---------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Pour de meilleurs performances, toutes les &lt;em&gt;tables transitoires&lt;/em&gt; sont &lt;strong&gt;non&#xA;journalisées (unlogged)&lt;/strong&gt;, puisque leur contenu n’est nécessaire que durant un&#xA;&lt;em&gt;snapshot&lt;/em&gt; et sont supprimées juste après.  Dans cet examlple, la &lt;em&gt;table&#xA;transitoire&lt;/em&gt; ne stocke que l’identifiant du serveur distant correspondant à ces&#xA;données, l’oid ainsi que le nom de chacune des bases de données présentes sur&#xA;le &lt;em&gt;serveur distant&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Et la &lt;em&gt;fonction source&lt;/em&gt; :&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;OR&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;REPLACE&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FUNCTION&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;powa_databases_src&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_srvid&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;OUT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;OUT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;RETURNS&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SETOF&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;record&lt;/span&gt;&#xA; &lt;span class=&#34;k&#34;&gt;LANGUAGE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plpgsql&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;BEGIN&lt;/span&gt;&#xA;    &lt;span class=&#34;n&#34;&gt;IF&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_srvid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;THEN&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;RETURN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_database&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;ELSE&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;RETURN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;QUERY&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powa_databases_src_tmp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;srvid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;_srvid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;    &lt;span class=&#34;k&#34;&gt;END&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IF&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;k&#34;&gt;END&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;Cette fonction retourne simplement le contenu de &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_database&lt;/code&gt; si les données&#xA;locales sont demandées (l’identifiant de serveur &lt;strong&gt;0&lt;/strong&gt; est toujours le serveur&#xA;local), ou alors le contenu de la &lt;em&gt;table transitoire&lt;/em&gt; pour le serveur distant&#xA;spécifié.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La &lt;em&gt;fonction de snapshot&lt;/em&gt; peut alors facilement effectuer n’importe quel&#xA;traitement avec ces données pour le &lt;em&gt;serveur distant&lt;/em&gt; voulu.  Dans le cas de la&#xA;fonction &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;powa_databases_snapshot()&lt;/code&gt;, il s’agit simplement de synchroniser la&#xA;liste des bases de données, et de stocker le timestamp de suppression si une&#xA;base de données qui existait précédemment n’est plus listée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour plus de détails, vous pouvez consulter la documentation concernant&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/development.html&#34;&gt;l’ajout d’une source de données dans&#xA;PoWA&lt;/a&gt;,&#xA;qui a été mise à jour pour les spécificités de la version 4.&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/06/05/powa-4-nouveaute-dans-powa-archivist.html&#34;&gt;PoWA 4: nouveautés dans powa-archivist !&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on June 05, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/06/05/powa-4-nouveaute-dans-powa-archivist.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>PoWA 4 apporte un mode remote, disponible en beta !</title>
    <updated>2019-05-17T11:04:17Z</updated>
    <id>tag:rjuju.github.io,2019-05-17:/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html</id>
    <content type="html">&lt;p&gt;&lt;a href=&#34;http://powa.readthedocs.io/&#34;&gt;PoWA 4&lt;/a&gt; est disponible en beta.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;nouveau-mode-remote-&#34;&gt;Nouveau mode remote !&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html&#34;&gt;nouveau mode remote&lt;/a&gt;&#xA;est la plus grosse fonctionnalité ajoutée dans PoWA 4, bien qu’il y ait eu&#xA;d’autres améliorations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Je vais décrire ici ce que ce nouveau mode implique ainsi que ce qui a changé&#xA;sur l’&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-web/index.html&#34;&gt;UI&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Si de plus amples détails sur le reste des changements apportés dans PoWA 4&#xA;vous intéresse, je publierai bientôt d’autres articles sur le sujet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour les plus pressés, n’hésitez pas à aller directement sur la &lt;a href=&#34;https://dev-powa.anayrat.info/&#34;&gt;démo v4 de&#xA;PoWA&lt;/a&gt;, très gentiment hébergée par &lt;a href=&#34;http://blog.anayrat.info/&#34;&gt;Adrien&#xA;Nayrat&lt;/a&gt;.  Aucun authentification n’est requise,&#xA;cliquez simplement sur “Login”.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;pourquoi-un-mode-remote-est-il-important&#34;&gt;Pourquoi un mode remote est-il important&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette fonctionnalité a probablement été la plus fréquemment demandée depuis que&#xA;PoWA a été publié, en 2014.  Et c’est pour de bonnes raisons, car un mode local&#xA;a quelques inconvénients.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tout d’abord, voyons comment se présentait l’architecture avec les versions 3&#xA;et antérieures.  Imaginons une instance contenant 2 bases de données (db1 et&#xA;db2), ainsi qu’&lt;strong&gt;une base de données dédiée à PoWA&lt;/strong&gt;.  Cette base de données&#xA;dédiée contient à la fois les &lt;em&gt;extensions statistiques&lt;/em&gt; nécessaires pour&#xA;récupérer compteurs de performances actuels ainsi que pour &lt;strong&gt;les stocker&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_local.svg&#34;&gt;&lt;img src=&#34;/images/powa_4_local.svg&#34; alt=&#34;Architecture en mode local&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Un &lt;em&gt;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/configuration.html#background-worker-configuration&#34;&gt;background&#xA;worker&lt;/a&gt;&lt;/em&gt;&#xA;est démarré par PoWA, qui est responsable d’effectuer des &lt;em&gt;snapshots&lt;/em&gt; et de les&#xA;stocker dans la base powa dédiée à intervalle réguliers.  Ensuite, en utilisant&#xA;powa-web, vous pouvez consulter l’activité de n’importe laquelle des bases de&#xA;données &lt;strong&gt;locales&lt;/strong&gt; en effectuant des requêtes sur les données stockées dans la&#xA;base dédié, et potentiellement en se connectant sur l’une des autres bases de&#xA;données locales lorsque les données complètes sont nécessaires, par exemple&#xA;lorsque l’outil de suggestion d’index est utilisé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Avec la version 4, l’architecture avec une configuration distante change de&#xA;manière significative:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_remote.svg&#34;&gt;&lt;img src=&#34;/images/powa_4_remote.svg&#34; alt=&#34;Architecture en mode distant&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Vous pouvez voir qu’une base de donnée powa dédiée est toujours nécessaire,&#xA;mais &lt;strong&gt;uniquement pour les extensions statistiques&lt;/strong&gt;.  Les données sont&#xA;maintenant stockées sur une instance différente.  Ensuite, le &lt;em&gt;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-archivist/configuration.html#background-worker-configuration&#34;&gt;background&#xA;worker&lt;/a&gt;&lt;/em&gt;&#xA;est remplacé par un &lt;strong&gt;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;nouveau daemon&#xA;collecteur&lt;/a&gt;&lt;/strong&gt;,&#xA;qui lit les métriques de performance depuis les &lt;em&gt;serveurs distants&lt;/em&gt;, et les&#xA;stocke sur le &lt;em&gt;serveur repository&lt;/em&gt; dédié.  Powa-web pourra présenter les&#xA;données en se connectant sur le &lt;em&gt;serveur repository&lt;/em&gt;, ainsi que sur les&#xA;&lt;strong&gt;serveurs distants&lt;/strong&gt; lorsque des données complètes sont nécessaires.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;En résumé, avec le nouveau mode distant ajouté dans cette version 4&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;un redémarrage de PostgreSQL n’est plus nécessaire pour installer&#xA;powa-archivist&lt;/li&gt;&#xA;  &lt;li&gt;il n’y a plus de surcoût du au fait de stocker et requêter les données sur&#xA;le même serveur PostgreSQL que vos serveurs de productions (il y a toujours&#xA;certaines partie de l’UI qui nécessitent d’effectuer des requêtes sur le&#xA;serveur d’origine, par exemple pour montrer des plans avec EXPLAIN, mais le&#xA;surcoût est négligeable)&lt;/li&gt;&#xA;  &lt;li&gt;il est maintenant possible d’utiliser PoWA sur un &lt;strong&gt;serveur en&#xA;hot-standby&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;L’UI vous accueillera donc maintenant avec une page initiale afin de choisir&#xA;lequel des serveurs stockés sur la base de données cible vous voulez&#xA;travailler :&#xA;&lt;a href=&#34;/images/powa_4_all_servers.png&#34;&gt;&lt;img src=&#34;/images/powa_4_all_servers.png&#34; alt=&#34;Choix des serveurs&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La principale raison pour laquelle il a fallu tellement de temps pour apporter&#xA;ce mode distant est parce que cela apporte beaucoup de complexité, nécessitant&#xA;une réécriture majeure de PoWA.  Nous voulions également ajouter d’abord&#xA;d’autres fonctionnalités, comme la &lt;strong&gt;suggestion globale d’index&lt;/strong&gt;, avec une&#xA;&lt;strong&gt;validation grâce à &lt;a href=&#34;http://hypopg.readthedocs.io/&#34;&gt;hypopg&lt;/a&gt;&lt;/strong&gt; introduit avec&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/releases/v3.0.0.html&#34;&gt;PoWA 3&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;changements-dans-powa-web&#34;&gt;Changements dans &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-web/index.html&#34;&gt;powa-web&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;L’&lt;em&gt;interface graphique&lt;/em&gt; est le composant qui a le plus de changements visibles&#xA;dans cette version 4.  Voici les plus changements les plus importants.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;compatibilité-avec-le-mode-distant&#34;&gt;Compatibilité avec le mode distant&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Le changement le plus important est bien évidemment le support pour le &lt;a href=&#34;https://powa.readthedocs.io/en/latest/remote_setup.html&#34;&gt;nouveau&#xA;mode remote&lt;/a&gt;.  En&#xA;conséquence, la première page affichée est maintenant une page de &lt;strong&gt;sélection&#xA;de serveur&lt;/strong&gt;, affichant tous les &lt;em&gt;serveurs distants&lt;/em&gt; enregistrés.  Après avoir&#xA;choisi le &lt;em&gt;serveur distant&lt;/em&gt; voulu (ou le &lt;em&gt;serveur local&lt;/em&gt; si vous n’utilisez pas&#xA;le mode distant), toutes les autres pages seront similaires à celles&#xA;disponibles jusqu’à la version 3, mais afficheront les données pour un &lt;em&gt;serveur&#xA;distant&lt;/em&gt; spécifique uniquement, et bien entendu en récupérant les données&#xA;depuis la &lt;strong&gt;base de données repository&lt;/strong&gt;, avec en plus de nouvelles&#xA;informations décrites ci-dessous.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez notez que puisque les données sont maintenant stockées sur un &lt;em&gt;serveur&#xA;repository&lt;/em&gt; dédié quand le mode remote est utilisé, la majorité de l’UI est&#xA;utilisable sans se connecter au &lt;em&gt;serveur distant&lt;/em&gt; sélectionné.  Toutefois,&#xA;powa-web nécessite toujours de pouvoir se connecter sur le &lt;em&gt;serveur distant&lt;/em&gt;&#xA;quand les données originales sont nécessaires (par exemple, pour la suggestion&#xA;d’index ou pour montrer des plans avec &lt;strong&gt;EXPLAIN&lt;/strong&gt;).  Les &lt;a href=&#34;https://powa.readthedocs.io/en/latest/security.html#connection-on-remote-servers&#34;&gt;mêmes considérations&#xA;et possibilités concernant&#xA;l’authentification&lt;/a&gt;&#xA;que pour le nouveau &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/powa-collector/index.html&#34;&gt;daemon powa-collector&#xA;&lt;/a&gt;&#xA;(qui sera décrit dans un prochain article) s’appliquent ici.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;pg_track_settings-support&#34;&gt;&lt;a href=&#34;https://github.com/rjuju/pg_track_settings/&#34;&gt;pg_track_settings&lt;/a&gt; support&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Quand cette extension est correctement configurée, un nouveau widget timeline&#xA;apparaîtra, placé entre chaque graph et son aperçu, affichant différents types&#xA;de changements enregistrés si ceux-ci ont été détectés sur l’intervalle de&#xA;temps sélectionné.  Sur les pages par base de données et par requête, la liste&#xA;sera également filtrée en fonction de la base de données sélectionnée.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;La même timeline sera affichée sur chacun des graphs de chacune des pages, afin&#xA;de facilement vérifier si ces changements ont eu un impact visible en utilisant&#xA;les différents graphs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez noter que les détails des changements sont affichés au survol de la&#xA;souris.  Vous pouvez également cliquer sur n’importe lequel des événements de&#xA;la timeline pour figer l’affichage, et tracer une ligne verticale sur le graph&#xA;associé.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple d’un tel changement de configuration en action :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/pg_track_settings_powa4.png&#34;&gt;&lt;img src=&#34;/images/pg_track_settings_powa4.png&#34; alt=&#34;Changements de configuration détectés&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Veuillez également noter qu’il est nécessaire d’avoir au minimum la version&#xA;2.0.0 de &lt;a href=&#34;https://github.com/rjuju/pg_track_settings/&#34;&gt;pg_track_settings&lt;/a&gt;, et&#xA;que l’extension doit être installée &lt;strong&gt;à la fois sur les &lt;em&gt;serveurs distants&lt;/em&gt;&#xA;ainsi que sur le &lt;em&gt;serveur repository&lt;/em&gt;.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;nouveaux-graphs-disponibles&#34;&gt;Nouveaux graphs disponibles&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Quand&#xA;&lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/pg_stat_kcache.html&#34;&gt;pg_stat_kcache&lt;/a&gt;&#xA;est configuré, ses informations n’étaient auparavant affichées que sur la page&#xA;par requête.  Les informations sont maintenant également affichées sur les&#xA;pages par serveur et par base, dans deux nouveaux graphs :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;dans le graph &lt;strong&gt;Block Access&lt;/strong&gt;, où les métriques &lt;strong&gt;OS cache&lt;/strong&gt; et &lt;strong&gt;disk&#xA;read&lt;/strong&gt; remplaceront la métrique &lt;strong&gt;read&lt;/strong&gt;&lt;/li&gt;&#xA;  &lt;li&gt;dans un nouveau graph &lt;strong&gt;System Resources&lt;/strong&gt; (qui est également ajouté dans&#xA;la page &lt;em&gt;par requête&lt;/em&gt;), montrant les &lt;a href=&#34;/postgresql/2018/07/17/pg_stat_kcache-2-1-is-out.html&#34;&gt;metrics ajoutées dans pg_stat_kcache&#xA;2.1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Voici un example de ce nouveau graph &lt;strong&gt;System Resources&lt;/strong&gt; :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/pg_stat_kcache_system_resources_powa4.png&#34;&gt;&lt;img src=&#34;/images/pg_stat_kcache_system_resources_powa4.png&#34; alt=&#34;Ressources système&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Il y avait également un graph &lt;strong&gt;Wait Events&lt;/strong&gt; (disponible quand &lt;a href=&#34;https://powa.readthedocs.io/en/v4/components/stats_extensions/pg_wait_sampling.html&#34;&gt;l’extension&#xA;pg_wait_sampling&lt;/a&gt;&#xA;est configuée) disponible uniquement sur la page par requête.  Ce graph est&#xA;maintenant disponible sur les pages par serveur et par base également.&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;documentation-des-métriques-et-liens-vers-la-documentation&#34;&gt;Documentation des métriques et liens vers la documentation&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Certaines métriques affichées sur l’interface sont assez parlante, mais&#xA;certaines autres peuvent être un peu obscures.  Jusqu’à maintenant, il n’y&#xA;avait malheureusement aucune documentation pour les métriques.  Le problème est&#xA;maintenant réglé, et tous les graphs ont une &lt;em&gt;icône d’information&lt;/em&gt;, qui&#xA;affichent une description des métriques utilisée dans le graph au survol de la&#xA;souris.  Certains graphs incluent également un lien vers la &lt;a href=&#34;https://powa.readthedocs.io/en/latest/components/stats_extensions/index.html&#34;&gt;documentation PoWA&#xA;de extension&#xA;statistiques&lt;/a&gt;&#xA;pour les utilisateurs qui désirent en apprendre plus à leur sujet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Voici un exemple :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;/images/powa_4_metrics_doc.png&#34;&gt;&lt;img src=&#34;/images/powa_4_metrics_doc.png&#34; alt=&#34;Documentation des métriques&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;et-des-correctifs-de-bugs-divers&#34;&gt;Et des correctifs de bugs divers&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Certains problèmes de longues dates ont également été rapportés :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;  &lt;li&gt;la boîte affichée au survol d’un graph montant les valeurs des métriques&#xA;avait une position verticale incorrecte&lt;/li&gt;&#xA;  &lt;li&gt;la sélection temporelle en utilisant l’aperçu des graphs ne montrait pas un&#xA;aperçu correct après avoir appliqué la sélection&lt;/li&gt;&#xA;  &lt;li&gt;les erreurs lors de la création d’index hypothétiques ou dans certains cas&#xA;leur affichage n’était pas correctement gérés sur plusieurs pages&lt;/li&gt;&#xA;  &lt;li&gt;les filtres des tableaux n’était pas réappliqués quand l’intervalle de&#xA;temps sélectionné était changé&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Si un de ces problèmes vous a un jour posé problème, vous serez ravi&#xA;d’apprendre qu’ils sont maintenant tous corrigés !&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cette 4ème version de PoWA représente un temps de développement très important,&#xA;de nombreuses améliorations sur la documentation et beaucoup de tests.  Nous&#xA;somme maintenant assez satisfaits, mais il est possible que nous ayons ratés&#xA;certains bugs.  Si vous vous intéressez à ce projet, j’espère que vous&#xA;essaierez de tester cette beta, et si besoin n’hésitez pas à &lt;a href=&#34;https://powa.readthedocs.io/en/latest/support.html#support&#34;&gt;nous remonter un&#xA;bug&lt;/a&gt;!&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html&#34;&gt;PoWA 4 apporte un mode remote, disponible en beta !&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on May 17, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/05/17/powa-4-avec-mode-remote-disponible-en-beta.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>Nouveauté pg12: Statistiques sur les erreurs de checkums</title>
    <updated>2019-04-18T11:02:26Z</updated>
    <id>tag:rjuju.github.io,2019-04-18:/postgresqlfr/2019/04/18/nouveau-dans-pg12-statistiques-erreurs-checksums.html</id>
    <content type="html">&lt;h3 id=&#34;data-checksums&#34;&gt;Data checksums&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Ajoutés dans &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=96ef3b8ff1c&#34;&gt;PostgreSQL&#xA;9.3&lt;/a&gt;,&#xA;les &lt;a href=&#34;https://www.postgresql.org/docs/current/app-initdb.html#APP-INITDB-DATA-CHECKSUMS&#34;&gt;data&#xA;checksums&lt;/a&gt;&#xA;peuvent aider à détecter les corruptions de données survenant sur votre&#xA;stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Les checksums sont activés si l’instance a été initialisée en utilisant &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;initdb&#xA;--data-checksums&lt;/code&gt; (ce qui n’est pas le comportement par défaut), ou s’ils ont&#xA;été activés après en utilisant la nouvelle utilitaire&#xA;activated afterwards with the new&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/devel/app-pgchecksums.html&#34;&gt;pg_checksums&lt;/a&gt;&#xA;également &lt;a href=&#34;https://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=ed308d783790&#34;&gt;ajouté dans PostgreSQL&#xA;12&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Quand les checksums sont ativés, ceux-ci sont écrits à chaque fois qu’un bloc&#xA;de données est écrit sur disque, et vérifiés à chaque fois qu’un bloc est lu&#xA;depuis le disque (ou depuis le cache du système d’exploitation).  Si la&#xA;vérification échoue, une erreur est remontée dans les logs.  Si le bloc était&#xA;lu par un processus client, la requête associée échouera bien évidemment, mais&#xA;si le bloc était lu par une opération&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/protocol-replication.html#id-1.10.5.9.7.1.8.1.12&#34;&gt;BASE_BACKUP&lt;/a&gt;&#xA;(tel que pg_basebackup), la commande continuera à s’exécuter.  Bien que les&#xA;data checksums ne détecteront qu’un sous ensemble des problèmes possibles, ils&#xA;ont tout de même une certaine utilisé, surtout si vous ne faites pas confiance&#xA;à votre stockage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Jusqu’à PostgreSQL 11, les erreurs de validation de checksum ne pouvaient être&#xA;trouvées qu’en cherchant dans les logs, ce qui n’est clairement pas pratique si&#xA;vous voulez monitorer de telles erreurs.&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;nouveaux-compteurs-disponibles-dans-pg_stat_database&#34;&gt;Nouveaux compteurs disponibles dans pg_stat_database&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Pour rendre la supervision des erreurs de checksum plus simple, et pour aider&#xA;les utilisateurs à réagir dès qu’un tel problème survient, PostgreSQL 12 ajoute&#xA;de nouveaux compteurs dans la vue &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_database&lt;/code&gt; :&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit 6b9e875f7286d8535bff7955e5aa3602e188e436&#xA;Author: Magnus Hagander &amp;lt;magnus@hagander.net&amp;gt;&#xA;Date:   Sat Mar 9 10:45:17 2019 -0800&#xA;&#xA;Track block level checksum failures in pg_stat_database&#xA;&#xA;This adds a column that counts how many checksum failures have occurred&#xA;on files belonging to a specific database. Both checksum failures&#xA;during normal backend processing and those created when a base backup&#xA;detects a checksum failure are counted.&#xA;&#xA;Author: Magnus Hagander&#xA;Reviewed by: Julien Rouhaud&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit 77bd49adba4711b4497e7e39a5ec3a9812cbd52a&#xA;Author: Magnus Hagander &amp;lt;magnus@hagander.net&amp;gt;&#xA;Date:   Fri Apr 12 14:04:50 2019 +0200&#xA;&#xA;    Show shared object statistics in pg_stat_database&#xA;&#xA;    This adds a row to the pg_stat_database view with datoid 0 and datname&#xA;    NULL for those objects that are not in a database. This was added&#xA;    particularly for checksums, but we were already tracking more satistics&#xA;    for these objects, just not returning it.&#xA;&#xA;    Also add a checksum_last_failure column that holds the timestamptz of&#xA;    the last checksum failure that occurred in a database (or in a&#xA;    non-dataabase file), if any.&#xA;&#xA;    Author: Julien Rouhaud &amp;lt;rjuju123@gmail.com&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;language-plaintext highlighter-rouge&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;commit 252b707bc41cc9bf6c55c18d8cb302a6176b7e48&#xA;Author: Magnus Hagander &amp;lt;magnus@hagander.net&amp;gt;&#xA;Date:   Wed Apr 17 13:51:48 2019 +0200&#xA;&#xA;    Return NULL for checksum failures if checksums are not enabled&#xA;&#xA;    Returning 0 could falsely indicate that there is no problem. NULL&#xA;    correctly indicates that there is no information about potential&#xA;    problems.&#xA;&#xA;    Also return 0 as numbackends instead of NULL for shared objects (as no&#xA;    connection can be made to a shared object only).&#xA;&#xA;    Author: Julien Rouhaud &amp;lt;rjuju123@gmail.com&amp;gt;&#xA;    Reviewed-by: Robert Treat &amp;lt;rob@xzilla.net&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;Ces compteurs reflèteront les erreurs de validation de checksum à la fois pour&#xA;les processus clients et pour l’activité&#xA;&lt;a href=&#34;https://www.postgresql.org/docs/current/protocol-replication.html#id-1.10.5.9.7.1.8.1.12&#34;&gt;BASE_BACKUP&lt;/a&gt;,&#xA;par base de données.&lt;/p&gt;&#xA;&#xA;&lt;figure class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;n&#34;&gt;rjuju&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pg_stat_database&lt;/span&gt;&#xA;                        &lt;span class=&#34;k&#34;&gt;View&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;&#34;pg_catalog.pg_stat_database&#34;&lt;/span&gt;&#xA;        &lt;span class=&#34;k&#34;&gt;Column&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;k&#34;&gt;Type&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Collation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Nullable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Default&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;-----------------------+--------------------------+-----------+----------+---------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;datid&lt;/span&gt;                 &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oid&lt;/span&gt;                      &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;datname&lt;/span&gt;               &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;                     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;p&#34;&gt;[...]&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;checksum_failures&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;bigint&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;checksum_last_failure&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&#xA; &lt;span class=&#34;p&#34;&gt;[...]&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;stats_reset&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;zone&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;La colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;checksum_failures&lt;/code&gt; montrera un nombre cumulé d’erreurs, et la&#xA;colonne &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;checksum_last_failure&lt;/code&gt; montrera l’horodatage de la dernière erreur de&#xA;validation sur la base de données (NULL si aucune erreur n’est jamais&#xA;survenue).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pour éviter toute confusion (merci à Robert Treat pour l’avoir signalé), ces&#xA;deux colonnes retourneront toujours NULL si les data checkums ne sont pas&#xA;activés, afin qu’on ne puisse pas croire que les checksums sont toujours&#xA;vérifiés avec succès.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Comme effet de bord, &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_stat_database&lt;/code&gt;  montrera maintenant également les&#xA;statistiques disponibles pour les objets partagés (tels que la table&#xA;&lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;pg_database&lt;/code&gt; par exemple), dans une nouvelle ligne pour laquelle &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;datid&lt;/code&gt; vaut&#xA;&lt;strong&gt;0&lt;/strong&gt;, et &lt;code class=&#34;language-plaintext highlighter-rouge&#34;&gt;datname&lt;/code&gt; vaut &lt;strong&gt;NULL&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;del&gt;Une sonde dédiée est également &lt;a href=&#34;https://github.com/OPMDG/check_pgactivity/issues/226&#34;&gt;déjà&#xA;planifiée&lt;/a&gt; dans&#xA;&lt;a href=&#34;https://opm.readthedocs.io/probes/check_pgactivity.html&#34;&gt;check_pgactivity&lt;/a&gt; !&lt;/del&gt;&#xA;Une sonde dédiée est également &lt;a href=&#34;https://github.com/OPMDG/check_pgactivity/commit/0e8b516e95e4364470d4e205aebc9fe68bbcfd23&#34;&gt;déjà&#xA;disponible&lt;/a&gt;&#xA;dans &lt;a href=&#34;https://opm.readthedocs.io/probes/check_pgactivity.html&#34;&gt;check_pgactivity&lt;/a&gt; !&lt;/p&gt;&#xA;&#xA;    &lt;p&gt;&lt;a href=&#34;https://rjuju.github.io/postgresqlfr/2019/04/18/nouveau-dans-pg12-statistiques-erreurs-checksums.html&#34;&gt;Nouveauté pg12: Statistiques sur les erreurs de checkums&lt;/a&gt; was originally published by Julien Rouhaud at &lt;a href=&#34;https://rjuju.github.io&#34;&gt;rjuju&#39;s home&lt;/a&gt; on April 18, 2019.&lt;/p&gt;</content>
    <link href="https://rjuju.github.io/postgresqlfr/2019/04/18/nouveau-dans-pg12-statistiques-erreurs-checksums.html" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>Julien Rouhaud</name>
    </author>
  </entry>
  <entry>
    <title>Utiliser le dépôt Debian/Ubuntu de PostgreSQL.org</title>
    <updated>2013-04-03T06:05:00Z</updated>
    <id>tag:blog.kryskool.org,2013-04-03:/utiliser-le-depot-debian-ubuntu-de-postgresql-org-fr.html</id>
    <link href="http://blog.kryskool.org/utiliser-le-depot-debian-ubuntu-de-postgresql-org-fr.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Le projet PostgreSQL possède depuis peu son propre dépôt APT pour les différentes versions des serveurs encore maintenu et &lt;a class=&#34;reference external&#34; href=&#34;http://pgadmin.org/&#34;&gt;PgAdmin3&lt;/a&gt;, sur les versions de Debian et Ubuntu suivantes&lt;/p&gt;&#xA;&lt;ul class=&#34;simple&#34;&gt;&#xA;&lt;li&gt;Debian&lt;ul&gt;&#xA;&lt;li&gt;Etch&lt;/li&gt;&#xA;&lt;li&gt;Lenny&lt;/li&gt;&#xA;&lt;li&gt;Squeeze&lt;/li&gt;&#xA;&lt;li&gt;Wheezy&lt;/li&gt;&#xA;&lt;li&gt;Sid&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Ubuntu&lt;ul&gt;&#xA;&lt;li&gt;Precise (12.04)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Si vous utilisiez déjà le dépôt squeeze backports par exemple, vous pouvez basculer facilement vers ce nouveau dépôt sans problème&lt;/p&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;cle-de-signature-des-paquets&#34;&gt;&#xA;&lt;h2&gt;Clé de signature des paquets&lt;/h2&gt;&#xA;&lt;p&gt;Avant d&#39;installer une version de PostgreSQL, il faut ajouter la clé d&#39;authentification des paquets dans notre trousseau de clé.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;wget -O - http://apt.postgresql.org/pub/repos/apt/ACCC4CF8.asc | sudo apt-key add -&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;source-list&#34;&gt;&#xA;&lt;h2&gt;source.list&lt;/h2&gt;&#xA;&lt;p&gt;Il faut ensuite ajouter le dépôt au source.list, pour cela créer le fichier &lt;tt class=&#34;docutils literal&#34;&gt;/etc/apt/sources.list.d/pgdg.list&lt;/tt&gt;&#xA;et ajouter les lignes suivantes (l&#39;exemple ci-dessous est pour la version squeeze).&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;deb http://apt.postgresql.org/pub/repos/apt/ squeeze-pgdg main&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Remplacer &lt;tt class=&#34;docutils literal&#34;&gt;Squeeze&lt;/tt&gt; par le nom de votre distribution.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;preferences&#34;&gt;&#xA;&lt;h2&gt;Préférences&lt;/h2&gt;&#xA;&lt;p&gt;Pour indiquer à votre distribution de prendre et mettre à jour votre ou vos PostgreSQL à partir de cette source,&#xA;il faut rajouter une configuration dite de &lt;tt class=&#34;docutils literal&#34;&gt;pinning&lt;/tt&gt;&lt;/p&gt;&#xA;&lt;p&gt;Créer le fichier &lt;tt class=&#34;docutils literal&#34;&gt;/etc/apt/preferences.d/pgdg.pref&lt;/tt&gt; et ajouter les lignes suivantes&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;Package: *&#xA;Pin: release o=apt.postgresql.org&#xA;Pin-Priority: 500&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;initialisation&#34;&gt;&#xA;&lt;h2&gt;Initialisation&lt;/h2&gt;&#xA;&lt;p&gt;Une fois la configuration, il faut faire un &lt;tt class=&#34;docutils literal&#34;&gt;update&lt;/tt&gt; pour mettre a jour votre gestionnaire de paquet avec ce nouveau dépôt, et charger le trousseau de clé&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;apt-get update&#xA;apt-get install pgdg-keyring&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Ensuite il en reste plus qu&#39;a installer la version de PostgreSQL que vous souhaitez.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;apt-get install postgresql-9.2 postgresql-client-9.2 postgresql-contrib-9.2 postgresql-plpython-9.2 postgresql-server-dev-9.2 libpq-dev&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;/div&gt;</summary>
    <author>
      <name>Christophe Chauvet</name>
    </author>
  </entry>
  <entry>
    <title>Connaitre la taille d&#39;un base de données PostgreSQL</title>
    <updated>2011-12-12T11:30:00Z</updated>
    <id>tag:blog.kryskool.org,2011-12-12:/connaitre-taille-base-postgresql.html</id>
    <link href="http://blog.kryskool.org/connaitre-taille-base-postgresql.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Pour connaitre la taille d&#39;un base de données il faut utiliser la fonction &lt;a class=&#34;reference external&#34; href=&#34;http://docs.postgresql.fr/9.1/functions-admin.html&#34;&gt;pg_database_size&lt;/a&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;production=# select pg_database_size(&amp;#39;production&amp;#39;);&#xA; pg_database_size&#xA;------------------&#xA;        513343780&#xA;(1 ligne)&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Cette taille est donnée en octets, pour avoir une meilleur représentation en Méga ou Giga, il faut utiliser la fonction &lt;a class=&#34;reference external&#34; href=&#34;http://docs.postgresql.fr/9.1/functions-admin.html&#34;&gt;pg_size_pretty&lt;/a&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;production=# select pg_size_pretty(pg_database_size(&amp;#39;production&amp;#39;));&#xA; pg_size_pretty&#xA;----------------&#xA; 490 MB&#xA;(1 ligne)&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Ensuite si l&#39;on souhaite connaître la taille d&#39;un table il faut utiliser la fonction &lt;a class=&#34;reference external&#34; href=&#34;http://docs.postgresql.fr/9.1/functions-admin.html&#34;&gt;pg_relation_size&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;production=# select pg_size_pretty(pg_relation_size(&amp;#39;res_partner&amp;#39;));&#xA; pg_size_pretty&#xA;----------------&#xA; 152 kB&#xA;(1 ligne)&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Si l&#39;on souhaite également avoir la place prise par les indexes, il faut utiliser la fonction &lt;a class=&#34;reference external&#34; href=&#34;http://docs.postgresql.fr/9.1/functions-admin.html&#34;&gt;pg_total_relation_size&lt;/a&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;production=# select pg_size_pretty(pg_total_relation_size(&amp;#39;res_partner&amp;#39;));&#xA; pg_size_pretty&#xA;----------------&#xA; 528 kB&#xA;(1 ligne)&#xA;&lt;/pre&gt;&lt;/div&gt;</summary>
    <author>
      <name>Christophe Chauvet</name>
    </author>
  </entry>
  <entry>
    <title>Installation TinyERP 4.2 avec PostgreSQL 8.3</title>
    <updated>2008-05-25T09:33:00Z</updated>
    <id>tag:blog.kryskool.org,2008-05-25:/Installation-TinyERP-42-avec-PostgreSQL-83-fr.html</id>
    <link href="http://blog.kryskool.org/Installation-TinyERP-42-avec-PostgreSQL-83-fr.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Depuis la version 8.3, certain CAST ne sont plus implicites, notamment ceux qui peuvent ramener des résultats inattendus.&#xA;Dans la version de TinyERP 4.2 (4.2.2 actuellement) certaines requêtes avec des CAST implicites sur les dates étaient utilisés,&#xA;ceux qui avec PostgreSQL 8.3 ramène un message d&#39;erreur à l&#39;utilisation de cette requête. La question que l&#39;on se pose:&lt;/p&gt;&#xA;&lt;ul class=&#34;simple&#34;&gt;&#xA;&lt;li&gt;Doit on utiliser PostgreSQL 8.3 avec TinyERP 4.2.2 ?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;La réponse est non, simplement que le version 4.2 de TinyERP est la version stable, il ne faut surtout pas toucher au code.&#xA;Le Trunk du SVN fonctionne déjà avec la version 8.3, ainsi la prochaine version de OpenERP fonctionnera avec PostgreSQL 8.3.&lt;/p&gt;&#xA;&lt;ul class=&#34;simple&#34;&gt;&#xA;&lt;li&gt;Quelle version de PostgreSQL puis je utiliser ?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Avec TinyERP 4.2 il est possible d&#39;utiliser PostgreSQL 7.4, 8.0, 8.1 et 8.2 sauf sous Windows ou les versions 8.0 et 8.1 ne sont plus maintenus. Sous Windows seule la version 8.2 est supporté.&lt;/p&gt;&#xA;&lt;p&gt;08/09/2008 : Ceci n&#39;est plus tout a fait vrai, voir ce &lt;a class=&#34;reference external&#34; href=&#34;Premier-patch-pour-TinyERP/OpenERP&#34;&gt;billet&lt;/a&gt; pour les explications&lt;/p&gt;</summary>
    <author>
      <name>Christophe Chauvet</name>
    </author>
  </entry>
  <entry>
    <title>Réinstallation PostgreSQL sous Windows XP</title>
    <updated>2008-03-31T14:00:00Z</updated>
    <id>tag:blog.kryskool.org,2008-03-31:/Reinstallation-PostgreSQL-sous-Windows-XP-fr.html</id>
    <link href="http://blog.kryskool.org/Reinstallation-PostgreSQL-sous-Windows-XP-fr.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Ce message d&#39;erreur vous indique que l&#39;utilisateur système Windows existe déjà, et donc par conséquent que sa création à échoué,&#xA;si vous aviez mémorisé le mot de passe attribuer à ce compte, il vous suffit de le saisir, sinon il va falloir supprimer l&#39;utilisateur avec la commande ci-dessous&#xA;a lancer dans une fenêtre CMD avec les droits administrateurs.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;net user postgres &lt;span class=&#34;n&#34;&gt;/DELETE&lt;/span&gt;&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Ensuite il vous suffit de relancer l&#39;installation, qui recréera le nouveau compte &lt;strong&gt;postgres&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Si vous avez également réinstallé &lt;strong&gt;PostgreSQL&lt;/strong&gt;, lors de la précédente désinstallation, le répertoire de données&#xA;se trouvant dans &amp;quot;Program FilesPostgreSQL8.x&amp;quot; (ou X est le numéro de version mineure) n&#39;est pas supprimé,&#xA;ce qui fait également échouer l&#39;installation lors de la création du &lt;em&gt;CLUSTER&lt;/em&gt;.&lt;/p&gt;</summary>
    <author>
      <name>Christophe Chauvet</name>
    </author>
  </entry>
  <entry>
    <title>Base de données de test utilisée pour les articles du site</title>
    <updated>2008-03-12T11:30:00Z</updated>
    <id>tag:blog.kryskool.org,2008-03-12:/Base-de-donnees-de-test-utilises-pour-les-articles-du-site-fr.html</id>
    <link href="http://blog.kryskool.org/Base-de-donnees-de-test-utilises-pour-les-articles-du-site-fr.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;La base de test utilisée, se nomme Pagila. Elle fait partie du projet &lt;em&gt;DbSample&lt;/em&gt; sur &lt;em&gt;pgFoundry.org&lt;/em&gt;&#xA;vous pouvez la télécharger directement &lt;a class=&#34;reference external&#34; href=&#34;http://pgfoundry.org/frs/download.php/1556/pagila-0.10.0.zip&#34;&gt;ici&lt;/a&gt;.&#xA;La version 0.10 supporte la version 8.3 de PostgreSQL qui intègre nativement Tsearch2 (la recherche FullText native),&#xA;les versions antérieurs de pagila nécessitait d&#39;avoir tsearch2 d&#39;activer ce qui n&#39;était pas possible de faire sous Windows sans compilation.&lt;/p&gt;&#xA;&lt;p&gt;L&#39;installation de la base pagila se fera en ligne de commande.&#xA;Les utilisateurs de windows se réfèrerons a cet &lt;a class=&#34;reference external&#34; href=&#34;/Utilisation-de-psql-sous-Windows&#34;&gt;article&lt;/a&gt; pour utiliser correctement la méthode en ligne de commande,&#xA;les utilisateurs sous Linux utiliserons l&#39;utilisateur système &lt;em&gt;postgres&lt;/em&gt; directement.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;%PSQL%&lt;span class=&#34;se&#34;&gt;\c&lt;/span&gt;reatedb -U postgres -E UTF8 -e pagila&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Lorsque vous allez valider cette commande, le mot de passe de l&#39;utilisateur &lt;em&gt;postgres&lt;/em&gt; vous sera demandé, et la base &lt;em&gt;pagila&lt;/em&gt; sera crée avec un encodage en UTF8.&#xA;La base de données est crée, nous allons pouvoir importer les données.&lt;/p&gt;&#xA;&lt;p&gt;Positionnez vous dans le répertoire ou vous avez décompressez l&#39;archive de &lt;em&gt;Pagila&lt;/em&gt;, puis toujours en ligne de commande exécuter la commande suivante :&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;%PSQL%&lt;span class=&#34;se&#34;&gt;\p&lt;/span&gt;sql -U postgres -d pagila -f pagila-schema.sql&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;une fois la touche entrée validé, le mot de passe de l&#39;utilisateur &lt;em&gt;postgres&lt;/em&gt; peut vous être demander, et ensuite vous verrez apparaître le retour de chaque commande,&#xA;vérifier qu&#39;aucun message d&#39;erreur n&#39;apparaît. a cet instant le schéma devant accueillir les données a été inséré dans la base &lt;em&gt;pagila&lt;/em&gt; crée précédemment.&lt;/p&gt;&#xA;&lt;p&gt;Nous allons maintenant y inséré les données à l&#39;aide de cette commande.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;%PSQL%&lt;span class=&#34;se&#34;&gt;\p&lt;/span&gt;sql -U postgres -d pagila -f pagila-data.sql&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Si pas de message d&#39;erreur, notre base de test est prête, nous allons faire une petite requête de vérification dans &lt;em&gt;psql&lt;/em&gt;. une fois connecté, exécuter la requête suivante&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;&lt;span class=&#34;n&#34;&gt;pagila&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=#&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;film&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;film_id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;      &lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;                                           &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt;&#xA;&lt;span class=&#34;c1&#34;&gt;------------------+--------------------------------------------------------------------------------------------------&lt;/span&gt;&#xA; &lt;span class=&#34;n&#34;&gt;ACADEMY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DINOSAUR&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Epic&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Drama&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Feminist&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;And&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mad&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Scientist&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;who&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;must&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Battle&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Teacher&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Canadian&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Rockies&lt;/span&gt;&#xA;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&#xA;&lt;span class=&#34;n&#34;&gt;pagila&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=#&lt;/span&gt;&#xA;&lt;/pre&gt;&lt;/div&gt;</summary>
    <author>
      <name>Christophe Chauvet</name>
    </author>
  </entry>
  <entry>
    <title>Installation de PostgreSQL 8.3 sous Windows XP</title>
    <updated>2008-02-26T13:02:00Z</updated>
    <id>tag:blog.kryskool.org,2008-02-26:/Installation-de-PostgreSQL-83-sous-Windows-XP-fr.html</id>
    <link href="http://blog.kryskool.org/Installation-de-PostgreSQL-83-sous-Windows-XP-fr.html" rel="alternate"></link>
    <summary type="html">&lt;div class=&#34;section&#34; id=&#34;telechargement&#34;&gt;&#xA;&lt;h2&gt;Téléchargement&lt;/h2&gt;&#xA;&lt;p&gt;Avant l&#39;installation de PostgreSQL 8.3, nous devons au préalable le récupérer, pour cela nous allons le télécharger sur l&#39;un des &lt;a class=&#34;reference external&#34; href=&#34;http://wwwmaster.postgresql.org/download/mirrors-ftp?file=%2Fbinary%2Fv8.3.0%2Fwin32%2Fpostgresql-8.3.0-1.zip&#34;&gt;miroirs&lt;/a&gt; disponibles.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;lancement&#34;&gt;&#xA;&lt;h2&gt;Lancement&lt;/h2&gt;&#xA;&lt;p&gt;Un fois le téléchargement terminé, vous obtenez un fichier nommé postgresql-8.3.0-1.zip dans votre répertoire de destination. Décompresser le et vous obtiendrez la liste de fichier ci-dessous.&lt;/p&gt;&#xA;&lt;img alt=&#34;Listes_fichiers&#34; src=&#34;images/InstPg83/liste_fichier.jpg&#34; /&gt;&#xA;&lt;p&gt;Puisqu&#39;il s&#39;agit de la première version stable de la version 8.3, il est pas conseiller d&#39;exécuter une mise à jour avec upgrade.bat, à partir des versions RC ou Beta.&#xA;Le script upgrade.bat ne peut en aucun cas servir à mettre à jour une 8.2 vers une 8.3. Il servira uniquement à la mise à jour de votre 8.3 lorsque de nouvelle versions correctives sortiront.&lt;/p&gt;&#xA;&lt;div class=&#34;note&#34;&gt;&#xA;&lt;p class=&#34;first admonition-title&#34;&gt;Note&lt;/p&gt;&#xA;&lt;p class=&#34;last&#34;&gt;Afin d&#39;eviter le plantage lors du démarrage du service PostgreSQL une fois installé, il convient de vérifier que le service windows &lt;strong&gt;Connexion secondaire&lt;/strong&gt; est démarré.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Pour commencer l&#39;installation de PostgreSQL 8.3, exécuter indifféremment &lt;strong&gt;SETUP.bat&lt;/strong&gt; ou &lt;strong&gt;postgresql-8.3.msi&lt;/strong&gt; (si votre environnement Windows est correctement installé,&#xA;le fichier msi devrait déclencher l&#39;installation.). Un fois lancer vous obtiendrez l&#39;écran suivant.&lt;/p&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;ecran-d-accueil&#34;&gt;&#xA;&lt;h3&gt;Ecran d&#39;accueil&lt;/h3&gt;&#xA;&lt;img alt=&#34;Choix_Langue&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--14-56-00.jpg&#34; /&gt;&#xA;&lt;p&gt;Ce premier écran va nous permettre de sélectionner la langue utiliser pour le reste de l&#39;installation, nous allons bien évidement choisir « French / Français ». Nous allons également cocher la case « &#39;&#39;Write detailed installation log to postgresql-8.3.log in the current directory&#39;&#39; », ceci enregistrera des informations utiles pour un éventuel dépannage, si l&#39;installation ne se déroulait pas correctement.&lt;/p&gt;&#xA;&lt;p&gt;Pour poursuivre l&#39;installation appuyer sur le bouton « Start ».&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;ecran-bienvenue-en-francais&#34;&gt;&#xA;&lt;h3&gt;Ecran bienvenue en Français&lt;/h3&gt;&#xA;&lt;img alt=&#34;Ecran debut install&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--14-56-40.jpg&#34; /&gt;&#xA;&lt;p&gt;Sur cette écran, rien de bien compliquer, il suffit de suivre les instructions, et de cliquer sur « Suivant »&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;license&#34;&gt;&#xA;&lt;h3&gt;License&lt;/h3&gt;&#xA;&lt;img alt=&#34;Licence&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--14-56-50.jpg&#34; /&gt;&#xA;&lt;p&gt;Cette écran détaille toutes les licenses inclus dans cette installation&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;option-d-installation&#34;&gt;&#xA;&lt;h3&gt;Option d&#39;installation&lt;/h3&gt;&#xA;&lt;img alt=&#34;Choix des options&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--14-57-23.jpg&#34; /&gt;&#xA;&lt;p&gt;Les options par défaut sont suffisantes, pour avoir la gestion de la langue, activé également &lt;strong&gt;Support de la langue&lt;/strong&gt;.&#xA;les messages d&#39;erreurs apparaîtrons également traduit, il sera possible au niveau de la session de les obtenir en Anglais,&#xA;ce qui vous permettra d&#39;avoir plus de resultat lors de la recherche de message d&#39;erreur similaire dans votre moteur de recherche favori.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;configuration-du-service&#34;&gt;&#xA;&lt;h3&gt;Configuration du service&lt;/h3&gt;&#xA;&lt;img alt=&#34;Configuration du service&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--14-58-05.jpg&#34; /&gt;&#xA;&lt;p&gt;PostgreSQL sous Windows est vu comme un service, celui a besoin d&#39;avoir un compte utilisateur avec le minimum de droit,&#xA;par defaut l&#39;utilisateur crée se nomme &lt;strong&gt;postgres&lt;/strong&gt;,&#xA;il convient de mémoriser son mot de passe, qui vous permettra par la suite de faire cohabiter plusieurs versions de &lt;strong&gt;PostgreSQL&lt;/strong&gt;,&#xA;en utilisant le même utilisateur système pour démarrer les différents services.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;initialisation-du-cluster&#34;&gt;&#xA;&lt;h3&gt;Initialisation du cluster&lt;/h3&gt;&#xA;&lt;img alt=&#34;Initialisation du cluster&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--14-58-46.jpg&#34; /&gt;&#xA;&lt;p&gt;&lt;strong&gt;psql&lt;/strong&gt; dans une console Windows a besoin d&#39;un encodage WIN1252. dans cette configuration coté serveur faut absolument choisir l&#39;encodage UTF8.&#xA;Par défaut un utilisateur &lt;strong&gt;postgres&lt;/strong&gt; est crée dans la base de données, il s&#39;agit du super utilisateur qui possèdent les pleins droits sur le cluster de base de données.&#xA;Pour cette raison il faut bien mémoriser le mot de passe que vous lui attribuer, car celui ci servira à établir la première connexion à la base de données,&#xA;en vue du crée votre première base, mais également un utilisateur lambda.&#xA;Il est bien sur fortement conseiller de mettre un mot de passe différents de celui qui a servit à créer l&#39;utilisateur local de la machine.&lt;/p&gt;&#xA;&lt;img alt=&#34;Connexions distantes&#34; src=&#34;images/InstPg83/Connexions%20distantes--2008-02-12--14-59-07.jpg&#34; /&gt;&#xA;&lt;p&gt;Ce message vous indique que vous avez activé la connexion TCP/IP et que votre serveur PostgreSQL est accessible à travers toutes les machines du réseau, pour en restreindre l&#39;usage, consulter cette &lt;a class=&#34;reference external&#34; href=&#34;http://docs.postgresqlfr.org/8.3/client-authentication.html#auth-pg-hba-conf&#34;&gt;partie&lt;/a&gt; de la documentation.&lt;/p&gt;&#xA;&lt;ul class=&#34;simple&#34;&gt;&#xA;&lt;li&gt;Dans cette configuration il convient de choisir un mot de passe pour le super-utilisateur &lt;strong&gt;postgres&lt;/strong&gt; qui ne soit pas identique au login.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;langages-proceduraux&#34;&gt;&#xA;&lt;h3&gt;Langages procéduraux&lt;/h3&gt;&#xA;&lt;img alt=&#34;Langages procéduraux&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--14-59-17.jpg&#34; /&gt;&#xA;&lt;p&gt;Les langages proceduraux (PL) peuvent être installer séparément, pendant l&#39;installation ou ultérieurement. Par défaut PL/pgSQL est activé,&#xA;cela signifie qu&#39;il sera installé dans la base &lt;strong&gt;template1&lt;/strong&gt; qui est utilisé comme modèle lors de la création d&#39;une nouvelle base de données.&#xA;L&#39;activation des case a coché pour les autres langages dépend si le module d&#39;installation a détecté la présence des interpreteurs pour les différents langages.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;choix-des-contrib&#34;&gt;&#xA;&lt;h3&gt;Choix des contrib&lt;/h3&gt;&#xA;&lt;img alt=&#34;Choix des contribs&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--15-00-08.jpg&#34; /&gt;&#xA;&lt;p&gt;Par défaut 2 contributions sont installés&lt;/p&gt;&#xA;&lt;ul class=&#34;simple&#34;&gt;&#xA;&lt;li&gt;Adminpack&lt;/li&gt;&#xA;&lt;li&gt;Debugger&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Si vous cochez d&#39;autres contributions, celles-ci seront installés et activés par défaut, sinon elle seront juste installés dans le répertoire de contrib et&#xA;leur activation se fera au travers de leurs scripts d&#39;installation respectif (dans ce même répertoire se trouve également les scripts de désinstallations)&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;progression-de-l-installation&#34;&gt;&#xA;&lt;h3&gt;Progression de l&#39;installation&lt;/h3&gt;&#xA;&lt;img alt=&#34;Debut installation&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--15-00-20.jpg&#34; /&gt;&#xA;&lt;p&gt;L&#39;installation ne devrait pas poser de soucis, sinon vous obtiendrez un message d&#39;erreur explique, mais également une trace dans le fichier de log.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;fin-d-installation&#34;&gt;&#xA;&lt;h3&gt;Fin d&#39;installation&lt;/h3&gt;&#xA;&lt;img alt=&#34;Ecran final&#34; src=&#34;images/InstPg83/PostgreSQL--2008-02-12--15-01-07.jpg&#34; /&gt;&#xA;&lt;p&gt;Voila &lt;strong&gt;PostgreSQL&lt;/strong&gt; est fraichement installé sur votre environnement. sur ce dernier écran il vous est conseillé de vous inscrire à la liste &lt;strong&gt;psql-announce&lt;/strong&gt;&#xA;pour être informer des nouvelles mises à jour mais également des bugs ou correction de bug.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;premiere-connexion&#34;&gt;&#xA;&lt;h2&gt;Première connexion&lt;/h2&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;avec-psql&#34;&gt;&#xA;&lt;h3&gt;Avec psql&lt;/h3&gt;&#xA;&lt;p&gt;Pour la première connexion avec psql, faite &lt;strong&gt;Demarrer / Executer&lt;/strong&gt; puis saisissez &lt;strong&gt;cmd&lt;/strong&gt;. Lorsque la console est ouverte saisissez les lignes ci-dessous.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;chcp 1252&#xA;set PSQL=&amp;quot;c:\Program Files\PostgreSQL\8.3\bin&amp;quot;&#xA;%PSQL%\psql -U postgres&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;vous devriez obtenir l&#39;écran ci-dessous, après avoir saisie le mot de passe de l&#39;utilisateur &lt;strong&gt;postgres&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre&gt;Password for user postgres:&#xA;Welcome to psql 8.3.0, the PostgreSQL interactive terminal.&#xA;&#xA;Type:  \copyright for distribution terms&#xA;       \h for help with SQL commands&#xA;       \? for help with psql commands&#xA;       \g or terminate with semicolon to execute query&#xA;       \q to quit&#xA;&#xA;postgres=#&#xA;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;section&#34; id=&#34;avec-pgadmin-iii&#34;&gt;&#xA;&lt;h3&gt;Avec pgAdmin III&lt;/h3&gt;&#xA;&lt;p&gt;Pour lancer pgAdmin3, aller sur &lt;strong&gt;Demarrer / Programmes / PostgreSQL 8.3 / pgAdmin3&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;img alt=&#34;pgAdmin3 Connexion&#34; src=&#34;images/InstPg83/pgAdmin_III--2008-03-01--20-58-50.jpg&#34; /&gt;&#xA;&lt;p&gt;Choisissez le serveur sur lequel vous souhaitez vous connecter, pour l&#39;instant 1 seul est déclaré et faites un clic droit, puis &lt;strong&gt;Se connecter&lt;/strong&gt;,&#xA;vous pouvez maintenant naviguer dans l&#39;arborescence, et commencer par créer un Utilisateur puis une base de données.&lt;/p&gt;&#xA;&lt;img alt=&#34;pgAdmin3 Arborescence&#34; src=&#34;images/InstPg83/pgAdmin_III--2008-03-01--21-23-40.jpg&#34; /&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;</summary>
    <author>
      <name>Christophe Chauvet</name>
    </author>
  </entry>
</feed>